services:
  # Loki for log aggregation
  loki:
    image: grafana/loki:3.5.7
    ports:
      - "3100:3100"
    volumes:
      - ./infra/docker/loki-config.yaml:/etc/loki/local-config.yaml
    command: -config.file=/etc/loki/local-config.yaml
    restart: unless-stopped
    networks:
      - rage

  # Tempo for distributed tracing
  tempo:
    image: grafana/tempo:2.9.0
    command: ["-config.file=/etc/tempo.yaml"]
    user: "root"
    volumes:
      - ./infra/docker/tempo-config.yaml:/etc/tempo.yaml:ro
      - tempo_data:/tmp/tempo
    ports:
      - "3200:3200" # tempo HTTP
      - "4317" # otlp grpc (internal only)
    restart: unless-stopped
    networks:
      - rage

  # Prometheus for metrics
  prometheus:
    image: prom/prometheus:v3.6.0
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--web.console.libraries=/etc/prometheus/console_libraries"
      - "--web.console.templates=/etc/prometheus/consoles"
      - "--enable-feature=exemplar-storage"
    volumes:
      - ./infra/docker/prometheus-config.yaml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"
    restart: unless-stopped
    networks:
      - rage

  # Grafana for visualization (LGTM stack)
  grafana:
    image: grafana/grafana:11.6.0
    environment:
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_BASIC_ENABLED=false
    ports:
      - "3000:3000"
    depends_on:
      - loki
      - tempo
      - prometheus
    restart: unless-stopped
    entrypoint:
      - sh
      - -euc
      - |
        mkdir -p /etc/grafana/provisioning/datasources
        cat <<EOF > /etc/grafana/provisioning/datasources/ds.yaml
        apiVersion: 1
        datasources:
        - name: Loki
          type: loki
          access: proxy
          orgId: 1
          url: http://loki:3100
          basicAuth: false
          isDefault: false
          version: 1
          editable: false
        - name: Tempo
          type: tempo
          access: proxy
          orgId: 1
          url: http://tempo:3200
          basicAuth: false
          isDefault: false
          version: 1
          editable: false
          jsonData:
            tracesToLogsV2:
              datasourceUid: 'loki'
              spanStartTimeShift: '-1h'
              spanEndTimeShift: '1h'
              filterByTraceID: true
              filterBySpanID: false
            tracesToMetrics:
              datasourceUid: 'prometheus'
            serviceMap:
              datasourceUid: 'prometheus'
        - name: Prometheus
          type: prometheus
          access: proxy
          orgId: 1
          url: http://prometheus:9090
          basicAuth: false
          isDefault: true
          version: 1
          editable: false
          jsonData:
            exemplarTraceIdDestinations:
              - name: trace_id
                datasourceUid: tempo
        EOF
        /run.sh
    networks:
      - rage

  # OpenTelemetry Collector for telemetry pipeline
  otel-collector:
    image: otel/opentelemetry-collector-contrib:0.137.0
    ports:
      - "4317:4317" # OTLP gRPC receiver
      - "4318:4318" # OTLP HTTP receiver
    depends_on:
      - loki
      - tempo
      - prometheus
    restart: unless-stopped
    volumes:
      - ./infra/docker/otel-config.yaml:/etc/otelcol-contrib/config.yaml:ro
    environment:
      - OTEL_LOG_LEVEL=info
    networks:
      - rage

  # Redis for session management
  redis:
    image: redis:8.2.2-alpine
    ports:
      - "6379:6379"
    restart: unless-stopped
    volumes:
      - redis_data:/data
      - ./infra/docker/redis.conf:/usr/local/etc/redis/redis.conf:ro
    command: redis-server /usr/local/etc/redis/redis.conf
    environment:
      - REDIS_REPLICATION_MODE=master
    mem_limit: 512m
    mem_reservation: 256m
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    sysctls:
      net.core.somaxconn: 1024
    networks:
      - rage

  # AI Agent Service
  agent-service:
    build:
      context: ./src/agent
      dockerfile: Dockerfile
    ports:
      - "8001:8001"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL:-}
      - OPENAI_CHAT_MODEL_ID=${OPENAI_CHAT_MODEL_ID:-gpt-oss:20b}
      - OTLP_ENDPOINT=http://otel-collector:4317
      - ENABLE_OTEL=true
      - ENABLE_SENSITIVE_DATA=true
      - RAG_INDEX_NAME=${RAG_INDEX_NAME:-}
      - REDIS_URL=redis://redis:6379
      - CORS_ORIGINS=http://localhost:3000,http://localhost:3001
    extra_hosts:
      - "host.docker.internal:host-gateway"
    depends_on:
      redis:
        condition: service_healthy
      otel-collector:
        condition: service_started
    restart: unless-stopped
    healthcheck:
      test:
        [
          "CMD",
          "python",
          "-c",
          "import urllib.request; urllib.request.urlopen('http://localhost:8001/health').read()",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - rage

  # Frontend Service
  web:
    build:
      context: ./src/web
      dockerfile: Dockerfile
    ports:
      - "3001:3000"
    environment:
      - NODE_ENV=production
      - AGENT_SERVICE_URL=${AGENT_SERVICE_URL:-http://agent-service:8001}
    depends_on:
      agent-service:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test:
        [
          "CMD",
          "node",
          "-e",
          "require('http').get('http://localhost:3000', (res) => { process.exit(res.statusCode === 200 ? 0 : 1); }).on('error', () => { process.exit(1); });",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - rage

volumes:
  redis_data:
    driver: local
  tempo_data:
    driver: local
  prometheus_data:
    driver: local

networks:
  rage:
    driver: bridge
