{
  "index_name": "schedule_index",
  "documents": [
    {
      "text": "Speakers: Jonathan Bryce Executive Director from Cloud and Infrastructure, Chris Aniszczyk CTO, Cloud and Infrastructure from Linux Foundation. Location: Building B | Level 1 | Exhibit Hall B2. Categories: KEYNOTE SESSIONS.",
      "metadata": {
        "title": "Keynote: Welcome + Opening Remarks",
        "description": "",
        "url": "http://kccncna2025.sched.com/event/1bfbeece449c3d2d66241beca3ca07d4",
        "uid": "1bfbeece449c3d2d66241beca3ca07d4",
        "start": "2025-11-11T09:00:00-05:00",
        "end": "2025-11-11T09:25:00-05:00",
        "categories": [
          "KEYNOTE SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B2"
        },
        "speakers": [
          {
            "name": "Jonathan Bryce",
            "title": "Executive Director",
            "company": "Cloud and Infrastructure"
          },
          {
            "name": "Chris Aniszczyk",
            "title": "CTO, Cloud and Infrastructure",
            "company": "Linux Foundation"
          }
        ]
      }
    },
    {
      "text": "Your Kubernetes cluster seems bulletproof: network policies, mTLS, no external API access, GitOps workflows, and automated CI/CD. But you're still vulnerable.\n\nThis talk follows a real-world attack where a hacker bypasses traditional defenses through supply chain exploits: poisoned commits, tainted build tools, malicious images, and backdoored dependencies. A diligent DevOps engineer struggles to keep up.\n\nBut this isnt just a tale of doom. Each attack vector is met with a practical counter using OpenSSF projects: Sigstore for image signing. SLSA attestations for build security, OpenVEX/SBOM for dependency protection, gittuf for source control\n\nThis session highlights how hardening the supply chain transforms into defense-in-depth without burdening the developer.\n\nTakeaways include:\n-How supply chain attacks bypass secure K8s setups\n-Actionable implementation and enforcement of OpenSSF tooling, coordinated through the OSPS Baseline\n-Practical CI/CD and GitOps integrity improvements Speakers: Stacey Potter from OpenSSF, Adolfo Garcia Veytia from Carabiner Systems. Location: Building B | Level 1 | Exhibit Hall B2. Categories: KEYNOTE SESSIONS.",
      "metadata": {
        "title": "Keynote: Supply Chain Reaction: A Cautionary Tale in K8s Security",
        "description": "Your Kubernetes cluster seems bulletproof: network policies, mTLS, no external API access, GitOps workflows, and automated CI/CD. But you're still vulnerable.\n\nThis talk follows a real-world attack where a hacker bypasses traditional defenses through supply chain exploits: poisoned commits, tainted build tools, malicious images, and backdoored dependencies. A diligent DevOps engineer struggles to keep up.\n\nBut this isnt just a tale of doom. Each attack vector is met with a practical counter using OpenSSF projects: Sigstore for image signing. SLSA attestations for build security, OpenVEX/SBOM for dependency protection, gittuf for source control\n\nThis session highlights how hardening the supply chain transforms into defense-in-depth without burdening the developer.\n\nTakeaways include:\n-How supply chain attacks bypass secure K8s setups\n-Actionable implementation and enforcement of OpenSSF tooling, coordinated through the OSPS Baseline\n-Practical CI/CD and GitOps integrity improvements",
        "url": "http://kccncna2025.sched.com/event/ae4739551c5145f05f03eeccbc670725",
        "uid": "ae4739551c5145f05f03eeccbc670725",
        "start": "2025-11-11T09:27:00-05:00",
        "end": "2025-11-11T09:42:00-05:00",
        "categories": [
          "KEYNOTE SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B2"
        },
        "speakers": [
          {
            "name": "Stacey Potter",
            "company": "OpenSSF"
          },
          {
            "name": "Adolfo Garcia Veytia",
            "company": "Carabiner Systems"
          }
        ]
      }
    },
    {
      "text": "Kubernetes is the leading foundation for cloud-native platforms, but when it comes to agentic workloads, critical gaps remain that prevent many organizations from getting agents to production. These gaps exist because agents and tools are not just containers; they introduce new requirements such as dynamic identity for agents acting on behalf of users, end-to-end observability for probabilistic workflows, and context-aware networking for MCP and A2A protocols. Bridging this gap requires Kubernetes itself to be extended to become a context-aware runtime. Just as platform engineering abstracts complexity for developers, context engineering extends Kubernetes to make AI and agentic workloads first-class citizens. This talk will focus on the key use cases, requirements, and solutions we see in the agentgateway and kagent communities that platform teams must navigate when bringing agents to production. Speakers: Idit Levine from Founder, CEO from Solo.io, Keith Babo Chief Product Officer from Solo.io. Location: Building B | Level 1 | Exhibit Hall B2. Categories: KEYNOTE SESSIONS.",
      "metadata": {
        "title": "Sponsored Keynote: From Cloud-Native to Agent-Native: Context Engineering for Kubernetes",
        "description": "Kubernetes is the leading foundation for cloud-native platforms, but when it comes to agentic workloads, critical gaps remain that prevent many organizations from getting agents to production. These gaps exist because agents and tools are not just containers; they introduce new requirements such as dynamic identity for agents acting on behalf of users, end-to-end observability for probabilistic workflows, and context-aware networking for MCP and A2A protocols. Bridging this gap requires Kubernetes itself to be extended to become a context-aware runtime. Just as platform engineering abstracts complexity for developers, context engineering extends Kubernetes to make AI and agentic workloads first-class citizens. This talk will focus on the key use cases, requirements, and solutions we see in the agentgateway and kagent communities that platform teams must navigate when bringing agents to production.",
        "url": "http://kccncna2025.sched.com/event/77c342393dd33ef644affa684e1df005",
        "uid": "77c342393dd33ef644affa684e1df005",
        "start": "2025-11-11T09:44:00-05:00",
        "end": "2025-11-11T09:49:00-05:00",
        "categories": [
          "KEYNOTE SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B2"
        },
        "speakers": [
          {
            "name": "Idit Levine",
            "company": "Founder"
          },
          {
            "name": "CEO",
            "company": "Solo.io"
          },
          {
            "name": "Keith Babo",
            "title": "Chief Product Officer",
            "company": "Solo.io"
          }
        ]
      }
    },
    {
      "text": "Pokemon Go continues to engage millions of players worldwide with its location-based gameplay. Behind the scenes, this presents a unique ML challenge: how to optimize real-world player experiences using massive volumes of geo-temporal data?\n\nIn 2024, a team of ML practitioners at Niantic started tackling this by optimizing Raid Battle spawnsacross dimensions of location, time, and difficultyat a global scale spanning millions of S2 cells. The complexity of this problem goes beyond pure modeling: it also demands high standards for player satisfaction, scalability, and privacy protection.\n\nThis talk shares how the team designed a geo-aware recommender system and operationalized it in a cloud-native environment. Attendees will learn:\n\n- Modeling recommendations across spatial, temporal, and difficulty axes\n- Geo-temporal feature engineering at scale\n- Building and scaling recommender systems using Kubernetes and Kubeflow\n- MLOps lessons from one of the most popular location-based games Speakers: Yunpeng Liu from  Niantic (Scopely), Andy Zhang from  Niantic (Scopely). Location: Building B | Level 1 | Exhibit Hall B2. Categories: KEYNOTE SESSIONS.",
      "metadata": {
        "title": "Keynote: Scaling Geo-Temporal ML: How Pokemon Go Optimizes Global Gameplay With Kubernetes and Kubeflow",
        "description": "Pokemon Go continues to engage millions of players worldwide with its location-based gameplay. Behind the scenes, this presents a unique ML challenge: how to optimize real-world player experiences using massive volumes of geo-temporal data?\n\nIn 2024, a team of ML practitioners at Niantic started tackling this by optimizing Raid Battle spawnsacross dimensions of location, time, and difficultyat a global scale spanning millions of S2 cells. The complexity of this problem goes beyond pure modeling: it also demands high standards for player satisfaction, scalability, and privacy protection.\n\nThis talk shares how the team designed a geo-aware recommender system and operationalized it in a cloud-native environment. Attendees will learn:\n\n- Modeling recommendations across spatial, temporal, and difficulty axes\n- Geo-temporal feature engineering at scale\n- Building and scaling recommender systems using Kubernetes and Kubeflow\n- MLOps lessons from one of the most popular location-based games",
        "url": "http://kccncna2025.sched.com/event/3be70591b297c077ac392a8a4e9e9722",
        "uid": "3be70591b297c077ac392a8a4e9e9722",
        "start": "2025-11-11T09:51:00-05:00",
        "end": "2025-11-11T10:06:00-05:00",
        "categories": [
          "KEYNOTE SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B2"
        },
        "speakers": [
          {
            "name": "Yunpeng Liu",
            "company": " Niantic (Scopely)"
          },
          {
            "name": "Andy Zhang",
            "company": " Niantic (Scopely)"
          }
        ]
      }
    },
    {
      "text": "Every revolution in computing has been defined by trust. Firewalls secured the internet, while API keys and IAM roles helped shape the cloud. Today, in the Kubernetes era of ephemeral workloads and Agentic AI, trust is no longer just about peoplehuman and machine identities now stand on equal footing. The challenge is ensuring auditability: knowing who or what is calling, and being able to trace every interaction.\nThis keynote shows how projects like Kubernetes can anchor a new trust fabric. With SPIFFE and SPIRE providing cryptographic workload identities, and Keycloak enabling another layer of identity and access control, we establish an auditable chain of trust. Paired with KServe, this fabric extends into AI serving so that every model, explainer, and pipeline step runs with verifiable identity. Together, they make Kubernetes a secure, accountable platform for the age of AI. Speakers: Yuan Tang Senior Principal Software Engineer from Red Hat, Anjali Telang Senior Principal Product Manager for OpenShift Security and Identity from Red Hat. Location: Building B | Level 1 | Exhibit Hall B2. Categories: KEYNOTE SESSIONS.",
      "metadata": {
        "title": "Sponsored Keynote: Anchoring Trust in the Age of AI: Identities Across Humans, Machines, and Models",
        "description": "Every revolution in computing has been defined by trust. Firewalls secured the internet, while API keys and IAM roles helped shape the cloud. Today, in the Kubernetes era of ephemeral workloads and Agentic AI, trust is no longer just about peoplehuman and machine identities now stand on equal footing. The challenge is ensuring auditability: knowing who or what is calling, and being able to trace every interaction.\nThis keynote shows how projects like Kubernetes can anchor a new trust fabric. With SPIFFE and SPIRE providing cryptographic workload identities, and Keycloak enabling another layer of identity and access control, we establish an auditable chain of trust. Paired with KServe, this fabric extends into AI serving so that every model, explainer, and pipeline step runs with verifiable identity. Together, they make Kubernetes a secure, accountable platform for the age of AI.",
        "url": "http://kccncna2025.sched.com/event/0fbf592df6e4117b2569ba4014b81412",
        "uid": "0fbf592df6e4117b2569ba4014b81412",
        "start": "2025-11-11T10:08:00-05:00",
        "end": "2025-11-11T10:13:00-05:00",
        "categories": [
          "KEYNOTE SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B2"
        },
        "speakers": [
          {
            "name": "Yuan Tang",
            "title": "Senior Principal Software Engineer",
            "company": "Red Hat"
          },
          {
            "name": "Anjali Telang",
            "title": "Senior Principal Product Manager for OpenShift Security and Identity",
            "company": "Red Hat"
          }
        ]
      }
    },
    {
      "text": "Location: Building B | Level 1 | Exhibit Hall B2. Categories: KEYNOTE SESSIONS.",
      "metadata": {
        "title": "Keynote: To be Announced",
        "description": "",
        "url": "http://kccncna2025.sched.com/event/de6a290652f030eb11226dc5cb2a21a6",
        "uid": "de6a290652f030eb11226dc5cb2a21a6",
        "start": "2025-11-11T10:15:00-05:00",
        "end": "2025-11-11T10:20:00-05:00",
        "categories": [
          "KEYNOTE SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B2"
        }
      }
    },
    {
      "text": "Cloud Native is not the end of the journey; it has become the substrate for what comes next. Breakthroughs in AI promise a future where ideas move from research to reality at unprecedented speed, but the gap between experimentation and production is widening. The challenge is not AI capability, it is infrastructure. Today's platforms were built for predictable, human-driven workloads, not for adaptive models that demand scale, resilience, and portability. This keynote explores how the CNCF community can focus on the critical areas that matter most for AI adoption. It will highlight where attention and investment can deliver maximum acceleration, ensuring that Cloud Native continues to evolve as the foundation for deploying and operating intelligent systems into the future. Speakers: Joseph Sandoval Principal Product Manager from Adobe. Location: Building B | Level 1 | Exhibit Hall B2. Categories: KEYNOTE SESSIONS.",
      "metadata": {
        "title": "Keynote: Maximum Acceleration: Cloud Native at the Speed of AI",
        "description": "Cloud Native is not the end of the journey; it has become the substrate for what comes next. Breakthroughs in AI promise a future where ideas move from research to reality at unprecedented speed, but the gap between experimentation and production is widening. The challenge is not AI capability, it is infrastructure. Today's platforms were built for predictable, human-driven workloads, not for adaptive models that demand scale, resilience, and portability. This keynote explores how the CNCF community can focus on the critical areas that matter most for AI adoption. It will highlight where attention and investment can deliver maximum acceleration, ensuring that Cloud Native continues to evolve as the foundation for deploying and operating intelligent systems into the future.",
        "url": "http://kccncna2025.sched.com/event/c480d6635f9527950bef509abb9f5b37",
        "uid": "c480d6635f9527950bef509abb9f5b37",
        "start": "2025-11-11T10:22:00-05:00",
        "end": "2025-11-11T10:37:00-05:00",
        "categories": [
          "KEYNOTE SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B2"
        },
        "speakers": [
          {
            "name": "Joseph Sandoval",
            "title": "Principal Product Manager",
            "company": "Adobe"
          }
        ]
      }
    },
    {
      "text": "Take a break from the buzz of the Solutions Showcase and sit back and relax at the Relaxation Station. Enjoy a soothing massage, try your hand at crocheting, or challenge someone to a game of chess. This is the perfect spot to recharge and unwind before diving back into action. \n\nSponsored by: Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: EXPERIENCES.",
      "metadata": {
        "title": "Relaxation Station",
        "description": "Take a break from the buzz of the Solutions Showcase and sit back and relax at the Relaxation Station. Enjoy a soothing massage, try your hand at crocheting, or challenge someone to a game of chess. This is the perfect spot to recharge and unwind before diving back into action. \n\nSponsored by:",
        "url": "http://kccncna2025.sched.com/event/3879c75feae665ca690e4ae69a6e054f",
        "uid": "3879c75feae665ca690e4ae69a6e054f",
        "start": "2025-11-11T10:30:00-05:00",
        "end": "2025-11-11T19:45:00-05:00",
        "categories": [
          "EXPERIENCES"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies. Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: SOLUTIONS SHOWCASE.",
      "metadata": {
        "title": "Solutions Showcase",
        "description": "In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.",
        "url": "http://kccncna2025.sched.com/event/087a5da87003955d42654ea2b1fc72e2",
        "uid": "087a5da87003955d42654ea2b1fc72e2",
        "start": "2025-11-11T10:30:00-05:00",
        "end": "2025-11-11T19:45:00-05:00",
        "categories": [
          "SOLUTIONS SHOWCASE"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "Location: Building B | Level 1 | Exhibit Hall B2. Categories: KEYNOTE SESSIONS.",
      "metadata": {
        "title": "Keynote: Closing Remarks",
        "description": "",
        "url": "http://kccncna2025.sched.com/event/cc9ce2b05f58032f75dc0fb85a45d8bf",
        "uid": "cc9ce2b05f58032f75dc0fb85a45d8bf",
        "start": "2025-11-11T10:39:00-05:00",
        "end": "2025-11-11T10:45:00-05:00",
        "categories": [
          "KEYNOTE SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B2"
        }
      }
    },
    {
      "text": "Location: TBA. Categories: BREAKS.",
      "metadata": {
        "title": "Coffee Break ",
        "description": "",
        "url": "http://kccncna2025.sched.com/event/a1187621f2fae236f53a25fb4931db87",
        "uid": "a1187621f2fae236f53a25fb4931db87",
        "start": "2025-11-11T10:45:00-05:00",
        "end": "2025-11-11T11:15:00-05:00",
        "categories": [
          "BREAKS"
        ],
        "location": {
          "room": "TBA"
        }
      }
    },
    {
      "text": "AI Agents have become increasingly capable at performing automated tasks yet theyre limited by the explicit tools theyve given. Computer use and code execution unlocks a new wave of agents for complex, human-like tasks by enabling the LLM to execute code and commands as tools. With these new capabilities users are faced with security, performance and efficiency trade-offs. Using Agent Sandboxes on Google Kubernetes Engine (GKE), engineers can build isolated execution environments\n\nThis session showcases how Google Kubernetes Engine (GKE) provides a robust, secure, and efficient platform for orchestrating and executing agentic AI applications at scale.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.* Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: SOLUTIONS SHOWCASE.",
      "metadata": {
        "title": "Sponsored Demo: Building Faster and More Efficient Computer Use Agents in Kubernetes",
        "description": "AI Agents have become increasingly capable at performing automated tasks yet theyre limited by the explicit tools theyve given. Computer use and code execution unlocks a new wave of agents for complex, human-like tasks by enabling the LLM to execute code and commands as tools. With these new capabilities users are faced with security, performance and efficiency trade-offs. Using Agent Sandboxes on Google Kubernetes Engine (GKE), engineers can build isolated execution environments\n\nThis session showcases how Google Kubernetes Engine (GKE) provides a robust, secure, and efficient platform for orchestrating and executing agentic AI applications at scale.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.*",
        "url": "http://kccncna2025.sched.com/event/3b0767e99ac5cfe6725d00f0b56b3a54",
        "uid": "3b0767e99ac5cfe6725d00f0b56b3a54",
        "start": "2025-11-11T10:50:00-05:00",
        "end": "2025-11-11T11:10:00-05:00",
        "categories": [
          "SOLUTIONS SHOWCASE"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "10-Minute Tip Talk Speakers: Clyde Seepersad from LF Education. Location: Level 1 | Learning Lounge. Categories: EXPERIENCES.",
      "metadata": {
        "title": "Learning Lounge: The \"Must Have\" OKR for 2026",
        "description": "10-Minute Tip Talk",
        "url": "http://kccncna2025.sched.com/event/0186c81a9cf4d5b6a4ae30ad76778c0b",
        "uid": "0186c81a9cf4d5b6a4ae30ad76778c0b",
        "start": "2025-11-11T11:00:00-05:00",
        "end": "2025-11-11T11:15:00-05:00",
        "categories": [
          "EXPERIENCES"
        ],
        "location": {
          "level": "1",
          "room": "Learning Lounge"
        },
        "speakers": [
          {
            "name": "Clyde Seepersad",
            "company": "LF Education"
          }
        ]
      }
    },
    {
      "text": "Foundation models are general purpose deep learning models trained on vast amounts of data capable of responding to a diverse set of tasks. To minimize the recurring inference costs, such large model deployments are now being optimized in various ways to reduce the model computations without substantial loss in accuracy. These include techniques to optimize the attention mechanism like flash attention, paged attention etc, model parameter optimizations like quantization and other serving optimizations like in-flight batching, speculative decoding, disaggregated serving and other smart routing strategies. One of the biggest requirements to testing and deploying any such inference optimization technique is a consistent framework to measure and benchmark the inference performance. This talk introduces a Kubernetes SIG project to benchmark GenAI foundation model inference and validate the performance usability of inference optimizations in a standard manner for real world applications. Speakers: Sachin Mathew Varghese from Capital One, Brendan Slabe from Google. Location: Building B | Level 5 | Thomas Murphy Ballroom 1. Categories: AI + ML.",
      "metadata": {
        "title": "Benchmarking GenAI Foundation Model Inference Optimizations on Kubernetes",
        "description": "Foundation models are general purpose deep learning models trained on vast amounts of data capable of responding to a diverse set of tasks. To minimize the recurring inference costs, such large model deployments are now being optimized in various ways to reduce the model computations without substantial loss in accuracy. These include techniques to optimize the attention mechanism like flash attention, paged attention etc, model parameter optimizations like quantization and other serving optimizations like in-flight batching, speculative decoding, disaggregated serving and other smart routing strategies. One of the biggest requirements to testing and deploying any such inference optimization technique is a consistent framework to measure and benchmark the inference performance. This talk introduces a Kubernetes SIG project to benchmark GenAI foundation model inference and validate the performance usability of inference optimizations in a standard manner for real world applications.",
        "url": "http://kccncna2025.sched.com/event/737fc179633583dd0622116a3ca430c7",
        "uid": "737fc179633583dd0622116a3ca430c7",
        "start": "2025-11-11T11:15:00-05:00",
        "end": "2025-11-11T11:45:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 1"
        },
        "speakers": [
          {
            "name": "Sachin Mathew Varghese",
            "company": "Capital One"
          },
          {
            "name": "Brendan Slabe",
            "company": "Google"
          }
        ]
      }
    },
    {
      "text": "Strongly and statically-typed programming languages, like Rust, could be difficult for humans, but they are especially well-suited for AI coding, as the generated code can be validated by compilers for real-time feedback and reinforcement learning. However, unlike Python, there are few examples of Rust code in LLMs training corpora, and hence limiting the LLM's capability in generating Rust code. This talk will discuss the open-source RustCoder project, which provides an integrated agentic framework based on MCP for generating complete and valid Rust projects. It enables the following functionalities for IDEs and coding tools. 1. Generates a Rust Cargo project from a user request (aka vibe coding). 2. Compiles and executes Rust Cargo projects. 3. Automatically fixes compiler errors. The project is supported by two Linux Foundation Mentorship grants, as well as content provided by the Rust Foundation. Speakers: Michael Yuan from Second State. Location: Building B | Level 4 | B401-402. Categories: AI + ML.",
      "metadata": {
        "title": "Rust Is the Language of AGI",
        "description": "Strongly and statically-typed programming languages, like Rust, could be difficult for humans, but they are especially well-suited for AI coding, as the generated code can be validated by compilers for real-time feedback and reinforcement learning. However, unlike Python, there are few examples of Rust code in LLMs training corpora, and hence limiting the LLM's capability in generating Rust code. This talk will discuss the open-source RustCoder project, which provides an integrated agentic framework based on MCP for generating complete and valid Rust projects. It enables the following functionalities for IDEs and coding tools. 1. Generates a Rust Cargo project from a user request (aka vibe coding). 2. Compiles and executes Rust Cargo projects. 3. Automatically fixes compiler errors. The project is supported by two Linux Foundation Mentorship grants, as well as content provided by the Rust Foundation.",
        "url": "http://kccncna2025.sched.com/event/fc61bfb0c931ca8839ecf14ee055dc0d",
        "uid": "fc61bfb0c931ca8839ecf14ee055dc0d",
        "start": "2025-11-11T11:15:00-05:00",
        "end": "2025-11-11T11:45:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B401-402"
        },
        "speakers": [
          {
            "name": "Michael Yuan",
            "company": "Second State"
          }
        ]
      }
    },
    {
      "text": "After a decade of \"microservices all the things,\" the industry is experiencing a fascinating recalibration. Organizations that rushed to decompose monoliths are now grappling with distributed system complexity, operational overhead, and the cognitive load on development teams. This panel explores how modern organizations are making more intentional architectural choices and evolving their approach to software consumption and deployment.\n\nThis panel will cover:\nFrom \"microservices by default\" to \"complexity-aware\" architectural decisions\n\nThe hidden costs of distributed systems: network calls, data consistency, observability overhead\n\nWhy some organizations are consolidating services or building \"modular monoliths\"\n\nThe rise of platform engineering as a response to operational complexity\n\nShifting from \"move fast and break things\" to sustainable velocity Speakers: Moderated by Katie Norton, Alex Zenla from Edera, Jason Hall from Chainguard, Jon Ceanfaglione from IBM. Location: Building B | Level 3 | B308-309. Categories: CLOUD NATIVE EXPERIENCE.",
      "metadata": {
        "title": "Taming the Complexity Beast: How Organizations Are Rethinking Software Architecture and Deployment",
        "description": "After a decade of \"microservices all the things,\" the industry is experiencing a fascinating recalibration. Organizations that rushed to decompose monoliths are now grappling with distributed system complexity, operational overhead, and the cognitive load on development teams. This panel explores how modern organizations are making more intentional architectural choices and evolving their approach to software consumption and deployment.\n\nThis panel will cover:\nFrom \"microservices by default\" to \"complexity-aware\" architectural decisions\n\nThe hidden costs of distributed systems: network calls, data consistency, observability overhead\n\nWhy some organizations are consolidating services or building \"modular monoliths\"\n\nThe rise of platform engineering as a response to operational complexity\n\nShifting from \"move fast and break things\" to sustainable velocity",
        "url": "http://kccncna2025.sched.com/event/117db8e22a3357441e5e7b6745a52d33",
        "uid": "117db8e22a3357441e5e7b6745a52d33",
        "start": "2025-11-11T11:15:00-05:00",
        "end": "2025-11-11T11:45:00-05:00",
        "categories": [
          "CLOUD NATIVE EXPERIENCE"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B308-309"
        },
        "speakers": [
          {
            "name": "Moderated by Katie Norton"
          },
          {
            "name": "Alex Zenla",
            "company": "Edera"
          },
          {
            "name": "Jason Hall",
            "company": "Chainguard"
          },
          {
            "name": "Jon Ceanfaglione",
            "company": "IBM"
          }
        ]
      }
    },
    {
      "text": "By default, Kubernetes workloads are distributed as evenly as possible across a pool of Kubernetes (worker) nodes. i.e., they are designed to be automatically deployed where they are best suited based on the state of each node. However, sometimes we need to modify the code in order to ensure that the workloads are deployed where we want them to be, and this can be as simple as 'nodeName', but sometimes we can use options like 'affinity' to ensure that they are deployed based on conditions. With all these different conditions, which one will take more precedence? On the flip side, we also add values like 'taints' to limit what we deploy to. If the condition you restrict are \"SHIELD\", then the condition you deploy can be likened to \"SPEAR\". Who win? Let's decode this paradox with an actual example in each case. Speakers: Hoon Jo from Megazone. Location: Building B | Level 2 | B206. Categories: CLOUD NATIVE NOVICE.",
      "metadata": {
        "title": "Anatomy of a Kubernetes Scheduler: Narrate Workloads Priority in Sequence",
        "description": "By default, Kubernetes workloads are distributed as evenly as possible across a pool of Kubernetes (worker) nodes. i.e., they are designed to be automatically deployed where they are best suited based on the state of each node. However, sometimes we need to modify the code in order to ensure that the workloads are deployed where we want them to be, and this can be as simple as 'nodeName', but sometimes we can use options like 'affinity' to ensure that they are deployed based on conditions. With all these different conditions, which one will take more precedence? On the flip side, we also add values like 'taints' to limit what we deploy to. If the condition you restrict are \"SHIELD\", then the condition you deploy can be likened to \"SPEAR\". Who win? Let's decode this paradox with an actual example in each case.",
        "url": "http://kccncna2025.sched.com/event/2ebdfd7f40ea23f2a70f784831b41812",
        "uid": "2ebdfd7f40ea23f2a70f784831b41812",
        "start": "2025-11-11T11:15:00-05:00",
        "end": "2025-11-11T11:45:00-05:00",
        "categories": [
          "CLOUD NATIVE NOVICE"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B206"
        },
        "speakers": [
          {
            "name": "Hoon Jo",
            "company": "Megazone"
          }
        ]
      }
    },
    {
      "text": "When your production network suddenly starts dropping packets, the last thing you expect is that your cloud provider quietly deployed a new monitoring tool. This talk shares our journey from mysterious outage to desperate fix to surprising discovery.\n\nIt started with alerts: packet loss spiking, network throughput crashing from 800MB/s to near 250MB/s. No recent changes on our end. Hours into the crisis, we discovered an unfamiliar DaemonSet running eBPF programs - Retina, silently rolled out across our clusters. But here's the catch: we couldn't remove it. The daemonset was reconciled instantly back to original state after an update.\nWith users impacted and no time for root cause analysis, we took a leap: build a mutation webhook to intercept and neuter this mysterious DaemonSet. It worked instantly - networks recovered, crisis averted.\n\nOnly then could we investigate: How did an eBPF observability tool cause such devastation? And why didn't we know it was being deployed? Speakers: Zain Malik from Exostellar, Grzegorz Gab from Whatnot. Location: Building B | Level 4 | B405-406a. Categories: CONNECTIVITY.",
      "metadata": {
        "title": "Fix First, Investigate Later: When an eBPF Rollout Brought Down Our Network",
        "description": "When your production network suddenly starts dropping packets, the last thing you expect is that your cloud provider quietly deployed a new monitoring tool. This talk shares our journey from mysterious outage to desperate fix to surprising discovery.\n\nIt started with alerts: packet loss spiking, network throughput crashing from 800MB/s to near 250MB/s. No recent changes on our end. Hours into the crisis, we discovered an unfamiliar DaemonSet running eBPF programs - Retina, silently rolled out across our clusters. But here's the catch: we couldn't remove it. The daemonset was reconciled instantly back to original state after an update.\nWith users impacted and no time for root cause analysis, we took a leap: build a mutation webhook to intercept and neuter this mysterious DaemonSet. It worked instantly - networks recovered, crisis averted.\n\nOnly then could we investigate: How did an eBPF observability tool cause such devastation? And why didn't we know it was being deployed?",
        "url": "http://kccncna2025.sched.com/event/4d531ae046388892d062298f98155ca2",
        "uid": "4d531ae046388892d062298f98155ca2",
        "start": "2025-11-11T11:15:00-05:00",
        "end": "2025-11-11T11:45:00-05:00",
        "categories": [
          "CONNECTIVITY"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B405-406a"
        },
        "speakers": [
          {
            "name": "Zain Malik",
            "company": "Exostellar"
          },
          {
            "name": "Grzegorz Gab",
            "company": "Whatnot"
          }
        ]
      }
    },
    {
      "text": "The Cloud Native Capture The Flag (CTF) is available to all KubeCon + CloudNativeCon attendees. &nbsp;In preparation for starting the activity, you are invited to attend an introductory session.\n\nThis session aims to introduce how to participate in CTF competition to those new to them. We will share tips and tricks for completing these challenges and work through a practice scenario together. Location: Building B | Level 2 | B203. Categories: EXPERIENCES.",
      "metadata": {
        "title": "An Introduction to Capture The Flag",
        "description": "The Cloud Native Capture The Flag (CTF) is available to all KubeCon + CloudNativeCon attendees. &nbsp;In preparation for starting the activity, you are invited to attend an introductory session.\n\nThis session aims to introduce how to participate in CTF competition to those new to them. We will share tips and tricks for completing these challenges and work through a practice scenario together.",
        "url": "http://kccncna2025.sched.com/event/338d1f9b07c3bf8d4d5ab089d54d8432",
        "uid": "338d1f9b07c3bf8d4d5ab089d54d8432",
        "start": "2025-11-11T11:15:00-05:00",
        "end": "2025-11-11T12:00:00-05:00",
        "categories": [
          "EXPERIENCES"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B203"
        }
      }
    },
    {
      "text": "Join us as we celebrate a decade of Cilium, now the de-facto standard CNI for Kubernetes and a cornerstone of cloud native networking and security. This session provides updates on the latest Cilium release and showcases how its unified eBPF-powered stack is transforming Kubernetes environments and beyond by replacing fragmented toolchains with seamless, secure, scalable, and simplified solutions.\n\nWell showcase advancements in multi-cluster connectivity and support for massively scalable clusters. Youll also hear updates from sub-project Tetragon for runtime enforcement and security observability.\n\nContributors and adopters from Isovalent, Microsoft, and UBS will share how theyre using Cilium to streamline operations and reshape the cloud native stack cementing Ciliums role as the networking and security data plane for modern infrastructure for the next decade to come. Speakers: Bill Mulligan from  Isovalent @ Cisco, Paul Arah from  Isovalent @ Cisco, Neha Aggarwal from Microsoft, Satish Krishnan from UBS. Location: Building C | Level 3 | Georgia Ballroom 3. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "10 Years of Cilium: Connecting, Securing, and Simplifying the Cloud Native Stack",
        "description": "Join us as we celebrate a decade of Cilium, now the de-facto standard CNI for Kubernetes and a cornerstone of cloud native networking and security. This session provides updates on the latest Cilium release and showcases how its unified eBPF-powered stack is transforming Kubernetes environments and beyond by replacing fragmented toolchains with seamless, secure, scalable, and simplified solutions.\n\nWell showcase advancements in multi-cluster connectivity and support for massively scalable clusters. Youll also hear updates from sub-project Tetragon for runtime enforcement and security observability.\n\nContributors and adopters from Isovalent, Microsoft, and UBS will share how theyre using Cilium to streamline operations and reshape the cloud native stack cementing Ciliums role as the networking and security data plane for modern infrastructure for the next decade to come.",
        "url": "http://kccncna2025.sched.com/event/b9672105dadc50490f28d55cc93a7744",
        "uid": "b9672105dadc50490f28d55cc93a7744",
        "start": "2025-11-11T11:15:00-05:00",
        "end": "2025-11-11T11:45:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 3"
        },
        "speakers": [
          {
            "name": "Bill Mulligan",
            "company": " Isovalent @ Cisco"
          },
          {
            "name": "Paul Arah",
            "company": " Isovalent @ Cisco"
          },
          {
            "name": "Neha Aggarwal",
            "company": "Microsoft"
          },
          {
            "name": "Satish Krishnan",
            "company": "UBS"
          }
        ]
      }
    },
    {
      "text": "After a quick detour to do Emissary-ingress 3.10, we're back to working on Emissary-ingress 4.0! This is the first new major version in some years for Emissary, one of the first Kubernetes-native, self-service API gateways and ingress controllers, and it's quite a significant change under the hood.\n\nIn this session, we'll start with a quick overview of the need for ingress controllers in general, the benefits of self-service developer workflows, and how Emissary-ingress can help with these issues. We'll also talk about the state of project, the path we're taking with Emissary 4, and how to get involved as a contributor, how to best offer feedback, and what's in store for the project in the future.\n\nEmissary's maintainer sessions are always great opportunities to talk directly with Emissary-ingress maintainers and make sure your voice is heard when it comes to the project's future -- looking forward to seeing you there! Speakers: Flynn from Buoyant. Location: Building C | Level 3 | Georgia Ballroom 1. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Emissary-ingress: Version 4 and the Road Ahead",
        "description": "After a quick detour to do Emissary-ingress 3.10, we're back to working on Emissary-ingress 4.0! This is the first new major version in some years for Emissary, one of the first Kubernetes-native, self-service API gateways and ingress controllers, and it's quite a significant change under the hood.\n\nIn this session, we'll start with a quick overview of the need for ingress controllers in general, the benefits of self-service developer workflows, and how Emissary-ingress can help with these issues. We'll also talk about the state of project, the path we're taking with Emissary 4, and how to get involved as a contributor, how to best offer feedback, and what's in store for the project in the future.\n\nEmissary's maintainer sessions are always great opportunities to talk directly with Emissary-ingress maintainers and make sure your voice is heard when it comes to the project's future -- looking forward to seeing you there!",
        "url": "http://kccncna2025.sched.com/event/740e4eecf05d158dd4b8895ac3724596",
        "uid": "740e4eecf05d158dd4b8895ac3724596",
        "start": "2025-11-11T11:15:00-05:00",
        "end": "2025-11-11T11:45:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 1"
        },
        "speakers": [
          {
            "name": "Flynn",
            "company": "Buoyant"
          }
        ]
      }
    },
    {
      "text": "Data Protection WG is dedicated to promoting data protection support in Kubernetes. The Working Group is working on identifying missing functionalities and collaborating across multiple SIGs to design features to enable data protection in Kubernetes. In this session, we will discuss what is the current state of data protection in Kubernetes and where it is heading in the future. We will also talk about how interested parties (including storage and backup vendors, cloud providers, application developers, and end users, etc.) can join this WG and contribute to this effort. Details of the WG can be found here: https://github.com/kubernetes/community/tree/master/wg-data-protection. Speakers: Dave Smith-Uchida from Veeam. Location: Building C | Level 3 | Georgia Ballroom 2. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Kubernetes Data Protection WG Intro & Deep Dive",
        "description": "Data Protection WG is dedicated to promoting data protection support in Kubernetes. The Working Group is working on identifying missing functionalities and collaborating across multiple SIGs to design features to enable data protection in Kubernetes. In this session, we will discuss what is the current state of data protection in Kubernetes and where it is heading in the future. We will also talk about how interested parties (including storage and backup vendors, cloud providers, application developers, and end users, etc.) can join this WG and contribute to this effort. Details of the WG can be found here: https://github.com/kubernetes/community/tree/master/wg-data-protection.",
        "url": "http://kccncna2025.sched.com/event/bcef476f7c94530220aff41460a1b9bc",
        "uid": "bcef476f7c94530220aff41460a1b9bc",
        "start": "2025-11-11T11:15:00-05:00",
        "end": "2025-11-11T11:45:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 2"
        },
        "speakers": [
          {
            "name": "Dave Smith-Uchida",
            "company": "Veeam"
          }
        ]
      }
    },
    {
      "text": "A year after the release of containerd 2.0, the containerd project has shifted to time based releases and recently released containerd 2.2. As the project has matured, the maintainers have continued to focus on stability along with more reliable release cadence and steady stream of new features. The 2.2 release is filled with new features to support the next generation of filesystems and container image formats. Join maintainers to discuss these project updates, integrations with Kubernetes, and how these new features can be used to support new use cases and increase runtime performance. Speakers: Derek McGowan from Docker, Phil Estes from AWS. Location: Building C | Level 1 | C111-112. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Whats New in Containerd 2.2",
        "description": "A year after the release of containerd 2.0, the containerd project has shifted to time based releases and recently released containerd 2.2. As the project has matured, the maintainers have continued to focus on stability along with more reliable release cadence and steady stream of new features. The 2.2 release is filled with new features to support the next generation of filesystems and container image formats. Join maintainers to discuss these project updates, integrations with Kubernetes, and how these new features can be used to support new use cases and increase runtime performance.",
        "url": "http://kccncna2025.sched.com/event/edebc172c77ff7b7b0d81e0aba3e76e1",
        "uid": "edebc172c77ff7b7b0d81e0aba3e76e1",
        "start": "2025-11-11T11:15:00-05:00",
        "end": "2025-11-11T11:45:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "1",
          "room": "C111-112"
        },
        "speakers": [
          {
            "name": "Derek McGowan",
            "company": "Docker"
          },
          {
            "name": "Phil Estes",
            "company": "AWS"
          }
        ]
      }
    },
    {
      "text": "Observability is only as good as its implementationand at enterprise scale, it's often fragmented. With teams deploying their own OpenTelemetry (OTel) configurations, inconsistencies arise in metrics, logs, and trace data, making it harder to validate system health or pinpoint root causes. This talk explores how platform engineering teams can address these inconsistencies using a standardized architecture built on OpAMP, Gateway API, and service mesh technologies like Kuma and Envoy.\nWell cover:\n- Common deployment patterns and team-specific observability needs\n- How Gateways and Meshes serve as rich telemetry aggregation points\n- How OpAMP helps centralize and automate OTel configuration management\n- Real-world examples of customer setups and results\n\nAttendees will walk away with reusable blueprints to align observability across teams while reducing MTTR and boosting operational clarity Speakers: Nancy Chauhan from Agno, Marino Wijay from Kong Inc.. Location: Building B | Level 3 | B304-305. Categories: OBSERVABILITY.",
      "metadata": {
        "title": "Taming Telemetry at Scale: Platform Blueprints for Consistent Observability",
        "description": "Observability is only as good as its implementationand at enterprise scale, it's often fragmented. With teams deploying their own OpenTelemetry (OTel) configurations, inconsistencies arise in metrics, logs, and trace data, making it harder to validate system health or pinpoint root causes. This talk explores how platform engineering teams can address these inconsistencies using a standardized architecture built on OpAMP, Gateway API, and service mesh technologies like Kuma and Envoy.\nWell cover:\n- Common deployment patterns and team-specific observability needs\n- How Gateways and Meshes serve as rich telemetry aggregation points\n- How OpAMP helps centralize and automate OTel configuration management\n- Real-world examples of customer setups and results\n\nAttendees will walk away with reusable blueprints to align observability across teams while reducing MTTR and boosting operational clarity",
        "url": "http://kccncna2025.sched.com/event/52b4990c8f7d9808f5762ded58b2be4d",
        "uid": "52b4990c8f7d9808f5762ded58b2be4d",
        "start": "2025-11-11T11:15:00-05:00",
        "end": "2025-11-11T11:45:00-05:00",
        "categories": [
          "OBSERVABILITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B304-305"
        },
        "speakers": [
          {
            "name": "Nancy Chauhan",
            "company": "Agno"
          },
          {
            "name": "Marino Wijay",
            "company": "Kong Inc."
          }
        ]
      }
    },
    {
      "text": "In-place pod resource resizing is a powerful K8S feature that can significantly accelerate application startup and improve autoscaling responsiveness. However, its integration with k8s workload and tooling, e.g. PodDisruptionBudget is lacking, and support across programming languages and frameworks remains limited, hindering widespread adoption.\n\nIn this session, we share real-world experiences from Alibaba and RedNote on deploying in-place resource resizing. We will discuss challenges such as CgroupV1 compatibility issues, and demonstrate language-level techniques to make resized resources available to applications, including JVM parameter tuning and elastic heap management for Java workloads. Additionally, we introduce a novel approach for dynamically resizing instances based on daily traffic patterns to optimize resource utilization. Finally, we show how to automate in-place resizing during workload rollouts and to minimize disruption caused by resizing using OpenKruise. Speakers: Zhang Zhen from  Alibaba Cloud, Yuxing Yuan from  Alibaba Cloud. Location: Building B | Level 4 | B406b-407. Categories: OPERATIONS + PERFORMANCE.",
      "metadata": {
        "title": "Unleash the Power of Inplace Pod Resource Resizing for Startup and Cost Optimization",
        "description": "In-place pod resource resizing is a powerful K8S feature that can significantly accelerate application startup and improve autoscaling responsiveness. However, its integration with k8s workload and tooling, e.g. PodDisruptionBudget is lacking, and support across programming languages and frameworks remains limited, hindering widespread adoption.\n\nIn this session, we share real-world experiences from Alibaba and RedNote on deploying in-place resource resizing. We will discuss challenges such as CgroupV1 compatibility issues, and demonstrate language-level techniques to make resized resources available to applications, including JVM parameter tuning and elastic heap management for Java workloads. Additionally, we introduce a novel approach for dynamically resizing instances based on daily traffic patterns to optimize resource utilization. Finally, we show how to automate in-place resizing during workload rollouts and to minimize disruption caused by resizing using OpenKruise.",
        "url": "http://kccncna2025.sched.com/event/0c1057392e30429ffe091edbe9b9e1a7",
        "uid": "0c1057392e30429ffe091edbe9b9e1a7",
        "start": "2025-11-11T11:15:00-05:00",
        "end": "2025-11-11T11:45:00-05:00",
        "categories": [
          "OPERATIONS + PERFORMANCE"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B406b-407"
        },
        "speakers": [
          {
            "name": "Zhang Zhen",
            "company": " Alibaba Cloud"
          },
          {
            "name": "Yuxing Yuan",
            "company": " Alibaba Cloud"
          }
        ]
      }
    },
    {
      "text": "How do you get started with platform engineering if you don't have time and resources to build a platform? -- In an ideal world, you are building a developer platform from the ground up with best practices, scalability, modularity, automation, self service capabilities, and best-of-breed technology in a greenfield environment. In reality however, there may be no paved roads, golden paths, guardrails, or organizational buy in, and the legacy of developers and sysadmins past may have generated mountains of debt that continue to accrue with compounding interest. In this talk, we will build a platform engineering roadmap, starting from your team or organization's current state - wherever that may be. You will have the opportunity to learn about some of the most common tools and technologies that go into building an internal developer platform, and to explore approaches for championing a platform engineering mindset, iterating on improvements to teams, processes, and technologies. Speakers: Murriel McCabe from Google. Location: Building B | Level 3 | B312-314. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "Platform Engineering: Day Zero, The Origin Story",
        "description": "How do you get started with platform engineering if you don't have time and resources to build a platform? -- In an ideal world, you are building a developer platform from the ground up with best practices, scalability, modularity, automation, self service capabilities, and best-of-breed technology in a greenfield environment. In reality however, there may be no paved roads, golden paths, guardrails, or organizational buy in, and the legacy of developers and sysadmins past may have generated mountains of debt that continue to accrue with compounding interest. In this talk, we will build a platform engineering roadmap, starting from your team or organization's current state - wherever that may be. You will have the opportunity to learn about some of the most common tools and technologies that go into building an internal developer platform, and to explore approaches for championing a platform engineering mindset, iterating on improvements to teams, processes, and technologies.",
        "url": "http://kccncna2025.sched.com/event/e99d57e23f54bde55c7a2e82ca91f222",
        "uid": "e99d57e23f54bde55c7a2e82ca91f222",
        "start": "2025-11-11T11:15:00-05:00",
        "end": "2025-11-11T11:45:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B312-314"
        },
        "speakers": [
          {
            "name": "Murriel McCabe",
            "company": "Google"
          }
        ]
      }
    },
    {
      "text": "Kubernetes networking by default is Malicious Actors heaven.\n\nWhy? Because by default, any pod can send and receive traffic to and from any other pod, ignoring namespace and privilege boundaries. External traffic in both directions is allowed as well, as far as Kubernetes is concerned.\n\nIndeed, best practices rightfully dictate that this default be modified, using \"Kubernetes Network Policies\" .\n\nYet most teams find this too difficult to implement.\nAuthoring NetworkPolicy YAML is very challenging.\nBaseline/AdminNetworkPolicy fills a gap for cluster administrators, but authoring these policies and understanding their impact is a new, additional challenge.\nFurthermore, policy authors may not know what the applications communication needs are.\n\nWhat if there was a way to automatically produce tight network policy rules, in YAML, and see the impact of applied B/ANP network policies?\n\nJoin this session to see the magic yourself, and learn how you can leverage this technology today! Speakers: Boaz Michaely from Red Hat, Adi Sosnovich from IBM Research. Location: Building B | Level 3 | B302-303. Categories: SECURITY.",
      "metadata": {
        "title": "Demonstration of Automatic Kubernetes Network Policies Generation",
        "description": "Kubernetes networking by default is Malicious Actors heaven.\n\nWhy? Because by default, any pod can send and receive traffic to and from any other pod, ignoring namespace and privilege boundaries. External traffic in both directions is allowed as well, as far as Kubernetes is concerned.\n\nIndeed, best practices rightfully dictate that this default be modified, using \"Kubernetes Network Policies\" .\n\nYet most teams find this too difficult to implement.\nAuthoring NetworkPolicy YAML is very challenging.\nBaseline/AdminNetworkPolicy fills a gap for cluster administrators, but authoring these policies and understanding their impact is a new, additional challenge.\nFurthermore, policy authors may not know what the applications communication needs are.\n\nWhat if there was a way to automatically produce tight network policy rules, in YAML, and see the impact of applied B/ANP network policies?\n\nJoin this session to see the magic yourself, and learn how you can leverage this technology today!",
        "url": "http://kccncna2025.sched.com/event/e90814e6c4b2e7a73f590da3f17d68b1",
        "uid": "e90814e6c4b2e7a73f590da3f17d68b1",
        "start": "2025-11-11T11:15:00-05:00",
        "end": "2025-11-11T11:45:00-05:00",
        "categories": [
          "SECURITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B302-303"
        },
        "speakers": [
          {
            "name": "Boaz Michaely",
            "company": "Red Hat"
          },
          {
            "name": "Adi Sosnovich",
            "company": "IBM Research"
          }
        ]
      }
    },
    {
      "text": "k0s is more than just a zero-friction Kubernetes distribution, it's a growing open source project committed to simplifying the Kubernetes experience while remaining fully upstream-conformant, production-grade, and lightweight. But like all great open source initiatives, k0s thrives when its community is active, and empowered. Thats where you come in.\n\nIn this contribfest, well open the doors to the k0s contributor journey.\nNo matter whether you're a seasoned Go developer, a DevOps practitioner, a docs enthusiast, or someone curious about Kubernetes internals. You'll learn what makes k0s different from other Kubernetes distributions and where we need help: docs, CLI, testing, integrations, issues, features.\nWe will shed light on how to get started: contributor workflows, issues to pick and guide you.\nWhether you're looking for a bug fix or major issue to hack on, or want to make long-term impact in the Kubernetes space, the k0s community is ready to support your contribfest journey. Speakers: Prithvi Raj from  Mirantis, Jussi Nummelin from  Mirantis. Location: Building B | Level 2 | B207. Categories:  CONTRIBFEST.",
      "metadata": {
        "title": "Contribfest: Contribute To Zero Friction Kubernetes: Scale K0s With the Community",
        "description": "k0s is more than just a zero-friction Kubernetes distribution, it's a growing open source project committed to simplifying the Kubernetes experience while remaining fully upstream-conformant, production-grade, and lightweight. But like all great open source initiatives, k0s thrives when its community is active, and empowered. Thats where you come in.\n\nIn this contribfest, well open the doors to the k0s contributor journey.\nNo matter whether you're a seasoned Go developer, a DevOps practitioner, a docs enthusiast, or someone curious about Kubernetes internals. You'll learn what makes k0s different from other Kubernetes distributions and where we need help: docs, CLI, testing, integrations, issues, features.\nWe will shed light on how to get started: contributor workflows, issues to pick and guide you.\nWhether you're looking for a bug fix or major issue to hack on, or want to make long-term impact in the Kubernetes space, the k0s community is ready to support your contribfest journey.",
        "url": "http://kccncna2025.sched.com/event/d4b70bc6688445a2d1a6ac1a1935fb77",
        "uid": "d4b70bc6688445a2d1a6ac1a1935fb77",
        "start": "2025-11-11T11:15:00-05:00",
        "end": "2025-11-11T12:30:00-05:00",
        "categories": [
          " CONTRIBFEST"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B207"
        },
        "speakers": [
          {
            "name": "Prithvi Raj",
            "company": " Mirantis"
          },
          {
            "name": "Jussi Nummelin",
            "company": " Mirantis"
          }
        ]
      }
    },
    {
      "text": "The DevOps tools are often intimidating because you have to use them as CLIs that have many different options and users don't know about all their flags and the ones they do know about have constraints and gotchas that's hard to remember.\n\nWhen SlimToolkit got its interactive prompt mode its user experienced improved significantly. It was easier to discover the CLI flag and autocomplete many of them, but still many users struggle with understanding what flags to use and when.\n\nWith this ContribFest session we'll build the AI Assistant Mode where SlimToolkit will be able to explain, recommend and automatically select the right flags when you inspect, debug and slim container images. We'll also add a built-in MCP Server, so SlimToolkit can be used by AI agents.\n\nNo low level SlimToolkit, container tech and AI expertise is required. You only need basic knowledge of Go. This is also an opportunity to learn how to build LLM-based AI assistants and agents as well as MCP Servers in Go. Speakers: Kyle Quest from MinToolkit. Location: Building B | Level 2 | B208. Categories:  CONTRIBFEST.",
      "metadata": {
        "title": "Contribfest: Making SlimToolkit Autonomous: Adding AI Assistant Mode and Built-in MCP Server",
        "description": "The DevOps tools are often intimidating because you have to use them as CLIs that have many different options and users don't know about all their flags and the ones they do know about have constraints and gotchas that's hard to remember.\n\nWhen SlimToolkit got its interactive prompt mode its user experienced improved significantly. It was easier to discover the CLI flag and autocomplete many of them, but still many users struggle with understanding what flags to use and when.\n\nWith this ContribFest session we'll build the AI Assistant Mode where SlimToolkit will be able to explain, recommend and automatically select the right flags when you inspect, debug and slim container images. We'll also add a built-in MCP Server, so SlimToolkit can be used by AI agents.\n\nNo low level SlimToolkit, container tech and AI expertise is required. You only need basic knowledge of Go. This is also an opportunity to learn how to build LLM-based AI assistants and agents as well as MCP Servers in Go.",
        "url": "http://kccncna2025.sched.com/event/1b5b0c4ffc6205832b4d49ea9dfac755",
        "uid": "1b5b0c4ffc6205832b4d49ea9dfac755",
        "start": "2025-11-11T11:15:00-05:00",
        "end": "2025-11-11T12:30:00-05:00",
        "categories": [
          " CONTRIBFEST"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B208"
        },
        "speakers": [
          {
            "name": "Kyle Quest",
            "company": "MinToolkit"
          }
        ]
      }
    },
    {
      "text": "Agentic platforms are redefining how cloud-native applications interactbut behind every action lies a critical question: who is allowed to do what, and why? Emerging standards such as MCP allow AI agents to easily connect with tools, but organizations looking to support agents must maintain security and transparency. They can do so by combining the power of OAuth 2.0 with strongly attested workload identity from SPIFFE.\n\nIn this hands-on workshop, well dive into the mechanics of secure workload identity for agents and toolsno prior experience required. Attendees will work hands-on with a working agentic stack, including MCP for agentic tool-calling, and integrate with cloud-native tools such as SPIRE for workload identity, and Keycloak for user management. These existing technologies are key for enabling granular access control and rich audit trails across the full agentic flow. This workshop lays the foundations to building identity-first, zero-trust agentic platforms. Speakers: Maia Iyer from Alan Cha, Mariusz Sabath from IBM Research, Anjali Telang from  Red Hat, Andrew Block from  Red Hat. Location: Building B | Level 5 | Thomas Murphy Ballroom 2-3. Categories:  TUTORIALS.",
      "metadata": {
        "title": "Tutorial: Build-a-Bot Workshop: Enabling Trusted Agents With SPIRE + MCP",
        "description": "Agentic platforms are redefining how cloud-native applications interactbut behind every action lies a critical question: who is allowed to do what, and why? Emerging standards such as MCP allow AI agents to easily connect with tools, but organizations looking to support agents must maintain security and transparency. They can do so by combining the power of OAuth 2.0 with strongly attested workload identity from SPIFFE.\n\nIn this hands-on workshop, well dive into the mechanics of secure workload identity for agents and toolsno prior experience required. Attendees will work hands-on with a working agentic stack, including MCP for agentic tool-calling, and integrate with cloud-native tools such as SPIRE for workload identity, and Keycloak for user management. These existing technologies are key for enabling granular access control and rich audit trails across the full agentic flow. This workshop lays the foundations to building identity-first, zero-trust agentic platforms.",
        "url": "http://kccncna2025.sched.com/event/02ab3d1a41ed305278fa6b2309defaf6",
        "uid": "02ab3d1a41ed305278fa6b2309defaf6",
        "start": "2025-11-11T11:15:00-05:00",
        "end": "2025-11-11T12:30:00-05:00",
        "categories": [
          " TUTORIALS"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 2-3"
        },
        "speakers": [
          {
            "name": "Maia Iyer",
            "company": "Alan Cha"
          },
          {
            "name": "Mariusz Sabath",
            "company": "IBM Research"
          },
          {
            "name": "Anjali Telang",
            "company": " Red Hat"
          },
          {
            "name": "Andrew Block",
            "company": " Red Hat"
          }
        ]
      }
    },
    {
      "text": "In this demo session, we look at securing Agent and MCP communication by building around the construct of an Agent Identity using SPIFFE. We see how agent identity can be used to represent agents taking autonomous action and how a user can give authority to an agent to act \"on-behalf-of\" the user. On the MCP or API side, we need to be able to distinguish when an agent is calling and apply policy to whether calls should proceed.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.* Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: SOLUTIONS SHOWCASE.",
      "metadata": {
        "title": "Sponsored Demo: Agent Identity and Access Management for Enterprise",
        "description": "In this demo session, we look at securing Agent and MCP communication by building around the construct of an Agent Identity using SPIFFE. We see how agent identity can be used to represent agents taking autonomous action and how a user can give authority to an agent to act \"on-behalf-of\" the user. On the MCP or API side, we need to be able to distinguish when an agent is calling and apply policy to whether calls should proceed.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.*",
        "url": "http://kccncna2025.sched.com/event/5c2c16b1dc6b3efc69b9a61a54131d41",
        "uid": "5c2c16b1dc6b3efc69b9a61a54131d41",
        "start": "2025-11-11T11:20:00-05:00",
        "end": "2025-11-11T11:40:00-05:00",
        "categories": [
          "SOLUTIONS SHOWCASE"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "This 20-minute demo showcases how HAProxy One with Universal Mesh helps platform engineers, DevOps teams, and Kubernetes experts solve their toughest connectivity problems. Through a unified, \"sidecarless\" approach, you'll learn how to get unmatched connectivity, security, and the ability to monitor your entire infrastructure.\n\nWe'll show you real-world examples of how it provides:\n\n Routable global services\n Better security and federated trust\n Simpler control over traffic coming in and out (ingress/egress)\n Increased operational efficiency\n Inner edge and outer edge patterns\n\nThrough live diagrams and practical scenarios, you'll see how HAProxy One offers a complete, high-performance solution that turns fragmented infrastructures into a cohesive, secure, and easy-to-manage network. This demo will give you the practical knowledge you need to improve your enterprise connectivity and streamline your operations.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.* Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: SOLUTIONS SHOWCASE.",
      "metadata": {
        "title": "Sponsored Demo: HAProxy & Universal Mesh: Connect Every Service, App, and Cloud",
        "description": "This 20-minute demo showcases how HAProxy One with Universal Mesh helps platform engineers, DevOps teams, and Kubernetes experts solve their toughest connectivity problems. Through a unified, \"sidecarless\" approach, you'll learn how to get unmatched connectivity, security, and the ability to monitor your entire infrastructure.\n\nWe'll show you real-world examples of how it provides:\n\n Routable global services\n Better security and federated trust\n Simpler control over traffic coming in and out (ingress/egress)\n Increased operational efficiency\n Inner edge and outer edge patterns\n\nThrough live diagrams and practical scenarios, you'll see how HAProxy One offers a complete, high-performance solution that turns fragmented infrastructures into a cohesive, secure, and easy-to-manage network. This demo will give you the practical knowledge you need to improve your enterprise connectivity and streamline your operations.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.*",
        "url": "http://kccncna2025.sched.com/event/50e83626895695c39c9dcd54614b2f10",
        "uid": "50e83626895695c39c9dcd54614b2f10",
        "start": "2025-11-11T11:50:00-05:00",
        "end": "2025-11-11T12:10:00-05:00",
        "categories": [
          "SOLUTIONS SHOWCASE"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "As Kubernetes environments grow increasingly complex, platform teams struggle with the escalating challenges of managing multi-tenant clusters efficiently. This session presents a groundbreaking approach to Kubernetes operations, leveraging generative AI and multi-agent collaboration to create a self-healing, intelligent cluster management system. Drawing from real-world implementations, we'll demonstrate how intelligent agents can manage and troubleshoot over 1,000 Kubernetes clusters, dramatically reducing mean time to identify (MTTI) and mean time to resolve (MTTR) for critical cluster issues. Our solution combines advanced AI technologies with GitOps principles to create a comprehensive automation framework that: Intelligently analyzes cluster health using AI-powered introspection Automatically diagnoses complex Kubernetes problems Implements guardrail workflows for secure, validated remediation Orchestrates multi-step resolutions with minimal human intervention Speakers: Vikram Venkataraman from AWS, Srikanth Rajan from Salesforce. Location: Building B | Level 5 | Thomas Murphy Ballroom 1. Categories: AI + ML.",
      "metadata": {
        "title": "1000 Clusters, 1 Brain: Salesforces Approach To Self-Healing Using AIOps",
        "description": "As Kubernetes environments grow increasingly complex, platform teams struggle with the escalating challenges of managing multi-tenant clusters efficiently. This session presents a groundbreaking approach to Kubernetes operations, leveraging generative AI and multi-agent collaboration to create a self-healing, intelligent cluster management system. Drawing from real-world implementations, we'll demonstrate how intelligent agents can manage and troubleshoot over 1,000 Kubernetes clusters, dramatically reducing mean time to identify (MTTI) and mean time to resolve (MTTR) for critical cluster issues. Our solution combines advanced AI technologies with GitOps principles to create a comprehensive automation framework that: Intelligently analyzes cluster health using AI-powered introspection Automatically diagnoses complex Kubernetes problems Implements guardrail workflows for secure, validated remediation Orchestrates multi-step resolutions with minimal human intervention",
        "url": "http://kccncna2025.sched.com/event/db04febfddddb5504ed19b9f0667fb52",
        "uid": "db04febfddddb5504ed19b9f0667fb52",
        "start": "2025-11-11T12:00:00-05:00",
        "end": "2025-11-11T12:30:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 1"
        },
        "speakers": [
          {
            "name": "Vikram Venkataraman",
            "company": "AWS"
          },
          {
            "name": "Srikanth Rajan",
            "company": "Salesforce"
          }
        ]
      }
    },
    {
      "text": "The AI model serving landscape on Kubernetes presents practitioners with an overwhelming array of technology choices: From inference servers like Ray Serve and Triton Inference Server, inference engines like vLLM, and orchestration platforms like Ray Cluster and KServe. While this diversity drives innovation, it also creates complexity. Teams often prematurely standardize on limited technology stacks to manage this complexity. This talk introduces an innovative Helm-based approach that abstracts the complexity of AI model serving while preserving the flexibility to leverage the best tools for each use case. Our solution is accelerator agnostic, and provides a consistent YAML interface for deploying and experimenting with various serving technologies. We'll demonstrate this approach through two concrete examples of multi-node, multi-accelerator model serving with auto scaling: 1/ Ray Serve + vLLM + Ray Cluster, and 2/ LeaderWorkerSet + Triton Inference Server + vLLM + Ray Cluster + HPA. Speakers: Ajay Vohra from Amazon, Tianlu Caron Zhang from Apple. Location: Building B | Level 4 | B401-402. Categories: AI + ML.",
      "metadata": {
        "title": "Simplifying Advanced AI Model Serving on Kubernetes Using Helm Charts",
        "description": "The AI model serving landscape on Kubernetes presents practitioners with an overwhelming array of technology choices: From inference servers like Ray Serve and Triton Inference Server, inference engines like vLLM, and orchestration platforms like Ray Cluster and KServe. While this diversity drives innovation, it also creates complexity. Teams often prematurely standardize on limited technology stacks to manage this complexity. This talk introduces an innovative Helm-based approach that abstracts the complexity of AI model serving while preserving the flexibility to leverage the best tools for each use case. Our solution is accelerator agnostic, and provides a consistent YAML interface for deploying and experimenting with various serving technologies. We'll demonstrate this approach through two concrete examples of multi-node, multi-accelerator model serving with auto scaling: 1/ Ray Serve + vLLM + Ray Cluster, and 2/ LeaderWorkerSet + Triton Inference Server + vLLM + Ray Cluster + HPA.",
        "url": "http://kccncna2025.sched.com/event/41a77cf0486964413a6b79962d7a73cf",
        "uid": "41a77cf0486964413a6b79962d7a73cf",
        "start": "2025-11-11T12:00:00-05:00",
        "end": "2025-11-11T12:30:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B401-402"
        },
        "speakers": [
          {
            "name": "Ajay Vohra",
            "company": "Amazon"
          },
          {
            "name": "Tianlu Caron Zhang",
            "company": "Apple"
          }
        ]
      }
    },
    {
      "text": "Running Java applications in Kubernetes brings a set of performance expectations: fast startup, low memory usage, and efficient container images. This session is a hands-on walkthrough of tools and techniques to help meet those goals. You'll learn how to use Jib to build lean container images, accelerate cold starts with GraalVM native image compilation, and improve runtime responsiveness with Class Data Sharing (CDS) and Coordinated Restore at Checkpoint (CRaC). We'll dive into real-world configuration examples, discuss trade-offs, and demonstrate how to combine these tools to boost performance in Kubernetes-native Java workloads. Speakers: Ryan Jarvinen from Red Hat, Daniel Oh from IBM. Location: Building B | Level 3 | B308-309. Categories: CLOUD NATIVE EXPERIENCE.",
      "metadata": {
        "title": "Performance Tuning Java Apps for Kubernetes: From Startup Time To Container Efficiency",
        "description": "Running Java applications in Kubernetes brings a set of performance expectations: fast startup, low memory usage, and efficient container images. This session is a hands-on walkthrough of tools and techniques to help meet those goals. You'll learn how to use Jib to build lean container images, accelerate cold starts with GraalVM native image compilation, and improve runtime responsiveness with Class Data Sharing (CDS) and Coordinated Restore at Checkpoint (CRaC). We'll dive into real-world configuration examples, discuss trade-offs, and demonstrate how to combine these tools to boost performance in Kubernetes-native Java workloads.",
        "url": "http://kccncna2025.sched.com/event/f4950ba758f189bd30041222336c6359",
        "uid": "f4950ba758f189bd30041222336c6359",
        "start": "2025-11-11T12:00:00-05:00",
        "end": "2025-11-11T12:30:00-05:00",
        "categories": [
          "CLOUD NATIVE EXPERIENCE"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B308-309"
        },
        "speakers": [
          {
            "name": "Ryan Jarvinen",
            "company": "Red Hat"
          },
          {
            "name": "Daniel Oh",
            "company": "IBM"
          }
        ]
      }
    },
    {
      "text": "Kubernetes is quickly becoming the de-facto platform for serving LLM workloads and with the ecosystem evolving at a staggering pace, it can get quite difficult to not only decouple the fundamentals from the diversity of features that so many Kubernetes based solutions offer today, but also understand them in a way that is not overwhelming. What if we could explore the fundamentals of LLM inference, strategies of efficient deployment, GPU scheduling and where Kubernetes comes in, while learning about how to run a cafe? Join us as we tune out the world for some time, geek out and revisit the fundamentals to explore how Kubernetes and LLM inference systems make sense together, and maybe even learn how to run a cafe! Speakers: Madhav Jivrajani from  UIUC, Kartik Ramesh from  UIUC. Location: Building B | Level 2 | B206. Categories: CLOUD NATIVE NOVICE.",
      "metadata": {
        "title": "CafeGPT: Serving LLMs Like Coffee With Kubernetes",
        "description": "Kubernetes is quickly becoming the de-facto platform for serving LLM workloads and with the ecosystem evolving at a staggering pace, it can get quite difficult to not only decouple the fundamentals from the diversity of features that so many Kubernetes based solutions offer today, but also understand them in a way that is not overwhelming. What if we could explore the fundamentals of LLM inference, strategies of efficient deployment, GPU scheduling and where Kubernetes comes in, while learning about how to run a cafe? Join us as we tune out the world for some time, geek out and revisit the fundamentals to explore how Kubernetes and LLM inference systems make sense together, and maybe even learn how to run a cafe!",
        "url": "http://kccncna2025.sched.com/event/91f05197732ac19959ee635e2fefde09",
        "uid": "91f05197732ac19959ee635e2fefde09",
        "start": "2025-11-11T12:00:00-05:00",
        "end": "2025-11-11T12:30:00-05:00",
        "categories": [
          "CLOUD NATIVE NOVICE"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B206"
        },
        "speakers": [
          {
            "name": "Madhav Jivrajani",
            "company": " UIUC"
          },
          {
            "name": "Kartik Ramesh",
            "company": " UIUC"
          }
        ]
      }
    },
    {
      "text": "In this session, The Trade Desk shares how we evolved our HAProxy Community Edition (open source) based load-balancing architecture running on bare metal into a cloud-native, Kubernetes-based Envoy Gateway platform powered by Gateway API. Youll learn how we migrated core services, refactored service discovery, and extended EnvoyGateway with advanced controls such as Circuit Breakers and Zone Aware Routing (plus upstream Envoy contributions) to gain richer control, smarter traffic distribution, and higher resilience across topology zones. Well walk through our key architectural decisions, automation strategies, things we broke along the way, and lessons learned to help you execute a smooth, large-scale migration. Speakers: Isaac Wilson from The Trade Desk. Location: Building B | Level 4 | B405-406a. Categories: CONNECTIVITY.",
      "metadata": {
        "title": "On-Prem Load Balancing Reimagined: Serving 20 Million QPS With Gateway API and EnvoyGateway",
        "description": "In this session, The Trade Desk shares how we evolved our HAProxy Community Edition (open source) based load-balancing architecture running on bare metal into a cloud-native, Kubernetes-based Envoy Gateway platform powered by Gateway API. Youll learn how we migrated core services, refactored service discovery, and extended EnvoyGateway with advanced controls such as Circuit Breakers and Zone Aware Routing (plus upstream Envoy contributions) to gain richer control, smarter traffic distribution, and higher resilience across topology zones. Well walk through our key architectural decisions, automation strategies, things we broke along the way, and lessons learned to help you execute a smooth, large-scale migration.",
        "url": "http://kccncna2025.sched.com/event/a95ac94dad73e7bcfcaf70b387d60045",
        "uid": "a95ac94dad73e7bcfcaf70b387d60045",
        "start": "2025-11-11T12:00:00-05:00",
        "end": "2025-11-11T12:30:00-05:00",
        "categories": [
          "CONNECTIVITY"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B405-406a"
        },
        "speakers": [
          {
            "name": "Isaac Wilson",
            "company": "The Trade Desk"
          }
        ]
      }
    },
    {
      "text": "The Network Policy API working group, part of Kubernetes SIG Network, focuses on designing and evolving APIs to secure Kubernetes cluster networking. Over the past year, the community has been actively working towards graduating the alpha-level AdminNetworkPolicy (ANP) and BaselineAdminNetworkPolicy (BANP) resourcesdesigned to give administrators powerful, cluster-wide controlstowards Beta status. In this session, well take a deep dive into the latest updates to the AdminNetworkPolicy API, including the consolidation of ANP and BANP into a unified resource and improvements to how ports are expressed to allow for greater extensibility. Well also share our roadmap to GA, discuss how you can get involved in shaping the future of Kubernetes network security, and host an open Q&A with project maintainers. Whether you're an operator, contributor, or just curious about cluster-level network policy, this session is for you! Speakers: Dan Winship from  Red Hat, Surya Seetharaman from  Red Hat, Nadia Pinaeva from NVIDIA, Bowei Du from Google. Location: Building C | Level 3 | Georgia Ballroom 3. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "AdminNetworkPolicy: From Alpha To Beta and Beyond",
        "description": "The Network Policy API working group, part of Kubernetes SIG Network, focuses on designing and evolving APIs to secure Kubernetes cluster networking. Over the past year, the community has been actively working towards graduating the alpha-level AdminNetworkPolicy (ANP) and BaselineAdminNetworkPolicy (BANP) resourcesdesigned to give administrators powerful, cluster-wide controlstowards Beta status. In this session, well take a deep dive into the latest updates to the AdminNetworkPolicy API, including the consolidation of ANP and BANP into a unified resource and improvements to how ports are expressed to allow for greater extensibility. Well also share our roadmap to GA, discuss how you can get involved in shaping the future of Kubernetes network security, and host an open Q&A with project maintainers. Whether you're an operator, contributor, or just curious about cluster-level network policy, this session is for you!",
        "url": "http://kccncna2025.sched.com/event/d97f46e414c32adec6038f50ffa88e46",
        "uid": "d97f46e414c32adec6038f50ffa88e46",
        "start": "2025-11-11T12:00:00-05:00",
        "end": "2025-11-11T12:30:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 3"
        },
        "speakers": [
          {
            "name": "Dan Winship",
            "company": " Red Hat"
          },
          {
            "name": "Surya Seetharaman",
            "company": " Red Hat"
          },
          {
            "name": "Nadia Pinaeva",
            "company": "NVIDIA"
          },
          {
            "name": "Bowei Du",
            "company": "Google"
          }
        ]
      }
    },
    {
      "text": "An update to the Maintainer's Track session conducted at CNCF Maintainer Summit EU 2025. Kaslin Fields and I would be doing this updated version. CFP FOLLOWS Most projects have a website. Most projects attempt to establish some form of Social Media presence. However, let's face the hard truth: communications for a project are challenging, and we can encounter various pitfalls. Let's explore the mechanisms and processes you can use in a project to ensure better communication. We begin by identifying mechanisms and target groups for Kubernetes Contributor Communications, what channels to use and will end in drafting social media policies and guidelines for the contributors when they are publishing comms in the name of a project. Also, have you ever considered critical communications for a project - how do you handle communications if something critical is happening? After the session, you have ideas for your project to move towards a more consistent and reliable communication. Speakers: Why Does a Project Need It - Chris Short from CIQ, Kaslin Fields from Google. Location: Building C | Level 3 | Georgia Ballroom 1. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Comms & Social Media",
        "description": "An update to the Maintainer's Track session conducted at CNCF Maintainer Summit EU 2025. Kaslin Fields and I would be doing this updated version. CFP FOLLOWS Most projects have a website. Most projects attempt to establish some form of Social Media presence. However, let's face the hard truth: communications for a project are challenging, and we can encounter various pitfalls. Let's explore the mechanisms and processes you can use in a project to ensure better communication. We begin by identifying mechanisms and target groups for Kubernetes Contributor Communications, what channels to use and will end in drafting social media policies and guidelines for the contributors when they are publishing comms in the name of a project. Also, have you ever considered critical communications for a project - how do you handle communications if something critical is happening? After the session, you have ideas for your project to move towards a more consistent and reliable communication.",
        "url": "http://kccncna2025.sched.com/event/3137b5abecf49019a02b22db94834b66",
        "uid": "3137b5abecf49019a02b22db94834b66",
        "start": "2025-11-11T12:00:00-05:00",
        "end": "2025-11-11T12:30:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 1"
        },
        "speakers": [
          {
            "name": "Why Does a Project Need It - Chris Short",
            "company": "CIQ"
          },
          {
            "name": "Kaslin Fields",
            "company": "Google"
          }
        ]
      }
    },
    {
      "text": "The Rook project will be introduced to attendees of all levels and experience. Rook is an open source cloud-native storage operator for Kubernetes, providing the platform, framework, and support for Ceph to natively integrate with Kubernetes. The panel will discuss various scenarios to show how Rook configures Ceph to provide stable block, shared file system, and object storage for your production data. Rook was accepted as a graduated project by the Cloud Native Computing Foundation in October 2020. Speakers: Blaine Gardner from IBM. Location: Building C | Level 3 | Georgia Ballroom 2. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Rook: Intro and Deep Dive With Ceph Storage",
        "description": "The Rook project will be introduced to attendees of all levels and experience. Rook is an open source cloud-native storage operator for Kubernetes, providing the platform, framework, and support for Ceph to natively integrate with Kubernetes. The panel will discuss various scenarios to show how Rook configures Ceph to provide stable block, shared file system, and object storage for your production data. Rook was accepted as a graduated project by the Cloud Native Computing Foundation in October 2020.",
        "url": "http://kccncna2025.sched.com/event/d44d5fafbea1b211bd543af80db50eac",
        "uid": "d44d5fafbea1b211bd543af80db50eac",
        "start": "2025-11-11T12:00:00-05:00",
        "end": "2025-11-11T12:30:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 2"
        },
        "speakers": [
          {
            "name": "Blaine Gardner",
            "company": "IBM"
          }
        ]
      }
    },
    {
      "text": "Widespread container adoption has inadvertently overburdened developers. While Dockerfiles simplified initial container creation, they lack the abstraction needed to clearly delineate responsibilities between developers and platform teams. This often results in developers managing operational tasks like app containerization, base image maintenance, and remediating third-party vulns--time-consuming burdens that hinder productivity. In addition, platform teams need to manage inconsistencies in Dockerfiles across teams which leads to difficult-to-manage images, and troubleshooting complex builds consumes valuable developer time. Cloud Native Buildpacks (CNBs) provide a solution by enabling a clear separation of concerns. Operations teams can manage base images and security updates, while developers focus on writing code. In this talk, you'll learn how your organization can leverage CNBs to empower developers, enhance security, and optimize your containerization workflows. Speakers: Joe Kutner from Salesforce, Joey Brown from Heroku. Location: Building C | Level 1 | C111-112. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Using Buildpacks To Boost Developer Productivity",
        "description": "Widespread container adoption has inadvertently overburdened developers. While Dockerfiles simplified initial container creation, they lack the abstraction needed to clearly delineate responsibilities between developers and platform teams. This often results in developers managing operational tasks like app containerization, base image maintenance, and remediating third-party vulns--time-consuming burdens that hinder productivity. In addition, platform teams need to manage inconsistencies in Dockerfiles across teams which leads to difficult-to-manage images, and troubleshooting complex builds consumes valuable developer time. Cloud Native Buildpacks (CNBs) provide a solution by enabling a clear separation of concerns. Operations teams can manage base images and security updates, while developers focus on writing code. In this talk, you'll learn how your organization can leverage CNBs to empower developers, enhance security, and optimize your containerization workflows.",
        "url": "http://kccncna2025.sched.com/event/a3b64e8111f84a5c684c4a8c6fafcaa3",
        "uid": "a3b64e8111f84a5c684c4a8c6fafcaa3",
        "start": "2025-11-11T12:00:00-05:00",
        "end": "2025-11-11T12:30:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "1",
          "room": "C111-112"
        },
        "speakers": [
          {
            "name": "Joe Kutner",
            "company": "Salesforce"
          },
          {
            "name": "Joey Brown",
            "company": "Heroku"
          }
        ]
      }
    },
    {
      "text": "In large-scale application services, dashboards serve as windows into system health. But as the number of systems grow, so does the complexity. Dashboards can become outdated, and queries may drift over time. Large Language Models (LLMs) offer a way to simplify the management of dashboards and alerts using natural language prompts. However, integrating this capability into open-source systems is challenging to scale due to fragmented APIs. Enter, Model Context Protocol (MCP), which addresses this challenge by exposing observability primitivesdashboards, datasources, alertsthrough a standardized schema that LLMs can understand. In this session, we'll demonstrate how MCP servers & clients can bridge LLMs with dashboard & alert management tools via natural language. You'll leave with practical techniques to integrate LLMs into your observability visualization stack like Persesno custom wrappers, & no brittle integrations. Speakers: Prashant Gupta from  Apple, Raj Bhensadadia from  Apple. Location: Building B | Level 3 | B304-305. Categories: OBSERVABILITY.",
      "metadata": {
        "title": "Talk To Your Dashboards: Using MCP and LLMs To Simplify Observability",
        "description": "In large-scale application services, dashboards serve as windows into system health. But as the number of systems grow, so does the complexity. Dashboards can become outdated, and queries may drift over time. Large Language Models (LLMs) offer a way to simplify the management of dashboards and alerts using natural language prompts. However, integrating this capability into open-source systems is challenging to scale due to fragmented APIs. Enter, Model Context Protocol (MCP), which addresses this challenge by exposing observability primitivesdashboards, datasources, alertsthrough a standardized schema that LLMs can understand. In this session, we'll demonstrate how MCP servers & clients can bridge LLMs with dashboard & alert management tools via natural language. You'll leave with practical techniques to integrate LLMs into your observability visualization stack like Persesno custom wrappers, & no brittle integrations.",
        "url": "http://kccncna2025.sched.com/event/5ae4f7e9df8978210f13c39d42bc70d8",
        "uid": "5ae4f7e9df8978210f13c39d42bc70d8",
        "start": "2025-11-11T12:00:00-05:00",
        "end": "2025-11-11T12:30:00-05:00",
        "categories": [
          "OBSERVABILITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B304-305"
        },
        "speakers": [
          {
            "name": "Prashant Gupta",
            "company": " Apple"
          },
          {
            "name": "Raj Bhensadadia",
            "company": " Apple"
          }
        ]
      }
    },
    {
      "text": "Deploying updates to web apps installed on managed client devicessuch as airport kiosks or retail POS systemscomes with unique challenges. In this session, well share how we used Kubernetes, Istio, and CI/CD pipelines to implement a location-aware gradual rollout strategy. Rather than applying global traffic weights, we targeted per-location percentages to minimize localized risk. The solution includes release-aware routing, dynamic profile updates, and flexible toolingadaptable across tech stacks for anyone managing applications deployed to physical sites or edge clients. Speakers: Angela Victorio from JP Morgan Chase. Location: Building B | Level 4 | B406b-407. Categories: OPERATIONS + PERFORMANCE.",
      "metadata": {
        "title": "Taming Rollout Risks in Distributed Web Apps: A Location-Aware Gradual Deployment Approach",
        "description": "Deploying updates to web apps installed on managed client devicessuch as airport kiosks or retail POS systemscomes with unique challenges. In this session, well share how we used Kubernetes, Istio, and CI/CD pipelines to implement a location-aware gradual rollout strategy. Rather than applying global traffic weights, we targeted per-location percentages to minimize localized risk. The solution includes release-aware routing, dynamic profile updates, and flexible toolingadaptable across tech stacks for anyone managing applications deployed to physical sites or edge clients.",
        "url": "http://kccncna2025.sched.com/event/44f6751fff4eea139fa8ea709f7325c1",
        "uid": "44f6751fff4eea139fa8ea709f7325c1",
        "start": "2025-11-11T12:00:00-05:00",
        "end": "2025-11-11T12:30:00-05:00",
        "categories": [
          "OPERATIONS + PERFORMANCE"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B406b-407"
        },
        "speakers": [
          {
            "name": "Angela Victorio",
            "company": "JP Morgan Chase"
          }
        ]
      }
    },
    {
      "text": "How do you design and evolve a robust platform for Kubernetes? And how can you ensure seamless testing at every stage, from development to CI pipelines? Join us to dive into the answers, showcasing Chainsaw alongside powerful tools like ArgoCD and Crossplane, to build a simple platform. In this hands-on session, youll: - Define the key expectations for a demo platform. - Watch Charles-Edouard and Viktor implement it live. - Discover how Chainsaw can be seamlessly integrated to test the platform during development and ensure its reliability under CI conditions. This session is designed for platform engineers, DevOps practitioners, and Kubernetes enthusiasts eager to enhance their workflows with practical tools and best practices. Prepare to walk away with actionable insights and inspiration to take your Kubernetes projects to the next level. Dont miss this opportunity to learn from two industry leaders shaping the future of platform engineering! Speakers: Charles-Edouard Breteche from Nirmata, Sara Qasmi from United Nations. Location: Building B | Level 3 | B312-314. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "Platform Engineering in Action: Test-Driven Development Applied To Developer Platforms",
        "description": "How do you design and evolve a robust platform for Kubernetes? And how can you ensure seamless testing at every stage, from development to CI pipelines? Join us to dive into the answers, showcasing Chainsaw alongside powerful tools like ArgoCD and Crossplane, to build a simple platform. In this hands-on session, youll: - Define the key expectations for a demo platform. - Watch Charles-Edouard and Viktor implement it live. - Discover how Chainsaw can be seamlessly integrated to test the platform during development and ensure its reliability under CI conditions. This session is designed for platform engineers, DevOps practitioners, and Kubernetes enthusiasts eager to enhance their workflows with practical tools and best practices. Prepare to walk away with actionable insights and inspiration to take your Kubernetes projects to the next level. Dont miss this opportunity to learn from two industry leaders shaping the future of platform engineering!",
        "url": "http://kccncna2025.sched.com/event/4091d870e0f2b5ed652577d24a2b1ce5",
        "uid": "4091d870e0f2b5ed652577d24a2b1ce5",
        "start": "2025-11-11T12:00:00-05:00",
        "end": "2025-11-11T12:30:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B312-314"
        },
        "speakers": [
          {
            "name": "Charles-Edouard Breteche",
            "company": "Nirmata"
          },
          {
            "name": "Sara Qasmi",
            "company": "United Nations"
          }
        ]
      }
    },
    {
      "text": "As cloud-native architectures continue to scale, ensuring secure communication across microservices is a critical challenge. gRPC is widely adopted for its high performance and efficiency, but achieving end-to-end security in Kubernetes-based deployments introduces unique complexities. This session will explore best practices for securing gRPC applications in Kubernetes environments. We will cover the implementation of TLS and MTLS for encrypted communication, authentication using JWT and OAuth2. Special focus will be given to leveraging Kubernetes-native tools like Cert-Manager and Secrets for certificate management and integrating service meshes such as Istio for automated security configurations. Speakers: Shiva from  Google, Abhishek Agrawal from  Google. Location: Building B | Level 3 | B302-303. Categories: SECURITY.",
      "metadata": {
        "title": "End-to-End Security With gRPC in Kubernetes",
        "description": "As cloud-native architectures continue to scale, ensuring secure communication across microservices is a critical challenge. gRPC is widely adopted for its high performance and efficiency, but achieving end-to-end security in Kubernetes-based deployments introduces unique complexities. This session will explore best practices for securing gRPC applications in Kubernetes environments. We will cover the implementation of TLS and MTLS for encrypted communication, authentication using JWT and OAuth2. Special focus will be given to leveraging Kubernetes-native tools like Cert-Manager and Secrets for certificate management and integrating service meshes such as Istio for automated security configurations.",
        "url": "http://kccncna2025.sched.com/event/fa728aae1956e297a9ef5625423128ff",
        "uid": "fa728aae1956e297a9ef5625423128ff",
        "start": "2025-11-11T12:00:00-05:00",
        "end": "2025-11-11T12:30:00-05:00",
        "categories": [
          "SECURITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B302-303"
        },
        "speakers": [
          {
            "name": "Shiva",
            "company": " Google"
          },
          {
            "name": "Abhishek Agrawal",
            "company": " Google"
          }
        ]
      }
    },
    {
      "text": "Location: TBA. Categories: BREAKS.",
      "metadata": {
        "title": "Lunch ",
        "description": "",
        "url": "http://kccncna2025.sched.com/event/91c8a182736933eaefe3ef27f9798a07",
        "uid": "91c8a182736933eaefe3ef27f9798a07",
        "start": "2025-11-11T12:30:00-05:00",
        "end": "2025-11-11T14:30:00-05:00",
        "categories": [
          "BREAKS"
        ],
        "location": {
          "room": "TBA"
        }
      }
    },
    {
      "text": "VMstore: A demo showing how to dynamically provision and manage persistent volumes for Kubernetes, highlighting ease of use, deployment, and scalability. This would cover their unified management interface for both Virtual Machines (VMs) and containers.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.* Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: SOLUTIONS SHOWCASE.",
      "metadata": {
        "title": "Sponsored Demo: Accelerate, Observe and Secure Kubernetes Deployments with Tintri",
        "description": "VMstore: A demo showing how to dynamically provision and manage persistent volumes for Kubernetes, highlighting ease of use, deployment, and scalability. This would cover their unified management interface for both Virtual Machines (VMs) and containers.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.*",
        "url": "http://kccncna2025.sched.com/event/40e8ebfe1ba68cac8ecabed6b7e1b0f5",
        "uid": "40e8ebfe1ba68cac8ecabed6b7e1b0f5",
        "start": "2025-11-11T12:30:00-05:00",
        "end": "2025-11-11T12:50:00-05:00",
        "categories": [
          "SOLUTIONS SHOWCASE"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "Join us for casual and engaging meetups at the Network Nook during lunch breaks! These informal gatherings are open to all, whether you're a first-time attendee, a solo traveler, or simply looking to chat about shared interests. This is a great way to connect with others.&nbsp;\n\nToday's theme is: 1st Time Attendees\nNew to KubeCon + CloudNativeCon? Connect with fellow first-time attendees, share tips, and get insights from CNCF ambassadors on how to make the most of your conference experience! Location: Building B | Level 1 | Solutions Showcase. Categories: EXPERIENCES.",
      "metadata": {
        "title": "Network Nook Meetup: 1st Time Attendees",
        "description": "Join us for casual and engaging meetups at the Network Nook during lunch breaks! These informal gatherings are open to all, whether you're a first-time attendee, a solo traveler, or simply looking to chat about shared interests. This is a great way to connect with others.&nbsp;\n\nToday's theme is: 1st Time Attendees\nNew to KubeCon + CloudNativeCon? Connect with fellow first-time attendees, share tips, and get insights from CNCF ambassadors on how to make the most of your conference experience!",
        "url": "http://kccncna2025.sched.com/event/2bdc893a2898e5e468326039f9098058",
        "uid": "2bdc893a2898e5e468326039f9098058",
        "start": "2025-11-11T13:00:00-05:00",
        "end": "2025-11-11T14:00:00-05:00",
        "categories": [
          "EXPERIENCES"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Solutions Showcase"
        }
      }
    },
    {
      "text": "Triaging and managing CVEs in container images can be a source of toil for users of open source applications - Do I need to worry about this vulnerability? Does this actually affect my application?\n\nAt Chainguard, we approach solving this problem by building minimal container images leaving little to no known vulnerabilities so that you never need to triage them in the first place. But how does this work?\n\nIn this demo, we'll explore how you can start building your own minimal vulnerability free images! We'll demo packaging an application from start to finish and cover some of the challenges of building minimal container images - how they work, what makes a container image \"distroless\", and tricks for how you can apply this into your own build pipelines.\n\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.* Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: SOLUTIONS SHOWCASE.",
      "metadata": {
        "title": "Sponsored Demo: We build 0 vulnerability container images and so can you!",
        "description": "Triaging and managing CVEs in container images can be a source of toil for users of open source applications - Do I need to worry about this vulnerability? Does this actually affect my application?\n\nAt Chainguard, we approach solving this problem by building minimal container images leaving little to no known vulnerabilities so that you never need to triage them in the first place. But how does this work?\n\nIn this demo, we'll explore how you can start building your own minimal vulnerability free images! We'll demo packaging an application from start to finish and cover some of the challenges of building minimal container images - how they work, what makes a container image \"distroless\", and tricks for how you can apply this into your own build pipelines.\n\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.*",
        "url": "http://kccncna2025.sched.com/event/338b6285cd1431d9fa52136fc985d57b",
        "uid": "338b6285cd1431d9fa52136fc985d57b",
        "start": "2025-11-11T13:00:00-05:00",
        "end": "2025-11-11T13:20:00-05:00",
        "categories": [
          "SOLUTIONS SHOWCASE"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "10-Minute Tip Talk Speakers: Ibrahim Kabiru from  Andela, Nicola Lyons from  Andela. Location: Level 1 | Learning Lounge. Categories: EXPERIENCES.",
      "metadata": {
        "title": "Learning Lounge: Bridging Skill Gaps to Train 30K in Africa",
        "description": "10-Minute Tip Talk",
        "url": "http://kccncna2025.sched.com/event/3ede184171d794b1a7a570ddc9be0421",
        "uid": "3ede184171d794b1a7a570ddc9be0421",
        "start": "2025-11-11T13:15:00-05:00",
        "end": "2025-11-11T13:30:00-05:00",
        "categories": [
          "EXPERIENCES"
        ],
        "location": {
          "level": "1",
          "room": "Learning Lounge"
        },
        "speakers": [
          {
            "name": "Ibrahim Kabiru",
            "company": " Andela"
          },
          {
            "name": "Nicola Lyons",
            "company": " Andela"
          }
        ]
      }
    },
    {
      "text": "Platform engineering is full of high-level concepts, but at the end of the day, someone has to write the code and connect the pipes. This session is for the builders. Well discuss how to architect a solid and secure platform leveraging the best in breed open-source and CNCF projects.\nThis session explores how to build a robust platform using a curated stack of open-source, cloud native technologies. We'll demonstrate how to shift left your security and compliance, creating \"golden paths\" that are not just efficient but also inherently trustworthy. We will cover practical examples of integrating tools for policy-as-code, software supply chain security, and continuous compliance, transforming your platform into a developer accelerator that your security team can finally get behind.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.* Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: SOLUTIONS SHOWCASE.",
      "metadata": {
        "title": "Sponsored Demo: Beyond the YAML: Architecting a Composable, Secure, and Open Source Platform for the Enterprise",
        "description": "Platform engineering is full of high-level concepts, but at the end of the day, someone has to write the code and connect the pipes. This session is for the builders. Well discuss how to architect a solid and secure platform leveraging the best in breed open-source and CNCF projects.\nThis session explores how to build a robust platform using a curated stack of open-source, cloud native technologies. We'll demonstrate how to shift left your security and compliance, creating \"golden paths\" that are not just efficient but also inherently trustworthy. We will cover practical examples of integrating tools for policy-as-code, software supply chain security, and continuous compliance, transforming your platform into a developer accelerator that your security team can finally get behind.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.*",
        "url": "http://kccncna2025.sched.com/event/be6bdcd755510681881814c45780b90a",
        "uid": "be6bdcd755510681881814c45780b90a",
        "start": "2025-11-11T13:30:00-05:00",
        "end": "2025-11-11T13:50:00-05:00",
        "categories": [
          "SOLUTIONS SHOWCASE"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "How CNCF members directly fuel the health and growth of the cloud native community. This session goes beyond sponsorship to show how member contributions, addressing financial support to engineering resources which are vital for sustaining core projects, funding security audits, and enabling community programs. Learn about the tangible impact of membership and what an ideal contributing member looks like. You'll leave with a clear understanding of the virtuous cycle that connects membership to community vitality. Location: Building B | Level 1 | Solutions Showcase. Categories: EXPERIENCES.",
      "metadata": {
        "title": "Becoming an Impactful CNCF Member",
        "description": "How CNCF members directly fuel the health and growth of the cloud native community. This session goes beyond sponsorship to show how member contributions, addressing financial support to engineering resources which are vital for sustaining core projects, funding security audits, and enabling community programs. Learn about the tangible impact of membership and what an ideal contributing member looks like. You'll leave with a clear understanding of the virtuous cycle that connects membership to community vitality.",
        "url": "http://kccncna2025.sched.com/event/06500640fb6d3b43ea2e30a9460238ed",
        "uid": "06500640fb6d3b43ea2e30a9460238ed",
        "start": "2025-11-11T14:00:00-05:00",
        "end": "2025-11-11T14:30:00-05:00",
        "categories": [
          "EXPERIENCES"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Solutions Showcase"
        }
      }
    },
    {
      "text": "Live Security Challenge Speakers: Aleks Jones from LF Education. Location: Level 1 | Learning Lounge. Categories: EXPERIENCES.",
      "metadata": {
        "title": "Learning Lounge: Sensitive Keys in Codebases & Hidden in Layers Contest",
        "description": "Live Security Challenge",
        "url": "http://kccncna2025.sched.com/event/605815ffe6c44e592dff8e6fe6835d8e",
        "uid": "605815ffe6c44e592dff8e6fe6835d8e",
        "start": "2025-11-11T14:00:00-05:00",
        "end": "2025-11-11T14:15:00-05:00",
        "categories": [
          "EXPERIENCES"
        ],
        "location": {
          "level": "1",
          "room": "Learning Lounge"
        },
        "speakers": [
          {
            "name": "Aleks Jones",
            "company": "LF Education"
          }
        ]
      }
    },
    {
      "text": "Tetragon is an open source project that exposes a lot more about what's happening at runtime on Linux Servers. Come Join Duffie Cooley and learn more about how to install it and what types of things it can show. *In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.* Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: SOLUTIONS SHOWCASE.",
      "metadata": {
        "title": "Sponsored Demo: What's new in Tetragon",
        "description": "Tetragon is an open source project that exposes a lot more about what's happening at runtime on Linux Servers. Come Join Duffie Cooley and learn more about how to install it and what types of things it can show. *In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.*",
        "url": "http://kccncna2025.sched.com/event/a9903a817ef27749caef29a623b1c3a0",
        "uid": "a9903a817ef27749caef29a623b1c3a0",
        "start": "2025-11-11T14:00:00-05:00",
        "end": "2025-11-11T14:20:00-05:00",
        "categories": [
          "SOLUTIONS SHOWCASE"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "As more applications for AI models emerge, high-performance, scalable inference is critical to fulfill the increasing demand. However, developing an infrastructure stack to support high-performance inference at scale and integrate the latest innovations can be a challenge.\nThe llm-d project provides an open solution on top of Kubernetes to provide a highly scalable and optimized infrastructure for AI inference. This talk explores the use of llm-d in a real-world application serving inference as well as beginner-developer topics, like \"what is llm-d?\", how llm-d can be applied to achieve a scalable infrastructure for inference workloads, and useful improvements for common challenges. Learn how to leverage llm-d to accelerate your deployment of inference at scale through the discussion of a real-world example. Speakers: Brandon Jacobs from CoreWeave. Location: Building B | Level 5 | Thomas Murphy Ballroom 1. Categories: AI + ML.",
      "metadata": {
        "title": "Best Practices for Leveraging Llm-d for Production-Scale Inference",
        "description": "As more applications for AI models emerge, high-performance, scalable inference is critical to fulfill the increasing demand. However, developing an infrastructure stack to support high-performance inference at scale and integrate the latest innovations can be a challenge.\nThe llm-d project provides an open solution on top of Kubernetes to provide a highly scalable and optimized infrastructure for AI inference. This talk explores the use of llm-d in a real-world application serving inference as well as beginner-developer topics, like \"what is llm-d?\", how llm-d can be applied to achieve a scalable infrastructure for inference workloads, and useful improvements for common challenges. Learn how to leverage llm-d to accelerate your deployment of inference at scale through the discussion of a real-world example.",
        "url": "http://kccncna2025.sched.com/event/2941f6a90dfba305e17f206ca6a670be",
        "uid": "2941f6a90dfba305e17f206ca6a670be",
        "start": "2025-11-11T14:30:00-05:00",
        "end": "2025-11-11T15:00:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 1"
        },
        "speakers": [
          {
            "name": "Brandon Jacobs",
            "company": "CoreWeave"
          }
        ]
      }
    },
    {
      "text": "If you are looking to run multi-node AI inference, AI training, or High Performance Computing workloads, scheduling resources efficiently is imperative. Kubernetes was created to manage microservices which requires reliability, but does not natively handle optimal workload placement. Slurm scheduling does account for the minutiae of node resources, such as node hardware topology, and other desired features such as workload planning, fair use, and batch type scheduling. With Slurms scheduling combined with fine-grained resource control offered by DRA drivers for CPUs, NICS, and GPUs, Kubernetes will be leveled up to support large-scale, granular resource scheduling. We demonstrate how the recently released Slurm Bridge, one of the projects within SlinkyProject, which uses the Kubernetes Scheduling Framework and the Slurm scheduler to drive multi-node workload placement decisions. Speakers: Alan Mutschelknaus from  SchedMD, Tim Wickberg from  SchedMD. Location: Building B | Level 4 | B401-402. Categories: AI + ML.",
      "metadata": {
        "title": "Slurm Bridge: Slurm Scheduling Superpowers in Kubernetes",
        "description": "If you are looking to run multi-node AI inference, AI training, or High Performance Computing workloads, scheduling resources efficiently is imperative. Kubernetes was created to manage microservices which requires reliability, but does not natively handle optimal workload placement. Slurm scheduling does account for the minutiae of node resources, such as node hardware topology, and other desired features such as workload planning, fair use, and batch type scheduling. With Slurms scheduling combined with fine-grained resource control offered by DRA drivers for CPUs, NICS, and GPUs, Kubernetes will be leveled up to support large-scale, granular resource scheduling. We demonstrate how the recently released Slurm Bridge, one of the projects within SlinkyProject, which uses the Kubernetes Scheduling Framework and the Slurm scheduler to drive multi-node workload placement decisions.",
        "url": "http://kccncna2025.sched.com/event/24d22ec7c3a5fe56b40d2473729f4cd2",
        "uid": "24d22ec7c3a5fe56b40d2473729f4cd2",
        "start": "2025-11-11T14:30:00-05:00",
        "end": "2025-11-11T15:00:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B401-402"
        },
        "speakers": [
          {
            "name": "Alan Mutschelknaus",
            "company": " SchedMD"
          },
          {
            "name": "Tim Wickberg",
            "company": " SchedMD"
          }
        ]
      }
    },
    {
      "text": "We've been sold a lie. The cloud native ecosystem promises portabilitywrite once, run anywhere! Just containerize everything, sprinkle some YAML, and you're cloud-agnostic! Except you're not. This talk examines how cloud native applications become inadvertently locked to their cloud provider, despite our best intentions. We'll dissect the subtle ways your \"portable\" application gets married to a specific cloud: from IAM systems that don't translate, to provider-specific load balancers masquerading as standard ingress, to that innocent-looking object storage bucket your app \"temporarily\" writes to. Through real-world examples and architectural patterns, we'll explore the hidden dependencies that make cloud switching a multi-million dollar project, why \"cloud-agnostic\" usually means \"works poorly everywhere,\" the true cost of maintaining actual portability (spoiler: it's more than just running containers), and when portability actually matters versus when it's expensive theater. Speakers: Corey Quinn from The Duckbill Group. Location: Building B | Level 3 | B308-309. Categories: CLOUD NATIVE EXPERIENCE.",
      "metadata": {
        "title": "The Myth of Portability: Why Your Cloud Native App Is Married To Your Provider",
        "description": "We've been sold a lie. The cloud native ecosystem promises portabilitywrite once, run anywhere! Just containerize everything, sprinkle some YAML, and you're cloud-agnostic! Except you're not. This talk examines how cloud native applications become inadvertently locked to their cloud provider, despite our best intentions. We'll dissect the subtle ways your \"portable\" application gets married to a specific cloud: from IAM systems that don't translate, to provider-specific load balancers masquerading as standard ingress, to that innocent-looking object storage bucket your app \"temporarily\" writes to. Through real-world examples and architectural patterns, we'll explore the hidden dependencies that make cloud switching a multi-million dollar project, why \"cloud-agnostic\" usually means \"works poorly everywhere,\" the true cost of maintaining actual portability (spoiler: it's more than just running containers), and when portability actually matters versus when it's expensive theater.",
        "url": "http://kccncna2025.sched.com/event/2e86468a8744f51a5a29f687355f133a",
        "uid": "2e86468a8744f51a5a29f687355f133a",
        "start": "2025-11-11T14:30:00-05:00",
        "end": "2025-11-11T15:00:00-05:00",
        "categories": [
          "CLOUD NATIVE EXPERIENCE"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B308-309"
        },
        "speakers": [
          {
            "name": "Corey Quinn",
            "company": "The Duckbill Group"
          }
        ]
      }
    },
    {
      "text": "Its 9 AM on Monday morning, and youre eager to dig into the new feature youve been designing over the past weeks. You write the code, deploy to testing, send your first request, and... it doesnt work. Now what?\nIf youre new to Kubernetes, this kind of thing can be a showstopper. Kubernetes is powerful and capable, but complex enough that knowing where to look when things go wrong can be a real challenge. This session, well give you what you need for a fighting chance. Well look at how Services, Deployments, and Pods hang together; logging and events (and their strengths and weaknesses); basic observability using a service mesh; health checking; and some common gotchas along the way. Well use Linkerd for our examples, but everything we show is applicable to other technologies as well. Join us and walk away with tools you can use immediately to make life easier! Speakers: Ivan Porta from  Buoyant, Phil Henderson from  Buoyant. Location: Building B | Level 2 | B206. Categories: CLOUD NATIVE NOVICE.",
      "metadata": {
        "title": "Don't Panic! A Beginner's Guide To K8s Debugging",
        "description": "Its 9 AM on Monday morning, and youre eager to dig into the new feature youve been designing over the past weeks. You write the code, deploy to testing, send your first request, and... it doesnt work. Now what?\nIf youre new to Kubernetes, this kind of thing can be a showstopper. Kubernetes is powerful and capable, but complex enough that knowing where to look when things go wrong can be a real challenge. This session, well give you what you need for a fighting chance. Well look at how Services, Deployments, and Pods hang together; logging and events (and their strengths and weaknesses); basic observability using a service mesh; health checking; and some common gotchas along the way. Well use Linkerd for our examples, but everything we show is applicable to other technologies as well. Join us and walk away with tools you can use immediately to make life easier!",
        "url": "http://kccncna2025.sched.com/event/5e16d5395a2dbaf5f66a55c90bb1aa6b",
        "uid": "5e16d5395a2dbaf5f66a55c90bb1aa6b",
        "start": "2025-11-11T14:30:00-05:00",
        "end": "2025-11-11T15:00:00-05:00",
        "categories": [
          "CLOUD NATIVE NOVICE"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B206"
        },
        "speakers": [
          {
            "name": "Ivan Porta",
            "company": " Buoyant"
          },
          {
            "name": "Phil Henderson",
            "company": " Buoyant"
          }
        ]
      }
    },
    {
      "text": "Kubernetes' \"IP-per-pod\" model is often praised for simplifying container networking by providing a flat, routable network that streamlines application deployment. But what happens when that \"simplification\" becomes a significant hurdle? Effective IP address management (IPAM) is challenging, and cluster administrators must carefully plan network connectivity as these early decisions are often irreversible.\nThis talk will cover fundamental Kubernetes IPAM concepts, including CNI plugin roles and IP assignment for pods/services/nodes. Well explore IPAM modes and address common challenges, like IP exhaustion (CIDR allocation, subnetting), dual-stack (IPv4/IPv6) complexities, and troubleshooting connectivity problems.\nFinally, we will cover new Kubernetes IPAM features such as Extend Service IP Range alongside a general look at common IPAM solutions. Attendees will gain knowledge to design, implement, and troubleshoot robust and scalable solutions for their containerized applications. Speakers: Ivy Zhuang from  Google, Whitney Jenkins from  Google. Location: Building B | Level 4 | B405-406a. Categories: CONNECTIVITY.",
      "metadata": {
        "title": "Kubernetes IP Management: From Core Concepts To Strategic Solutions",
        "description": "Kubernetes' \"IP-per-pod\" model is often praised for simplifying container networking by providing a flat, routable network that streamlines application deployment. But what happens when that \"simplification\" becomes a significant hurdle? Effective IP address management (IPAM) is challenging, and cluster administrators must carefully plan network connectivity as these early decisions are often irreversible.\nThis talk will cover fundamental Kubernetes IPAM concepts, including CNI plugin roles and IP assignment for pods/services/nodes. Well explore IPAM modes and address common challenges, like IP exhaustion (CIDR allocation, subnetting), dual-stack (IPv4/IPv6) complexities, and troubleshooting connectivity problems.\nFinally, we will cover new Kubernetes IPAM features such as Extend Service IP Range alongside a general look at common IPAM solutions. Attendees will gain knowledge to design, implement, and troubleshoot robust and scalable solutions for their containerized applications.",
        "url": "http://kccncna2025.sched.com/event/6852dc1f688d4ddec1f9c86cca5743a3",
        "uid": "6852dc1f688d4ddec1f9c86cca5743a3",
        "start": "2025-11-11T14:30:00-05:00",
        "end": "2025-11-11T15:00:00-05:00",
        "categories": [
          "CONNECTIVITY"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B405-406a"
        },
        "speakers": [
          {
            "name": "Ivy Zhuang",
            "company": " Google"
          },
          {
            "name": "Whitney Jenkins",
            "company": " Google"
          }
        ]
      }
    },
    {
      "text": "The Cloud Native Capture The Flag (CTF) is available to all KubeCon + CloudNativeCon attendees. &nbsp;In preparation for starting the activity, you are invited to attend an introductory session.\n\nThis session aims to introduce how to participate in CTF competition to those new to them. We will share tips and tricks for completing these challenges and work through a practice scenario together. Location: Building B | Level 2 | B203. Categories: EXPERIENCES.",
      "metadata": {
        "title": "An Introduction to Capture The Flag",
        "description": "The Cloud Native Capture The Flag (CTF) is available to all KubeCon + CloudNativeCon attendees. &nbsp;In preparation for starting the activity, you are invited to attend an introductory session.\n\nThis session aims to introduce how to participate in CTF competition to those new to them. We will share tips and tricks for completing these challenges and work through a practice scenario together.",
        "url": "http://kccncna2025.sched.com/event/dbebf48db275604541198c7a1c51158d",
        "uid": "dbebf48db275604541198c7a1c51158d",
        "start": "2025-11-11T14:30:00-05:00",
        "end": "2025-11-11T15:15:00-05:00",
        "categories": [
          "EXPERIENCES"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B203"
        }
      }
    },
    {
      "text": "As the container ecosystem continues to evolve, CRI-O is innovating to meet new challenges. In this session, we will explore the latest advancements in CRI-O, including support for OCI Artifacts beyond container images, such as AI and ML model deployment, as well as new security features like advanced seccomp profile controls and customizable stop signal handling. We'll also highlight performance and infrastructure updates. Through demos, we'll examine these capabilities and preview future additions. Attendees will gain insights to improve the security, adaptability, and operational efficiency of their container environments. This talk is ideal for SysAdmins, SREs, and Developers. Speakers: Ayato Tokubi from  Red Hat, Sohan Kunkerkar from  Red Hat. Location: Building C | Level 3 | Georgia Ballroom 3. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "CRI-O: Thriving in a Changing World, One Container at a Time",
        "description": "As the container ecosystem continues to evolve, CRI-O is innovating to meet new challenges. In this session, we will explore the latest advancements in CRI-O, including support for OCI Artifacts beyond container images, such as AI and ML model deployment, as well as new security features like advanced seccomp profile controls and customizable stop signal handling. We'll also highlight performance and infrastructure updates. Through demos, we'll examine these capabilities and preview future additions. Attendees will gain insights to improve the security, adaptability, and operational efficiency of their container environments. This talk is ideal for SysAdmins, SREs, and Developers.",
        "url": "http://kccncna2025.sched.com/event/521bcc1d4fed334eed3420db41d8e287",
        "uid": "521bcc1d4fed334eed3420db41d8e287",
        "start": "2025-11-11T14:30:00-05:00",
        "end": "2025-11-11T15:00:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 3"
        },
        "speakers": [
          {
            "name": "Ayato Tokubi",
            "company": " Red Hat"
          },
          {
            "name": "Sohan Kunkerkar",
            "company": " Red Hat"
          }
        ]
      }
    },
    {
      "text": "Dive into Cortex with us in this interactive session designed to help you get started with one of the most powerful open-source metrics platforms. Well also highlight key improvements from the latest 1.19 release and share whats ahead on the roadmap. Whether youre just beginning your journey with Cortex or already contributing to the project, youll walk away with practical insights and expert tips. Stick around for a live Q&A with core maintainersyour chance to ask questions, share thoughts, and connect directly with the team driving Cortex forward. Speakers: Friedrich Gonzalez from Charlie Le, Alolita Sharma from Apple, Anand Rajagopal from Amazon Web Services. Location: Building C | Level 3 | Georgia Ballroom 1. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Discover Cortex: High Scalability Metrics in 2025",
        "description": "Dive into Cortex with us in this interactive session designed to help you get started with one of the most powerful open-source metrics platforms. Well also highlight key improvements from the latest 1.19 release and share whats ahead on the roadmap. Whether youre just beginning your journey with Cortex or already contributing to the project, youll walk away with practical insights and expert tips. Stick around for a live Q&A with core maintainersyour chance to ask questions, share thoughts, and connect directly with the team driving Cortex forward.",
        "url": "http://kccncna2025.sched.com/event/6a91cfd2240e48a218f48450fccf0de5",
        "uid": "6a91cfd2240e48a218f48450fccf0de5",
        "start": "2025-11-11T14:30:00-05:00",
        "end": "2025-11-11T15:00:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 1"
        },
        "speakers": [
          {
            "name": "Friedrich Gonzalez",
            "company": "Charlie Le"
          },
          {
            "name": "Alolita Sharma",
            "company": "Apple"
          },
          {
            "name": "Anand Rajagopal",
            "company": "Amazon Web Services"
          }
        ]
      }
    },
    {
      "text": "The CNCF Technical Advisory Groups (TAGs) play a vital role in shaping the future of cloud native. Were excited to introduce a new addition: the TAG Workloads Foundation. This session will present the mission, scope, and early initiatives of TAG Workloads Foundation, focused on defining and advancing practices and standards for cloud native workload execution environments and lifecycle management. Attendees will learn how this TAG supports the CNCF's technical vision, why workload execution is critical for adopters, and how community members can get involved to help solve real-world challenges across container platforms, schedulers, orchestration systems, etc. Join us to help shape the next phase of cloud native maturityfrom fundamental runtime environments to future-forward workload patterns. Speakers: Yuan Tang from Red Hat, Paco Xu from DaoCloud, Marlow Weston from SchedMD, Rajas Kakodkar from Broadcom, Stephen Rust from Akamai. Location: Building C | Level 3 | Georgia Ballroom 2. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Introducing TAG Workloads Foundation: Advancing the Core of Cloud Native Execution",
        "description": "The CNCF Technical Advisory Groups (TAGs) play a vital role in shaping the future of cloud native. Were excited to introduce a new addition: the TAG Workloads Foundation. This session will present the mission, scope, and early initiatives of TAG Workloads Foundation, focused on defining and advancing practices and standards for cloud native workload execution environments and lifecycle management. Attendees will learn how this TAG supports the CNCF's technical vision, why workload execution is critical for adopters, and how community members can get involved to help solve real-world challenges across container platforms, schedulers, orchestration systems, etc. Join us to help shape the next phase of cloud native maturityfrom fundamental runtime environments to future-forward workload patterns.",
        "url": "http://kccncna2025.sched.com/event/30afcaff87e83e2fcb13ecd3ecd826a4",
        "uid": "30afcaff87e83e2fcb13ecd3ecd826a4",
        "start": "2025-11-11T14:30:00-05:00",
        "end": "2025-11-11T15:00:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 2"
        },
        "speakers": [
          {
            "name": "Yuan Tang",
            "company": "Red Hat"
          },
          {
            "name": "Paco Xu",
            "company": "DaoCloud"
          },
          {
            "name": "Marlow Weston",
            "company": "SchedMD"
          },
          {
            "name": "Rajas Kakodkar",
            "company": "Broadcom"
          },
          {
            "name": "Stephen Rust",
            "company": "Akamai"
          }
        ]
      }
    },
    {
      "text": "As software supply chain threats increase, verifying the provenance and integrity of container images is essential for securing Kubernetes workloads. The SLSA framework provides a standardized way to achieve this through artifact attestations, and platforms like GitHub have begun integrating provenance features into their CI/CD systems. However, organizations often face practical challenges when verifying these attestations at deployment time, particularly in controlled or restricted environments.\n\nIn this talk, maintainers from Microsoft Azure and Alibaba Cloud will introduce upcoming support for SLSA attestation verification in the Notary Project and Ratify. Well demonstrate how these open-source tools enable policy-based verification of OCI artifact attestations across cloud providers and on-premise, making them suitable for a wide range of enterprise and Kubernetes scenarios. Speakers: Feynman Zhou from Microsoft, Dahu Kuang from Alibaba Cloud. Location: Building C | Level 1 | C111-112. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Strengthening Supply Chain for Kubernetes: Cross-Cloud SLSA Attestation Verification",
        "description": "As software supply chain threats increase, verifying the provenance and integrity of container images is essential for securing Kubernetes workloads. The SLSA framework provides a standardized way to achieve this through artifact attestations, and platforms like GitHub have begun integrating provenance features into their CI/CD systems. However, organizations often face practical challenges when verifying these attestations at deployment time, particularly in controlled or restricted environments.\n\nIn this talk, maintainers from Microsoft Azure and Alibaba Cloud will introduce upcoming support for SLSA attestation verification in the Notary Project and Ratify. Well demonstrate how these open-source tools enable policy-based verification of OCI artifact attestations across cloud providers and on-premise, making them suitable for a wide range of enterprise and Kubernetes scenarios.",
        "url": "http://kccncna2025.sched.com/event/49c572fafc3bd2493316e626c7904d88",
        "uid": "49c572fafc3bd2493316e626c7904d88",
        "start": "2025-11-11T14:30:00-05:00",
        "end": "2025-11-11T15:00:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "1",
          "room": "C111-112"
        },
        "speakers": [
          {
            "name": "Feynman Zhou",
            "company": "Microsoft"
          },
          {
            "name": "Dahu Kuang",
            "company": "Alibaba Cloud"
          }
        ]
      }
    },
    {
      "text": "Managing and understanding thousands of workload rollouts is challengingespecially in Kubernetes, where the system is always converging, making it difficult to track deployment origins, changes, and statuses. Developers and platform teams want clear answers: Did the rollout succeed? What changed? Is it stable? At LinkedIn, we handle 50,000+ app deployments weekly, making visibility and quick debugging crucial. Weve built a system that tracks every changefrom pipeline-triggered rollouts and kubectl edits to controller-driven podSpec mutationscapturing both the source and the result. It helps surface failure reasons such as pod scheduling issues, app/init container crashes, and image pull delays. In this talk, well share our journey building a unified system, categorizing failures, simplifying interactions by abstracting Kubernetes, and delivering out-of-the-box app health metrics. Our goal: to enhance platform reliability and streamline the developer experience with Kubernetes. Speakers: Vasudev Bongale from LinkedIn. Location: Building B | Level 3 | B304-305. Categories: OBSERVABILITY.",
      "metadata": {
        "title": "Making Application Rollouts Observable, Actionable and Boring",
        "description": "Managing and understanding thousands of workload rollouts is challengingespecially in Kubernetes, where the system is always converging, making it difficult to track deployment origins, changes, and statuses. Developers and platform teams want clear answers: Did the rollout succeed? What changed? Is it stable? At LinkedIn, we handle 50,000+ app deployments weekly, making visibility and quick debugging crucial. Weve built a system that tracks every changefrom pipeline-triggered rollouts and kubectl edits to controller-driven podSpec mutationscapturing both the source and the result. It helps surface failure reasons such as pod scheduling issues, app/init container crashes, and image pull delays. In this talk, well share our journey building a unified system, categorizing failures, simplifying interactions by abstracting Kubernetes, and delivering out-of-the-box app health metrics. Our goal: to enhance platform reliability and streamline the developer experience with Kubernetes.",
        "url": "http://kccncna2025.sched.com/event/92c6023521cbcbff79262d3f7bf2e7d5",
        "uid": "92c6023521cbcbff79262d3f7bf2e7d5",
        "start": "2025-11-11T14:30:00-05:00",
        "end": "2025-11-11T15:00:00-05:00",
        "categories": [
          "OBSERVABILITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B304-305"
        },
        "speakers": [
          {
            "name": "Vasudev Bongale",
            "company": "LinkedIn"
          }
        ]
      }
    },
    {
      "text": "Divvying up a network card using Kubernetes is really hard to do. If you need to spin up virtual interfaces on top of a NIC, limit their bandwidth, and hand them out to different Pods, you will have a rough time. Come find out how the Kubernetes project will make sharing network hardware just as easy as sharing node CPU and memory! And networking is just the initial use case - this functionality can work with any device. Being able to sub-divide devices will really improve utilization of your pricey hardware. In this talk, we detail a new way to request resources from attached devices like NICs, GPUs, and DPUs. Building on the recently released Device Resource Allocation (DRA), this feature performs on-demand provisioning based on resource requests, allowing a physical device to be independently shared among Pods multiple times. It extends K8s multi-tenancy to the sub-device level. Well dive deep and explore real-world use cases, under the hood details, and future extensions. Speakers: Sunyanan Choochotkaew from IBM Research, John Belamaric from Google. Location: Building B | Level 4 | B406b-407. Categories: OPERATIONS + PERFORMANCE.",
      "metadata": {
        "title": "Share With Care: Efficient Device Sharing With Guaranteed Resources Using DRA",
        "description": "Divvying up a network card using Kubernetes is really hard to do. If you need to spin up virtual interfaces on top of a NIC, limit their bandwidth, and hand them out to different Pods, you will have a rough time. Come find out how the Kubernetes project will make sharing network hardware just as easy as sharing node CPU and memory! And networking is just the initial use case - this functionality can work with any device. Being able to sub-divide devices will really improve utilization of your pricey hardware. In this talk, we detail a new way to request resources from attached devices like NICs, GPUs, and DPUs. Building on the recently released Device Resource Allocation (DRA), this feature performs on-demand provisioning based on resource requests, allowing a physical device to be independently shared among Pods multiple times. It extends K8s multi-tenancy to the sub-device level. Well dive deep and explore real-world use cases, under the hood details, and future extensions.",
        "url": "http://kccncna2025.sched.com/event/2ab41193b1ca885a329cf8a49127d27b",
        "uid": "2ab41193b1ca885a329cf8a49127d27b",
        "start": "2025-11-11T14:30:00-05:00",
        "end": "2025-11-11T15:00:00-05:00",
        "categories": [
          "OPERATIONS + PERFORMANCE"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B406b-407"
        },
        "speakers": [
          {
            "name": "Sunyanan Choochotkaew",
            "company": "IBM Research"
          },
          {
            "name": "John Belamaric",
            "company": "Google"
          }
        ]
      }
    },
    {
      "text": "Are your Kubernetes costs spiraling out of control? You're not aloneand there's no silver bullet. This talk explores the most common cost pitfalls in Kubernetes environments and offers multiple, practical solutions that teams can tailor to their needs. We'll dive into real-world FinOps challenges like over-provisioned workloads, idle resources, inefficient scaling, and lack of governance. You'll learn how tools like Karpenter, VPA, Spot Instances, cleanup utilities, and policy enforcement each solve a piece of the puzzle. Whether you're just starting out or trying to reduce an already hefty bill, this session will help you map the right strategies to your workloads and teams. Expect hands-on examples, decision criteria, and battle-tested tips to help you slash your cloud spendwithout compromising on performance or velocity. Speakers: Dolis Sharma from Nirmata. Location: Building B | Level 3 | B312-314. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "Real-World Strategies for Cutting Kubernetes Costs: Why One Size Doesnt Fit All",
        "description": "Are your Kubernetes costs spiraling out of control? You're not aloneand there's no silver bullet. This talk explores the most common cost pitfalls in Kubernetes environments and offers multiple, practical solutions that teams can tailor to their needs. We'll dive into real-world FinOps challenges like over-provisioned workloads, idle resources, inefficient scaling, and lack of governance. You'll learn how tools like Karpenter, VPA, Spot Instances, cleanup utilities, and policy enforcement each solve a piece of the puzzle. Whether you're just starting out or trying to reduce an already hefty bill, this session will help you map the right strategies to your workloads and teams. Expect hands-on examples, decision criteria, and battle-tested tips to help you slash your cloud spendwithout compromising on performance or velocity.",
        "url": "http://kccncna2025.sched.com/event/7fd7dd1c0085e6f318e9d016f23f3543",
        "uid": "7fd7dd1c0085e6f318e9d016f23f3543",
        "start": "2025-11-11T14:30:00-05:00",
        "end": "2025-11-11T15:00:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B312-314"
        },
        "speakers": [
          {
            "name": "Dolis Sharma",
            "company": "Nirmata"
          }
        ]
      }
    },
    {
      "text": "At State Farm, securing microservices across multi-cluster K8s environments demanded a robust zero-trust architecture. Our initial bespoke SPIFFE/SPIRE deployment provided workload identities but faltered under scale. To achieve enterprise-grade resilience, we transitioned to an HA nestedSpire architecture, enabling seamless integration with ESO for secure secret retrieval. This talk shares our journey, from debugging 500 errors in ESOs webhook-based SecretStore to scaling SPIRE agents. Well detail how we configured nestedSpire for HA, integrated SPIFFE SVIDs with ESOs webhook authentication, and automated secret rotation to remove credential leaks. Attendees will learn steps for deploying nestedSpire, troubleshooting common issues (like attestation failures). Well share lessons from our bespoke-to-bulletproof evolution. Whether youre adopting SPIRE or optimizing an existing setup, this talk offers a blueprint for building scalable, secure zero-trust systems in Kubernetes. Speakers: May Large from  State Farm, Ivy Moore from  State Farm. Location: Building B | Level 3 | B302-303. Categories: SECURITY.",
      "metadata": {
        "title": "From Bespoke To Bulletproof: SPIFFE/SPIRE With ESO for Enterprise Zero Trust",
        "description": "At State Farm, securing microservices across multi-cluster K8s environments demanded a robust zero-trust architecture. Our initial bespoke SPIFFE/SPIRE deployment provided workload identities but faltered under scale. To achieve enterprise-grade resilience, we transitioned to an HA nestedSpire architecture, enabling seamless integration with ESO for secure secret retrieval. This talk shares our journey, from debugging 500 errors in ESOs webhook-based SecretStore to scaling SPIRE agents. Well detail how we configured nestedSpire for HA, integrated SPIFFE SVIDs with ESOs webhook authentication, and automated secret rotation to remove credential leaks. Attendees will learn steps for deploying nestedSpire, troubleshooting common issues (like attestation failures). Well share lessons from our bespoke-to-bulletproof evolution. Whether youre adopting SPIRE or optimizing an existing setup, this talk offers a blueprint for building scalable, secure zero-trust systems in Kubernetes.",
        "url": "http://kccncna2025.sched.com/event/c6eb3d7f2c9053ff9258d7926198d621",
        "uid": "c6eb3d7f2c9053ff9258d7926198d621",
        "start": "2025-11-11T14:30:00-05:00",
        "end": "2025-11-11T15:00:00-05:00",
        "categories": [
          "SECURITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B302-303"
        },
        "speakers": [
          {
            "name": "May Large",
            "company": " State Farm"
          },
          {
            "name": "Ivy Moore",
            "company": " State Farm"
          }
        ]
      }
    },
    {
      "text": "Last year, we built a multi-agent RAG system to streamline intelligent document processing. This year, were taking it a step further by integrating the Agent2Agent (A2A) protocol, an open standard from Google that enables seamless communication between AI agents. In this session, well share how we transformed our RAG system from a standalone tool into a fully interoperable agent capable of collaborating within complex multi-agent ecosystems, unlocking richer automation and smarter workflows.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.* Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: SOLUTIONS SHOWCASE.",
      "metadata": {
        "title": "Sponsored Demo: Agent2Agent Protocol Integration in a Multi-Agent RAG System",
        "description": "Last year, we built a multi-agent RAG system to streamline intelligent document processing. This year, were taking it a step further by integrating the Agent2Agent (A2A) protocol, an open standard from Google that enables seamless communication between AI agents. In this session, well share how we transformed our RAG system from a standalone tool into a fully interoperable agent capable of collaborating within complex multi-agent ecosystems, unlocking richer automation and smarter workflows.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.*",
        "url": "http://kccncna2025.sched.com/event/e87c0c6a5ae2bd0ebc3ce7ff25d771ea",
        "uid": "e87c0c6a5ae2bd0ebc3ce7ff25d771ea",
        "start": "2025-11-11T14:30:00-05:00",
        "end": "2025-11-11T14:50:00-05:00",
        "categories": [
          "SOLUTIONS SHOWCASE"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "Join the Argo maintainers for an interactive session designed to jumpstart your contribution journey! This workshop is perfect for aspiring contributors and experienced users who are ready to dive into the Argo CD codebase and resolve issues, but need a helping hand with their local development environment.\nWe will walk you through the essential steps to set up your local Argo CD development environment, provide practical guidance on debugging issues within the codebase and help you run the linter, unit tests and e2e tests locally.\nBy the end of this session, you'll have a fully functional local Argo CD development environment and the confidence to debug issues and submit your valuable contributions to the project! And if your environment is already configured, you can still join us to tackle open issues or to discuss future enhancements to the project.\nDont forget your laptop, join our thriving community and start contributing! Speakers: Alexandre Gaudreault from Peter Jiang, Codey Jenkins from Intuit, Nitish Kumar from Akuity. Location: Building B | Level 2 | B207. Categories:  CONTRIBFEST.",
      "metadata": {
        "title": "Contribfest: Argo: Configure Your Local Setup and Contribute!",
        "description": "Join the Argo maintainers for an interactive session designed to jumpstart your contribution journey! This workshop is perfect for aspiring contributors and experienced users who are ready to dive into the Argo CD codebase and resolve issues, but need a helping hand with their local development environment.\nWe will walk you through the essential steps to set up your local Argo CD development environment, provide practical guidance on debugging issues within the codebase and help you run the linter, unit tests and e2e tests locally.\nBy the end of this session, you'll have a fully functional local Argo CD development environment and the confidence to debug issues and submit your valuable contributions to the project! And if your environment is already configured, you can still join us to tackle open issues or to discuss future enhancements to the project.\nDont forget your laptop, join our thriving community and start contributing!",
        "url": "http://kccncna2025.sched.com/event/e19c407664659109f64ef94c1a4033c1",
        "uid": "e19c407664659109f64ef94c1a4033c1",
        "start": "2025-11-11T14:30:00-05:00",
        "end": "2025-11-11T15:45:00-05:00",
        "categories": [
          " CONTRIBFEST"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B207"
        },
        "speakers": [
          {
            "name": "Alexandre Gaudreault",
            "company": "Peter Jiang"
          },
          {
            "name": "Codey Jenkins",
            "company": "Intuit"
          },
          {
            "name": "Nitish Kumar",
            "company": "Akuity"
          }
        ]
      }
    },
    {
      "text": "Many CNCF tools and projects could become more accessible if they had a UI or an AI chat interface that's integrated where users can also explore other Kubernetes resources and tools. But how to do this without having to \"reinvent the wheel\" or maintain much more than the projects need? This is exactly what Headlamp enables!\n\nHeadlamp is an extensible Kubernetes UI that is part of the Kubernetes project under the SIG UI. It offers a great base UX for managing Kubernetes and serves as a building block for creating new user interfaces and user experiences, including extending its own AI assistant interface.\n\nSo join us to explore Headlamp! Whether you're looking to contribute or use it for your own project, everyone is welcome! We'll run a quick workshop on building plugins and contributing to the core project. We're also excited to brainstorm ways to improve Headlamp and the Kubernetes UX in general. Lets build together! Speakers: Joaquim Rocha from  Microsoft, Oleksandr Dubenko from  Microsoft. Location: Building B | Level 2 | B208. Categories:  CONTRIBFEST.",
      "metadata": {
        "title": "Contribfest: Power up Your CNCF Tools With Headlamp",
        "description": "Many CNCF tools and projects could become more accessible if they had a UI or an AI chat interface that's integrated where users can also explore other Kubernetes resources and tools. But how to do this without having to \"reinvent the wheel\" or maintain much more than the projects need? This is exactly what Headlamp enables!\n\nHeadlamp is an extensible Kubernetes UI that is part of the Kubernetes project under the SIG UI. It offers a great base UX for managing Kubernetes and serves as a building block for creating new user interfaces and user experiences, including extending its own AI assistant interface.\n\nSo join us to explore Headlamp! Whether you're looking to contribute or use it for your own project, everyone is welcome! We'll run a quick workshop on building plugins and contributing to the core project. We're also excited to brainstorm ways to improve Headlamp and the Kubernetes UX in general. Lets build together!",
        "url": "http://kccncna2025.sched.com/event/64f3a8a16c87593db5a9f599f9cabae0",
        "uid": "64f3a8a16c87593db5a9f599f9cabae0",
        "start": "2025-11-11T14:30:00-05:00",
        "end": "2025-11-11T15:45:00-05:00",
        "categories": [
          " CONTRIBFEST"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B208"
        },
        "speakers": [
          {
            "name": "Joaquim Rocha",
            "company": " Microsoft"
          },
          {
            "name": "Oleksandr Dubenko",
            "company": " Microsoft"
          }
        ]
      }
    },
    {
      "text": "Explore the world of platform engineering with open-source cloud native tooling in this hands-on workshop.\n\nThis hands-on workshop is led by open-source experts who will guide you through building a real Internal Developer Platform (IDP) using production-proven CNCF tools like Crossplane, Backstage, Argo CD, and Kyverno. We will cover the tools and practices needed to gain platform adoption and discover how other companies are using these tools to expedite their platform journey. Speakers: Ana Margarita Medina from Upbound, Cortney Nickerson from Nirmata, Scott Rosenberg from TeraSky, Christian Hernandez from GitOps Advocate. Location: Building B | Level 5 | Thomas Murphy Ballroom 2-3. Categories:  TUTORIALS.",
      "metadata": {
        "title": "Tutorial: Build Your Internal Developer Platform With the Experts: A Hands-On Workshop",
        "description": "Explore the world of platform engineering with open-source cloud native tooling in this hands-on workshop.\n\nThis hands-on workshop is led by open-source experts who will guide you through building a real Internal Developer Platform (IDP) using production-proven CNCF tools like Crossplane, Backstage, Argo CD, and Kyverno. We will cover the tools and practices needed to gain platform adoption and discover how other companies are using these tools to expedite their platform journey.",
        "url": "http://kccncna2025.sched.com/event/ef986be486a21d5caf706f6936ae9f14",
        "uid": "ef986be486a21d5caf706f6936ae9f14",
        "start": "2025-11-11T14:30:00-05:00",
        "end": "2025-11-11T15:45:00-05:00",
        "categories": [
          " TUTORIALS"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 2-3"
        },
        "speakers": [
          {
            "name": "Ana Margarita Medina",
            "company": "Upbound"
          },
          {
            "name": "Cortney Nickerson",
            "company": "Nirmata"
          },
          {
            "name": "Scott Rosenberg",
            "company": "TeraSky"
          },
          {
            "name": "Christian Hernandez",
            "company": "GitOps Advocate"
          }
        ]
      }
    },
    {
      "text": "Smarter Together: Orchestrating Multi-Agent AI Systems with A2A and MCP on Containers AI is moving beyond single models into distributed, agent-based ecosystems. In this talk, well explore how to orchestrate multi-agent systems using Agent-to-Agent (A2A) communication and Model Context Protocol (MCP), running in containerized, cloud-native environments. Through a live scenario, well show how an orchestrator agent deployed in Kubernetes coordinates autonomous agents running in Azure and GCP. Attendees will learn how to enable secure, cross-cloud collaboration between agents, share memory context using MCP, and scale intelligent workflows across containers. If youre building AI copilots or multi-agent platforms, this session will help you design modular and interoperable architectures with modern AI infrastructure. Speakers: Ana Maria Lopez Moreno from Microsoft, Sharon Camacho from Summan. Location: Building B | Level 4 | B401-402. Categories: AI + ML.",
      "metadata": {
        "title": "Smarter Together: Orchestrating Multi-Agent AI Systems With A2A and MCP on Containers",
        "description": "Smarter Together: Orchestrating Multi-Agent AI Systems with A2A and MCP on Containers AI is moving beyond single models into distributed, agent-based ecosystems. In this talk, well explore how to orchestrate multi-agent systems using Agent-to-Agent (A2A) communication and Model Context Protocol (MCP), running in containerized, cloud-native environments. Through a live scenario, well show how an orchestrator agent deployed in Kubernetes coordinates autonomous agents running in Azure and GCP. Attendees will learn how to enable secure, cross-cloud collaboration between agents, share memory context using MCP, and scale intelligent workflows across containers. If youre building AI copilots or multi-agent platforms, this session will help you design modular and interoperable architectures with modern AI infrastructure.",
        "url": "http://kccncna2025.sched.com/event/68ff66281ff17c05885626be1765a541",
        "uid": "68ff66281ff17c05885626be1765a541",
        "start": "2025-11-11T15:15:00-05:00",
        "end": "2025-11-11T15:45:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B401-402"
        },
        "speakers": [
          {
            "name": "Ana Maria Lopez Moreno",
            "company": "Microsoft"
          },
          {
            "name": "Sharon Camacho",
            "company": "Summan"
          }
        ]
      }
    },
    {
      "text": "Modern applications need to respond to real-world eventsuser actions, system signals, business milestones. Explore a flexible approach to orchestrating workflows that grow step by step without locking you into a fixed structure.\n\nThis talk introduces a new way to build event-driven applications using Sveltos, an open source tool for declarative multi-cluster orchestration, and NATS, a lightweight messaging system designed for speed and simplicity. Instead of rigid execution graphs, this model uses declarative triggers for event-driven behavior, built on the CloudEvents standard, to guide how workflows evolve.\n\nAnd the best part: each step runs in a standard Kubernetes Job, making these applications easy to build, test, and extend using familiar tooling.\n\nAttendees will leave with a fresh approach to reactive system design using open source toolsand a new perspective on how orchestration can be declarative, flexible, and developer-friendly. Speakers: Colin Lacy from  Cisco, Grace Brickley from  Cisco. Location: Building B | Level 5 | Thomas Murphy Ballroom 1. Categories: APPLICATION DEVELOPMENT.",
      "metadata": {
        "title": "Message In, Job Out: Build Event-Driven Workflows in Kubernetes Using NATS, CloudEvents, and Sveltos",
        "description": "Modern applications need to respond to real-world eventsuser actions, system signals, business milestones. Explore a flexible approach to orchestrating workflows that grow step by step without locking you into a fixed structure.\n\nThis talk introduces a new way to build event-driven applications using Sveltos, an open source tool for declarative multi-cluster orchestration, and NATS, a lightweight messaging system designed for speed and simplicity. Instead of rigid execution graphs, this model uses declarative triggers for event-driven behavior, built on the CloudEvents standard, to guide how workflows evolve.\n\nAnd the best part: each step runs in a standard Kubernetes Job, making these applications easy to build, test, and extend using familiar tooling.\n\nAttendees will leave with a fresh approach to reactive system design using open source toolsand a new perspective on how orchestration can be declarative, flexible, and developer-friendly.",
        "url": "http://kccncna2025.sched.com/event/ac88993c2620bf565a891f6185742559",
        "uid": "ac88993c2620bf565a891f6185742559",
        "start": "2025-11-11T15:15:00-05:00",
        "end": "2025-11-11T15:45:00-05:00",
        "categories": [
          "APPLICATION DEVELOPMENT"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 1"
        },
        "speakers": [
          {
            "name": "Colin Lacy",
            "company": " Cisco"
          },
          {
            "name": "Grace Brickley",
            "company": " Cisco"
          }
        ]
      }
    },
    {
      "text": "You released an open source project that is gaining users. Now, how do you build a sustainable community?\n\nAn open source project runs on people, a community. This talk is the missing manual. Learn to build and sustain cloud native open source communities and how to do so by supporting the people behind the code.\n\nWell explore the three pillars of every open source project:\n\n* Builders  writing the code and shaping the roadmap\n* Users  deploying and running the software\n* Silent Users  benefiting quietly, but rarely engaging\n\nWell also look at the Builder-User hybrid, the vital link that fuels feedback and momentum.\n\nYoull walk away with:\n\n* A practical guide to preventing burnout and project decay\n* Strategies to identify and retain contributors who keep the soul alive\n* A renewed sense of purpose for growing a thriving community\n\nWe have the manual you need if your project has code and user documentation, but no community playbook. Speakers: Taylor Dolezal from Merly, Erica Hughberg from Tetrate. Location: Building B | Level 3 | B308-309. Categories: CLOUD NATIVE EXPERIENCE.",
      "metadata": {
        "title": "The Missing Manual for Open Source Community Sustainability",
        "description": "You released an open source project that is gaining users. Now, how do you build a sustainable community?\n\nAn open source project runs on people, a community. This talk is the missing manual. Learn to build and sustain cloud native open source communities and how to do so by supporting the people behind the code.\n\nWell explore the three pillars of every open source project:\n\n* Builders  writing the code and shaping the roadmap\n* Users  deploying and running the software\n* Silent Users  benefiting quietly, but rarely engaging\n\nWell also look at the Builder-User hybrid, the vital link that fuels feedback and momentum.\n\nYoull walk away with:\n\n* A practical guide to preventing burnout and project decay\n* Strategies to identify and retain contributors who keep the soul alive\n* A renewed sense of purpose for growing a thriving community\n\nWe have the manual you need if your project has code and user documentation, but no community playbook.",
        "url": "http://kccncna2025.sched.com/event/51807c07f8572b3211e24e9430ec6f26",
        "uid": "51807c07f8572b3211e24e9430ec6f26",
        "start": "2025-11-11T15:15:00-05:00",
        "end": "2025-11-11T15:45:00-05:00",
        "categories": [
          "CLOUD NATIVE EXPERIENCE"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B308-309"
        },
        "speakers": [
          {
            "name": "Taylor Dolezal",
            "company": "Merly"
          },
          {
            "name": "Erica Hughberg",
            "company": "Tetrate"
          }
        ]
      }
    },
    {
      "text": "Microservices architecture is foundational to cloud native applications, yet many beginners struggle to understand when and how to adopt this approach. This session uses visual storytelling to guide you through the evolution from monolith to microservices using a practical example application. You'll see a step-by-step transformation that highlights key motivations, challenges, and benefits. Through clear diagrams and analogies, we'll provide decision frameworks for when microservices make sense and when they don't. You'll gain a mental model that demystifies microservices and leave with practical insights to guide your own architectural decisions. Speakers: Pedro Henrique Oliveira from  AWS, Henrique Santana from  AWS. Location: Building B | Level 2 | B206. Categories: CLOUD NATIVE NOVICE.",
      "metadata": {
        "title": "From Monolith To Microservices: A Visual Journey for Beginners",
        "description": "Microservices architecture is foundational to cloud native applications, yet many beginners struggle to understand when and how to adopt this approach. This session uses visual storytelling to guide you through the evolution from monolith to microservices using a practical example application. You'll see a step-by-step transformation that highlights key motivations, challenges, and benefits. Through clear diagrams and analogies, we'll provide decision frameworks for when microservices make sense and when they don't. You'll gain a mental model that demystifies microservices and leave with practical insights to guide your own architectural decisions.",
        "url": "http://kccncna2025.sched.com/event/d3d24fcd944fd17bebd1fa03c80e4df3",
        "uid": "d3d24fcd944fd17bebd1fa03c80e4df3",
        "start": "2025-11-11T15:15:00-05:00",
        "end": "2025-11-11T15:45:00-05:00",
        "categories": [
          "CLOUD NATIVE NOVICE"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B206"
        },
        "speakers": [
          {
            "name": "Pedro Henrique Oliveira",
            "company": " AWS"
          },
          {
            "name": "Henrique Santana",
            "company": " AWS"
          }
        ]
      }
    },
    {
      "text": "When Edera's all-female founding team stepped into the world of deep enterprise technology in April 2024, we weren't just solving the \"unsolvable\" problem of container isolation  we were dismantling every assumption about who builds category-defining infrastructure companies. In nine months, we raised over $20 million across seed and Series A rounds, but the path to that first million revealed brutal truths about what it takes for women to secure funding in tech.\n\nWhile the industry talks about the value of diverse teams in theory, we're proving it works in practice, delivering results that have customers asking \"is this too good to be true?\"\n\nOur approach turned conventional startup wisdom upside down. Instead of a technical CEO learning people skills, we led with operational expertise and culture-first thinking  skills investors initially questioned but now credit as key differentiators. When you're already doing what nobody else is doing  building the first hardened runtime  why not push every boundary?\n\nThis talk exposes the unvarnished reality of raising that crucial first million: the investor meetings where we had to prove container isolation was possible before we could discuss market size, the sleepless nights one month before I would have had to cash out my 401k to keep my family fed and the company alive, and how being underestimated became our secret weapon. We'll share what it's like to be \"very rare\"  having all female founders in this industry  and how that rarity opened doors traditional approaches couldn't.\n\nThroughout this journey, we've learned that exceptional execution speaks louder than any bias. But getting that first check? That required everything we had  and then some serious manifesting. We turned being \"foundationally unique\" into a license to take even bigger risks, but more importantly, we learned that founders get to choose their investors  not the other way around. While everyone chases the biggest names on Sand Hill Road, we intentionally built our cap table with partners who shared our values and vision for what technology companies should be. Sometimes the best money isn't the most famous money.\n\nKey Takeaways:\nWhy choosing values-aligned investors over brand names builds stronger companiesConcrete strategies for female founders raising in enterprise techHow to weaponize skepticism when everyone thinks your problem is \"unsolvable\"The unexpected advantages of being the anomaly in investor meetings\nNo luck required  just the audacity to prove the impossible is inevitable. Speakers: Emily Long from Edera. Location: Building B | Level 5 | Thomas Murphy Ballroom 4. Categories: CLOUD NATIVE STARTUP.",
      "metadata": {
        "title": "Manifesting Millions: No Luck Required, Just Tenacity",
        "description": "When Edera's all-female founding team stepped into the world of deep enterprise technology in April 2024, we weren't just solving the \"unsolvable\" problem of container isolation  we were dismantling every assumption about who builds category-defining infrastructure companies. In nine months, we raised over $20 million across seed and Series A rounds, but the path to that first million revealed brutal truths about what it takes for women to secure funding in tech.\n\nWhile the industry talks about the value of diverse teams in theory, we're proving it works in practice, delivering results that have customers asking \"is this too good to be true?\"\n\nOur approach turned conventional startup wisdom upside down. Instead of a technical CEO learning people skills, we led with operational expertise and culture-first thinking  skills investors initially questioned but now credit as key differentiators. When you're already doing what nobody else is doing  building the first hardened runtime  why not push every boundary?\n\nThis talk exposes the unvarnished reality of raising that crucial first million: the investor meetings where we had to prove container isolation was possible before we could discuss market size, the sleepless nights one month before I would have had to cash out my 401k to keep my family fed and the company alive, and how being underestimated became our secret weapon. We'll share what it's like to be \"very rare\"  having all female founders in this industry  and how that rarity opened doors traditional approaches couldn't.\n\nThroughout this journey, we've learned that exceptional execution speaks louder than any bias. But getting that first check? That required everything we had  and then some serious manifesting. We turned being \"foundationally unique\" into a license to take even bigger risks, but more importantly, we learned that founders get to choose their investors  not the other way around. While everyone chases the biggest names on Sand Hill Road, we intentionally built our cap table with partners who shared our values and vision for what technology companies should be. Sometimes the best money isn't the most famous money.\n\nKey Takeaways:\nWhy choosing values-aligned investors over brand names builds stronger companiesConcrete strategies for female founders raising in enterprise techHow to weaponize skepticism when everyone thinks your problem is \"unsolvable\"The unexpected advantages of being the anomaly in investor meetings\nNo luck required  just the audacity to prove the impossible is inevitable.",
        "url": "http://kccncna2025.sched.com/event/189c85918d895fca5adb5d4ec251b9ec",
        "uid": "189c85918d895fca5adb5d4ec251b9ec",
        "start": "2025-11-11T15:15:00-05:00",
        "end": "2025-11-11T15:45:00-05:00",
        "categories": [
          "CLOUD NATIVE STARTUP"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 4"
        },
        "speakers": [
          {
            "name": "Emily Long",
            "company": "Edera"
          }
        ]
      }
    },
    {
      "text": "As the industry's infrastructure requirements have progressed over time, so have its proxies. Apache Traffic Server gave way to Nginx as traffic scales increased, with Envoy eventually joining the picture to fill in the gaps of high scale micro-service architectures. A similar shift is happening today with the dramatic surge in AI infrastructure, which have unique requirements to efficiently run. Intelligent request batching, model-aware load balancing, and token-based rate limiting are table stakes. Traditional proxies weren't designed for any of this. Like Envoy was built to fill the need for a micro-service optimized proxy, a new data plane is needed to fill the need for an AI optimized proxy. In this talk, I'll walk through the design decisions behind a new CNCF AI proxy built as part of kgateway. We'll explore what makes AI traffic unique, as well as lessons learned from existing proxies, and explore the tradeoffs needed to build an optimal AI data plane. Speakers: John Howard from Solo.io. Location: Building B | Level 4 | B405-406a. Categories: CONNECTIVITY.",
      "metadata": {
        "title": "Lessons Applied Building a Next-generation AI Proxy",
        "description": "As the industry's infrastructure requirements have progressed over time, so have its proxies. Apache Traffic Server gave way to Nginx as traffic scales increased, with Envoy eventually joining the picture to fill in the gaps of high scale micro-service architectures. A similar shift is happening today with the dramatic surge in AI infrastructure, which have unique requirements to efficiently run. Intelligent request batching, model-aware load balancing, and token-based rate limiting are table stakes. Traditional proxies weren't designed for any of this. Like Envoy was built to fill the need for a micro-service optimized proxy, a new data plane is needed to fill the need for an AI optimized proxy. In this talk, I'll walk through the design decisions behind a new CNCF AI proxy built as part of kgateway. We'll explore what makes AI traffic unique, as well as lessons learned from existing proxies, and explore the tradeoffs needed to build an optimal AI data plane.",
        "url": "http://kccncna2025.sched.com/event/23257c9357d705e8d71001812e3fa473",
        "uid": "23257c9357d705e8d71001812e3fa473",
        "start": "2025-11-11T15:15:00-05:00",
        "end": "2025-11-11T15:45:00-05:00",
        "categories": [
          "CONNECTIVITY"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B405-406a"
        },
        "speakers": [
          {
            "name": "John Howard",
            "company": "Solo.io"
          }
        ]
      }
    },
    {
      "text": "Falco is soaring higher than ever into the stratosphere of observabilityfaster, sharper, and with a deeper lens into cloud native runtime security. In this session, maintainers will reveal two major breakthroughs: a reengineered event collection strategy that delivers significant performance gains, and a pioneering integration with StratoShark that enables Falco to capture targeted runtime activity for powerful post-incident analysis. These innovations push Falco beyond traditional detection into a new realm of forensic depth and responsiveness. Join us for a glimpse of whats next as Falco charts a course toward faster, wiser, and more connected runtime security. Speakers: Leonardo Grasso from  Sysdig, Leonardo Di Giovanna from  Sysdig. Location: Building C | Level 3 | Georgia Ballroom 3. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Beyond the Cloud(s): Falcos Ascent in Performance and Deep Visibility",
        "description": "Falco is soaring higher than ever into the stratosphere of observabilityfaster, sharper, and with a deeper lens into cloud native runtime security. In this session, maintainers will reveal two major breakthroughs: a reengineered event collection strategy that delivers significant performance gains, and a pioneering integration with StratoShark that enables Falco to capture targeted runtime activity for powerful post-incident analysis. These innovations push Falco beyond traditional detection into a new realm of forensic depth and responsiveness. Join us for a glimpse of whats next as Falco charts a course toward faster, wiser, and more connected runtime security.",
        "url": "http://kccncna2025.sched.com/event/7dcab46ea0decc3c486304968929e8f3",
        "uid": "7dcab46ea0decc3c486304968929e8f3",
        "start": "2025-11-11T15:15:00-05:00",
        "end": "2025-11-11T15:45:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 3"
        },
        "speakers": [
          {
            "name": "Leonardo Grasso",
            "company": " Sysdig"
          },
          {
            "name": "Leonardo Di Giovanna",
            "company": " Sysdig"
          }
        ]
      }
    },
    {
      "text": "Kyverno, the Kubernetes-native policy engine, has evolved with new specialized policy types leveraging CEL (Common Expressions Language), and now works inside and outside Kubernetes. This shift enables robust, scalable, and maintainable, and unified policy-as-code.\n\nKyverno maintainers, Jim and Charles-Edouard, will deep dive into each new policy type, demonstrating CEL use and integration with native policy resources. They'll show how these capabilities automate complex platform engineering use cases that previously required custom controllers. The session will also cover Kyverno features like fine-grained policy exceptions and OpenReports integration for flexible, scalable policy management.\n\nAttend to understand how Kyverno simplifies cloud-native governance with policy-as-code, enhances performance, and unlocks advanced self-service automation for Kubernetes clusters, IaC, CI/CD pipelines, and everywhere policy-based guardrails are required. Speakers: Jim Bugwadia from  Nirmata, Charles-Edouard Breteche from  Nirmata. Location: Building C | Level 3 | Georgia Ballroom 1. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Kyverno Everywhere: Simplifying Unified Policy as Code",
        "description": "Kyverno, the Kubernetes-native policy engine, has evolved with new specialized policy types leveraging CEL (Common Expressions Language), and now works inside and outside Kubernetes. This shift enables robust, scalable, and maintainable, and unified policy-as-code.\n\nKyverno maintainers, Jim and Charles-Edouard, will deep dive into each new policy type, demonstrating CEL use and integration with native policy resources. They'll show how these capabilities automate complex platform engineering use cases that previously required custom controllers. The session will also cover Kyverno features like fine-grained policy exceptions and OpenReports integration for flexible, scalable policy management.\n\nAttend to understand how Kyverno simplifies cloud-native governance with policy-as-code, enhances performance, and unlocks advanced self-service automation for Kubernetes clusters, IaC, CI/CD pipelines, and everywhere policy-based guardrails are required.",
        "url": "http://kccncna2025.sched.com/event/7aebf7355e0a47044e2e279ba9f31ba2",
        "uid": "7aebf7355e0a47044e2e279ba9f31ba2",
        "start": "2025-11-11T15:15:00-05:00",
        "end": "2025-11-11T15:45:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 1"
        },
        "speakers": [
          {
            "name": "Jim Bugwadia",
            "company": " Nirmata"
          },
          {
            "name": "Charles-Edouard Breteche",
            "company": " Nirmata"
          }
        ]
      }
    },
    {
      "text": "On June, 2025, a misconfigured quota policy is deployed without proper validation in Google Cloud, which caused widespread service disruption. Similar incidences related to un-safe configuration updates are reported by many cloud providers and users. Configuration updates in Kubernetes often lack the progressive delivery capability like code updates. While the community advocates generating new ConfigMaps with Deployment rolling updates, this approach lacks systematic support and fails to address complex scenarios where configuration and image rollouts must be decoupled.\n\nIn this session, we'll explore ConfigMapSet, an OpenKruise innovation that redefines configuration management in Kubernetes, supporting progressive delivery patterns combined with AI-ready orchestration. We'll demonstrate how this CRD-based solution enables zero-downtime configuration updates, decouples config/image versioning, and supports dynamic AI/ML workflows like distributed model inference. Speakers: Yuxing Yuan from Alibaba Cloud, Hao Wu from Bilibili Inc.. Location: Building C | Level 3 | Georgia Ballroom 2. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Progressive Configuration Delivery for Zero-Downtime Cloud Workloads",
        "description": "On June, 2025, a misconfigured quota policy is deployed without proper validation in Google Cloud, which caused widespread service disruption. Similar incidences related to un-safe configuration updates are reported by many cloud providers and users. Configuration updates in Kubernetes often lack the progressive delivery capability like code updates. While the community advocates generating new ConfigMaps with Deployment rolling updates, this approach lacks systematic support and fails to address complex scenarios where configuration and image rollouts must be decoupled.\n\nIn this session, we'll explore ConfigMapSet, an OpenKruise innovation that redefines configuration management in Kubernetes, supporting progressive delivery patterns combined with AI-ready orchestration. We'll demonstrate how this CRD-based solution enables zero-downtime configuration updates, decouples config/image versioning, and supports dynamic AI/ML workflows like distributed model inference.",
        "url": "http://kccncna2025.sched.com/event/6f04b5c58c2f7fbaf10e7fc1ff8bf3e9",
        "uid": "6f04b5c58c2f7fbaf10e7fc1ff8bf3e9",
        "start": "2025-11-11T15:15:00-05:00",
        "end": "2025-11-11T15:45:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 2"
        },
        "speakers": [
          {
            "name": "Yuxing Yuan",
            "company": "Alibaba Cloud"
          },
          {
            "name": "Hao Wu",
            "company": "Bilibili Inc."
          }
        ]
      }
    },
    {
      "text": "This session explores significant improvements made to NATS over the past year that push the boundaries of scale and performance while adding functionality that increases utility and flexibility for application developers. We'll examine real-world use cases that drove these enhancements and demonstrate new configuration options, APIs, and patterns through examples. You'll see how these improvements solve common challenges in cloud-to-edge systems and enable teams to build more resilient, scalable applications. Speakers: Byron Ruth from Synadia. Location: Building C | Level 1 | C111-112. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "State of NATS: Scale, Performance, and Flexibility",
        "description": "This session explores significant improvements made to NATS over the past year that push the boundaries of scale and performance while adding functionality that increases utility and flexibility for application developers. We'll examine real-world use cases that drove these enhancements and demonstrate new configuration options, APIs, and patterns through examples. You'll see how these improvements solve common challenges in cloud-to-edge systems and enable teams to build more resilient, scalable applications.",
        "url": "http://kccncna2025.sched.com/event/c95b7b0aff6e8d38e8a1ff1632879d65",
        "uid": "c95b7b0aff6e8d38e8a1ff1632879d65",
        "start": "2025-11-11T15:15:00-05:00",
        "end": "2025-11-11T15:45:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "1",
          "room": "C111-112"
        },
        "speakers": [
          {
            "name": "Byron Ruth",
            "company": "Synadia"
          }
        ]
      }
    },
    {
      "text": "\"Just Do It: OpAMP\", is an in-depth session on building an enterprise-grade implementation of the Open Agent Management Protocol (OpAMP) specification that is part of the OpenTelemetry CNCF project. In todays cloud-native environments, managing thousands of observability agents, and especially so OpenTelemetry Collectors for which most major vendors have no fleet management solution available, is a daunting task. This session explores how OpAMP enables efficient remote configuration, update, and real-time monitoring of a fleet of such agents.\n\nWell break down the protocols core concepts by reviewing system design diagrams that address security, network and resiliency challenges. Finally, we'll go over practical strategies for a successful roll out and enterprise-wide adoption at scale.\n\nThis session aims to equip you with actionable insights and robust techniques to streamline agent management, ultimately enhancing operational efficiency in distributed environments. Speakers: Panos Tsilopoulos from  Inc., Bob Johnson from  Inc.. Location: Building B | Level 3 | B304-305. Categories: OBSERVABILITY.",
      "metadata": {
        "title": "Just Do It: OpAMP",
        "description": "\"Just Do It: OpAMP\", is an in-depth session on building an enterprise-grade implementation of the Open Agent Management Protocol (OpAMP) specification that is part of the OpenTelemetry CNCF project. In todays cloud-native environments, managing thousands of observability agents, and especially so OpenTelemetry Collectors for which most major vendors have no fleet management solution available, is a daunting task. This session explores how OpAMP enables efficient remote configuration, update, and real-time monitoring of a fleet of such agents.\n\nWell break down the protocols core concepts by reviewing system design diagrams that address security, network and resiliency challenges. Finally, we'll go over practical strategies for a successful roll out and enterprise-wide adoption at scale.\n\nThis session aims to equip you with actionable insights and robust techniques to streamline agent management, ultimately enhancing operational efficiency in distributed environments.",
        "url": "http://kccncna2025.sched.com/event/277f4733631b2968f70cdf774a4fce18",
        "uid": "277f4733631b2968f70cdf774a4fce18",
        "start": "2025-11-11T15:15:00-05:00",
        "end": "2025-11-11T15:45:00-05:00",
        "categories": [
          "OBSERVABILITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B304-305"
        },
        "speakers": [
          {
            "name": "Panos Tsilopoulos",
            "company": " Inc."
          },
          {
            "name": "Bob Johnson",
            "company": " Inc."
          }
        ]
      }
    },
    {
      "text": "Discover how Banco Mercantil in Brazil revolutionized its data streaming with Strimzi, Argo, and Kubernetes. The automation of data connector creation, previously manual and complex, is now efficient. The Integration Hub engineering team uses Git to request connectors; Argo automates creation in Kubernetes; and Strimzi creates the Kafka Connect connectors. This agile and persistent process, with GitOps, reduced errors and optimized delivery, supporting growth, as in Open Finance Project (Open Finance allows consumers to share their banking data between institutions, fostering competition, innovation, and personalized financial services). Learn how this modern architecture simplifies work and scales the data ecosystem. Speakers: Marcelo Costa from Banco Mercantil. Location: Building B | Level 4 | B406b-407. Categories: OPERATIONS + PERFORMANCE.",
      "metadata": {
        "title": "Unveiling Automation: How Mercantil Transformed Data Streaming With Strimzi, Argo, and Kubernetes",
        "description": "Discover how Banco Mercantil in Brazil revolutionized its data streaming with Strimzi, Argo, and Kubernetes. The automation of data connector creation, previously manual and complex, is now efficient. The Integration Hub engineering team uses Git to request connectors; Argo automates creation in Kubernetes; and Strimzi creates the Kafka Connect connectors. This agile and persistent process, with GitOps, reduced errors and optimized delivery, supporting growth, as in Open Finance Project (Open Finance allows consumers to share their banking data between institutions, fostering competition, innovation, and personalized financial services). Learn how this modern architecture simplifies work and scales the data ecosystem.",
        "url": "http://kccncna2025.sched.com/event/46787f482f9db3e795ce937cffde8172",
        "uid": "46787f482f9db3e795ce937cffde8172",
        "start": "2025-11-11T15:15:00-05:00",
        "end": "2025-11-11T15:45:00-05:00",
        "categories": [
          "OPERATIONS + PERFORMANCE"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B406b-407"
        },
        "speakers": [
          {
            "name": "Marcelo Costa",
            "company": "Banco Mercantil"
          }
        ]
      }
    },
    {
      "text": "Before adopting a centralized approach, engineering teams at GE HealthCare managed their Infrastructure as Code (IaC) deployments independentlyleading to fragmentation, inconsistent security practices, and operational overhead. Each team had its own tools, processes, and storage methods, making it difficult to scale, enforce standards, and ensure traceability across environments.\nTo solve this, GE HealthCare introduced a shared delivery model built on ORAS and OCI registries, enabling teams to package infrastructure definitions (e.g. Terraform modules) as OCI artifacts. This decouples infrastructure delivery from specific IaC tools, while providing a secure, consistent, and versioned distribution mechanism.\nIn this session, an engineer from GE HealthCare will share how they partnered with the ORAS community to build a SaaS platform that empowers teams to provision infrastructure using their preferred IaC technologieswithout compromising on governance, consistency, or security. Speakers: Feynman Zhou from Microsoft, Katherine Pitz from GE HealthCare. Location: Building B | Level 3 | B312-314. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "Shipping Secure, Reusable, and Composable Infrastructure as Code: GE HealthCares Journey With ORAS",
        "description": "Before adopting a centralized approach, engineering teams at GE HealthCare managed their Infrastructure as Code (IaC) deployments independentlyleading to fragmentation, inconsistent security practices, and operational overhead. Each team had its own tools, processes, and storage methods, making it difficult to scale, enforce standards, and ensure traceability across environments.\nTo solve this, GE HealthCare introduced a shared delivery model built on ORAS and OCI registries, enabling teams to package infrastructure definitions (e.g. Terraform modules) as OCI artifacts. This decouples infrastructure delivery from specific IaC tools, while providing a secure, consistent, and versioned distribution mechanism.\nIn this session, an engineer from GE HealthCare will share how they partnered with the ORAS community to build a SaaS platform that empowers teams to provision infrastructure using their preferred IaC technologieswithout compromising on governance, consistency, or security.",
        "url": "http://kccncna2025.sched.com/event/84d9cb0df4c72902b8ea1e66000c11f1",
        "uid": "84d9cb0df4c72902b8ea1e66000c11f1",
        "start": "2025-11-11T15:15:00-05:00",
        "end": "2025-11-11T15:45:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B312-314"
        },
        "speakers": [
          {
            "name": "Feynman Zhou",
            "company": "Microsoft"
          },
          {
            "name": "Katherine Pitz",
            "company": "GE HealthCare"
          }
        ]
      }
    },
    {
      "text": "Secure AI workloads require verifiable trust regardless of where GPUs operateon-premises, private clouds, or public CSPs. CNCF Confidential Containers facilitate infrastructure-agnostic, lift-and-shift deployments of GPU workloads, delivering confidentiality seamlessly without needing modifications. This is accomplished by layering trust-oriented elements over Kubernetes for compute, networking, storage, and the control plane. Hardware-backed confidential VMs ensure runtime integrity for GPU workloads, identity-based overlay networks, and a confidential storage layer safeguards highly valuable data against replay attacks. A confidential control plane overlays K8S default control plane, offering mechanisms for multi-tenancy, key lifecycle management, and maintenance of trust boundaries. This architecture supports trusted, portable AI infrastructure at scale, enabling secure AI deployments across any IaaSon-premises, private cloud, or CSPfacilitating true hybrid secure AI at scale. Speakers: Zvonko Kaiser from NVIDIA. Location: Building B | Level 3 | B302-303. Categories: SECURITY.",
      "metadata": {
        "title": "Hybrid-Confidential-Cloud: Democratize Secure AI With GPUs and Confidential Containers",
        "description": "Secure AI workloads require verifiable trust regardless of where GPUs operateon-premises, private clouds, or public CSPs. CNCF Confidential Containers facilitate infrastructure-agnostic, lift-and-shift deployments of GPU workloads, delivering confidentiality seamlessly without needing modifications. This is accomplished by layering trust-oriented elements over Kubernetes for compute, networking, storage, and the control plane. Hardware-backed confidential VMs ensure runtime integrity for GPU workloads, identity-based overlay networks, and a confidential storage layer safeguards highly valuable data against replay attacks. A confidential control plane overlays K8S default control plane, offering mechanisms for multi-tenancy, key lifecycle management, and maintenance of trust boundaries. This architecture supports trusted, portable AI infrastructure at scale, enabling secure AI deployments across any IaaSon-premises, private cloud, or CSPfacilitating true hybrid secure AI at scale.",
        "url": "http://kccncna2025.sched.com/event/4054a869e54699cac36c52198cd16230",
        "uid": "4054a869e54699cac36c52198cd16230",
        "start": "2025-11-11T15:15:00-05:00",
        "end": "2025-11-11T15:45:00-05:00",
        "categories": [
          "SECURITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B302-303"
        },
        "speakers": [
          {
            "name": "Zvonko Kaiser",
            "company": "NVIDIA"
          }
        ]
      }
    },
    {
      "text": "Location: TBA. Categories: BREAKS.",
      "metadata": {
        "title": "Coffee Break ",
        "description": "",
        "url": "http://kccncna2025.sched.com/event/d6c88a5e0ef832f9ff3c4ee58be5d4d4",
        "uid": "d6c88a5e0ef832f9ff3c4ee58be5d4d4",
        "start": "2025-11-11T15:45:00-05:00",
        "end": "2025-11-11T16:15:00-05:00",
        "categories": [
          "BREAKS"
        ],
        "location": {
          "room": "TBA"
        }
      }
    },
    {
      "text": "10-Minute Tip Talk Speakers: Angel Ramirez from CNCF, OSPO Ambassador. Location: Level 1 | Learning Lounge. Categories: EXPERIENCES.",
      "metadata": {
        "title": "Learning Lounge: Using Passion for Community & Kubernetes to Unlock Emerging Markets",
        "description": "10-Minute Tip Talk",
        "url": "http://kccncna2025.sched.com/event/b1c0fab147c411627e5dd4ef97dfd122",
        "uid": "b1c0fab147c411627e5dd4ef97dfd122",
        "start": "2025-11-11T15:45:00-05:00",
        "end": "2025-11-11T16:00:00-05:00",
        "categories": [
          "EXPERIENCES"
        ],
        "location": {
          "level": "1",
          "room": "Learning Lounge"
        },
        "speakers": [
          {
            "name": "Angel Ramirez",
            "company": "CNCF"
          },
          {
            "name": "OSPO Ambassador"
          }
        ]
      }
    },
    {
      "text": "AI is reshaping observability and observability is becoming essential for AI. In this session, well cut through the hype and focus on whats possible today. Well explore how generative and agentic AI are being embedded into observability platforms to accelerate root cause analysis, reduce toil, and automate incident response. Equally important, well dive into how to apply observability to GenAI and agentic AI workloads themselves, covering tracing, monitoring, and debugging of these complex, non-deterministic systems. This session will provide a practical lens on the intersection of AI and observability - whats working now, whats experimental, and whats next.\n\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.* Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: SOLUTIONS SHOWCASE.",
      "metadata": {
        "title": "Sponsored Demo: AI for Observability, Observability for AI: From Hype to Hands-On",
        "description": "AI is reshaping observability and observability is becoming essential for AI. In this session, well cut through the hype and focus on whats possible today. Well explore how generative and agentic AI are being embedded into observability platforms to accelerate root cause analysis, reduce toil, and automate incident response. Equally important, well dive into how to apply observability to GenAI and agentic AI workloads themselves, covering tracing, monitoring, and debugging of these complex, non-deterministic systems. This session will provide a practical lens on the intersection of AI and observability - whats working now, whats experimental, and whats next.\n\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.*",
        "url": "http://kccncna2025.sched.com/event/3d7b3e3c4e0d85ea868a7e11d2402755",
        "uid": "3d7b3e3c4e0d85ea868a7e11d2402755",
        "start": "2025-11-11T15:45:00-05:00",
        "end": "2025-11-11T16:05:00-05:00",
        "categories": [
          "SOLUTIONS SHOWCASE"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "AI agents are supposed to make life easier, but until now, getting them to work with real world tools was a pain. If you wanted an agent to interact with your database, or IDE, you had to write custom API integrations for every single one. The thought of scaling this across multiple tools/ resources seemed impossible.\n\nBut what if you could just grab an AI agent, plug it into whatever service you need, and get to work, without any extra coding or complex setup?\n\nIn this talk, we'll cover how AI agents are becoming more modular with standards like the Model Context Protocol (MCP). Instead of being stuck with whatever knowledge they were trained on, agents can now dynamically connect to APIs, dev tools, and cloud services on the fly. I'll show a live example of how the Kubernetes MCP server enables AI agents to discover clusters, list pods, etc, making AI more flexible, powerful, and actually useful.\n\nIf you're ready to make AI agents work for you, and not the other way around, come see how the next generation is built to simply plug in and play. Speakers: Ebony Louis from Block, Inc. Location: Building B | Level 2 | B207. Categories: AI + ML.",
      "metadata": {
        "title": "Plug & Play: How AI Agents Are Adapting",
        "description": "AI agents are supposed to make life easier, but until now, getting them to work with real world tools was a pain. If you wanted an agent to interact with your database, or IDE, you had to write custom API integrations for every single one. The thought of scaling this across multiple tools/ resources seemed impossible.\n\nBut what if you could just grab an AI agent, plug it into whatever service you need, and get to work, without any extra coding or complex setup?\n\nIn this talk, we'll cover how AI agents are becoming more modular with standards like the Model Context Protocol (MCP). Instead of being stuck with whatever knowledge they were trained on, agents can now dynamically connect to APIs, dev tools, and cloud services on the fly. I'll show a live example of how the Kubernetes MCP server enables AI agents to discover clusters, list pods, etc, making AI more flexible, powerful, and actually useful.\n\nIf you're ready to make AI agents work for you, and not the other way around, come see how the next generation is built to simply plug in and play.",
        "url": "http://kccncna2025.sched.com/event/2acfcdaeda39b5e1eec7e4e40b4aa190",
        "uid": "2acfcdaeda39b5e1eec7e4e40b4aa190",
        "start": "2025-11-11T16:15:00-05:00",
        "end": "2025-11-11T16:45:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B207"
        },
        "speakers": [
          {
            "name": "Ebony Louis",
            "company": "Block, Inc"
          }
        ]
      }
    },
    {
      "text": "Kubernetes excels at stateless service routing - but modern AI workloads are not stateless. Generative workloads demand context-aware routing that maximizes performance while reducing costs.\n\nThis talk explores layered routing strategies for stateful LLM workloads on Kubernetes - from round-robin to full KV-Cache-aware load balancing. Well explain when each level applies, and its effects on performance.\n\nBased on our experience developing llm-d - a framework using the K8s Gateway API Inference Extension, a collaboration between Google, IBM Research, and RedHat - well cover:\n- Why traditional Kubernetes routing falls short for generative AI\n- Routing patterns for long-context, sessionful traffic\n- Global cache indices and local offloading for smart routing\n- Benchmarks showing latency, cache hit rates, and GPU utilization\n- Practical ways to adopt cache-aware routing without major infra changes\n\nIf youre scaling multi-turn, agentic, or LLM-powered workloads, this session is for you. Speakers: Maroon Ayoub from IBM, Michey Mehta from Red Hat. Location: Building B | Level 4 | B401-402. Categories: AI + ML.",
      "metadata": {
        "title": "Routing Stateful AI Workloads in Kubernetes",
        "description": "Kubernetes excels at stateless service routing - but modern AI workloads are not stateless. Generative workloads demand context-aware routing that maximizes performance while reducing costs.\n\nThis talk explores layered routing strategies for stateful LLM workloads on Kubernetes - from round-robin to full KV-Cache-aware load balancing. Well explain when each level applies, and its effects on performance.\n\nBased on our experience developing llm-d - a framework using the K8s Gateway API Inference Extension, a collaboration between Google, IBM Research, and RedHat - well cover:\n- Why traditional Kubernetes routing falls short for generative AI\n- Routing patterns for long-context, sessionful traffic\n- Global cache indices and local offloading for smart routing\n- Benchmarks showing latency, cache hit rates, and GPU utilization\n- Practical ways to adopt cache-aware routing without major infra changes\n\nIf youre scaling multi-turn, agentic, or LLM-powered workloads, this session is for you.",
        "url": "http://kccncna2025.sched.com/event/a56fdf56a0d7319b2742780c9f78b131",
        "uid": "a56fdf56a0d7319b2742780c9f78b131",
        "start": "2025-11-11T16:15:00-05:00",
        "end": "2025-11-11T16:45:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B401-402"
        },
        "speakers": [
          {
            "name": "Maroon Ayoub",
            "company": "IBM"
          },
          {
            "name": "Michey Mehta",
            "company": "Red Hat"
          }
        ]
      }
    },
    {
      "text": "This session delves into the critical aspects of developing production-ready Large Language Model (LLM) applications using Java. We'll explore how to leverage Java's strengths to build scalable and efficient LLM systems, addressing key challenges such as performance optimization, resource management, and seamless integration with existing infrastructures.\n\nAttendees will gain practical knowledge on handling massive datasets, optimizing model inference, and fine-tuning LLMs for optimal performance. We'll discuss strategies for ensuring the reliability and scalability of your LLM deployments, empowering you to create robust and high-performing AI applications. Whether you're a seasoned Java developer or new to the AI domain, this session will provide valuable insights and guidance for your LLM development journey, equipping you with the tools and knowledge to navigate the complexities of building production-grade LLM systems. Speakers: Daniel Oh from  IBM, Kevin Dubois from  IBM. Location: Building B | Level 5 | Thomas Murphy Ballroom 1. Categories: APPLICATION DEVELOPMENT.",
      "metadata": {
        "title": "Scaling Generative AI: Building Production-Ready LLM Applications",
        "description": "This session delves into the critical aspects of developing production-ready Large Language Model (LLM) applications using Java. We'll explore how to leverage Java's strengths to build scalable and efficient LLM systems, addressing key challenges such as performance optimization, resource management, and seamless integration with existing infrastructures.\n\nAttendees will gain practical knowledge on handling massive datasets, optimizing model inference, and fine-tuning LLMs for optimal performance. We'll discuss strategies for ensuring the reliability and scalability of your LLM deployments, empowering you to create robust and high-performing AI applications. Whether you're a seasoned Java developer or new to the AI domain, this session will provide valuable insights and guidance for your LLM development journey, equipping you with the tools and knowledge to navigate the complexities of building production-grade LLM systems.",
        "url": "http://kccncna2025.sched.com/event/9144b1c8f0b7a342581f9a483a6f44d7",
        "uid": "9144b1c8f0b7a342581f9a483a6f44d7",
        "start": "2025-11-11T16:15:00-05:00",
        "end": "2025-11-11T16:45:00-05:00",
        "categories": [
          "APPLICATION DEVELOPMENT"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 1"
        },
        "speakers": [
          {
            "name": "Daniel Oh",
            "company": " IBM"
          },
          {
            "name": "Kevin Dubois",
            "company": " IBM"
          }
        ]
      }
    },
    {
      "text": "CopperPoint Insurance embarked on a bold transformation initiativetransitioning from legacy, on-premises infrastructure to a cloud-native foundation on AWS powered by CNCF-hosted technologies. This presentation is the real story of how CopperPoint leveraged Kubernetes on Amazon EKS, Prometheus, Fluent Bit, OpenTelemetry, and other CNCF projects to modernize its core systems, enhance observability, and build a composable integration layer that now powers over 100 enterprise integrations.We will share how this new platform has enabled agility, innovation, and rapid scalability via CopperPoint's ecosystem, thus directly contributing to premium growth of over $1 billion. You will find out the architecture blueprint, top-level decisions, governance model, and lessons learned from cost and environment management perspective that you may apply to replicate this kind of transformation within your company. Speakers: Sid Dixit from  CopperPoint Insurance Companies, Sham Rao from  CopperPoint Insurance Companies. Location: Building B | Level 3 | B308-309. Categories: CLOUD NATIVE EXPERIENCE.",
      "metadata": {
        "title": "Reimagining Insurance Infrastructure: CopperPoint's Cloud Native Blueprint",
        "description": "CopperPoint Insurance embarked on a bold transformation initiativetransitioning from legacy, on-premises infrastructure to a cloud-native foundation on AWS powered by CNCF-hosted technologies. This presentation is the real story of how CopperPoint leveraged Kubernetes on Amazon EKS, Prometheus, Fluent Bit, OpenTelemetry, and other CNCF projects to modernize its core systems, enhance observability, and build a composable integration layer that now powers over 100 enterprise integrations.We will share how this new platform has enabled agility, innovation, and rapid scalability via CopperPoint's ecosystem, thus directly contributing to premium growth of over $1 billion. You will find out the architecture blueprint, top-level decisions, governance model, and lessons learned from cost and environment management perspective that you may apply to replicate this kind of transformation within your company.",
        "url": "http://kccncna2025.sched.com/event/d2f9fc71eb9cebf6e69f021f1767d686",
        "uid": "d2f9fc71eb9cebf6e69f021f1767d686",
        "start": "2025-11-11T16:15:00-05:00",
        "end": "2025-11-11T16:45:00-05:00",
        "categories": [
          "CLOUD NATIVE EXPERIENCE"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B308-309"
        },
        "speakers": [
          {
            "name": "Sid Dixit",
            "company": " CopperPoint Insurance Companies"
          },
          {
            "name": "Sham Rao",
            "company": " CopperPoint Insurance Companies"
          }
        ]
      }
    },
    {
      "text": "Embark on an engaging journey with two security maintainers as they explore a Kubernetes cluster, armed with their \"security toolbelts.\" This 101-level session demystifies essential Kubernetes security. We'll navigate the intricacies of Network Policies, dissect Role-Based Access Control (RBAC) permissions, evaluate Pod Security Standards, and demonstrate practical vulnerability scanning. Witness firsthand as common security pitfalls are uncovered through practical examples and learn how to fortify your defenses. Our maintainers will share crucial insights and actionable best practices, helping you understand why these foundational components are vital and how to apply them effectively. Is your cluster truly secure? Join us to find out and learn how to pass the inspection! Speakers: Jackie Maertens from  Microsoft, Nilekh Chaudhari from  Microsoft. Location: Building B | Level 2 | B206. Categories: CLOUD NATIVE NOVICE.",
      "metadata": {
        "title": "No Joke: Two Security Maintainers Walk Into a Cluster",
        "description": "Embark on an engaging journey with two security maintainers as they explore a Kubernetes cluster, armed with their \"security toolbelts.\" This 101-level session demystifies essential Kubernetes security. We'll navigate the intricacies of Network Policies, dissect Role-Based Access Control (RBAC) permissions, evaluate Pod Security Standards, and demonstrate practical vulnerability scanning. Witness firsthand as common security pitfalls are uncovered through practical examples and learn how to fortify your defenses. Our maintainers will share crucial insights and actionable best practices, helping you understand why these foundational components are vital and how to apply them effectively. Is your cluster truly secure? Join us to find out and learn how to pass the inspection!",
        "url": "http://kccncna2025.sched.com/event/7045784db3aed83123b786840399b2fd",
        "uid": "7045784db3aed83123b786840399b2fd",
        "start": "2025-11-11T16:15:00-05:00",
        "end": "2025-11-11T16:45:00-05:00",
        "categories": [
          "CLOUD NATIVE NOVICE"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B206"
        },
        "speakers": [
          {
            "name": "Jackie Maertens",
            "company": " Microsoft"
          },
          {
            "name": "Nilekh Chaudhari",
            "company": " Microsoft"
          }
        ]
      }
    },
    {
      "text": "Careem, the leading multi-service app in the Middle East, handles over 5 billion Kubernetes-based service requests daily. As our platform evolved, we began to outgrow the operational and extensibility constraints of our existing service mesh.\n\nThis talk shares how we executed an in-place, zero-downtime migration to Istio within the same Kubernetes clusterwithout increasing infrastructure cost or rewriting most service configurations. A key enabler was our early adoption of the Kubernetes Gateway API (GAMMA initiative). By building on vendor-neutral, Kubernetes-native APIs for routing and traffic policies, we achieved a define once, swap many times model that allowed us to reuse the majority of our existing config during the transition.\n\nTo validate changes in production safely, we integrated Flagger to implement metrics-driven canary rollouts and gradual traffic shifting. Speakers: Suren Raju from Careem, Sergey Marunich from Tetrate. Location: Building B | Level 4 | B405-406a. Categories: CONNECTIVITY.",
      "metadata": {
        "title": "GAMMA in Action: How Careem Migrated To Istio Without Downtime",
        "description": "Careem, the leading multi-service app in the Middle East, handles over 5 billion Kubernetes-based service requests daily. As our platform evolved, we began to outgrow the operational and extensibility constraints of our existing service mesh.\n\nThis talk shares how we executed an in-place, zero-downtime migration to Istio within the same Kubernetes clusterwithout increasing infrastructure cost or rewriting most service configurations. A key enabler was our early adoption of the Kubernetes Gateway API (GAMMA initiative). By building on vendor-neutral, Kubernetes-native APIs for routing and traffic policies, we achieved a define once, swap many times model that allowed us to reuse the majority of our existing config during the transition.\n\nTo validate changes in production safely, we integrated Flagger to implement metrics-driven canary rollouts and gradual traffic shifting.",
        "url": "http://kccncna2025.sched.com/event/ef9f5fdd709a89c12a0f71f9c8aa6c4a",
        "uid": "ef9f5fdd709a89c12a0f71f9c8aa6c4a",
        "start": "2025-11-11T16:15:00-05:00",
        "end": "2025-11-11T16:45:00-05:00",
        "categories": [
          "CONNECTIVITY"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B405-406a"
        },
        "speakers": [
          {
            "name": "Suren Raju",
            "company": "Careem"
          },
          {
            "name": "Sergey Marunich",
            "company": "Tetrate"
          }
        ]
      }
    },
    {
      "text": "Have you ever experienced a Kubernetes cluster that suddenly stops responding? As basic debugging steps, you run kubectl commands, but all of them result in a request timeout. So what is happening? Most likely, etcd is failing.\nEtcd, as we know, is the sole distributed key-value store for Kubernetes, responsible for continuously and consistently storing the state of the entire cluster. Every configuration, workload information, node registration is stored in etcd. So, a degraded etcd cluster can cause stale reads and a possible cluster-wide outage since Kubernetes cannot reconcile or serve API requests.\nIn this session, well explore common causes of etcd failures that affect Kubernetes stability and performance. Well also discuss debugging methods and introduce tools like etcd-diagnosis to analyse the health of etcd in a running cluster. Finally, well share the best practices for operating etcd - upgrades, backups, recovery, and key workarounds to ensure a resilient control plane. Speakers: Arka Saha from  Broadcom, Nabarun Pal from  Broadcom. Location: Building B | Level 5 | Thomas Murphy Ballroom 4. Categories: DATA PROCESSING + STORAGE.",
      "metadata": {
        "title": "Kubernetes and etcd: Common Pitfalls and How To Avoid Them",
        "description": "Have you ever experienced a Kubernetes cluster that suddenly stops responding? As basic debugging steps, you run kubectl commands, but all of them result in a request timeout. So what is happening? Most likely, etcd is failing.\nEtcd, as we know, is the sole distributed key-value store for Kubernetes, responsible for continuously and consistently storing the state of the entire cluster. Every configuration, workload information, node registration is stored in etcd. So, a degraded etcd cluster can cause stale reads and a possible cluster-wide outage since Kubernetes cannot reconcile or serve API requests.\nIn this session, well explore common causes of etcd failures that affect Kubernetes stability and performance. Well also discuss debugging methods and introduce tools like etcd-diagnosis to analyse the health of etcd in a running cluster. Finally, well share the best practices for operating etcd - upgrades, backups, recovery, and key workarounds to ensure a resilient control plane.",
        "url": "http://kccncna2025.sched.com/event/5bcf6ba0523c3001e8cd685d66fc4d67",
        "uid": "5bcf6ba0523c3001e8cd685d66fc4d67",
        "start": "2025-11-11T16:15:00-05:00",
        "end": "2025-11-11T16:45:00-05:00",
        "categories": [
          "DATA PROCESSING + STORAGE"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 4"
        },
        "speakers": [
          {
            "name": "Arka Saha",
            "company": " Broadcom"
          },
          {
            "name": "Nabarun Pal",
            "company": " Broadcom"
          }
        ]
      }
    },
    {
      "text": "The maintainers of the CNCF Crossplane project (https://www.crossplane.io/) will lead this session that will not only introduce the project to new attendees, but also dive deep into the details of Crossplanes latest features, releases, and roadmap. There is always something new to show off at Kubecon! Were especially excited this time to walk through all the details of the new Crossplane v2. Over the many years of the project, we have heard great feedback from the community and we have taken the opportunity in this major new release to invest in a number of impactful improvements. Crossplane v2 sets up the project for many years to come, so join us to see how you can accelerate your platform journey with all the details of Crossplane v2! Speakers: The Cloud Native Framework for Platform Engineering - Jared Watts from  Upbound, Nic Cope from  Upbound. Location: Building C | Level 3 | Georgia Ballroom 1. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Crossplane",
        "description": "The maintainers of the CNCF Crossplane project (https://www.crossplane.io/) will lead this session that will not only introduce the project to new attendees, but also dive deep into the details of Crossplanes latest features, releases, and roadmap. There is always something new to show off at Kubecon! Were especially excited this time to walk through all the details of the new Crossplane v2. Over the many years of the project, we have heard great feedback from the community and we have taken the opportunity in this major new release to invest in a number of impactful improvements. Crossplane v2 sets up the project for many years to come, so join us to see how you can accelerate your platform journey with all the details of Crossplane v2!",
        "url": "http://kccncna2025.sched.com/event/cf3e8c099990311341268223df3a4ab6",
        "uid": "cf3e8c099990311341268223df3a4ab6",
        "start": "2025-11-11T16:15:00-05:00",
        "end": "2025-11-11T16:45:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 1"
        },
        "speakers": [
          {
            "name": "The Cloud Native Framework for Platform Engineering - Jared Watts",
            "company": " Upbound"
          },
          {
            "name": "Nic Cope",
            "company": " Upbound"
          }
        ]
      }
    },
    {
      "text": "WG Device Management continues to make great progress in enhancing support for GPUs, TPUs, NICs, and other specialized hardware in Kubernetes. With the 1.34 release, Dynamic Resource Allocation (DRA) has finally reached General Availability, making it easier than ever to configure, allocate, and share advanced hardware resources efficiently.For 1.35, our focus is on expanding the capabilities and maturity of additional features and add-ons, ensuring they are robust and ready for broader adoption.Join our session to discover whats new in Kubernetes 1.34, get a sneak peek at whats planned for 1.35 and future releases, and learn how you can help shape the future of accelerated workload support in Kubernetes! Speakers: GPUs TPUs, NICs and More With DRA - Kevin Klues from NVIDIA, Patrick Ohly from Intel. Location: Building C | Level 3 | Georgia Ballroom 3. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "DRA is GA! Kubernetes WG Device Management",
        "description": "WG Device Management continues to make great progress in enhancing support for GPUs, TPUs, NICs, and other specialized hardware in Kubernetes. With the 1.34 release, Dynamic Resource Allocation (DRA) has finally reached General Availability, making it easier than ever to configure, allocate, and share advanced hardware resources efficiently.For 1.35, our focus is on expanding the capabilities and maturity of additional features and add-ons, ensuring they are robust and ready for broader adoption.Join our session to discover whats new in Kubernetes 1.34, get a sneak peek at whats planned for 1.35 and future releases, and learn how you can help shape the future of accelerated workload support in Kubernetes!",
        "url": "http://kccncna2025.sched.com/event/b1a985a2f138667def0560f4b37a230d",
        "uid": "b1a985a2f138667def0560f4b37a230d",
        "start": "2025-11-11T16:15:00-05:00",
        "end": "2025-11-11T16:45:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 3"
        },
        "speakers": [
          {
            "name": "GPUs",
            "title": "TPUs, NICs and More With DRA - Kevin Klues",
            "company": "NVIDIA"
          },
          {
            "name": "Patrick Ohly",
            "company": "Intel"
          }
        ]
      }
    },
    {
      "text": "Knative, the most widely-adopted serverless platform on Kubernetes, offers a streamlined developer experience for deploying and managing stateless and event-driven applications. During this project update from its maintainers, attendees will learn about the latest developments in Knative, including updates on Serving, Eventing, Functions, and more. Additionally, the \"sandbox\" projects related to Knative, such as plugins for eventing, networking have also grown. Finally, the update will conclude with a review of the upcoming releases and roadmaps. Join us to stay informed on the latest advancements in Knative and to have your questions answered by on-site Knative maintainers. Speakers: Dave Protasowski from Independent. Location: Building C | Level 3 | Georgia Ballroom 2. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Knative Project Update",
        "description": "Knative, the most widely-adopted serverless platform on Kubernetes, offers a streamlined developer experience for deploying and managing stateless and event-driven applications. During this project update from its maintainers, attendees will learn about the latest developments in Knative, including updates on Serving, Eventing, Functions, and more. Additionally, the \"sandbox\" projects related to Knative, such as plugins for eventing, networking have also grown. Finally, the update will conclude with a review of the upcoming releases and roadmaps. Join us to stay informed on the latest advancements in Knative and to have your questions answered by on-site Knative maintainers.",
        "url": "http://kccncna2025.sched.com/event/5123807e35ca8b389917af94a5f3989f",
        "uid": "5123807e35ca8b389917af94a5f3989f",
        "start": "2025-11-11T16:15:00-05:00",
        "end": "2025-11-11T16:45:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 2"
        },
        "speakers": [
          {
            "name": "Dave Protasowski",
            "company": "Independent"
          }
        ]
      }
    },
    {
      "text": "SIG Scheduling is responsible for the components that make Pod scheduling decisions in a Kubernetes cluster, such as kube-scheduler for pod to node assignment, Kueue for job queueing, among other sub-projects too. In this session, you will learn the basics of kube-scheduler and improvements the community was working on around scheduling performance and communication of scheduling decisions. We will also discuss challenges that scheduling is facing related to the DRA effort and limitations of pod-by-pod scheduling approach. Then we will talk about several major updates in kube-scheduler, including the workload-aware scheduling effort that we want to kick off, which is supposed to address the above challenges. Lastly, well see some updates from sub-projects, such as FairSharing and HierarchicalCohort in Kueue. Speakers: Kensei Nakada from Independent, Dominik Marcinski from Google. Location: Building C | Level 1 | C111-112. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "SIG Scheduling Intro & Updates",
        "description": "SIG Scheduling is responsible for the components that make Pod scheduling decisions in a Kubernetes cluster, such as kube-scheduler for pod to node assignment, Kueue for job queueing, among other sub-projects too. In this session, you will learn the basics of kube-scheduler and improvements the community was working on around scheduling performance and communication of scheduling decisions. We will also discuss challenges that scheduling is facing related to the DRA effort and limitations of pod-by-pod scheduling approach. Then we will talk about several major updates in kube-scheduler, including the workload-aware scheduling effort that we want to kick off, which is supposed to address the above challenges. Lastly, well see some updates from sub-projects, such as FairSharing and HierarchicalCohort in Kueue.",
        "url": "http://kccncna2025.sched.com/event/a29054e91b6c19709c74ed46f27d194e",
        "uid": "a29054e91b6c19709c74ed46f27d194e",
        "start": "2025-11-11T16:15:00-05:00",
        "end": "2025-11-11T16:45:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "1",
          "room": "C111-112"
        },
        "speakers": [
          {
            "name": "Kensei Nakada",
            "company": "Independent"
          },
          {
            "name": "Dominik Marcinski",
            "company": "Google"
          }
        ]
      }
    },
    {
      "text": "You've started with OpenTelemetry. Data flows. And reality hits hard. Did you instrument the right things? Is your telemetry consistent enough to analyze it easily? Do you have enough context to make sense of it? Observability efforts flounder by yielding too little insights compared to the associated costs. This session introduces the \"Instrumentation Score,\" an open standard to help you collect excellent telemetry. It assesses OpenTelemetry data quality, consistency and completeness. Using OTLP analysis against best practices, it offers actionable insights to identify gaps and prioritize enhancements in your instrumentation. Discover how the Instrumentation Score provides a clear path from uncertainty to effective observability. Learn to benchmark services, systematically improve telemetry, and gather truly actionable insights. Confidently mature your OpenTelemetry practice, ensuring you're building high-value observability, rather than just collecting data. Speakers: Juraci Paixao Krohling from OllyGarden, Michele Mancioppi from Dash0. Location: Building B | Level 3 | B304-305. Categories: OBSERVABILITY.",
      "metadata": {
        "title": "Instrumentation Score: The Difference Between Telemetry and Good Telemetry",
        "description": "You've started with OpenTelemetry. Data flows. And reality hits hard. Did you instrument the right things? Is your telemetry consistent enough to analyze it easily? Do you have enough context to make sense of it? Observability efforts flounder by yielding too little insights compared to the associated costs. This session introduces the \"Instrumentation Score,\" an open standard to help you collect excellent telemetry. It assesses OpenTelemetry data quality, consistency and completeness. Using OTLP analysis against best practices, it offers actionable insights to identify gaps and prioritize enhancements in your instrumentation. Discover how the Instrumentation Score provides a clear path from uncertainty to effective observability. Learn to benchmark services, systematically improve telemetry, and gather truly actionable insights. Confidently mature your OpenTelemetry practice, ensuring you're building high-value observability, rather than just collecting data.",
        "url": "http://kccncna2025.sched.com/event/fcac21489a67655b017857abbcc61747",
        "uid": "fcac21489a67655b017857abbcc61747",
        "start": "2025-11-11T16:15:00-05:00",
        "end": "2025-11-11T16:45:00-05:00",
        "categories": [
          "OBSERVABILITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B304-305"
        },
        "speakers": [
          {
            "name": "Juraci Paixao Krohling",
            "company": "OllyGarden"
          },
          {
            "name": "Michele Mancioppi",
            "company": "Dash0"
          }
        ]
      }
    },
    {
      "text": "Kubernetes upgrades often feel like a roll of the dice, especially when safeguarding critical production workloads with strict uptime requirements. A single misstep can lead to cascading failures, performance degradation, or even data loss.\n\nThis talk pulls back the curtain on the battle-tested strategies of a core cloud provider's managed Kubernetes team. We'll share our strategies for transforming perilous upgrades into routine, reliable operations.\n\nYou'll learn directly from our operational scars and successes.This includes detailed insights into our automated remediation pipelines and intelligent, safer rollback mechanisms that minimize impact, ensuring you can react fast when things go wrong.\n\nAttendees will leave with:\n\nActionable insights and real-world techniques from a leading cloud provider.\nStrategies to enhance observability, automation, and incident response for maximized uptime.\nThe confidence to make upgrades a routine, safe, and even boring event. Speakers: Yuchen Zhou from Google, Uttam Kumar from Salesforce. Location: Building B | Level 4 | B406b-407. Categories: OPERATIONS + PERFORMANCE.",
      "metadata": {
        "title": "Upgrade Nightmare To Uptime Dream: The Cloud Provider's Playbook for Critical Kubernetes Work",
        "description": "Kubernetes upgrades often feel like a roll of the dice, especially when safeguarding critical production workloads with strict uptime requirements. A single misstep can lead to cascading failures, performance degradation, or even data loss.\n\nThis talk pulls back the curtain on the battle-tested strategies of a core cloud provider's managed Kubernetes team. We'll share our strategies for transforming perilous upgrades into routine, reliable operations.\n\nYou'll learn directly from our operational scars and successes.This includes detailed insights into our automated remediation pipelines and intelligent, safer rollback mechanisms that minimize impact, ensuring you can react fast when things go wrong.\n\nAttendees will leave with:\n\nActionable insights and real-world techniques from a leading cloud provider.\nStrategies to enhance observability, automation, and incident response for maximized uptime.\nThe confidence to make upgrades a routine, safe, and even boring event.",
        "url": "http://kccncna2025.sched.com/event/516976250d417f913d35029d98092ba9",
        "uid": "516976250d417f913d35029d98092ba9",
        "start": "2025-11-11T16:15:00-05:00",
        "end": "2025-11-11T16:45:00-05:00",
        "categories": [
          "OPERATIONS + PERFORMANCE"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B406b-407"
        },
        "speakers": [
          {
            "name": "Yuchen Zhou",
            "company": "Google"
          },
          {
            "name": "Uttam Kumar",
            "company": "Salesforce"
          }
        ]
      }
    },
    {
      "text": "Many projects and companies use genAI to produce source code and speed up software development tasks. Other companies focus on using generative AI to troubleshoot our environments and reduce user interactions and downtime.\n\nThis presentation will look at how platform APIs are slowly evolving to be more dynamic and less strict.\n\nSlowly, we are shifting to a world where platform engineers define the platform building blocks so they can be consumed as models that can explore, discover, and guide users through wizard-like interactions, to manage the lifecycle of platform resources autonomously.\n\nThe presentation's demo highlights AI's potential as an intuitive, powerful, and easily maintainable interface for internal platforms, radically simplifying service consumption, management, and troubleshooting for developers. Speakers: Mauricio \"Salaboy\" Salatino from Diagrid, Viktor Farcic from Upbound. Location: Building B | Level 3 | B312-314. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "The Evolution of Platform APIs in the Age of LLMs",
        "description": "Many projects and companies use genAI to produce source code and speed up software development tasks. Other companies focus on using generative AI to troubleshoot our environments and reduce user interactions and downtime.\n\nThis presentation will look at how platform APIs are slowly evolving to be more dynamic and less strict.\n\nSlowly, we are shifting to a world where platform engineers define the platform building blocks so they can be consumed as models that can explore, discover, and guide users through wizard-like interactions, to manage the lifecycle of platform resources autonomously.\n\nThe presentation's demo highlights AI's potential as an intuitive, powerful, and easily maintainable interface for internal platforms, radically simplifying service consumption, management, and troubleshooting for developers.",
        "url": "http://kccncna2025.sched.com/event/da4d98085378632a7b2704455b25b826",
        "uid": "da4d98085378632a7b2704455b25b826",
        "start": "2025-11-11T16:15:00-05:00",
        "end": "2025-11-11T16:45:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B312-314"
        },
        "speakers": [
          {
            "name": "Mauricio \"Salaboy\" Salatino",
            "company": "Diagrid"
          },
          {
            "name": "Viktor Farcic",
            "company": "Upbound"
          }
        ]
      }
    },
    {
      "text": "Can we secure AI workloads, agents, and MCP servers the same way we secure traditional microservices? Are established tools and standardssuch as SPIFFE identities, mutual TLS, authorization policies, and supply chain securitysufficient, or do AI workloads require a fundamentally different approach?\n\nThis panel discusses the unique challenges AI introduces across multiple dimensions: model selection, enterprise operations, hardening and red teaming, end-user management, model compute optimization, and long-running, context-heavy sessions. Well also explore disaster scenarios such as multi-cluster/region failovers, and what they mean for securing distributed AI applications.\n\nJoin our panel of AI and security experts for a dynamic discussion that clarifies what can be reused and what must be reimagined to effectively protect AI workloads. Speakers: Lin Sun from  Solo.io, Christian Posta from  Solo.io, Hannah Foxwell from Kortensia, Andrew Martin from ControlPlane, Ricardo Aravena from Snowflake. Location: Building B | Level 3 | B302-303. Categories: SECURITY.",
      "metadata": {
        "title": "In AI We Trust? Securing the Future, One Agent at a Time",
        "description": "Can we secure AI workloads, agents, and MCP servers the same way we secure traditional microservices? Are established tools and standardssuch as SPIFFE identities, mutual TLS, authorization policies, and supply chain securitysufficient, or do AI workloads require a fundamentally different approach?\n\nThis panel discusses the unique challenges AI introduces across multiple dimensions: model selection, enterprise operations, hardening and red teaming, end-user management, model compute optimization, and long-running, context-heavy sessions. Well also explore disaster scenarios such as multi-cluster/region failovers, and what they mean for securing distributed AI applications.\n\nJoin our panel of AI and security experts for a dynamic discussion that clarifies what can be reused and what must be reimagined to effectively protect AI workloads.",
        "url": "http://kccncna2025.sched.com/event/75ea0a33c1a779987c26bdb92c67211f",
        "uid": "75ea0a33c1a779987c26bdb92c67211f",
        "start": "2025-11-11T16:15:00-05:00",
        "end": "2025-11-11T16:45:00-05:00",
        "categories": [
          "SECURITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B302-303"
        },
        "speakers": [
          {
            "name": "Lin Sun",
            "company": " Solo.io"
          },
          {
            "name": "Christian Posta",
            "company": " Solo.io"
          },
          {
            "name": "Hannah Foxwell",
            "company": "Kortensia"
          },
          {
            "name": "Andrew Martin",
            "company": "ControlPlane"
          },
          {
            "name": "Ricardo Aravena",
            "company": "Snowflake"
          }
        ]
      }
    },
    {
      "text": "Platform and DevOps teams today face a new decision in traffic management: should they continue relying on the stable and proven Ingress API, or begin adopting the more flexible but still evolving Gateway API? Both specifications are viable, but each comes with distinct trade-offs. Ingress offers simplicity, maturity, and broad ecosystem support, making it ideal for production environments where stability is paramount. Gateway API introduces richer routing, role separation between operators and developers, and extensibility designed for the future of service networking. This session provides a balanced, vendor-neutral guide to help you choose the right approach. We will compare capabilities, highlight real-world use cases, and explore strategies for adoption, including hybrid patterns where Ingress and Gateway coexist. Attendees will leave with practical decision frameworks and concrete examples to help them balance todays stability needs with tomorrows innovation.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.* Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: SOLUTIONS SHOWCASE.",
      "metadata": {
        "title": "Sponsored Demo: Kubernetes Ingress or Gateway API  It depends!",
        "description": "Platform and DevOps teams today face a new decision in traffic management: should they continue relying on the stable and proven Ingress API, or begin adopting the more flexible but still evolving Gateway API? Both specifications are viable, but each comes with distinct trade-offs. Ingress offers simplicity, maturity, and broad ecosystem support, making it ideal for production environments where stability is paramount. Gateway API introduces richer routing, role separation between operators and developers, and extensibility designed for the future of service networking. This session provides a balanced, vendor-neutral guide to help you choose the right approach. We will compare capabilities, highlight real-world use cases, and explore strategies for adoption, including hybrid patterns where Ingress and Gateway coexist. Attendees will leave with practical decision frameworks and concrete examples to help them balance todays stability needs with tomorrows innovation.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.*",
        "url": "http://kccncna2025.sched.com/event/2622ec9534ea11ff1e2f5611d6ddc1a4",
        "uid": "2622ec9534ea11ff1e2f5611d6ddc1a4",
        "start": "2025-11-11T16:15:00-05:00",
        "end": "2025-11-11T16:35:00-05:00",
        "categories": [
          "SOLUTIONS SHOWCASE"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "As organizations deploy LLMs as distributed stacks in production Kubernetes environments, optimizing inference performance has been critical. This collaborative tutorial brings together experts from Google, NVIDIA, RedHat, IBM, and University of Chicago (LMCache) to provide practical benchmarking techniques for impactful LLM optimization strategies.\nUsing identified use cases as examples, we'll show how to benchmark key optimization strategies: KV Cache offloading, autoscaling, prefix/session-aware routing, KVCache-aware routing, and xPyD for prefill decode disaggregation. Attendees will learn a unified benchmarking approach integrating tools including vLLM, LMBenchmark, GuideLLM, GenAIperf, inference-perf, and fmperf. Through live demonstrations, participants gain hands-on experience with production-tested methodologies reflecting real-world scenarios. Attendees will be equipped to implement these approaches for data-driven LLM serving optimizations on Kubernetes. Speakers: Jing Chen from IBM Research, Junchen Jiang from University of Chicago, Ganesh Kudleppanavar from NVIDIA, Samuel Monson from Red Hat, Jason Kramberger from Google. Location: Building B | Level 5 | Thomas Murphy Ballroom 2-3. Categories:  TUTORIALS.",
      "metadata": {
        "title": "Tutorial: A Cross-Industry Benchmarking Tutorial for Distributed LLM Inference on Kubernetes",
        "description": "As organizations deploy LLMs as distributed stacks in production Kubernetes environments, optimizing inference performance has been critical. This collaborative tutorial brings together experts from Google, NVIDIA, RedHat, IBM, and University of Chicago (LMCache) to provide practical benchmarking techniques for impactful LLM optimization strategies.\nUsing identified use cases as examples, we'll show how to benchmark key optimization strategies: KV Cache offloading, autoscaling, prefix/session-aware routing, KVCache-aware routing, and xPyD for prefill decode disaggregation. Attendees will learn a unified benchmarking approach integrating tools including vLLM, LMBenchmark, GuideLLM, GenAIperf, inference-perf, and fmperf. Through live demonstrations, participants gain hands-on experience with production-tested methodologies reflecting real-world scenarios. Attendees will be equipped to implement these approaches for data-driven LLM serving optimizations on Kubernetes.",
        "url": "http://kccncna2025.sched.com/event/af001cd6d374e91b410a4cadeda4e4ee",
        "uid": "af001cd6d374e91b410a4cadeda4e4ee",
        "start": "2025-11-11T16:15:00-05:00",
        "end": "2025-11-11T17:30:00-05:00",
        "categories": [
          " TUTORIALS"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 2-3"
        },
        "speakers": [
          {
            "name": "Jing Chen",
            "company": "IBM Research"
          },
          {
            "name": "Junchen Jiang",
            "company": "University of Chicago"
          },
          {
            "name": "Ganesh Kudleppanavar",
            "company": "NVIDIA"
          },
          {
            "name": "Samuel Monson",
            "company": "Red Hat"
          },
          {
            "name": "Jason Kramberger",
            "company": "Google"
          }
        ]
      }
    },
    {
      "text": "Monitoring Kubernetes and cloud-native environments can be incredibly challenging. The sheer scale coupled with the dynamic and ephemeral nature of these architectures, makes identifying and resolving issues harder than ever. Yet, with Splunk Observability Cloud, organizations have reduced mean time to resolution (MTTR) by over 90%, even while managing massive environments with thousands of microservices and pods across tens of thousands of nodes.\n\nIn this session, you'll discover how Splunk Observability Clouds Kubernetes monitoring features can help you failure-proof your Kubernetes environments. Join us to learn how to harness proactive troubleshooting workflows, interactive cluster maps, entity health and relationships, and AI-powered recommendations to give you the real-time insight needed to maintain performance and reliability at scale.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.* Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: SOLUTIONS SHOWCASE.",
      "metadata": {
        "title": "Sponsored Demo: Proactively Troubleshoot Kubernetes Environments with Splunk Observability",
        "description": "Monitoring Kubernetes and cloud-native environments can be incredibly challenging. The sheer scale coupled with the dynamic and ephemeral nature of these architectures, makes identifying and resolving issues harder than ever. Yet, with Splunk Observability Cloud, organizations have reduced mean time to resolution (MTTR) by over 90%, even while managing massive environments with thousands of microservices and pods across tens of thousands of nodes.\n\nIn this session, you'll discover how Splunk Observability Clouds Kubernetes monitoring features can help you failure-proof your Kubernetes environments. Join us to learn how to harness proactive troubleshooting workflows, interactive cluster maps, entity health and relationships, and AI-powered recommendations to give you the real-time insight needed to maintain performance and reliability at scale.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.*",
        "url": "http://kccncna2025.sched.com/event/efd83a91245f0d75b3ff69968d2a04f0",
        "uid": "efd83a91245f0d75b3ff69968d2a04f0",
        "start": "2025-11-11T16:45:00-05:00",
        "end": "2025-11-11T17:05:00-05:00",
        "categories": [
          "SOLUTIONS SHOWCASE"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "As developers push the boundaries of AI-driven automation, the challenge of orchestrating and managing autonomous agents at scale becomes increasingly complex. Dapr Agents is an open-source CNCF framework that allows developers to create durable agents that persist state and are resilient to network failures, crashes and full cluster shutdowns. This talk will provide a deep dive into Dapr Agents, demonstrating how it facilitates structured LLM interactions, long-term memory, multi-agent collaboration and MCP integration. Most importantly, we will show how complex agents can remain resilient to failures as they are given more autonomy. If you're interested in building scalable and resilient agentic systems that run natively on Kubernetes, this session will equip you with the knowledge to easily build these. Speakers: Yaron Schneider from Diagrid. Location: Building B | Level 4 | B401-402. Categories: AI + ML.",
      "metadata": {
        "title": "Resilient by Design: Building Durable AI Agents on Kubernetes",
        "description": "As developers push the boundaries of AI-driven automation, the challenge of orchestrating and managing autonomous agents at scale becomes increasingly complex. Dapr Agents is an open-source CNCF framework that allows developers to create durable agents that persist state and are resilient to network failures, crashes and full cluster shutdowns. This talk will provide a deep dive into Dapr Agents, demonstrating how it facilitates structured LLM interactions, long-term memory, multi-agent collaboration and MCP integration. Most importantly, we will show how complex agents can remain resilient to failures as they are given more autonomy. If you're interested in building scalable and resilient agentic systems that run natively on Kubernetes, this session will equip you with the knowledge to easily build these.",
        "url": "http://kccncna2025.sched.com/event/858eb4e9a6412921c8b8474622369926",
        "uid": "858eb4e9a6412921c8b8474622369926",
        "start": "2025-11-11T17:00:00-05:00",
        "end": "2025-11-11T17:30:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B401-402"
        },
        "speakers": [
          {
            "name": "Yaron Schneider",
            "company": "Diagrid"
          }
        ]
      }
    },
    {
      "text": "While gRPC is well known for its performance and efficiency, this talk argues that these are not the primary features driving enterprise adoption. Enterprises ultimately seek stability. Marking its tenth anniversary, gRPC has firmly established it is here to stay and proven itself as a dependable foundation upon which to build.\n\nThis talk delves into the lesser-known, yet enterprise-critical, benefits of gRPC, highlighting features essential for building up organizational confidence. The talk covered:\n\n- In-process transport, presenting a pattern for the controlled decomposition of a monolithic.\n- Protobuf's superior binary message compatibility and the strategic power of unknown fields.\n- The reuse of messages on an enterprise bus, notably without the requirement for a schema registry.\n- Compatibility with JSON and RESTful architectures.\n\nThis session is designed to equip engineers and decision-makers with a comprehensive set of arguments to effectively champion gRPC adoption. Speakers: Alex Van Boxel from Collibra. Location: Building B | Level 5 | Thomas Murphy Ballroom 1. Categories: APPLICATION DEVELOPMENT.",
      "metadata": {
        "title": "The Enterprise Is Ready for gRPC",
        "description": "While gRPC is well known for its performance and efficiency, this talk argues that these are not the primary features driving enterprise adoption. Enterprises ultimately seek stability. Marking its tenth anniversary, gRPC has firmly established it is here to stay and proven itself as a dependable foundation upon which to build.\n\nThis talk delves into the lesser-known, yet enterprise-critical, benefits of gRPC, highlighting features essential for building up organizational confidence. The talk covered:\n\n- In-process transport, presenting a pattern for the controlled decomposition of a monolithic.\n- Protobuf's superior binary message compatibility and the strategic power of unknown fields.\n- The reuse of messages on an enterprise bus, notably without the requirement for a schema registry.\n- Compatibility with JSON and RESTful architectures.\n\nThis session is designed to equip engineers and decision-makers with a comprehensive set of arguments to effectively champion gRPC adoption.",
        "url": "http://kccncna2025.sched.com/event/767224bc75346a381c664f0feb87512b",
        "uid": "767224bc75346a381c664f0feb87512b",
        "start": "2025-11-11T17:00:00-05:00",
        "end": "2025-11-11T17:30:00-05:00",
        "categories": [
          "APPLICATION DEVELOPMENT"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 1"
        },
        "speakers": [
          {
            "name": "Alex Van Boxel",
            "company": "Collibra"
          }
        ]
      }
    },
    {
      "text": "Everyone is talking about Kubernetes LTSbut whats actually happening behind the scenes? While community discussions continue, several major vendors have already begun supporting Kubernetes over extended timelines to meet customer and regulatory needs.\n\nIn this panel, engineering leaders from AWS, Microsoft, and Broadcom come together to share lessons learned in the community and surface common patterns that can help move the broader LTS conversation forward.\n\nWell explore:\n- Tradeoffs in LTS timelines\n- Navigating upgrade path complexity\n- Aligning with ecosystem dependencies\n- Defining what LTS includes: security fixes, stability, critical patches\n- Identifying opportunities for cross-industry collaboration and community alignment\n\nThe discussion will be a real-world experience-driven conversation about whats working, whats challenging, and how the Kubernetes community can collectively shape the future of long term support. Speakers: Nikhita Raghunath from  Broadcom, Nikhila Kamath from  Broadcom, Micah Hausler from AWS, Jeremy Rickard from Microsoft, Aniket Ponkshe from Canonical. Location: Building B | Level 3 | B308-309. Categories: CLOUD NATIVE EXPERIENCE.",
      "metadata": {
        "title": "Shaping LTS Together: What Weve Learned the Hard Way",
        "description": "Everyone is talking about Kubernetes LTSbut whats actually happening behind the scenes? While community discussions continue, several major vendors have already begun supporting Kubernetes over extended timelines to meet customer and regulatory needs.\n\nIn this panel, engineering leaders from AWS, Microsoft, and Broadcom come together to share lessons learned in the community and surface common patterns that can help move the broader LTS conversation forward.\n\nWell explore:\n- Tradeoffs in LTS timelines\n- Navigating upgrade path complexity\n- Aligning with ecosystem dependencies\n- Defining what LTS includes: security fixes, stability, critical patches\n- Identifying opportunities for cross-industry collaboration and community alignment\n\nThe discussion will be a real-world experience-driven conversation about whats working, whats challenging, and how the Kubernetes community can collectively shape the future of long term support.",
        "url": "http://kccncna2025.sched.com/event/6400a6b954af847350a624322c2afe44",
        "uid": "6400a6b954af847350a624322c2afe44",
        "start": "2025-11-11T17:00:00-05:00",
        "end": "2025-11-11T17:30:00-05:00",
        "categories": [
          "CLOUD NATIVE EXPERIENCE"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B308-309"
        },
        "speakers": [
          {
            "name": "Nikhita Raghunath",
            "company": " Broadcom"
          },
          {
            "name": "Nikhila Kamath",
            "company": " Broadcom"
          },
          {
            "name": "Micah Hausler",
            "company": "AWS"
          },
          {
            "name": "Jeremy Rickard",
            "company": "Microsoft"
          },
          {
            "name": "Aniket Ponkshe",
            "company": "Canonical"
          }
        ]
      }
    },
    {
      "text": "Kubernetes is powerfulbut not always user-friendly. What if you could manage your cluster just by asking for what you need? In this talk, well introduce a new AI assistant built into Headlamp, the open-source Kubernetes UI. It brings natural language interaction directly into your desktop environment, translating plain English into kubectl commands, executing them, and returning resultsall through a conversational interface. Well demonstrate how the assistant understands UI context, supports multiple AI providers like Azure OpenAI and Claude, and simplifies complex workflows. By integrating AI directly into the Kubernetes UI, were making cluster management more accessible, intuitive, and efficientno terminal required. Whether you're new to Kubernetes or building internal platforms, this is a glimpse into a more human-centered, AI-powered future. Speakers: Will Case from Microsoft. Location: Building B | Level 2 | B206. Categories: CLOUD NATIVE NOVICE.",
      "metadata": {
        "title": "No Kubectl, No Problem: The Future With Conversational Kubernetes",
        "description": "Kubernetes is powerfulbut not always user-friendly. What if you could manage your cluster just by asking for what you need? In this talk, well introduce a new AI assistant built into Headlamp, the open-source Kubernetes UI. It brings natural language interaction directly into your desktop environment, translating plain English into kubectl commands, executing them, and returning resultsall through a conversational interface. Well demonstrate how the assistant understands UI context, supports multiple AI providers like Azure OpenAI and Claude, and simplifies complex workflows. By integrating AI directly into the Kubernetes UI, were making cluster management more accessible, intuitive, and efficientno terminal required. Whether you're new to Kubernetes or building internal platforms, this is a glimpse into a more human-centered, AI-powered future.",
        "url": "http://kccncna2025.sched.com/event/bbc0c49de1b8bb4748eb307d2c25bcd3",
        "uid": "bbc0c49de1b8bb4748eb307d2c25bcd3",
        "start": "2025-11-11T17:00:00-05:00",
        "end": "2025-11-11T17:30:00-05:00",
        "categories": [
          "CLOUD NATIVE NOVICE"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B206"
        },
        "speakers": [
          {
            "name": "Will Case",
            "company": "Microsoft"
          }
        ]
      }
    },
    {
      "text": "As organizations converge infrastructure by running VMs alongside containers in Kubernetes for cost savings and simplified operations, networking performance remains a key challenge especially for latency and throughput sensitive workloads. In this talk, we'll show how eBPF with AF_XDP can improve KubeVirt networking by putting QEMU in the fast lane (all without losing the ability to observe and enforce policy on traffic in the host unlike SR-IOV). We'll unpack an architecture built on Cilium, netkit, and upstream Linux kernel enhancements that enable KubeVirt Pods to launch QEMU/KVM instances backed by high-performance AF_XDP interfaces. You'll learn how our contributions to QEMU and the kernel enable this accelerated path, and how it stacks up against KubeVirt defaults using real world benchmarks. Expect kernel spelunking, performance graphs, and a vision for adding a fast lane to VM networking. Speakers: Daniel Borkmann from  Isovalent at Cisco, Anton Protopopov from  Isovalent at Cisco. Location: Building B | Level 4 | B405-406a. Categories: CONNECTIVITY.",
      "metadata": {
        "title": "QEMU in the Fast Lane: Accelerating KubeVirt Networking With eBPF",
        "description": "As organizations converge infrastructure by running VMs alongside containers in Kubernetes for cost savings and simplified operations, networking performance remains a key challenge especially for latency and throughput sensitive workloads. In this talk, we'll show how eBPF with AF_XDP can improve KubeVirt networking by putting QEMU in the fast lane (all without losing the ability to observe and enforce policy on traffic in the host unlike SR-IOV). We'll unpack an architecture built on Cilium, netkit, and upstream Linux kernel enhancements that enable KubeVirt Pods to launch QEMU/KVM instances backed by high-performance AF_XDP interfaces. You'll learn how our contributions to QEMU and the kernel enable this accelerated path, and how it stacks up against KubeVirt defaults using real world benchmarks. Expect kernel spelunking, performance graphs, and a vision for adding a fast lane to VM networking.",
        "url": "http://kccncna2025.sched.com/event/c325b68abd8560a1871588d9df13a841",
        "uid": "c325b68abd8560a1871588d9df13a841",
        "start": "2025-11-11T17:00:00-05:00",
        "end": "2025-11-11T17:30:00-05:00",
        "categories": [
          "CONNECTIVITY"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B405-406a"
        },
        "speakers": [
          {
            "name": "Daniel Borkmann",
            "company": " Isovalent at Cisco"
          },
          {
            "name": "Anton Protopopov",
            "company": " Isovalent at Cisco"
          }
        ]
      }
    },
    {
      "text": "In the cloud-native world, Container Storage Interface (CSI) drivers are the unsung heroes behind the seamless provisioning and management of persistent storage. With so many options, protocols, and features, choosing the right CSI driver can feel like navigating a maze in the dark.\n\nWell shine a spotlight on the CSI standard, comparing both traditional external storage platforms and software defined storage solutions, breaking down the architectures and key capabilities. You'll learn how these solutions support VM workloads, what features to prioritize, and how to avoid common pitfalls when building a resilient storage backend for your virtualized workloads.\n\nBy the end of this talk, the fog will lift, and youll walk away with the clarity and confidence whether you're integrating with legacy storage arrays or adopting modern SDS solutions to unlock the full potential of virtualized infrastructure on Kubernetes with KubeVirt. Speakers: Brenda McLaren from  Red Hat, Chris Keller from  Red Hat. Location: Building B | Level 5 | Thomas Murphy Ballroom 4. Categories: DATA PROCESSING + STORAGE.",
      "metadata": {
        "title": "Untangling CSI: Powering Persistent Storage for KubeVirt",
        "description": "In the cloud-native world, Container Storage Interface (CSI) drivers are the unsung heroes behind the seamless provisioning and management of persistent storage. With so many options, protocols, and features, choosing the right CSI driver can feel like navigating a maze in the dark.\n\nWell shine a spotlight on the CSI standard, comparing both traditional external storage platforms and software defined storage solutions, breaking down the architectures and key capabilities. You'll learn how these solutions support VM workloads, what features to prioritize, and how to avoid common pitfalls when building a resilient storage backend for your virtualized workloads.\n\nBy the end of this talk, the fog will lift, and youll walk away with the clarity and confidence whether you're integrating with legacy storage arrays or adopting modern SDS solutions to unlock the full potential of virtualized infrastructure on Kubernetes with KubeVirt.",
        "url": "http://kccncna2025.sched.com/event/1e08bb43747ec6a1741602b6c6b96816",
        "uid": "1e08bb43747ec6a1741602b6c6b96816",
        "start": "2025-11-11T17:00:00-05:00",
        "end": "2025-11-11T17:30:00-05:00",
        "categories": [
          "DATA PROCESSING + STORAGE"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 4"
        },
        "speakers": [
          {
            "name": "Brenda McLaren",
            "company": " Red Hat"
          },
          {
            "name": "Chris Keller",
            "company": " Red Hat"
          }
        ]
      }
    },
    {
      "text": "The CNCF project landscape has long been supported by a secondary, parallel structure of Technical Advisory Groups (TAGs) chartered by the Technical Oversight Committee (TOC). The ten year anniversary of CNCF has brought with it a reboot of how the TOC is supporting the community at large. This takes the form of reorganized TAGs and all new Technical Community Groups (TCGs), Initiatives, and Subprojects. Come learn about this parallel-world within the CNCF landscape, and pick up some strategies for how you can best contribute to  or take advantage of  each different part. Speakers: Eddie Knight from Sonatype. Location: Building C | Level 3 | Georgia Ballroom 2. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "A Parallel World: Understanding CNCF's TOC, TAGs, and TCGs",
        "description": "The CNCF project landscape has long been supported by a secondary, parallel structure of Technical Advisory Groups (TAGs) chartered by the Technical Oversight Committee (TOC). The ten year anniversary of CNCF has brought with it a reboot of how the TOC is supporting the community at large. This takes the form of reorganized TAGs and all new Technical Community Groups (TCGs), Initiatives, and Subprojects. Come learn about this parallel-world within the CNCF landscape, and pick up some strategies for how you can best contribute to  or take advantage of  each different part.",
        "url": "http://kccncna2025.sched.com/event/fa6f920e87ad5d26ea4d6ef1a99c086c",
        "uid": "fa6f920e87ad5d26ea4d6ef1a99c086c",
        "start": "2025-11-11T17:00:00-05:00",
        "end": "2025-11-11T17:30:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 2"
        },
        "speakers": [
          {
            "name": "Eddie Knight",
            "company": "Sonatype"
          }
        ]
      }
    },
    {
      "text": "What happens when a critical communication tool for thousands of contributors suddenly may need to be migrated? Or when the official documentation can no longer maintain links to third-party projects, and those projects voice their concerns? These are the kinds of real-world, non-technical challenges the Kubernetes Steering Committee tackles every day. This session will pull back the curtain on the often unseen and unglamorous work of the Steering Committee. We'll go beyond the formal charter and talk about the \"janitorial\" work that's essential to keeping a project of Kubernetes' scale healthy and productive. From managing contributor burnout and navigating funding requests to resolving conflicts and making difficult decisions about project resources, you'll hear firsthand what it takes to govern one of the world's largest open-source projects. Speakers: Antonio Ojea from  Google, Benjamin Elder from  Google. Location: Building C | Level 3 | Georgia Ballroom 1. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Beyond the Code: How the Kubernetes Steering Committee Tackles the Hard, Non-Technical Problems",
        "description": "What happens when a critical communication tool for thousands of contributors suddenly may need to be migrated? Or when the official documentation can no longer maintain links to third-party projects, and those projects voice their concerns? These are the kinds of real-world, non-technical challenges the Kubernetes Steering Committee tackles every day. This session will pull back the curtain on the often unseen and unglamorous work of the Steering Committee. We'll go beyond the formal charter and talk about the \"janitorial\" work that's essential to keeping a project of Kubernetes' scale healthy and productive. From managing contributor burnout and navigating funding requests to resolving conflicts and making difficult decisions about project resources, you'll hear firsthand what it takes to govern one of the world's largest open-source projects.",
        "url": "http://kccncna2025.sched.com/event/0a686bc86f18cae26b6177599470ce8c",
        "uid": "0a686bc86f18cae26b6177599470ce8c",
        "start": "2025-11-11T17:00:00-05:00",
        "end": "2025-11-11T17:30:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 1"
        },
        "speakers": [
          {
            "name": "Antonio Ojea",
            "company": " Google"
          },
          {
            "name": "Benjamin Elder",
            "company": " Google"
          }
        ]
      }
    },
    {
      "text": "Please join in for an insightful session which focuses on the impactful features and initiatives OpenTelemetry rolled out in 2025. You'll also get the inside scoop on what's coming in 2026 and how it's all going to shape the future of observability.\n\nThis session will also give you an opportunity to ask the awesome OpenTelemetry maintainers, TC and GC members, your questions about your favorite features or anything else OpenTelemetry. Join in and lets chat! Speakers: Alolita Sharma from Apple, Trask Stalnaker from Microsoft, Josh Suereth from Google, Austin Parker from Honeycomb.io. Location: Building C | Level 3 | Georgia Ballroom 3. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "OpenTelemetry: Unpacking 2025, Charting 2026",
        "description": "Please join in for an insightful session which focuses on the impactful features and initiatives OpenTelemetry rolled out in 2025. You'll also get the inside scoop on what's coming in 2026 and how it's all going to shape the future of observability.\n\nThis session will also give you an opportunity to ask the awesome OpenTelemetry maintainers, TC and GC members, your questions about your favorite features or anything else OpenTelemetry. Join in and lets chat!",
        "url": "http://kccncna2025.sched.com/event/71df3753f0a4b91a89304ccb97f58042",
        "uid": "71df3753f0a4b91a89304ccb97f58042",
        "start": "2025-11-11T17:00:00-05:00",
        "end": "2025-11-11T17:30:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 3"
        },
        "speakers": [
          {
            "name": "Alolita Sharma",
            "company": "Apple"
          },
          {
            "name": "Trask Stalnaker",
            "company": "Microsoft"
          },
          {
            "name": "Josh Suereth",
            "company": "Google"
          },
          {
            "name": "Austin Parker",
            "company": "Honeycomb.io"
          }
        ]
      }
    },
    {
      "text": "Kubernetes SIG Instrumentation is responsible for ensuring high quality and consistent instrumentation across the Kubernetes project. We will begin with an introductory overview of the efforts the SIG Instrumentation has worked on in the past and is currently working on. This deep dive session will go into detail about currently ongoing efforts happening within SIG Instrumentation to share with the audience concrete pieces of work to encourage future collaboration. Software engineering and operations are both disciplines practiced in SIG Instrumentation, and any experience will help the special interest group's mission. Join this session to learn how to get involved in SIG Instrumentation to make instrumentation even better! Speakers: Catherine Fang from  Google, David Ashpole from  Google. Location: Building C | Level 1 | C111-112. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "SIG Instrumentation Introduction and Deep Dive",
        "description": "Kubernetes SIG Instrumentation is responsible for ensuring high quality and consistent instrumentation across the Kubernetes project. We will begin with an introductory overview of the efforts the SIG Instrumentation has worked on in the past and is currently working on. This deep dive session will go into detail about currently ongoing efforts happening within SIG Instrumentation to share with the audience concrete pieces of work to encourage future collaboration. Software engineering and operations are both disciplines practiced in SIG Instrumentation, and any experience will help the special interest group's mission. Join this session to learn how to get involved in SIG Instrumentation to make instrumentation even better!",
        "url": "http://kccncna2025.sched.com/event/3dd391da9fa19a2433e396f83806134e",
        "uid": "3dd391da9fa19a2433e396f83806134e",
        "start": "2025-11-11T17:00:00-05:00",
        "end": "2025-11-11T17:30:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "1",
          "room": "C111-112"
        },
        "speakers": [
          {
            "name": "Catherine Fang",
            "company": " Google"
          },
          {
            "name": "David Ashpole",
            "company": " Google"
          }
        ]
      }
    },
    {
      "text": "Weve gotten good at observing applications in Kubernetes, but the underlying data center often remains a black box. When the physical environment breaks, it typically surfaces as a service issue, not an infrastructure one.\nAt the Legislative Chamber of the Federal District (the CLDF) in Brazil, a small team managing on-premises Kubernetes clusters faced this challenge. This talk shows how they addressed it using an open-source observability stack built on Redfish, SNMP, and Syslog, funneled into a unified OpenTelemetry pipeline. Using tools like Telegraf Collector, OpenTelemetry Collector, Perses, and OpenSearch, they gained end-to-end visibility without commercial tools or silos.\nIf you run Kubernetes in on-premises, retail, or edge environments, this session offers a practical, vendor-neutral approach to bridging physical infrastructure with cloud-native observability workflows. Speakers: Pedro Celestin from CLDF, Julia Furst Morgado from Veeam. Location: Building B | Level 3 | B304-305. Categories: OBSERVABILITY.",
      "metadata": {
        "title": "Integrating Data Center Observability Into Cloud Native Environment",
        "description": "Weve gotten good at observing applications in Kubernetes, but the underlying data center often remains a black box. When the physical environment breaks, it typically surfaces as a service issue, not an infrastructure one.\nAt the Legislative Chamber of the Federal District (the CLDF) in Brazil, a small team managing on-premises Kubernetes clusters faced this challenge. This talk shows how they addressed it using an open-source observability stack built on Redfish, SNMP, and Syslog, funneled into a unified OpenTelemetry pipeline. Using tools like Telegraf Collector, OpenTelemetry Collector, Perses, and OpenSearch, they gained end-to-end visibility without commercial tools or silos.\nIf you run Kubernetes in on-premises, retail, or edge environments, this session offers a practical, vendor-neutral approach to bridging physical infrastructure with cloud-native observability workflows.",
        "url": "http://kccncna2025.sched.com/event/fb8f1a3e74eae8cdb76a63a5627d74ec",
        "uid": "fb8f1a3e74eae8cdb76a63a5627d74ec",
        "start": "2025-11-11T17:00:00-05:00",
        "end": "2025-11-11T17:30:00-05:00",
        "categories": [
          "OBSERVABILITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B304-305"
        },
        "speakers": [
          {
            "name": "Pedro Celestin",
            "company": "CLDF"
          },
          {
            "name": "Julia Furst Morgado",
            "company": "Veeam"
          }
        ]
      }
    },
    {
      "text": "Migrating a monolith to Kubernetes (k8s) with zero downtime comes with unique challenges depending on the tech stack. In this session, well share our real-world journey, highlighting both strategy and a live demo that showcases our lessons learnedboth wins and pitfalls. We will cover: - Container Lifecycle Hooks: Why they matter and how they support seamless deployments - Using Lifecycle hooks to control termination of POD to avoid HTTP 503 errors during rolling deployment. - Real config examples, troubleshooting tips, and best practices to maintain high availability Youll leave with a solid grasp of how and when to use Lifecycle hooks to ensure smooth rolling deployments. Our live demo will dive into key issues to address for zero downtime migration of any service. By the end, youll understand the complexities of transitioning monolithic apps to Kubernetes using CNCF tools and gain insights to guide your own migration efforts. Speakers: Deepak Kosaraju from  Procore, James Dabbs from  Procore. Location: Building B | Level 4 | B406b-407. Categories: OPERATIONS + PERFORMANCE.",
      "metadata": {
        "title": "Zero Downtime Migration of Monolith To K8s Using Sidecar and Container Lifecycle Hooks",
        "description": "Migrating a monolith to Kubernetes (k8s) with zero downtime comes with unique challenges depending on the tech stack. In this session, well share our real-world journey, highlighting both strategy and a live demo that showcases our lessons learnedboth wins and pitfalls. We will cover: - Container Lifecycle Hooks: Why they matter and how they support seamless deployments - Using Lifecycle hooks to control termination of POD to avoid HTTP 503 errors during rolling deployment. - Real config examples, troubleshooting tips, and best practices to maintain high availability Youll leave with a solid grasp of how and when to use Lifecycle hooks to ensure smooth rolling deployments. Our live demo will dive into key issues to address for zero downtime migration of any service. By the end, youll understand the complexities of transitioning monolithic apps to Kubernetes using CNCF tools and gain insights to guide your own migration efforts.",
        "url": "http://kccncna2025.sched.com/event/ba77e5972a94ffc03b14812c96973235",
        "uid": "ba77e5972a94ffc03b14812c96973235",
        "start": "2025-11-11T17:00:00-05:00",
        "end": "2025-11-11T17:30:00-05:00",
        "categories": [
          "OPERATIONS + PERFORMANCE"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B406b-407"
        },
        "speakers": [
          {
            "name": "Deepak Kosaraju",
            "company": " Procore"
          },
          {
            "name": "James Dabbs",
            "company": " Procore"
          }
        ]
      }
    },
    {
      "text": "Have you ever stopped to think about how much the cloud spoils us? Managed services, infinite scalability, auto-healing clusters, instant backups  all just a click away. But what happens when you're told: no cloud, no internet, on-prem only? This session breaks down the brutal wake-up call that comes when cloud-native engineers are dropped into an air-gapped, on-prem world. Drawing from real-world experience rebuilding Kubernetes infrastructure in restricted environments, the talk explores what it really takes to replicate the clouds conveniences from scratch. From object storage and backup strategies to HA, deployment scalability, and monitoring  every layer of magic once taken for granted becomes a manual puzzle to solve. This talk is for anyone facing compliance constraints, cost-driven on-prem mandates, or just curious about what lies beneath the surface of their cloud-native stack. Warning: you may never see the cloud the same way again. Speakers: Paris Nakita Kejser from Terma A/S. Location: Building B | Level 3 | B312-314. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "The Cloud Is Lying To You: What It Really Takes To Run On-Prem",
        "description": "Have you ever stopped to think about how much the cloud spoils us? Managed services, infinite scalability, auto-healing clusters, instant backups  all just a click away. But what happens when you're told: no cloud, no internet, on-prem only? This session breaks down the brutal wake-up call that comes when cloud-native engineers are dropped into an air-gapped, on-prem world. Drawing from real-world experience rebuilding Kubernetes infrastructure in restricted environments, the talk explores what it really takes to replicate the clouds conveniences from scratch. From object storage and backup strategies to HA, deployment scalability, and monitoring  every layer of magic once taken for granted becomes a manual puzzle to solve. This talk is for anyone facing compliance constraints, cost-driven on-prem mandates, or just curious about what lies beneath the surface of their cloud-native stack. Warning: you may never see the cloud the same way again.",
        "url": "http://kccncna2025.sched.com/event/d4ec3d5b04edf5027805383ffb88d88d",
        "uid": "d4ec3d5b04edf5027805383ffb88d88d",
        "start": "2025-11-11T17:00:00-05:00",
        "end": "2025-11-11T17:30:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B312-314"
        },
        "speakers": [
          {
            "name": "Paris Nakita Kejser",
            "company": "Terma A/S"
          }
        ]
      }
    },
    {
      "text": "Its 2025. Weve been talking about the fundamental insecurity and unreliability of the network for at least ten years, and there are great options for addressing these issues these days. So why are folks still running applications without secure communications instead of taking advantage of these options? Are they trusting Kubernetes to protect them? Do they think security is too complex? Are we as an industry just doing a terrible job explaining that its important? In this session, were going to tease apart the barriers to good security in the cloud. Well talk about meshes, application code, and memory safety, but above all well talk about operational simplicity and how the real key to security is understanding whats happening in your application. Youll leave this talk with actionable information about taking charge of your own security, illustrated with examples using Linkerd, but applicable everywhere. Speakers: Alex Leong from Buoyant. Location: Building B | Level 3 | B302-303. Categories: SECURITY.",
      "metadata": {
        "title": "Its 2025; Why Are You OK With an Insecure Network?",
        "description": "Its 2025. Weve been talking about the fundamental insecurity and unreliability of the network for at least ten years, and there are great options for addressing these issues these days. So why are folks still running applications without secure communications instead of taking advantage of these options? Are they trusting Kubernetes to protect them? Do they think security is too complex? Are we as an industry just doing a terrible job explaining that its important? In this session, were going to tease apart the barriers to good security in the cloud. Well talk about meshes, application code, and memory safety, but above all well talk about operational simplicity and how the real key to security is understanding whats happening in your application. Youll leave this talk with actionable information about taking charge of your own security, illustrated with examples using Linkerd, but applicable everywhere.",
        "url": "http://kccncna2025.sched.com/event/53affcb37a186339c9b12490d1de4c1f",
        "uid": "53affcb37a186339c9b12490d1de4c1f",
        "start": "2025-11-11T17:00:00-05:00",
        "end": "2025-11-11T17:30:00-05:00",
        "categories": [
          "SECURITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B302-303"
        },
        "speakers": [
          {
            "name": "Alex Leong",
            "company": "Buoyant"
          }
        ]
      }
    },
    {
      "text": "With the purchase of VMware, Broadcom introduced a new consideration that every C-level executive needed to manage; Risk. With most customers running a 2-vendor system for their storage, compute, and in some cases networking; if a single vendor made an unfavorable change...the organization could pivot as-needed to the second vendor and continue operations. This was not the case with VMware, where organizations had enjoyed over a decade of high-quality, (relatively) low-cost, high-capability virtualization that became the standard in the industry. Now that risk is a topic of conversation and consideration, presenting the right second solution to a customer is key. They need usability, capability, extensibility, and most of all flexibility to address not only Virtualization, but AI and DevOps too.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.* Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: SOLUTIONS SHOWCASE.",
      "metadata": {
        "title": "Sponsored Demo: De-risking Your Virtualization, AI, and DevOps Strategies",
        "description": "With the purchase of VMware, Broadcom introduced a new consideration that every C-level executive needed to manage; Risk. With most customers running a 2-vendor system for their storage, compute, and in some cases networking; if a single vendor made an unfavorable change...the organization could pivot as-needed to the second vendor and continue operations. This was not the case with VMware, where organizations had enjoyed over a decade of high-quality, (relatively) low-cost, high-capability virtualization that became the standard in the industry. Now that risk is a topic of conversation and consideration, presenting the right second solution to a customer is key. They need usability, capability, extensibility, and most of all flexibility to address not only Virtualization, but AI and DevOps too.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.*",
        "url": "http://kccncna2025.sched.com/event/89ee87d51ce3d82c659e510fa835f092",
        "uid": "89ee87d51ce3d82c659e510fa835f092",
        "start": "2025-11-11T17:15:00-05:00",
        "end": "2025-11-11T17:35:00-05:00",
        "categories": [
          "SOLUTIONS SHOWCASE"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "In this session, well show how to use the Kubeflow Trainer, KServe, and Feast to fine tune, deploy, and serve a scalable Production Retrieval Augmented Generation (RAG) application. Well review the seminal 2020 RAG paper and demonstrate how you can use Kubernetes and distributed computing to fine tune a Retrieval model and Generator model for knowledge tasks. We will also show how to deploy this software application using Feast and KServe. The session will review the challenges of production AI applications such as data preprocessing/transforming data with varying formats, data ingestion, data lineage, trade-offs in write patterns, scaling horizontally, customizing models to your domain, and serving latency. Join us for a practical guide to implementing end-to-end RAG with Kubeflow! Speakers: Francisco Javier Arceo from Red Hat, Andrey Velichkevich from Apple. Location: Building B | Level 4 | B401-402. Categories: AI + ML.",
      "metadata": {
        "title": "RAG and Fine Tuning With Kubeflow",
        "description": "In this session, well show how to use the Kubeflow Trainer, KServe, and Feast to fine tune, deploy, and serve a scalable Production Retrieval Augmented Generation (RAG) application. Well review the seminal 2020 RAG paper and demonstrate how you can use Kubernetes and distributed computing to fine tune a Retrieval model and Generator model for knowledge tasks. We will also show how to deploy this software application using Feast and KServe. The session will review the challenges of production AI applications such as data preprocessing/transforming data with varying formats, data ingestion, data lineage, trade-offs in write patterns, scaling horizontally, customizing models to your domain, and serving latency. Join us for a practical guide to implementing end-to-end RAG with Kubeflow!",
        "url": "http://kccncna2025.sched.com/event/e1c6f4d70ce416592feb468b0d6c63ee",
        "uid": "e1c6f4d70ce416592feb468b0d6c63ee",
        "start": "2025-11-11T17:45:00-05:00",
        "end": "2025-11-11T18:15:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B401-402"
        },
        "speakers": [
          {
            "name": "Francisco Javier Arceo",
            "company": "Red Hat"
          },
          {
            "name": "Andrey Velichkevich",
            "company": "Apple"
          }
        ]
      }
    },
    {
      "text": "Launch reliability is crucial for applications on Kubernetes that frequently restart. However, applications often struggle to achieve optimal performance immediately after starting, failing to handle the load and experiencing startup failures. This lack of launch reliability can result in service downtime during rollouts and make the horizontal pod autoscaler ineffective. To prevent these issues, it's essential to tune the application and apply various practices within manifests.\n\nThis session will cover best practices for maximizing the launch reliability of applications on Kubernetes, including application tuning, appropriate resource allocation, health check settings, and techniques for automated warm-up. Additionally, he will explore the practical use of Kubernetes' recent feature, in-place pod resize, particularly for CPU bursting at startup. By the end of the session, you will gain actionable insights to enhance application stability and achieve flexible scaling. Speakers: Hiroshi Hayakawa from LY Corporation. Location: Building B | Level 4 | B406b-407. Categories: APPLICATION DEVELOPMENT.",
      "metadata": {
        "title": "Maximizing the Launch Reliability: Ensuring Stable Application Lift-off and Orbit on Kubernetes",
        "description": "Launch reliability is crucial for applications on Kubernetes that frequently restart. However, applications often struggle to achieve optimal performance immediately after starting, failing to handle the load and experiencing startup failures. This lack of launch reliability can result in service downtime during rollouts and make the horizontal pod autoscaler ineffective. To prevent these issues, it's essential to tune the application and apply various practices within manifests.\n\nThis session will cover best practices for maximizing the launch reliability of applications on Kubernetes, including application tuning, appropriate resource allocation, health check settings, and techniques for automated warm-up. Additionally, he will explore the practical use of Kubernetes' recent feature, in-place pod resize, particularly for CPU bursting at startup. By the end of the session, you will gain actionable insights to enhance application stability and achieve flexible scaling.",
        "url": "http://kccncna2025.sched.com/event/a2316efb8fd83cb3fbff19e465486f18",
        "uid": "a2316efb8fd83cb3fbff19e465486f18",
        "start": "2025-11-11T17:45:00-05:00",
        "end": "2025-11-11T18:15:00-05:00",
        "categories": [
          "APPLICATION DEVELOPMENT"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B406b-407"
        },
        "speakers": [
          {
            "name": "Hiroshi Hayakawa",
            "company": "LY Corporation"
          }
        ]
      }
    },
    {
      "text": "When you want a language model to do productive work, providing it with the right context and grounding it with organizational data is key to preventing unwanted outputs. But building on foundational models can be complex and time-consuming  especially if you consider fine-tuning them on your own data. So, most often, Retrieval-Augmented Generation (RAG) is implemented to provide the necessary context, but building RAG pipelines vector DBs, embeddings, indexing  can be a significant undertaking. How do we make this simpler and more approachable for developers starting to build AI applications? With KAITO, a CNCF sandbox project, you can start to tame the complexities and quickly build RAG pipelines using the RAGEngine CRD reducing the need for complex coding. KAITO streamlines this process, allowing developers to focus on application logic rather than infrastructure management. Join us to learn how KAITO can simplify your RAG pipelines and accelerate your AI application development Speakers: Paul Yu from  Microsoft, Sachi Desai from  Microsoft. Location: Building B | Level 5 | Thomas Murphy Ballroom 1. Categories: APPLICATION DEVELOPMENT.",
      "metadata": {
        "title": "Rage Against the Machine: Fighting AI Complexity With Kubernetes Simplicity",
        "description": "When you want a language model to do productive work, providing it with the right context and grounding it with organizational data is key to preventing unwanted outputs. But building on foundational models can be complex and time-consuming  especially if you consider fine-tuning them on your own data. So, most often, Retrieval-Augmented Generation (RAG) is implemented to provide the necessary context, but building RAG pipelines vector DBs, embeddings, indexing  can be a significant undertaking. How do we make this simpler and more approachable for developers starting to build AI applications? With KAITO, a CNCF sandbox project, you can start to tame the complexities and quickly build RAG pipelines using the RAGEngine CRD reducing the need for complex coding. KAITO streamlines this process, allowing developers to focus on application logic rather than infrastructure management. Join us to learn how KAITO can simplify your RAG pipelines and accelerate your AI application development",
        "url": "http://kccncna2025.sched.com/event/2f0e74406851a0d1563e79e1759698e5",
        "uid": "2f0e74406851a0d1563e79e1759698e5",
        "start": "2025-11-11T17:45:00-05:00",
        "end": "2025-11-11T18:15:00-05:00",
        "categories": [
          "APPLICATION DEVELOPMENT"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 1"
        },
        "speakers": [
          {
            "name": "Paul Yu",
            "company": " Microsoft"
          },
          {
            "name": "Sachi Desai",
            "company": " Microsoft"
          }
        ]
      }
    },
    {
      "text": "Youre starting your new Cloud Native application and soon realize that running it across different environments can be daunting! Youre targeting Kubernetes or Cloud provider services, but how can you work and test effectively without spinning up full clusters?\n\nIn this presentation, we will look into how testing complex Cloud Native applications with heavy infrastructure and dependencies can be simplified using the right tools for the job. This talk will dig into projects like Testcontainers for local development, Microcks for mocking and testing, and Dapr for cross-environment portability.\n\nLearn how to eliminate drift between environments and improve efficiency and confidence without running applications on Kubernetes clusters! Speakers: Laurent Broudoux from Postman, Artur Ciocanu from Adobe Inc. Location: Building B | Level 5 | Thomas Murphy Ballroom 2-3. Categories: APPLICATION DEVELOPMENT.",
      "metadata": {
        "title": "Simplifying Cloud Native App Testing Across Environments",
        "description": "Youre starting your new Cloud Native application and soon realize that running it across different environments can be daunting! Youre targeting Kubernetes or Cloud provider services, but how can you work and test effectively without spinning up full clusters?\n\nIn this presentation, we will look into how testing complex Cloud Native applications with heavy infrastructure and dependencies can be simplified using the right tools for the job. This talk will dig into projects like Testcontainers for local development, Microcks for mocking and testing, and Dapr for cross-environment portability.\n\nLearn how to eliminate drift between environments and improve efficiency and confidence without running applications on Kubernetes clusters!",
        "url": "http://kccncna2025.sched.com/event/d2755f447c5ecb2eba71063a22c9bde4",
        "uid": "d2755f447c5ecb2eba71063a22c9bde4",
        "start": "2025-11-11T17:45:00-05:00",
        "end": "2025-11-11T18:15:00-05:00",
        "categories": [
          "APPLICATION DEVELOPMENT"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 2-3"
        },
        "speakers": [
          {
            "name": "Laurent Broudoux",
            "company": "Postman"
          },
          {
            "name": "Artur Ciocanu",
            "company": "Adobe Inc"
          }
        ]
      }
    },
    {
      "text": "How do you move a 400-year-old university with 60,000 students and staff from a monolithic ESB to a decentralized, Kubernetes-native futurewhile keeping everyone engaged? The universitys API-first mandate exposed hundreds of services but surfaced bottlenecks in governance, release cadence, and team autonomy. By grouping related microservices, APIs, and policies into self-contained cells deployed on Kubernetes, the team built a repeatable framework any squad could adopt in days. Provisioning fell from weeks to minutes, cell & artifact level logging streamlined incident investigation, deploying code couldn't be easier. Most important was how they succeeded: involving both business users and technical staff throughout the process, they built engagement and trust together. Collectively developing lightweight playbooks meant they now have a blueprint for rolling out cell-based architecture in large, federated organizationsstarting with people, not platforms. Speakers: Martin Jones from University of Edinburgh, Asanka Abeysinghe from WSO2. Location: Building B | Level 3 | B308-309. Categories: CLOUD NATIVE EXPERIENCE.",
      "metadata": {
        "title": "People-first Path To Cell-based Architecture",
        "description": "How do you move a 400-year-old university with 60,000 students and staff from a monolithic ESB to a decentralized, Kubernetes-native futurewhile keeping everyone engaged? The universitys API-first mandate exposed hundreds of services but surfaced bottlenecks in governance, release cadence, and team autonomy. By grouping related microservices, APIs, and policies into self-contained cells deployed on Kubernetes, the team built a repeatable framework any squad could adopt in days. Provisioning fell from weeks to minutes, cell & artifact level logging streamlined incident investigation, deploying code couldn't be easier. Most important was how they succeeded: involving both business users and technical staff throughout the process, they built engagement and trust together. Collectively developing lightweight playbooks meant they now have a blueprint for rolling out cell-based architecture in large, federated organizationsstarting with people, not platforms.",
        "url": "http://kccncna2025.sched.com/event/670d737e86b44f285809bd1bd97d2670",
        "uid": "670d737e86b44f285809bd1bd97d2670",
        "start": "2025-11-11T17:45:00-05:00",
        "end": "2025-11-11T18:15:00-05:00",
        "categories": [
          "CLOUD NATIVE EXPERIENCE"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B308-309"
        },
        "speakers": [
          {
            "name": "Martin Jones",
            "company": "University of Edinburgh"
          },
          {
            "name": "Asanka Abeysinghe",
            "company": "WSO2"
          }
        ]
      }
    },
    {
      "text": "Many people attending KubeCon have spent years on both Cloud Native and Kubernetes - growing in their technical knowledge alongside the development of these concepts and technologies. But, there are others for whom that isnt the case. There are those who are just starting out their careers. And there are others who pivoted from industries that used older methods, tools, and technologies, which is the case for one of the presenters. This talk aims to take those very people through what its like to dive head-first into Kubernetes and Cloud-Native in the modern day through the eyes of an engineer who did exactly that just recently  learning it in its mature form instead of iteratively along with it. It discusses the challenges and pitfalls that can be overcome or avoided. Additionally, it discusses whats changed in those years that has made things easier, from the alternate perspective of an engineer who has been using Kubernetes for many years. Speakers: Eamon Ryan from  Grafana Labs, Ayah Elshaikh from  Grafana Labs. Location: Building B | Level 2 | B206. Categories: CLOUD NATIVE NOVICE.",
      "metadata": {
        "title": "Straight Into the Deep End! Learning Kubernetes and Cloud Native From Scratch in Late 2024.",
        "description": "Many people attending KubeCon have spent years on both Cloud Native and Kubernetes - growing in their technical knowledge alongside the development of these concepts and technologies. But, there are others for whom that isnt the case. There are those who are just starting out their careers. And there are others who pivoted from industries that used older methods, tools, and technologies, which is the case for one of the presenters. This talk aims to take those very people through what its like to dive head-first into Kubernetes and Cloud-Native in the modern day through the eyes of an engineer who did exactly that just recently  learning it in its mature form instead of iteratively along with it. It discusses the challenges and pitfalls that can be overcome or avoided. Additionally, it discusses whats changed in those years that has made things easier, from the alternate perspective of an engineer who has been using Kubernetes for many years.",
        "url": "http://kccncna2025.sched.com/event/b97c0b35ccb614df271f263321cd6154",
        "uid": "b97c0b35ccb614df271f263321cd6154",
        "start": "2025-11-11T17:45:00-05:00",
        "end": "2025-11-11T18:15:00-05:00",
        "categories": [
          "CLOUD NATIVE NOVICE"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B206"
        },
        "speakers": [
          {
            "name": "Eamon Ryan",
            "company": " Grafana Labs"
          },
          {
            "name": "Ayah Elshaikh",
            "company": " Grafana Labs"
          }
        ]
      }
    },
    {
      "text": "Service Mesh technology revolutionizes networking, security, and observability. Yet, the CNCF landscape reveals a crowded field with overlapping solutions. In the Service Mesh space, options aboundIstio, Kuma, Linkerd, Traefik Mesh, and the promising Ambient Mesh. Each Service Mesh demands mastery of unique Custom Resource Definitions (CRDs), complicating transitions. Enter the Gateway API (GAMA) initiative, a beacon of hope promising standardized CRDs for Ingress, routing, and Service Mesh management. But does it truly deliver a unified configuration across diverse Service Meshes? This talk offers a community feedback loop, evaluating how each solution supports the Gateway API. We'll configure meshes using HTTPRoute and GRPCRoute, spotlighting areas needing custom tweaks. Plus, we'll benchmark performance across solutions, providing actionable insights for your Service Mesh journey. Speakers: Henrik Rexed from Dynatrace. Location: Building B | Level 4 | B405-406a. Categories: CONNECTIVITY.",
      "metadata": {
        "title": "Return of the Mesh: Gateway API's Epic Quest for Unity",
        "description": "Service Mesh technology revolutionizes networking, security, and observability. Yet, the CNCF landscape reveals a crowded field with overlapping solutions. In the Service Mesh space, options aboundIstio, Kuma, Linkerd, Traefik Mesh, and the promising Ambient Mesh. Each Service Mesh demands mastery of unique Custom Resource Definitions (CRDs), complicating transitions. Enter the Gateway API (GAMA) initiative, a beacon of hope promising standardized CRDs for Ingress, routing, and Service Mesh management. But does it truly deliver a unified configuration across diverse Service Meshes? This talk offers a community feedback loop, evaluating how each solution supports the Gateway API. We'll configure meshes using HTTPRoute and GRPCRoute, spotlighting areas needing custom tweaks. Plus, we'll benchmark performance across solutions, providing actionable insights for your Service Mesh journey.",
        "url": "http://kccncna2025.sched.com/event/f3c5c7e63830b515d8d823f1121e5859",
        "uid": "f3c5c7e63830b515d8d823f1121e5859",
        "start": "2025-11-11T17:45:00-05:00",
        "end": "2025-11-11T18:15:00-05:00",
        "categories": [
          "CONNECTIVITY"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B405-406a"
        },
        "speakers": [
          {
            "name": "Henrik Rexed",
            "company": "Dynatrace"
          }
        ]
      }
    },
    {
      "text": "AI applications face retrieval challenges, driving the rise of vector databases. However, AI workflows demand morefeature store retrieval and analytical queries are just as essential. This often leads to AI data being stored in separate silos and queried using separate systems, increasing cost and complexity.\nLanceDB eliminates this complexity by unifying vector search, feature retrieval, and SQL-based analytics within a single system, built on the open-source Lance columnar formatthe new standard for AI data. With Kubernetes-native autoscaling, RAG and AI Agent applications embedding LanceDB can scale dynamically. This architecture redefines the performance-scale-cost curve, delivering hyper-scalable AI applications at 10X better cost-efficiency. Leveraged KServe for model serving, Postgres for metadata caching, and Kubernetes native data caching solutions, the impossible triangle of performance, scale, and cost is broken. Speakers: Lu Qiu from  LanceDB, Chanchan Mao from  LanceDB. Location: Building B | Level 5 | Thomas Murphy Ballroom 4. Categories: DATA PROCESSING + STORAGE.",
      "metadata": {
        "title": "Highly ScalableAI Search Engine and AI Data Lake With Kubernetes and LanceDB",
        "description": "AI applications face retrieval challenges, driving the rise of vector databases. However, AI workflows demand morefeature store retrieval and analytical queries are just as essential. This often leads to AI data being stored in separate silos and queried using separate systems, increasing cost and complexity.\nLanceDB eliminates this complexity by unifying vector search, feature retrieval, and SQL-based analytics within a single system, built on the open-source Lance columnar formatthe new standard for AI data. With Kubernetes-native autoscaling, RAG and AI Agent applications embedding LanceDB can scale dynamically. This architecture redefines the performance-scale-cost curve, delivering hyper-scalable AI applications at 10X better cost-efficiency. Leveraged KServe for model serving, Postgres for metadata caching, and Kubernetes native data caching solutions, the impossible triangle of performance, scale, and cost is broken.",
        "url": "http://kccncna2025.sched.com/event/f80855ea095f67572fc29e688b82cd61",
        "uid": "f80855ea095f67572fc29e688b82cd61",
        "start": "2025-11-11T17:45:00-05:00",
        "end": "2025-11-11T18:15:00-05:00",
        "categories": [
          "DATA PROCESSING + STORAGE"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 4"
        },
        "speakers": [
          {
            "name": "Lu Qiu",
            "company": " LanceDB"
          },
          {
            "name": "Chanchan Mao",
            "company": " LanceDB"
          }
        ]
      }
    },
    {
      "text": "This session will discuss the challenges about helping the Kubernetes Project to steer through an era of AI. We will look at how ContribEx creates Guidelines for the usage of AI tools in an Open Source Project, as well as how to manage critical communications. Also about the challenges of maintaining a contributor base in an age of shrinking contributors for Open Source by creating programs and possibilities to recruit new Contributors. Speakers: Mario Fahlandt from Kubermatic, Nabarun Pal from Broadcom, Priyanka Saggu from SUSE, Madhav Jivrajani from UIUC, Kaslin Fields from Google. Location: Building C | Level 3 | Georgia Ballroom 1. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Contributing To Kubernetes in an Age of AI",
        "description": "This session will discuss the challenges about helping the Kubernetes Project to steer through an era of AI. We will look at how ContribEx creates Guidelines for the usage of AI tools in an Open Source Project, as well as how to manage critical communications. Also about the challenges of maintaining a contributor base in an age of shrinking contributors for Open Source by creating programs and possibilities to recruit new Contributors.",
        "url": "http://kccncna2025.sched.com/event/2c5d15caeef11f6094263f0b928faa7d",
        "uid": "2c5d15caeef11f6094263f0b928faa7d",
        "start": "2025-11-11T17:45:00-05:00",
        "end": "2025-11-11T18:15:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 1"
        },
        "speakers": [
          {
            "name": "Mario Fahlandt",
            "company": "Kubermatic"
          },
          {
            "name": "Nabarun Pal",
            "company": "Broadcom"
          },
          {
            "name": "Priyanka Saggu",
            "company": "SUSE"
          },
          {
            "name": "Madhav Jivrajani",
            "company": "UIUC"
          },
          {
            "name": "Kaslin Fields",
            "company": "Google"
          }
        ]
      }
    },
    {
      "text": "In this session, Dipti and Stefan will talk about the evolution of Flux CD towards a GitLess GitOps model. They will start with a brief history of the Open Container Initiative (OCI), highlighting the key milestones that led to the development of OCI Artifacts as a standard in the Flux project. Stefan will do a deep dive into Flux OCI features and will share success stories from Flux users who have adopted the GitLess GitOps model. Dipti will talk about the latest developments around OIDC-based authentication & provenance verification, and how it enabled Flux users to achieve better security and compliance. Finally, they will discuss the roadmap for Flux and how the community can contribute to the project's success. Speakers: The GitLess GitOps Edition - Stefan Prodan from ControlPlane, Dipti Pai from Microsoft. Location: Building C | Level 3 | Georgia Ballroom 2. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Flux",
        "description": "In this session, Dipti and Stefan will talk about the evolution of Flux CD towards a GitLess GitOps model. They will start with a brief history of the Open Container Initiative (OCI), highlighting the key milestones that led to the development of OCI Artifacts as a standard in the Flux project. Stefan will do a deep dive into Flux OCI features and will share success stories from Flux users who have adopted the GitLess GitOps model. Dipti will talk about the latest developments around OIDC-based authentication & provenance verification, and how it enabled Flux users to achieve better security and compliance. Finally, they will discuss the roadmap for Flux and how the community can contribute to the project's success.",
        "url": "http://kccncna2025.sched.com/event/10a20188c3741b562d5f7b90617b256a",
        "uid": "10a20188c3741b562d5f7b90617b256a",
        "start": "2025-11-11T17:45:00-05:00",
        "end": "2025-11-11T18:15:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 2"
        },
        "speakers": [
          {
            "name": "The GitLess GitOps Edition - Stefan Prodan",
            "company": "ControlPlane"
          },
          {
            "name": "Dipti Pai",
            "company": "Microsoft"
          }
        ]
      }
    },
    {
      "text": "This session covers the latest updates in the Kubernetes Node subsystem. SIG Node owns components like Kubelet, Container Runtime Interface (CRI), Node API. SIG Node is responsible for Pod lifecycle from allocation to teardown, shared (classic) resource management, topology alignment and device access via device plugins. SIG Node is also a major contributor of the Dynamic Resource Allocation (DRA) which is becoming the bedrock of the new generation or resource management. We work with container runtimes, kernels, networking, storage, and more; anything between the pod and the underlying hardware that runs them is in SIG Nodes purview! This session will be interesting for end users, seasoned contributors, and people seeking to get involved. Attendees will leave the session with a better understanding of the latest developments like DRA, in-place VPA, PSI, pod level resources, and more, as well as understand the roadmap in these days of AI/ML and other workloads adoption. Speakers: Peter Hunt from Red Hat, Sergey Kanzhelev from Google, Mrunal Patel from Red Hat. Location: Building C | Level 1 | C111-112. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "SIG-Node: Intro and Deep Dive",
        "description": "This session covers the latest updates in the Kubernetes Node subsystem. SIG Node owns components like Kubelet, Container Runtime Interface (CRI), Node API. SIG Node is responsible for Pod lifecycle from allocation to teardown, shared (classic) resource management, topology alignment and device access via device plugins. SIG Node is also a major contributor of the Dynamic Resource Allocation (DRA) which is becoming the bedrock of the new generation or resource management. We work with container runtimes, kernels, networking, storage, and more; anything between the pod and the underlying hardware that runs them is in SIG Nodes purview! This session will be interesting for end users, seasoned contributors, and people seeking to get involved. Attendees will leave the session with a better understanding of the latest developments like DRA, in-place VPA, PSI, pod level resources, and more, as well as understand the roadmap in these days of AI/ML and other workloads adoption.",
        "url": "http://kccncna2025.sched.com/event/eb67a03b3cc3cac6669960b0e57a493e",
        "uid": "eb67a03b3cc3cac6669960b0e57a493e",
        "start": "2025-11-11T17:45:00-05:00",
        "end": "2025-11-11T18:15:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "1",
          "room": "C111-112"
        },
        "speakers": [
          {
            "name": "Peter Hunt",
            "company": "Red Hat"
          },
          {
            "name": "Sergey Kanzhelev",
            "company": "Google"
          },
          {
            "name": "Mrunal Patel",
            "company": "Red Hat"
          }
        ]
      }
    },
    {
      "text": "Kubernetes is more than a container orchestrator; it is a platform for building custom compute abstractions. This extensibility is rooted in its modular architecture, where platform engineers can deploy custom resources and controllers to achieve specialized functionalities. Although powerful, this extensibility creates new challenges: complex interactions between controllers can lead to unintended behaviors that can cause outages or data loss. Worse yet, diagnosing these behaviors is notoriously difficult; the loosely coupled, asynchronous nature of the control plane offers poor visibility into the reconciliation process. This talk introduces Kamera, a new observability toolkit that empowers developers to quickly diagnose issues in custom control planes by tracing causality across controller reconciliations and the environmental events that trigger them. We will also show how Kamera uses model-checking and simulation techniques to catch problematic emergent behaviors pre-deployment. Speakers: Tim Goodwin from UC Santa Cruz. Location: Building B | Level 3 | B304-305. Categories: OBSERVABILITY.",
      "metadata": {
        "title": "Ive Got 99 Problems and Theyre All Controllers",
        "description": "Kubernetes is more than a container orchestrator; it is a platform for building custom compute abstractions. This extensibility is rooted in its modular architecture, where platform engineers can deploy custom resources and controllers to achieve specialized functionalities. Although powerful, this extensibility creates new challenges: complex interactions between controllers can lead to unintended behaviors that can cause outages or data loss. Worse yet, diagnosing these behaviors is notoriously difficult; the loosely coupled, asynchronous nature of the control plane offers poor visibility into the reconciliation process. This talk introduces Kamera, a new observability toolkit that empowers developers to quickly diagnose issues in custom control planes by tracing causality across controller reconciliations and the environmental events that trigger them. We will also show how Kamera uses model-checking and simulation techniques to catch problematic emergent behaviors pre-deployment.",
        "url": "http://kccncna2025.sched.com/event/3a748b8d03e6f95de0b99881565ea6b5",
        "uid": "3a748b8d03e6f95de0b99881565ea6b5",
        "start": "2025-11-11T17:45:00-05:00",
        "end": "2025-11-11T18:15:00-05:00",
        "categories": [
          "OBSERVABILITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B304-305"
        },
        "speakers": [
          {
            "name": "Tim Goodwin",
            "company": "UC Santa Cruz"
          }
        ]
      }
    },
    {
      "text": "Platform teams today face a growing challenge: understanding whats happening across sprawling, multi-cluster environments where observability signals are scattered and context is missing. When infrastructure drifts or deployments fail, engineers dig through logs and piece together fragmented views. This talk makes the case for a more connected, observable platform, showing how Crossplane, OpenTelemetry, and ArgoCD can work together to reduce blind spots in cluster provisioning. As the platform stack evolves, tools like Crossplane put the Kubernetes API at the center of infrastructure provisioning. While powerful, this shift complicates gaining a high level view of all moving parts. This session will focus on how declarative infrastructure and well-instrumented conditions improve visibility into system health and intent. Attendees will learn strategies for tracking object state, correlating signals across clusters, and building feedback loops that clarify operations. Speakers: Heather Lee from  Apple, Mike Cutsail from  Apple. Location: Building B | Level 3 | B312-314. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "Sync or Swim: Building Platforms You Can See",
        "description": "Platform teams today face a growing challenge: understanding whats happening across sprawling, multi-cluster environments where observability signals are scattered and context is missing. When infrastructure drifts or deployments fail, engineers dig through logs and piece together fragmented views. This talk makes the case for a more connected, observable platform, showing how Crossplane, OpenTelemetry, and ArgoCD can work together to reduce blind spots in cluster provisioning. As the platform stack evolves, tools like Crossplane put the Kubernetes API at the center of infrastructure provisioning. While powerful, this shift complicates gaining a high level view of all moving parts. This session will focus on how declarative infrastructure and well-instrumented conditions improve visibility into system health and intent. Attendees will learn strategies for tracking object state, correlating signals across clusters, and building feedback loops that clarify operations.",
        "url": "http://kccncna2025.sched.com/event/e8cc6a98edbaec0200ea80ca0ad46df9",
        "uid": "e8cc6a98edbaec0200ea80ca0ad46df9",
        "start": "2025-11-11T17:45:00-05:00",
        "end": "2025-11-11T18:15:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B312-314"
        },
        "speakers": [
          {
            "name": "Heather Lee",
            "company": " Apple"
          },
          {
            "name": "Mike Cutsail",
            "company": " Apple"
          }
        ]
      }
    },
    {
      "text": "Still using usernames and passwords for DB access? In 2025, thats not just outdatedits a security liability. Static credentials are hard to manage, rotate, and audit, especially in dynamic, multi-tenant cloud-native environments. Traditional DB authentication no longer meets modern security and compliance needs. In this session, Yoshiyuki Tabata and Gabriele Bartolini will show how to modernize PostgreSQL authorization by integrating it with Keycloak, an identity and access management OSS. Theyll walk through externalizing authentication and authorization logic from the DB, enabling centralized identity control across services. Youll learn how to map Keycloak roles and groups to PostgreSQL privileges, enforce fine-grained access policies, and manage secure access in Kubernetes environments using CloudNativePG. They will explore how the innovative native OAuth support introduced in PostgreSQL 18 has the potential to transform the landscape of DB authentication in Kubernetes. Speakers: Yoshiyuki Tabata from Hitachi, Ltd., Gabriele Bartolini from EDB. Location: Building B | Level 3 | B302-303. Categories: SECURITY.",
      "metadata": {
        "title": "Modern PostgreSQL Authorization With Keycloak: Cloud Native Identity Meets Database Security",
        "description": "Still using usernames and passwords for DB access? In 2025, thats not just outdatedits a security liability. Static credentials are hard to manage, rotate, and audit, especially in dynamic, multi-tenant cloud-native environments. Traditional DB authentication no longer meets modern security and compliance needs. In this session, Yoshiyuki Tabata and Gabriele Bartolini will show how to modernize PostgreSQL authorization by integrating it with Keycloak, an identity and access management OSS. Theyll walk through externalizing authentication and authorization logic from the DB, enabling centralized identity control across services. Youll learn how to map Keycloak roles and groups to PostgreSQL privileges, enforce fine-grained access policies, and manage secure access in Kubernetes environments using CloudNativePG. They will explore how the innovative native OAuth support introduced in PostgreSQL 18 has the potential to transform the landscape of DB authentication in Kubernetes.",
        "url": "http://kccncna2025.sched.com/event/d958814ff2f4978334a0a1d056d7b90a",
        "uid": "d958814ff2f4978334a0a1d056d7b90a",
        "start": "2025-11-11T17:45:00-05:00",
        "end": "2025-11-11T18:15:00-05:00",
        "categories": [
          "SECURITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B302-303"
        },
        "speakers": [
          {
            "name": "Yoshiyuki Tabata",
            "company": "Hitachi, Ltd."
          },
          {
            "name": "Gabriele Bartolini",
            "company": "EDB"
          }
        ]
      }
    },
    {
      "text": "With rising demand for AI workloads, SaaS providers are evolving their K8s-based GPU offerings, often built on NVIDIA Container Toolkit: the industry-standard framework for running GPU-based containers. In this talk, well show you how a single vulnerability in this fundamental framework impacted the entire cloud-native ecosystem  and how each environment handled a brand-new 0day.\nWell walk through our discovery of this Pod-to-Node escape vulnerability, and its impact across 3 different providers: Azure, DigitalOcean, and Replicate. Each case began with a weak Pod running our exploit  but outcomes varied widely. One led to minor impact; another with lateral movement that triggered blue teamers; and one with complete service takeover.\nJoin us to gain a firsthand look on how major cloud-native companies build their K8s environments, and the anatomy of a container escape vulnerability in the wild. Finally, learn how to build stronger K8s guardrails by examining the flaws we exploited. Speakers: Hillai Ben-Sasson from  Wiz, Nir Ohfeld from  Wiz. Location: Building C | Level 3 | Georgia Ballroom 3. Categories: SECURITY.",
      "metadata": {
        "title": "The Good, the Bad, and the Ugly: Hacking 3 Cloud Native AI Services With 1 Vulnerability",
        "description": "With rising demand for AI workloads, SaaS providers are evolving their K8s-based GPU offerings, often built on NVIDIA Container Toolkit: the industry-standard framework for running GPU-based containers. In this talk, well show you how a single vulnerability in this fundamental framework impacted the entire cloud-native ecosystem  and how each environment handled a brand-new 0day.\nWell walk through our discovery of this Pod-to-Node escape vulnerability, and its impact across 3 different providers: Azure, DigitalOcean, and Replicate. Each case began with a weak Pod running our exploit  but outcomes varied widely. One led to minor impact; another with lateral movement that triggered blue teamers; and one with complete service takeover.\nJoin us to gain a firsthand look on how major cloud-native companies build their K8s environments, and the anatomy of a container escape vulnerability in the wild. Finally, learn how to build stronger K8s guardrails by examining the flaws we exploited.",
        "url": "http://kccncna2025.sched.com/event/a7d58f9388beca72d9f4314cd57731fe",
        "uid": "a7d58f9388beca72d9f4314cd57731fe",
        "start": "2025-11-11T17:45:00-05:00",
        "end": "2025-11-11T18:15:00-05:00",
        "categories": [
          "SECURITY"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 3"
        },
        "speakers": [
          {
            "name": "Hillai Ben-Sasson",
            "company": " Wiz"
          },
          {
            "name": "Nir Ohfeld",
            "company": " Wiz"
          }
        ]
      }
    },
    {
      "text": "Welcome, cloud native community! Were excited to kick off our time in Atlanta with you. Join the community and our sponsors from 6:15 - 7:45 in the Solutions Showcase for an incredible gathering of local food favorites, beverages, games, and other activities.\n\nGrab a drink, follow the buzz, and dont miss the Poster Sessions!&nbsp;\nCheck out the Poster Sessions and dive into the latest research, community hacks, and cloud native experiments. No slides, no stage, just brilliant people talking tech.\n\nExplore the sponsor booths to learn more about the latest technologies, browse special offers, job posts, and much more.\n\n\nIn order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies. Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: EXPERIENCES.",
      "metadata": {
        "title": " #KubeCrawl + #CloudNativeFest",
        "description": "Welcome, cloud native community! Were excited to kick off our time in Atlanta with you. Join the community and our sponsors from 6:15 - 7:45 in the Solutions Showcase for an incredible gathering of local food favorites, beverages, games, and other activities.\n\nGrab a drink, follow the buzz, and dont miss the Poster Sessions!&nbsp;\nCheck out the Poster Sessions and dive into the latest research, community hacks, and cloud native experiments. No slides, no stage, just brilliant people talking tech.\n\nExplore the sponsor booths to learn more about the latest technologies, browse special offers, job posts, and much more.\n\n\nIn order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.",
        "url": "http://kccncna2025.sched.com/event/28eb2f091a0ce0811b52a81c2943eb39",
        "uid": "28eb2f091a0ce0811b52a81c2943eb39",
        "start": "2025-11-11T18:15:00-05:00",
        "end": "2025-11-11T19:45:00-05:00",
        "categories": [
          "EXPERIENCES"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "In Kubernetes, DaemonSet workloads are constrained to a single set of CPU and memory requests across all nodes, regardless of instance size. This one-size-fits-all approach can be riskywhat works for a 2xlarge node may be insufficient or wasteful on a 48xlarge. To ensure critical DaemonSets like Istio's ztunnel always receive adequate resources, especially during Ambient Mesh rollouts, we built a mechanism to dynamically rightsize resource requests based on node capacity. In this poster session, well share how we implemented this automated rightsizing approach. Speakers: Artur Beznosyuk from  Verkada, Rohan Sood from  Verkada. Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories:  POSTER SESSIONS.",
      "metadata": {
        "title": "Poster Session (PS1): Automated Rightsizing for Istio DaemonSet Workloads",
        "description": "In Kubernetes, DaemonSet workloads are constrained to a single set of CPU and memory requests across all nodes, regardless of instance size. This one-size-fits-all approach can be riskywhat works for a 2xlarge node may be insufficient or wasteful on a 48xlarge. To ensure critical DaemonSets like Istio's ztunnel always receive adequate resources, especially during Ambient Mesh rollouts, we built a mechanism to dynamically rightsize resource requests based on node capacity. In this poster session, well share how we implemented this automated rightsizing approach.",
        "url": "http://kccncna2025.sched.com/event/4c99d6482933d1e66b6b78c9a68f53c2",
        "uid": "4c99d6482933d1e66b6b78c9a68f53c2",
        "start": "2025-11-11T18:15:00-05:00",
        "end": "2025-11-11T19:45:00-05:00",
        "categories": [
          " POSTER SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        },
        "speakers": [
          {
            "name": "Artur Beznosyuk",
            "company": " Verkada"
          },
          {
            "name": "Rohan Sood",
            "company": " Verkada"
          }
        ]
      }
    },
    {
      "text": "Mounting S3-compatible storage via S3FS seems like an easy way to enable POSIX-like access in Kubernetes. But in real AI/ML workloadse.g., training with PyTorch or TensorFlowwe hit major issues: crashes from incomplete writes, vanished checkpoints, inconsistent metadata, and unpredictable I/O latency.\n\nThis session shares our journey from debugging S3FS failures to deploying a scalable, POSIX-compliant file system that still leverages object storage. Well cover:\n\n- Benchmarks comparing S3FS and a user-space distributed FS\n- I/O traces showing metadata and small file pain points\n- Key design decisions for compatibility and performance\n- Kubernetes CSI and Operator integration for scale\n- Lessons from running it on 1,000+ node AI training clusters\n\nIdeal for platform engineers, MLOps, and Kubernetes architects seeking reliable, scalable storage for data-heavy workloads. Speakers: Rui Su from Juicedata, Inc.. Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories:  POSTER SESSIONS.",
      "metadata": {
        "title": "Poster Session (PS10): Why We Replaced S3FS: Lessons From Building a Better Filesystem for AI Workloads on Kubernetes",
        "description": "Mounting S3-compatible storage via S3FS seems like an easy way to enable POSIX-like access in Kubernetes. But in real AI/ML workloadse.g., training with PyTorch or TensorFlowwe hit major issues: crashes from incomplete writes, vanished checkpoints, inconsistent metadata, and unpredictable I/O latency.\n\nThis session shares our journey from debugging S3FS failures to deploying a scalable, POSIX-compliant file system that still leverages object storage. Well cover:\n\n- Benchmarks comparing S3FS and a user-space distributed FS\n- I/O traces showing metadata and small file pain points\n- Key design decisions for compatibility and performance\n- Kubernetes CSI and Operator integration for scale\n- Lessons from running it on 1,000+ node AI training clusters\n\nIdeal for platform engineers, MLOps, and Kubernetes architects seeking reliable, scalable storage for data-heavy workloads.",
        "url": "http://kccncna2025.sched.com/event/7ba11f5c1644b18eb7e520faa6bac2fa",
        "uid": "7ba11f5c1644b18eb7e520faa6bac2fa",
        "start": "2025-11-11T18:15:00-05:00",
        "end": "2025-11-11T19:45:00-05:00",
        "categories": [
          " POSTER SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        },
        "speakers": [
          {
            "name": "Rui Su",
            "company": "Juicedata, Inc."
          }
        ]
      }
    },
    {
      "text": "Statistical institutes and public organizations have faced increasing demand for secure, scalable, and user-friendly data platforms. At INSEE (Frances national statistics office), we created SSPCloud, a collaborative cloud-native sandbox, and Onyxia, its open-source front-end, to address these challenges.\n\nBut more than building platforms, we built a community.\n\nThis poster will explore how weve fostered an open and international ecosystem across National Statistical Institutes (NSIs), researchers, and developers. Our approach combines transparency,, and a design philosophy that places non-expert users at the center. Onyxia abstracts the complexity of the underlying cloud infrastructure while exposing its mechanisms for those who want to dig deeper.\n\nSSPCloud and Onyxia are now used as a shared reference by a growing number of NSIs beyond Europe, promoting interoperability, reproducibility, and innovationall while respecting data sensitivity and sovereignty. SSPCloud serves as the sandbox infrastructure for Eurostats AIML4OS project, while Onyxia has been identified as a reference software solution by the UN Global Platform. Speakers: Frederic Comte from  Insee, Joseph Garrone from  Insee. Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories:  POSTER SESSIONS.",
      "metadata": {
        "title": "Poster Session (PS2): Building a Community With an Open Datalab Platform",
        "description": "Statistical institutes and public organizations have faced increasing demand for secure, scalable, and user-friendly data platforms. At INSEE (Frances national statistics office), we created SSPCloud, a collaborative cloud-native sandbox, and Onyxia, its open-source front-end, to address these challenges.\n\nBut more than building platforms, we built a community.\n\nThis poster will explore how weve fostered an open and international ecosystem across National Statistical Institutes (NSIs), researchers, and developers. Our approach combines transparency,, and a design philosophy that places non-expert users at the center. Onyxia abstracts the complexity of the underlying cloud infrastructure while exposing its mechanisms for those who want to dig deeper.\n\nSSPCloud and Onyxia are now used as a shared reference by a growing number of NSIs beyond Europe, promoting interoperability, reproducibility, and innovationall while respecting data sensitivity and sovereignty. SSPCloud serves as the sandbox infrastructure for Eurostats AIML4OS project, while Onyxia has been identified as a reference software solution by the UN Global Platform.",
        "url": "http://kccncna2025.sched.com/event/1cffcd558982812b6c17701584a74568",
        "uid": "1cffcd558982812b6c17701584a74568",
        "start": "2025-11-11T18:15:00-05:00",
        "end": "2025-11-11T19:45:00-05:00",
        "categories": [
          " POSTER SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        },
        "speakers": [
          {
            "name": "Frederic Comte",
            "company": " Insee"
          },
          {
            "name": "Joseph Garrone",
            "company": " Insee"
          }
        ]
      }
    },
    {
      "text": "As cloud-native environments scale in complexity, observability is no longer just about collecting logs, metrics, and tracesits about making sense of them. While modern observability stacks deliver a wealth of data, the real challenge is translating this information into actionable insights that everyone on the team can understand and use, from SREs and developers to business stakeholders.\n\nThis talk explores the next evolution: From Noise to Clarity. Well dive into practical strategies and open source tools (like OpenTelemetry, Prometheus, and emerging AI/LLM-powered solutions) that help demystify observability data. Attendees will learn how to:\n\nCorrelate signals across distributed systems for a unified view\n\nUse AI and LLMs to generate human-friendly explanations of complex incidents\n\nBuild dashboards and alerts that surface root causes, not just symptoms\n\nEmpower teams to act quickly and confidentlyregardless of their observability expertise\n\nWell showcase real-world examples. Speakers: Nikita Verma from Zscaler, Harshita Varma from Juspay. Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories:  POSTER SESSIONS.",
      "metadata": {
        "title": "Poster Session (PS3): From Noise To Clarity: Humanizing Observability in Cloud Native Systems",
        "description": "As cloud-native environments scale in complexity, observability is no longer just about collecting logs, metrics, and tracesits about making sense of them. While modern observability stacks deliver a wealth of data, the real challenge is translating this information into actionable insights that everyone on the team can understand and use, from SREs and developers to business stakeholders.\n\nThis talk explores the next evolution: From Noise to Clarity. Well dive into practical strategies and open source tools (like OpenTelemetry, Prometheus, and emerging AI/LLM-powered solutions) that help demystify observability data. Attendees will learn how to:\n\nCorrelate signals across distributed systems for a unified view\n\nUse AI and LLMs to generate human-friendly explanations of complex incidents\n\nBuild dashboards and alerts that surface root causes, not just symptoms\n\nEmpower teams to act quickly and confidentlyregardless of their observability expertise\n\nWell showcase real-world examples.",
        "url": "http://kccncna2025.sched.com/event/5600eab4c24d59e64d6f389fb098f965",
        "uid": "5600eab4c24d59e64d6f389fb098f965",
        "start": "2025-11-11T18:15:00-05:00",
        "end": "2025-11-11T19:45:00-05:00",
        "categories": [
          " POSTER SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        },
        "speakers": [
          {
            "name": "Nikita Verma",
            "company": "Zscaler"
          },
          {
            "name": "Harshita Varma",
            "company": "Juspay"
          }
        ]
      }
    },
    {
      "text": "Open source Digital Public Infrastructure, DPI is the leading approach for lowering the barrier of digital transformation for governments in the global south and boosting inclusive socio-economic development.\nLower technical skills, heterogeneous digital infrastructure and fragmented digital sovereignty significantly hinder the adoption and scalability of critical public services like OpenCRVS, a project for civil registration and vital statistics.\nLearn how a Kubernetes based architecture addresses these challenges, using OpenCRVS as a case study to demo a shift from inefficient, manual deployments with artisanal scripts to an out-of-box and automated process while reducing the resource footprint. Explore the practical strategies employed to optimize and deploy OpenCRVS in a heterogenous air-gapped environment, reducing development and deployment times from months to days while enhancing security and maintainability. The lessons we gleaned are recommendations for DPIs in general. Speakers: Andrew Amstrong Musoke from  Upanzi Network, Samuel Emmanuel from  Upanzi Network. Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories:  POSTER SESSIONS.",
      "metadata": {
        "title": "Poster Session (PS4): Optimising OpenCRVS Deployment With Kubernetes: Lessons for DPI Adoption in the Global South",
        "description": "Open source Digital Public Infrastructure, DPI is the leading approach for lowering the barrier of digital transformation for governments in the global south and boosting inclusive socio-economic development.\nLower technical skills, heterogeneous digital infrastructure and fragmented digital sovereignty significantly hinder the adoption and scalability of critical public services like OpenCRVS, a project for civil registration and vital statistics.\nLearn how a Kubernetes based architecture addresses these challenges, using OpenCRVS as a case study to demo a shift from inefficient, manual deployments with artisanal scripts to an out-of-box and automated process while reducing the resource footprint. Explore the practical strategies employed to optimize and deploy OpenCRVS in a heterogenous air-gapped environment, reducing development and deployment times from months to days while enhancing security and maintainability. The lessons we gleaned are recommendations for DPIs in general.",
        "url": "http://kccncna2025.sched.com/event/5662f0741a4a7ae891d613adf8b8dbef",
        "uid": "5662f0741a4a7ae891d613adf8b8dbef",
        "start": "2025-11-11T18:15:00-05:00",
        "end": "2025-11-11T19:45:00-05:00",
        "categories": [
          " POSTER SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        },
        "speakers": [
          {
            "name": "Andrew Amstrong Musoke",
            "company": " Upanzi Network"
          },
          {
            "name": "Samuel Emmanuel",
            "company": " Upanzi Network"
          }
        ]
      }
    },
    {
      "text": "This presentation provides an in-depth analysis of how HAProxy can be configured and optimized to support HTTP-based communication within 5G core network environments. It focuses on performance benchmarking, tuning strategies, and system sizing to ensure scalability and reliability in carrier-grade deployments. In addition, the session highlights how HAProxy can be effectively used to facilitate service-based interactions between 5G network functions (NFs), acting as a high-performance intermediary for routing, load balancing, and health monitoring. Speakers: Bach Phan Tuan from Viettel High Technology. Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories:  POSTER SESSIONS.",
      "metadata": {
        "title": "Poster Session (PS5): Performance Evaluation and Sizing of HAProxy for HTTP Communication in 5G Core Networks",
        "description": "This presentation provides an in-depth analysis of how HAProxy can be configured and optimized to support HTTP-based communication within 5G core network environments. It focuses on performance benchmarking, tuning strategies, and system sizing to ensure scalability and reliability in carrier-grade deployments. In addition, the session highlights how HAProxy can be effectively used to facilitate service-based interactions between 5G network functions (NFs), acting as a high-performance intermediary for routing, load balancing, and health monitoring.",
        "url": "http://kccncna2025.sched.com/event/f59fa756250f45035874e6ee50920135",
        "uid": "f59fa756250f45035874e6ee50920135",
        "start": "2025-11-11T18:15:00-05:00",
        "end": "2025-11-11T19:45:00-05:00",
        "categories": [
          " POSTER SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        },
        "speakers": [
          {
            "name": "Bach Phan Tuan",
            "company": "Viettel High Technology"
          }
        ]
      }
    },
    {
      "text": "The recent popularity of generative AI in sensitive domains such as healthcare and digital agriculture presents new challenges for protecting user data and model intellectual property. We propose Private Computation Spaces (PCS), a distributed confidential computing framework that enables secure deployment of generative AI models inside hardware-protected enclaves. We use two open-source CNCF projects, Confidential Containers and KubeStellar, to enable multi-cluster orchestration particularly for digital agriculture workloads. The proposed framework is designed with agricultural users/researchers in mind and allows researchers to rapidly deploy/manage computational AI models for plant disease detection using NASA imagery without retaining confidential stakeholder information. The PCS enhances user trust, supports disconnected operation in rural environments with KubeStellar, and generalizes to other privacy-sensitive domains as a platform. Speakers: Salman Abid from  Cornell University, Shuangyu Lei from  Cornell University. Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories:  POSTER SESSIONS.",
      "metadata": {
        "title": "Poster Session (PS6): Private Computation Spaces Via Confidential Containers and KubeStellar",
        "description": "The recent popularity of generative AI in sensitive domains such as healthcare and digital agriculture presents new challenges for protecting user data and model intellectual property. We propose Private Computation Spaces (PCS), a distributed confidential computing framework that enables secure deployment of generative AI models inside hardware-protected enclaves. We use two open-source CNCF projects, Confidential Containers and KubeStellar, to enable multi-cluster orchestration particularly for digital agriculture workloads. The proposed framework is designed with agricultural users/researchers in mind and allows researchers to rapidly deploy/manage computational AI models for plant disease detection using NASA imagery without retaining confidential stakeholder information. The PCS enhances user trust, supports disconnected operation in rural environments with KubeStellar, and generalizes to other privacy-sensitive domains as a platform.",
        "url": "http://kccncna2025.sched.com/event/0d43500c7a80f87d2944b9151742fd7a",
        "uid": "0d43500c7a80f87d2944b9151742fd7a",
        "start": "2025-11-11T18:15:00-05:00",
        "end": "2025-11-11T19:45:00-05:00",
        "categories": [
          " POSTER SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        },
        "speakers": [
          {
            "name": "Salman Abid",
            "company": " Cornell University"
          },
          {
            "name": "Shuangyu Lei",
            "company": " Cornell University"
          }
        ]
      }
    },
    {
      "text": "While Kubernetes-based computing infrastructure aids practitioners in rapid deployment of software, security weaknesses can make the computing infrastructure susceptible to security attacks. In order to secure their computing infrastructure, practitioners can benefit from a systematic analysis that derives what configuration parameters can facilitate security attacks related to pods, which is the most fundamental deployment unit of Kubernetes. We conduct an empirical investigation where we derive 7 security attacks, characterize the derived attacks using the MITRE ATT&CK framework, and identify pod-related configuration parameters that facilitate each of the attacks. We find 6 of the 7 attacks can be conducted using combinations of configuration parameters, whereas one attack can be conducted using only one configuration parameter.\n\nAs part of our investigation, we evaluate if t-way covering array, large language models, and existing static application security testing tools can detect the identified combinations of configuration parameters that facilitate security attacks. With respect to average precision and average recall, t-way covering array with t=4 performs the best among the investigated techniques, achieving average precision and average recall of 0.83 and 0.68, respectively. We conclude our paper by providing recommendations for practitioners on how to securely develop configuration scripts so that the identified attacks can be mitigated. Speakers: Yue Zhang from Auburn University. Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories:  POSTER SESSIONS.",
      "metadata": {
        "title": "Poster Session (PS7): Security Attacks on Kubernetes Pods",
        "description": "While Kubernetes-based computing infrastructure aids practitioners in rapid deployment of software, security weaknesses can make the computing infrastructure susceptible to security attacks. In order to secure their computing infrastructure, practitioners can benefit from a systematic analysis that derives what configuration parameters can facilitate security attacks related to pods, which is the most fundamental deployment unit of Kubernetes. We conduct an empirical investigation where we derive 7 security attacks, characterize the derived attacks using the MITRE ATT&CK framework, and identify pod-related configuration parameters that facilitate each of the attacks. We find 6 of the 7 attacks can be conducted using combinations of configuration parameters, whereas one attack can be conducted using only one configuration parameter.\n\nAs part of our investigation, we evaluate if t-way covering array, large language models, and existing static application security testing tools can detect the identified combinations of configuration parameters that facilitate security attacks. With respect to average precision and average recall, t-way covering array with t=4 performs the best among the investigated techniques, achieving average precision and average recall of 0.83 and 0.68, respectively. We conclude our paper by providing recommendations for practitioners on how to securely develop configuration scripts so that the identified attacks can be mitigated.",
        "url": "http://kccncna2025.sched.com/event/58db487d170e5ee2377223741d4e240d",
        "uid": "58db487d170e5ee2377223741d4e240d",
        "start": "2025-11-11T18:15:00-05:00",
        "end": "2025-11-11T19:45:00-05:00",
        "categories": [
          " POSTER SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        },
        "speakers": [
          {
            "name": "Yue Zhang",
            "company": "Auburn University"
          }
        ]
      }
    },
    {
      "text": "When working on a cloud-native product that is an aggregate of separate products, each with their own cadence, clear communication is critical to smooth integration. Ideally, each product team wants to know when the other related products have published a new release and if it's ready to be integrated with their product. It becomes an exponential, logistical nightmare to have each team subscribe to notifications of each other team. Using an \"integration repository\" helps solve both the business and technical needs of product integration and currency. In this talk, learn how the Fusion DevOps team turned the pull-request into a mechanism for streamlining team handoffs, notifying the appropriate focals, and clearly defining boundaries of responsibilities between teams. Speakers: Prajakta Kashalkar-Joshi from  IBM, Socheat Sou from  IBM. Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories:  POSTER SESSIONS.",
      "metadata": {
        "title": "Poster Session (PS8): The Handoff Pipeline: Using Pull Requests to Manage Integration Points",
        "description": "When working on a cloud-native product that is an aggregate of separate products, each with their own cadence, clear communication is critical to smooth integration. Ideally, each product team wants to know when the other related products have published a new release and if it's ready to be integrated with their product. It becomes an exponential, logistical nightmare to have each team subscribe to notifications of each other team. Using an \"integration repository\" helps solve both the business and technical needs of product integration and currency. In this talk, learn how the Fusion DevOps team turned the pull-request into a mechanism for streamlining team handoffs, notifying the appropriate focals, and clearly defining boundaries of responsibilities between teams.",
        "url": "http://kccncna2025.sched.com/event/df35e4a84ebffc43de41bd59028c821a",
        "uid": "df35e4a84ebffc43de41bd59028c821a",
        "start": "2025-11-11T18:15:00-05:00",
        "end": "2025-11-11T19:45:00-05:00",
        "categories": [
          " POSTER SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        },
        "speakers": [
          {
            "name": "Prajakta Kashalkar-Joshi",
            "company": " IBM"
          },
          {
            "name": "Socheat Sou",
            "company": " IBM"
          }
        ]
      }
    },
    {
      "text": "Running WebAssembly workloads on Kubernetes is much simpler than even a year or two ago. As the WebAssembly ecosystem standardizes and matures, integrations with the wider world of cloud native tooling make it possible to package and manage both infrastructure primitives and WebAssembly components using GitOps patterns and standard tooling like Helm and Argo.\n\nThis poster session demonstrates how wasmCloud, Argo, and Helm can work together for a smooth, GitOps approach to deployment and management for highly efficient, polyglot server-side WebAssembly applications. Youll walk away ready to apply these techniques in your own environments. Speakers: Eric Gregory from Cosmonic. Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories:  POSTER SESSIONS.",
      "metadata": {
        "title": "Poster Session (PS9): Wasm X GitOps: WebAssembly Components With Argo and Helm",
        "description": "Running WebAssembly workloads on Kubernetes is much simpler than even a year or two ago. As the WebAssembly ecosystem standardizes and matures, integrations with the wider world of cloud native tooling make it possible to package and manage both infrastructure primitives and WebAssembly components using GitOps patterns and standard tooling like Helm and Argo.\n\nThis poster session demonstrates how wasmCloud, Argo, and Helm can work together for a smooth, GitOps approach to deployment and management for highly efficient, polyglot server-side WebAssembly applications. Youll walk away ready to apply these techniques in your own environments.",
        "url": "http://kccncna2025.sched.com/event/ef6acca5b2cd648e4a9f8b70c9e03ef9",
        "uid": "ef6acca5b2cd648e4a9f8b70c9e03ef9",
        "start": "2025-11-11T18:15:00-05:00",
        "end": "2025-11-11T19:45:00-05:00",
        "categories": [
          " POSTER SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        },
        "speakers": [
          {
            "name": "Eric Gregory",
            "company": "Cosmonic"
          }
        ]
      }
    },
    {
      "text": "Location: Building B | Level 1 | Exhibit Hall B2. Categories: KEYNOTE SESSIONS.",
      "metadata": {
        "title": "Keynote: Welcome Back + Opening Remarks",
        "description": "",
        "url": "http://kccncna2025.sched.com/event/b11fbec426aa827fee2c62e1425ce4c3",
        "uid": "b11fbec426aa827fee2c62e1425ce4c3",
        "start": "2025-11-12T09:00:00-05:00",
        "end": "2025-11-12T09:05:00-05:00",
        "categories": [
          "KEYNOTE SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B2"
        }
      }
    },
    {
      "text": "Location: Building B | Level 1 | Exhibit Hall B2. Categories: KEYNOTE SESSIONS.",
      "metadata": {
        "title": "Keynote: To Be Announced",
        "description": "",
        "url": "http://kccncna2025.sched.com/event/921d0dacd7e3ae89e7f44a2a634b9f50",
        "uid": "921d0dacd7e3ae89e7f44a2a634b9f50",
        "start": "2025-11-12T09:07:00-05:00",
        "end": "2025-11-12T09:12:00-05:00",
        "categories": [
          "KEYNOTE SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B2"
        }
      }
    },
    {
      "text": "In this keynote, leaders from end user companies will share how their organization leverages cloud native technologies to tackle real-world challenges, scale efficiently, and drive innovation. Through firsthand insights, youll learn key lessons, best practices, and the evolving needs of cloud native adopters.\n\nMAILCHIMP\nMaura Kelly, Engineering Director at Mailchimp, will share how the team migrated a massive on-prem monolith to Intuits cloud-native platform built on CNCF technologies, achieving 99.997% availability while development continued. Shell highlight three key engineering practices that made this scale and reliability leap possible. Location: Building B | Level 1 | Exhibit Hall B2. Categories: KEYNOTE SESSIONS.",
      "metadata": {
        "title": "Keynote: Turn Up the Heat: Driving Cloud Native Innovation into Real-World Impact",
        "description": "In this keynote, leaders from end user companies will share how their organization leverages cloud native technologies to tackle real-world challenges, scale efficiently, and drive innovation. Through firsthand insights, youll learn key lessons, best practices, and the evolving needs of cloud native adopters.\n\nMAILCHIMP\nMaura Kelly, Engineering Director at Mailchimp, will share how the team migrated a massive on-prem monolith to Intuits cloud-native platform built on CNCF technologies, achieving 99.997% availability while development continued. Shell highlight three key engineering practices that made this scale and reliability leap possible.",
        "url": "http://kccncna2025.sched.com/event/6cc1794900e0727b387c47cca74d26e3",
        "uid": "6cc1794900e0727b387c47cca74d26e3",
        "start": "2025-11-12T09:14:00-05:00",
        "end": "2025-11-12T09:29:00-05:00",
        "categories": [
          "KEYNOTE SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B2"
        }
      }
    },
    {
      "text": "Location: Building B | Level 1 | Exhibit Hall B2. Categories: KEYNOTE SESSIONS.",
      "metadata": {
        "title": "Keynote: To Be Announced",
        "description": "",
        "url": "http://kccncna2025.sched.com/event/152a1baa97e4cb9b336f263a17d8b9d1",
        "uid": "152a1baa97e4cb9b336f263a17d8b9d1",
        "start": "2025-11-12T09:31:00-05:00",
        "end": "2025-11-12T09:36:00-05:00",
        "categories": [
          "KEYNOTE SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B2"
        }
      }
    },
    {
      "text": "Universal Mesh is an architectural pattern that emerged from observing common connectivity challenges faced by HAProxy customers. Unlike traditional, more complex service meshes, Universal Mesh is a fresh approach to creating a system that facilitates a more seamless and secure connectivity.\nThis pattern lets you connect systems across different environments, like business units, cloud regions, and outside partners. It allows both Kubernetes and non-Kubernetes services to communicate seamlessly, no matter where they are located. It offers a streamlined approach to security, observability, and scalability, integrating with existing brownfield services and Kubernetes fundamentals without altering network fundamentals.\nFind out how Universal Mesh can connect fragmented setups, simplifying the complex connectivity issues that modern teams face. Speakers: Frank Mancina VP of Engineering and Operations from HAProxy Technologies. Location: Building B | Level 1 | Exhibit Hall B2. Categories: KEYNOTE SESSIONS.",
      "metadata": {
        "title": "Sponsored Keynote: Universal Mesh: Simplifying Modern Connectivity",
        "description": "Universal Mesh is an architectural pattern that emerged from observing common connectivity challenges faced by HAProxy customers. Unlike traditional, more complex service meshes, Universal Mesh is a fresh approach to creating a system that facilitates a more seamless and secure connectivity.\nThis pattern lets you connect systems across different environments, like business units, cloud regions, and outside partners. It allows both Kubernetes and non-Kubernetes services to communicate seamlessly, no matter where they are located. It offers a streamlined approach to security, observability, and scalability, integrating with existing brownfield services and Kubernetes fundamentals without altering network fundamentals.\nFind out how Universal Mesh can connect fragmented setups, simplifying the complex connectivity issues that modern teams face.",
        "url": "http://kccncna2025.sched.com/event/cdcce0e95e517c57e206028d1230a3ad",
        "uid": "cdcce0e95e517c57e206028d1230a3ad",
        "start": "2025-11-12T09:38:00-05:00",
        "end": "2025-11-12T09:43:00-05:00",
        "categories": [
          "KEYNOTE SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B2"
        },
        "speakers": [
          {
            "name": "Frank Mancina",
            "title": "VP of Engineering and Operations",
            "company": "HAProxy Technologies"
          }
        ]
      }
    },
    {
      "text": "Location: Building B | Level 1 | Exhibit Hall B2. Categories: KEYNOTE SESSIONS.",
      "metadata": {
        "title": "Keynote: Awards Ceremony",
        "description": "",
        "url": "http://kccncna2025.sched.com/event/7f7753563da57fd775cca00603689381",
        "uid": "7f7753563da57fd775cca00603689381",
        "start": "2025-11-12T09:45:00-05:00",
        "end": "2025-11-12T09:55:00-05:00",
        "categories": [
          "KEYNOTE SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B2"
        }
      }
    },
    {
      "text": "There has been a lot of uncertainty around the European Union's new Cyber Resilience Act when it comes to open source projects and developers. This short talk will go into the basics of what developers need to know about this law that will affect them no matter where they live, and the two tiny things that they will need to do if they manage a project that they should already be doing to comply with it. Speakers: Greg Kroah-Hartman from Linux Kernel Maintainer, Fellow from The Linux Foundation. Location: Building B | Level 1 | Exhibit Hall B2. Categories: KEYNOTE SESSIONS.",
      "metadata": {
        "title": "Keynote: There's Nothing to Fear About the EU's New Cybersecurity Law",
        "description": "There has been a lot of uncertainty around the European Union's new Cyber Resilience Act when it comes to open source projects and developers. This short talk will go into the basics of what developers need to know about this law that will affect them no matter where they live, and the two tiny things that they will need to do if they manage a project that they should already be doing to comply with it.",
        "url": "http://kccncna2025.sched.com/event/b981eac5d793dd4836d8dc51032006f4",
        "uid": "b981eac5d793dd4836d8dc51032006f4",
        "start": "2025-11-12T09:57:00-05:00",
        "end": "2025-11-12T10:02:00-05:00",
        "categories": [
          "KEYNOTE SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B2"
        },
        "speakers": [
          {
            "name": "Greg Kroah-Hartman",
            "company": "Linux Kernel Maintainer"
          },
          {
            "name": "Fellow",
            "company": "The Linux Foundation"
          }
        ]
      }
    },
    {
      "text": "In its first decade, Kubernetes earned a critical place in modern workload and infrastructure orchestration - but new workloads and unprecedented scale were pushing the limits. Last year, we highlighted some fundamental gaps in Kubernetes for emerging workloads, and shared Googles commitment to invest in its evolution.\n\nIn this keynote, we will reflect on the foundational role and exciting future of Kubernetes as the leading platform for both traditional and AI workloads. Kubernetes evolved quickly over the past year, due largely to the declarative API, the modular and extensible nature of the platform, and the strength of the ecosystem - and innovation is only accelerating.\n\nWith some key new primitives landing recently, and the broader evolution of Kubernetes well underway, well close with a vision of the future and highlight some exciting projects underway. Speakers: Jago Macleod Engineering Director from Kubernetes, GKE from Google. Location: Building B | Level 1 | Exhibit Hall B2. Categories: KEYNOTE SESSIONS.",
      "metadata": {
        "title": "Sponsored Keynote: Accelerating Innovation: The Evolution of Kubernetes and the Road Ahead",
        "description": "In its first decade, Kubernetes earned a critical place in modern workload and infrastructure orchestration - but new workloads and unprecedented scale were pushing the limits. Last year, we highlighted some fundamental gaps in Kubernetes for emerging workloads, and shared Googles commitment to invest in its evolution.\n\nIn this keynote, we will reflect on the foundational role and exciting future of Kubernetes as the leading platform for both traditional and AI workloads. Kubernetes evolved quickly over the past year, due largely to the declarative API, the modular and extensible nature of the platform, and the strength of the ecosystem - and innovation is only accelerating.\n\nWith some key new primitives landing recently, and the broader evolution of Kubernetes well underway, well close with a vision of the future and highlight some exciting projects underway.",
        "url": "http://kccncna2025.sched.com/event/1c062ef49316598d2e67cdb57bd0a273",
        "uid": "1c062ef49316598d2e67cdb57bd0a273",
        "start": "2025-11-12T10:04:00-05:00",
        "end": "2025-11-12T10:09:00-05:00",
        "categories": [
          "KEYNOTE SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B2"
        },
        "speakers": [
          {
            "name": "Jago Macleod",
            "title": "Engineering Director",
            "company": "Kubernetes"
          },
          {
            "name": "GKE",
            "company": "Google"
          }
        ]
      }
    },
    {
      "text": "Cloud native technologies have revolutionized industries across the boardbut what about their role in solving real-world societal challenges? While we often celebrate enterprise success stories, the true transformative power of Kubernetes and its wider ecosystem is also unfolding in unexpected and deeply impactful ways.\n\nDid you know Kubernetes is helping over 30 governments map, monitor, and improve internet access for schools? Or that KubeVirt and Longhorn have helped rescue 3,800+ children from abuse, leading to the arrest of over 16,700+ online predators in over 105 countries? Or that Prometheus and OpenTelemetry not only power platforms that have saved millions from floods and pandemics, butcloser to hometeam up with Kubernetes to steer the fleet, check its vitals, and trace every heartbeat of 2000+ TeleICU Bed edge nodes in perfect rhythm across geographically dispersed locations? Or that Kubernetes, ArgoCD, and other CNCF tools power mission-critical services like blood supply management, disaster response, and emergency trainingstretching every dollar to maximize humanitarian impact?\n\nIn this compelling panel, Faseela brings together real-world end-user stories from around the globe, showcasing how open source and cloud-native technologies are being harnessed to tackle humanitarian issues. From disaster response and education to public health, child safety, and environmental conservation, learn how organizations are using cloud-native tooling to collaborate at scale, unlock powerful analytics, and reallocate resources from overhead to frontline impact.\n\nWith expert speakers from diverse domains, this session offers a unique look into how Kubernetes and its ecosystem are driving innovation and ultimately driving social good, sustainability and inclusivity beyond the enterprise world! Speakers: Faseela K from Ericsson Software Technology, Omar Mohsine from United Nations, Roberto Machorro from Child Rescue Coalition, Bodhish Thomas from Open Healthcare Network, Jayson Workman from American Red Cross. Location: Building B | Level 1 | Exhibit Hall B2. Categories: KEYNOTE SESSIONS.",
      "metadata": {
        "title": "Keynote: Cloud Native for Good",
        "description": "Cloud native technologies have revolutionized industries across the boardbut what about their role in solving real-world societal challenges? While we often celebrate enterprise success stories, the true transformative power of Kubernetes and its wider ecosystem is also unfolding in unexpected and deeply impactful ways.\n\nDid you know Kubernetes is helping over 30 governments map, monitor, and improve internet access for schools? Or that KubeVirt and Longhorn have helped rescue 3,800+ children from abuse, leading to the arrest of over 16,700+ online predators in over 105 countries? Or that Prometheus and OpenTelemetry not only power platforms that have saved millions from floods and pandemics, butcloser to hometeam up with Kubernetes to steer the fleet, check its vitals, and trace every heartbeat of 2000+ TeleICU Bed edge nodes in perfect rhythm across geographically dispersed locations? Or that Kubernetes, ArgoCD, and other CNCF tools power mission-critical services like blood supply management, disaster response, and emergency trainingstretching every dollar to maximize humanitarian impact?\n\nIn this compelling panel, Faseela brings together real-world end-user stories from around the globe, showcasing how open source and cloud-native technologies are being harnessed to tackle humanitarian issues. From disaster response and education to public health, child safety, and environmental conservation, learn how organizations are using cloud-native tooling to collaborate at scale, unlock powerful analytics, and reallocate resources from overhead to frontline impact.\n\nWith expert speakers from diverse domains, this session offers a unique look into how Kubernetes and its ecosystem are driving innovation and ultimately driving social good, sustainability and inclusivity beyond the enterprise world!",
        "url": "http://kccncna2025.sched.com/event/affe6e0044e2cd0e7fdf3b447fe88d84",
        "uid": "affe6e0044e2cd0e7fdf3b447fe88d84",
        "start": "2025-11-12T10:11:00-05:00",
        "end": "2025-11-12T10:26:00-05:00",
        "categories": [
          "KEYNOTE SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B2"
        },
        "speakers": [
          {
            "name": "Faseela K",
            "company": "Ericsson Software Technology"
          },
          {
            "name": "Omar Mohsine",
            "company": "United Nations"
          },
          {
            "name": "Roberto Machorro",
            "company": "Child Rescue Coalition"
          },
          {
            "name": "Bodhish Thomas",
            "company": "Open Healthcare Network"
          },
          {
            "name": "Jayson Workman",
            "company": "American Red Cross"
          }
        ]
      }
    },
    {
      "text": "Take a break from the buzz of the Solutions Showcase and sit back and relax at the Relaxation Station. Enjoy a soothing massage, try your hand at crocheting, or challenge someone to a game of chess. This is the perfect spot to recharge and unwind before diving back into action.\n\nSponsored by: Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: EXPERIENCES.",
      "metadata": {
        "title": "Relaxation Station",
        "description": "Take a break from the buzz of the Solutions Showcase and sit back and relax at the Relaxation Station. Enjoy a soothing massage, try your hand at crocheting, or challenge someone to a game of chess. This is the perfect spot to recharge and unwind before diving back into action.\n\nSponsored by:",
        "url": "http://kccncna2025.sched.com/event/b061f62e35c66ac63eabdbd8e8ab6fbd",
        "uid": "b061f62e35c66ac63eabdbd8e8ab6fbd",
        "start": "2025-11-12T10:15:00-05:00",
        "end": "2025-11-12T17:00:00-05:00",
        "categories": [
          "EXPERIENCES"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies. Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: SOLUTIONS SHOWCASE.",
      "metadata": {
        "title": "Solutions Showcase",
        "description": "In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.",
        "url": "http://kccncna2025.sched.com/event/ff393bd50fd28f99a5cf4cff7643b2e2",
        "uid": "ff393bd50fd28f99a5cf4cff7643b2e2",
        "start": "2025-11-12T10:15:00-05:00",
        "end": "2025-11-12T17:00:00-05:00",
        "categories": [
          "SOLUTIONS SHOWCASE"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "Location: Building B | Level 1 | Exhibit Hall B2. Categories: KEYNOTE SESSIONS.",
      "metadata": {
        "title": "Keynote: Closing Remarks",
        "description": "",
        "url": "http://kccncna2025.sched.com/event/e0869e76d8a543eefb699dbe4daff025",
        "uid": "e0869e76d8a543eefb699dbe4daff025",
        "start": "2025-11-12T10:28:00-05:00",
        "end": "2025-11-12T10:30:00-05:00",
        "categories": [
          "KEYNOTE SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B2"
        }
      }
    },
    {
      "text": "Location: TBA. Categories: BREAKS.",
      "metadata": {
        "title": "Coffee Break ",
        "description": "",
        "url": "http://kccncna2025.sched.com/event/2dab9e2cd1b93749ea46a9916c2b8dab",
        "uid": "2dab9e2cd1b93749ea46a9916c2b8dab",
        "start": "2025-11-12T10:30:00-05:00",
        "end": "2025-11-12T11:00:00-05:00",
        "categories": [
          "BREAKS"
        ],
        "location": {
          "room": "TBA"
        }
      }
    },
    {
      "text": "We all love and use Argo CD to sync our applications to clusters. With thousands of applications, what's the best way to promote changes from one application to another? In 2025, anti-patterns abound with many teams adopting backwards and even dangerous methods to orchestrate changes across applications. In this session, we'll expose anti-patterns like promoting SHAs, misusing branch environments and many more. Well replace these with a pathway to handling app and environment promotion that is flexible, easy to configure, and incredibly scalable, even to the point of handling thousands of deployment targets with a couple of simple Kubernetes CRDs for configuration.\n\nWe'll show how the value of abstracting clusters into environments, how to build relationships and customize diffing between applications, and demonstrate how to streamline your change management in 2026.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.* Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: SOLUTIONS SHOWCASE.",
      "metadata": {
        "title": "Sponsored Demo: Beware Argo CD App Promotion Anti-Patterns and Embrace Scalable Promotion in GitOps Cloud",
        "description": "We all love and use Argo CD to sync our applications to clusters. With thousands of applications, what's the best way to promote changes from one application to another? In 2025, anti-patterns abound with many teams adopting backwards and even dangerous methods to orchestrate changes across applications. In this session, we'll expose anti-patterns like promoting SHAs, misusing branch environments and many more. Well replace these with a pathway to handling app and environment promotion that is flexible, easy to configure, and incredibly scalable, even to the point of handling thousands of deployment targets with a couple of simple Kubernetes CRDs for configuration.\n\nWe'll show how the value of abstracting clusters into environments, how to build relationships and customize diffing between applications, and demonstrate how to streamline your change management in 2026.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.*",
        "url": "http://kccncna2025.sched.com/event/ea9761aa565f257516eb558550c597ac",
        "uid": "ea9761aa565f257516eb558550c597ac",
        "start": "2025-11-12T10:35:00-05:00",
        "end": "2025-11-12T10:55:00-05:00",
        "categories": [
          "SOLUTIONS SHOWCASE"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "10-Minute Tip Talk Speakers: Mauricio Salatino from Diagrid. Location: Level 1 | Learning Lounge. Categories: EXPERIENCES.",
      "metadata": {
        "title": "Learning Lounge: What Platform Engineers Need to Know About Developer Experience",
        "description": "10-Minute Tip Talk",
        "url": "http://kccncna2025.sched.com/event/68f4170692f64ae7075ba2ae356a8b4a",
        "uid": "68f4170692f64ae7075ba2ae356a8b4a",
        "start": "2025-11-12T10:45:00-05:00",
        "end": "2025-11-12T11:00:00-05:00",
        "categories": [
          "EXPERIENCES"
        ],
        "location": {
          "level": "1",
          "room": "Learning Lounge"
        },
        "speakers": [
          {
            "name": "Mauricio Salatino",
            "company": "Diagrid"
          }
        ]
      }
    },
    {
      "text": "What does it take to build an online model serving platform that ML engineers actually want to use? At Hinge, were building an ML platform that smooths the rough edges of OSS Kubernetes-native tools with interfaces aligned to internal conventions like gRPC and OTel, so ML engineers can focus on models that shine. In this talk, Stephanie Pavlick shares how Hinges AI Platform Core team designed a self-serve platform for deploying and monitoring online models using Ray Serve, MLflow, Grafana, and more. The platform enables ML engineers to deploy models as microservices without touching Kubernetes or Helm while offering fine-grained observability and standardized SLIs. But the story is more than just tooling. Stephanie will share how the team cut model production timelines by over 40% through early partnerships and a focus on developer experience. Along the way, they fostered a culture of collaboration and trust that helped drive broader adoption across Hinges engineering org. Speakers: Stephanie Pavlick from Hinge. Location: Building B | Level 4 | B401-402. Categories: AI + ML.",
      "metadata": {
        "title": "Models as Microservices, Platforms as Partners: Collaboratively Building ML Infra at Hinge",
        "description": "What does it take to build an online model serving platform that ML engineers actually want to use? At Hinge, were building an ML platform that smooths the rough edges of OSS Kubernetes-native tools with interfaces aligned to internal conventions like gRPC and OTel, so ML engineers can focus on models that shine. In this talk, Stephanie Pavlick shares how Hinges AI Platform Core team designed a self-serve platform for deploying and monitoring online models using Ray Serve, MLflow, Grafana, and more. The platform enables ML engineers to deploy models as microservices without touching Kubernetes or Helm while offering fine-grained observability and standardized SLIs. But the story is more than just tooling. Stephanie will share how the team cut model production timelines by over 40% through early partnerships and a focus on developer experience. Along the way, they fostered a culture of collaboration and trust that helped drive broader adoption across Hinges engineering org.",
        "url": "http://kccncna2025.sched.com/event/6133e63ce0e45440984a3e9e703be937",
        "uid": "6133e63ce0e45440984a3e9e703be937",
        "start": "2025-11-12T11:00:00-05:00",
        "end": "2025-11-12T11:30:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B401-402"
        },
        "speakers": [
          {
            "name": "Stephanie Pavlick",
            "company": "Hinge"
          }
        ]
      }
    },
    {
      "text": "Kubernetes environments evolve quickly, making static troubleshooting methods outdated soon after they're deployed. k8sgpt has emerged as a powerful tool to simplify diagnostics, but what if it could dynamically adapt to your team's runbooks and instantly consult the latest Kubernetes documentation? Leveraging the Model Context Protocol (MCP) and Retrieval-Augmented Generation (RAG), this session introduces a novel integration enabling k8sgpt to ingest real-time updates, ensuring your diagnostics remain perpetually relevant and accurate. Further, by harnessing RAG explicitly tailored to your organization's unique operational playbooks, k8sgpt doesn't just diagnose... it proactively recommends solutions aligned with your workflows. Through practical demonstrations, attendees will witness firsthand how MCP-enabled RAG transforms k8sgpt troubleshooting into a highly customized and continuously evolving practice, significantly improving response times, accuracy, and operational agility. Speakers: David vonThenen from NetApp, Yash Sharma from DigitalOcean. Location: Building B | Level 5 | Thomas Murphy Ballroom 1. Categories: AI + ML.",
      "metadata": {
        "title": "Your Kubernetes Playbook at Your Fingertips: Advanced Troubleshooting With MCP, RAG, and K8sgpt",
        "description": "Kubernetes environments evolve quickly, making static troubleshooting methods outdated soon after they're deployed. k8sgpt has emerged as a powerful tool to simplify diagnostics, but what if it could dynamically adapt to your team's runbooks and instantly consult the latest Kubernetes documentation? Leveraging the Model Context Protocol (MCP) and Retrieval-Augmented Generation (RAG), this session introduces a novel integration enabling k8sgpt to ingest real-time updates, ensuring your diagnostics remain perpetually relevant and accurate. Further, by harnessing RAG explicitly tailored to your organization's unique operational playbooks, k8sgpt doesn't just diagnose... it proactively recommends solutions aligned with your workflows. Through practical demonstrations, attendees will witness firsthand how MCP-enabled RAG transforms k8sgpt troubleshooting into a highly customized and continuously evolving practice, significantly improving response times, accuracy, and operational agility.",
        "url": "http://kccncna2025.sched.com/event/a30b5cbaf56f7af964359360398e5cfe",
        "uid": "a30b5cbaf56f7af964359360398e5cfe",
        "start": "2025-11-12T11:00:00-05:00",
        "end": "2025-11-12T11:30:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 1"
        },
        "speakers": [
          {
            "name": "David vonThenen",
            "company": "NetApp"
          },
          {
            "name": "Yash Sharma",
            "company": "DigitalOcean"
          }
        ]
      }
    },
    {
      "text": "Open Source maintainers are often seen as gatekeepers of progress, expected to fix bugs, review PRs, design features, answer questions, and keep the community happy. But behind that facade is often an unexpected reality, especially in high-velocity CNCF projects.\n\nIn this talk, we will share what its like to maintain a CNCF Graduated project, not just the technical side, but the human side: how we keep the project growing, prioritize responsibly, and how governance structures like SIGs help scale responsibilities. Youll hear stories, lessons, and hard truths that rarely make it into blog posts.\n\nThe more successful a project becomes, the harder it gets to sustain, and thats something we dont acknowledge enough. If youve ever wondered why your issue didnt get a response, why a feature was declined, or what being supportive really looks like in open source, this talk will help you understand the maintainers side and maybe rethink your own role in the ecosystem to support them. Speakers: Welcome To Maintainers Life Please Bring Snacks and Boundaries - Nitish Kumar from Akuity, Veronica Lopez from AuthZed, Lee Calcote from Layer5. Location: Building B | Level 3 | B308-309. Categories: CLOUD NATIVE EXPERIENCE.",
      "metadata": {
        "title": "Do You Even Merge?",
        "description": "Open Source maintainers are often seen as gatekeepers of progress, expected to fix bugs, review PRs, design features, answer questions, and keep the community happy. But behind that facade is often an unexpected reality, especially in high-velocity CNCF projects.\n\nIn this talk, we will share what its like to maintain a CNCF Graduated project, not just the technical side, but the human side: how we keep the project growing, prioritize responsibly, and how governance structures like SIGs help scale responsibilities. Youll hear stories, lessons, and hard truths that rarely make it into blog posts.\n\nThe more successful a project becomes, the harder it gets to sustain, and thats something we dont acknowledge enough. If youve ever wondered why your issue didnt get a response, why a feature was declined, or what being supportive really looks like in open source, this talk will help you understand the maintainers side and maybe rethink your own role in the ecosystem to support them.",
        "url": "http://kccncna2025.sched.com/event/31645cdd675aa9e6b7b8a2be378fb460",
        "uid": "31645cdd675aa9e6b7b8a2be378fb460",
        "start": "2025-11-12T11:00:00-05:00",
        "end": "2025-11-12T11:30:00-05:00",
        "categories": [
          "CLOUD NATIVE EXPERIENCE"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B308-309"
        },
        "speakers": [
          {
            "name": "Welcome To Maintainers Life",
            "title": "Please Bring Snacks and Boundaries - Nitish Kumar",
            "company": "Akuity"
          },
          {
            "name": "Veronica Lopez",
            "company": "AuthZed"
          },
          {
            "name": "Lee Calcote",
            "company": "Layer5"
          }
        ]
      }
    },
    {
      "text": "Sometimes it seems like magic when we deploy a service with a few lines of YAML and Kubernetes starts actually routing traffic to our pods -- or we create those pods with a certain configuration and Kubernetes sets everything up for us. But what is Kubernetes actually *doing*? In many cases, it's actually the node's OS that does the heavy lifting behind the scenes, through existing OS features that were used to manage workloads for years before Kubernetes appeared. In this session, Joe pulls aside the curtain to give you a tour of the OS nuts and bolts behind the magic of services, pods, and other mystical Kubernetes incantations. Whether you're a novice who's never heard of cgroups or iptables, or a more experienced user who just wants to learn how everything you already knew ties together, you'll see what your nodes do to make Kubernetes possible and gain a deeper understanding of why certain things in your cluster work the way they do. Speakers: Joe Thompson from Clarity Business Solutions. Location: Building B | Level 5 | Thomas Murphy Ballroom 4. Categories: CLOUD NATIVE NOVICE.",
      "metadata": {
        "title": "The OS Behind the Curtain: What Happens on Your Nodes When Things Happen in Your Cluster",
        "description": "Sometimes it seems like magic when we deploy a service with a few lines of YAML and Kubernetes starts actually routing traffic to our pods -- or we create those pods with a certain configuration and Kubernetes sets everything up for us. But what is Kubernetes actually *doing*? In many cases, it's actually the node's OS that does the heavy lifting behind the scenes, through existing OS features that were used to manage workloads for years before Kubernetes appeared. In this session, Joe pulls aside the curtain to give you a tour of the OS nuts and bolts behind the magic of services, pods, and other mystical Kubernetes incantations. Whether you're a novice who's never heard of cgroups or iptables, or a more experienced user who just wants to learn how everything you already knew ties together, you'll see what your nodes do to make Kubernetes possible and gain a deeper understanding of why certain things in your cluster work the way they do.",
        "url": "http://kccncna2025.sched.com/event/b58e0d70345d117b4caf00e0d91920df",
        "uid": "b58e0d70345d117b4caf00e0d91920df",
        "start": "2025-11-12T11:00:00-05:00",
        "end": "2025-11-12T11:30:00-05:00",
        "categories": [
          "CLOUD NATIVE NOVICE"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 4"
        },
        "speakers": [
          {
            "name": "Joe Thompson",
            "company": "Clarity Business Solutions"
          }
        ]
      }
    },
    {
      "text": "Managing AI inference workloads on k8s is hard: you need to choose the right GPU instance type, configure services, balance costs vs. performance, write tedious YAML, and continuously monitor utilization and inference latency. What if you can leverage AI to determine these factors with high accuracy? Learn how to build an end-to-end AI-PaaS on k8s by combining cloud-native tools, Model Context Protocol (MCP) servers, and intelligent agents. We will show how an agent can resolve a simple text command (deploy llama-3-70b-chat), call out to external MCP metadata services (e.g. HuggingFace), calculate the optimal GPU topology, and provision nodes via the Kubernetes AI Toolchain Operator, deploy the model, and then automatically scale based on real-time metrics -- all without hand-editing a single manifest. We will also discuss how to address underspecified aspects (like model quantization levels, cost vs latency tradeoffs), and the guardrails needed to validate before deploying. Speakers: Ganeshkumar Ashokavardhanan from  Microsoft, Qinghui Zhuang from  Microsoft. Location: Building B | Level 2 | B206. Categories: EMERGING + ADVANCED.",
      "metadata": {
        "title": "Agent-Driven MCP for AI Workloads on Kubernetes",
        "description": "Managing AI inference workloads on k8s is hard: you need to choose the right GPU instance type, configure services, balance costs vs. performance, write tedious YAML, and continuously monitor utilization and inference latency. What if you can leverage AI to determine these factors with high accuracy? Learn how to build an end-to-end AI-PaaS on k8s by combining cloud-native tools, Model Context Protocol (MCP) servers, and intelligent agents. We will show how an agent can resolve a simple text command (deploy llama-3-70b-chat), call out to external MCP metadata services (e.g. HuggingFace), calculate the optimal GPU topology, and provision nodes via the Kubernetes AI Toolchain Operator, deploy the model, and then automatically scale based on real-time metrics -- all without hand-editing a single manifest. We will also discuss how to address underspecified aspects (like model quantization levels, cost vs latency tradeoffs), and the guardrails needed to validate before deploying.",
        "url": "http://kccncna2025.sched.com/event/7c36b3fe0676ab8725f2426dd55cfaf5",
        "uid": "7c36b3fe0676ab8725f2426dd55cfaf5",
        "start": "2025-11-12T11:00:00-05:00",
        "end": "2025-11-12T11:30:00-05:00",
        "categories": [
          "EMERGING + ADVANCED"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B206"
        },
        "speakers": [
          {
            "name": "Ganeshkumar Ashokavardhanan",
            "company": " Microsoft"
          },
          {
            "name": "Qinghui Zhuang",
            "company": " Microsoft"
          }
        ]
      }
    },
    {
      "text": "The Capture The Flag (CTF) experience runs concurrently to KubeCon + CloudNativeCon North America 2025!\n\nDelve deeper into the dark and mysterious world of Cloud Native security! Exploit a supply chain or foothold attack and start your journey deep inside the target infrastructure, utilize your position to hunt and collect the flags, and hopefully learn something new and wryly amusing along the way!\nAttendees can play three increasingly treacherous and demanding scenarios to bushwhack their way through the dense jungle of Cloud Native security. Everybody is welcome, from beginner to seasoned veterans, as we venture amongst the low-hanging fruits of insecure configuration and scale the lofty peaks of cluster compromise! Location: Building B | Level 2 | B203. Categories: EXPERIENCES.",
      "metadata": {
        "title": "Capture The Flag Experience",
        "description": "The Capture The Flag (CTF) experience runs concurrently to KubeCon + CloudNativeCon North America 2025!\n\nDelve deeper into the dark and mysterious world of Cloud Native security! Exploit a supply chain or foothold attack and start your journey deep inside the target infrastructure, utilize your position to hunt and collect the flags, and hopefully learn something new and wryly amusing along the way!\nAttendees can play three increasingly treacherous and demanding scenarios to bushwhack their way through the dense jungle of Cloud Native security. Everybody is welcome, from beginner to seasoned veterans, as we venture amongst the low-hanging fruits of insecure configuration and scale the lofty peaks of cluster compromise!",
        "url": "http://kccncna2025.sched.com/event/db0243279f1202c0f4a445304c7c769b",
        "uid": "db0243279f1202c0f4a445304c7c769b",
        "start": "2025-11-12T11:00:00-05:00",
        "end": "2025-11-12T16:45:00-05:00",
        "categories": [
          "EXPERIENCES"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B203"
        }
      }
    },
    {
      "text": "Gateway API has matured into a core building block for cloud-native application networking. As organizations increasingly converge on this technology, it's expanding to support critical new use cases, including AI Inference. In this session, maintainers will provide a comprehensive overview of the latest progress, challenges, and roadmap, highlighting the recent v1.4 release and future milestones. They'll dive into complex topics such as handling conflicting use cases like TLS termination across multiple routes, efforts to create a more intuitive API, and the upcoming critical features.\n\nBeyond a mere status update, the talk will offer deep insights into project decision-making and the challenges of managing a large-scale open-source initiative. Whether you're a platform builder, SIG contributor, or someone using ingress Gateways or service mesh in production, this session invites you to help shape the future of Kubernetes networking. Speakers: Shane Utt from  Red Hat, Candace Holman from  Red Hat, Mike Morris from Microsoft, Lior Lieberman from  Google, Kellen Swain from  Google. Location: Building C | Level 3 | Georgia Ballroom 3. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Gateway API: Table Stakes",
        "description": "Gateway API has matured into a core building block for cloud-native application networking. As organizations increasingly converge on this technology, it's expanding to support critical new use cases, including AI Inference. In this session, maintainers will provide a comprehensive overview of the latest progress, challenges, and roadmap, highlighting the recent v1.4 release and future milestones. They'll dive into complex topics such as handling conflicting use cases like TLS termination across multiple routes, efforts to create a more intuitive API, and the upcoming critical features.\n\nBeyond a mere status update, the talk will offer deep insights into project decision-making and the challenges of managing a large-scale open-source initiative. Whether you're a platform builder, SIG contributor, or someone using ingress Gateways or service mesh in production, this session invites you to help shape the future of Kubernetes networking.",
        "url": "http://kccncna2025.sched.com/event/02a95b2ec247b27ebee1189404c4bde0",
        "uid": "02a95b2ec247b27ebee1189404c4bde0",
        "start": "2025-11-12T11:00:00-05:00",
        "end": "2025-11-12T11:30:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 3"
        },
        "speakers": [
          {
            "name": "Shane Utt",
            "company": " Red Hat"
          },
          {
            "name": "Candace Holman",
            "company": " Red Hat"
          },
          {
            "name": "Mike Morris",
            "company": "Microsoft"
          },
          {
            "name": "Lior Lieberman",
            "company": " Google"
          },
          {
            "name": "Kellen Swain",
            "company": " Google"
          }
        ]
      }
    },
    {
      "text": "The wait is over! After six years with Helm v3, Helm v4 is finally here. In this session you'll learn about Helm v4, why there was 6 years between major versions (from backwards compatible feature development to maintainer ups and downs), what's new in Helm v4, how long Helm v3 will still be supported, and what comes next. Could that include a Helm v5? Speakers: Matt Farina from  SUSE, Robert Sirchia from  SUSE. Location: Building C | Level 3 | Georgia Ballroom 1. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Introducing Helm 4",
        "description": "The wait is over! After six years with Helm v3, Helm v4 is finally here. In this session you'll learn about Helm v4, why there was 6 years between major versions (from backwards compatible feature development to maintainer ups and downs), what's new in Helm v4, how long Helm v3 will still be supported, and what comes next. Could that include a Helm v5?",
        "url": "http://kccncna2025.sched.com/event/05dfaf06cda3231a824e5a641483eef5",
        "uid": "05dfaf06cda3231a824e5a641483eef5",
        "start": "2025-11-12T11:00:00-05:00",
        "end": "2025-11-12T11:30:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 1"
        },
        "speakers": [
          {
            "name": "Matt Farina",
            "company": " SUSE"
          },
          {
            "name": "Robert Sirchia",
            "company": " SUSE"
          }
        ]
      }
    },
    {
      "text": "Kubernetes at the edge is no longer experimental - its becoming the default choice for various use cases. As adoption grows, new challenges emerge: managing scale, handling connectivity issues, and delivering updates. Sparse, unreliable internet connectivity - requires a rethinking of typical GitOps workflows. This talk presents a production-grade, end-to-end architecture with Argo CD at the center, enabling centralized management of a fleet of disconnected or intermittently connected clusters. The design includes an in-cluster Git server and container image registry to ensure local availability of both manifests and images during offline operation. Well cover controlled sync strategies, secure update propagation during reconnection windows, and how to bootstrap new clusters in isolated environments. The talk concludes with a live demo of the full setup, and attendees will walk away with a reference implementation they can adopt for industrial, telco, or remote field deployments. Speakers: Alexander Matyushentsev from Akuity. Location: Building C | Level 3 | Georgia Ballroom 2. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Offline, Not Off-Limits: Edge Fleet Management With Argo CD",
        "description": "Kubernetes at the edge is no longer experimental - its becoming the default choice for various use cases. As adoption grows, new challenges emerge: managing scale, handling connectivity issues, and delivering updates. Sparse, unreliable internet connectivity - requires a rethinking of typical GitOps workflows. This talk presents a production-grade, end-to-end architecture with Argo CD at the center, enabling centralized management of a fleet of disconnected or intermittently connected clusters. The design includes an in-cluster Git server and container image registry to ensure local availability of both manifests and images during offline operation. Well cover controlled sync strategies, secure update propagation during reconnection windows, and how to bootstrap new clusters in isolated environments. The talk concludes with a live demo of the full setup, and attendees will walk away with a reference implementation they can adopt for industrial, telco, or remote field deployments.",
        "url": "http://kccncna2025.sched.com/event/0e54a3e2c6b073960988a9b92167f9f5",
        "uid": "0e54a3e2c6b073960988a9b92167f9f5",
        "start": "2025-11-12T11:00:00-05:00",
        "end": "2025-11-12T11:30:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 2"
        },
        "speakers": [
          {
            "name": "Alexander Matyushentsev",
            "company": "Akuity"
          }
        ]
      }
    },
    {
      "text": "SIG Auth is leading efforts to strengthen Kubernetes authentication and authorization foundations. This session covers recent and upcoming features shaping security across the stack. Secure image pulls are being enabled using ephemeral ServiceAccount tokens, reducing reliance on long-lived secrets and node-scoped credentials. Kubernetes is gaining a new mechanism for provisioning X.509 certificates directly to pods via the kubelet, enabling strong mTLS authentication and service-to-service communication. Kubelet serving certificate validation is being hardened to prevent node impersonation, especially in dynamic or on-prem environments. In resource management, DRA adds support for privileged admin access to devices in use, enabling secure diagnostics without weakening isolation. Well also cover current and future improvements in authorization, such as tighter policy for image pull operations. Join us to learn how these efforts are improving the trust model across Kubernetes. Speakers: Anish Ramasekar Mo Khan, Stanislav Laznicka from Rita Zhang, Peter Engelbert from Microsoft. Location: Building C | Level 1 | C111-112. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Strengthening Kubernetes Trust: SIG Auth's Latest Security Enhancements",
        "description": "SIG Auth is leading efforts to strengthen Kubernetes authentication and authorization foundations. This session covers recent and upcoming features shaping security across the stack. Secure image pulls are being enabled using ephemeral ServiceAccount tokens, reducing reliance on long-lived secrets and node-scoped credentials. Kubernetes is gaining a new mechanism for provisioning X.509 certificates directly to pods via the kubelet, enabling strong mTLS authentication and service-to-service communication. Kubelet serving certificate validation is being hardened to prevent node impersonation, especially in dynamic or on-prem environments. In resource management, DRA adds support for privileged admin access to devices in use, enabling secure diagnostics without weakening isolation. Well also cover current and future improvements in authorization, such as tighter policy for image pull operations. Join us to learn how these efforts are improving the trust model across Kubernetes.",
        "url": "http://kccncna2025.sched.com/event/75c38e2b65b9c06b5b84728c13963797",
        "uid": "75c38e2b65b9c06b5b84728c13963797",
        "start": "2025-11-12T11:00:00-05:00",
        "end": "2025-11-12T11:30:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "1",
          "room": "C111-112"
        },
        "speakers": [
          {
            "name": "Anish Ramasekar",
            "title": "Mo Khan, Stanislav Laznicka",
            "company": "Rita Zhang"
          },
          {
            "name": "Peter Engelbert",
            "company": "Microsoft"
          }
        ]
      }
    },
    {
      "text": "We have all run into this problem - \"OTEL Collector/Prometheus does things differently and it doesn't fit my organization's design or can't really scale to my need\". Once that statement is made, the almost immediate goto is to either customize or ditch the project completely. With some of the connectors/processors in OTEL we ran into this issue where we were unable to operate them. Ex:\n* eBay's span traffic spans multiple kubernetes clusters and multiple regions. Service graph connector would need to see spans globally routed into a single collector. At scale, this requires a lot of memory to account for all kind of trace durations.\n* Prometheus has no support for long term retention for exemplars.\n\nIn this talk we discussion practical solutions of how we leveraged our Clickhouse based internal tracestore to provide spans to servicegraph connector in a sustainable way to generate metrics and how we used clickhouse to provide long term retention of exemplars. Speakers: How To Overcome Scale/Design Limitations - Vijay Samuel from  eBay, Sandeep Raveesh from  eBay. Location: Building B | Level 3 | B304-305. Categories: OBSERVABILITY.",
      "metadata": {
        "title": "Retrofitting OTEL Collectors & Prometheus",
        "description": "We have all run into this problem - \"OTEL Collector/Prometheus does things differently and it doesn't fit my organization's design or can't really scale to my need\". Once that statement is made, the almost immediate goto is to either customize or ditch the project completely. With some of the connectors/processors in OTEL we ran into this issue where we were unable to operate them. Ex:\n* eBay's span traffic spans multiple kubernetes clusters and multiple regions. Service graph connector would need to see spans globally routed into a single collector. At scale, this requires a lot of memory to account for all kind of trace durations.\n* Prometheus has no support for long term retention for exemplars.\n\nIn this talk we discussion practical solutions of how we leveraged our Clickhouse based internal tracestore to provide spans to servicegraph connector in a sustainable way to generate metrics and how we used clickhouse to provide long term retention of exemplars.",
        "url": "http://kccncna2025.sched.com/event/d4c83fac204c66a2e71168d49676b74d",
        "uid": "d4c83fac204c66a2e71168d49676b74d",
        "start": "2025-11-12T11:00:00-05:00",
        "end": "2025-11-12T11:30:00-05:00",
        "categories": [
          "OBSERVABILITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B304-305"
        },
        "speakers": [
          {
            "name": "How To Overcome Scale/Design Limitations - Vijay Samuel",
            "company": " eBay"
          },
          {
            "name": "Sandeep Raveesh",
            "company": " eBay"
          }
        ]
      }
    },
    {
      "text": "At Coinbase, we run thousands of workloads - from high-throughput APIs to long-lived blockchain nodes. As traffic patterns scale due to cryptos volatility and expectations around reliability and cost got tighter, our prior cluster setup using cluster-autoscaler and EKS managed node groups couldnt strike the right balance. This talk covers why we moved to Karpenter (including pain points around scaling latency, bin packing, and satisfying unique topology and hardware requirements) and what it took to get there. Youll learn how we implemented a scalable and tag-driven EC2NodeClass abstraction, tuned Karpenter for burst elasticity, and built observability and guardrails to make scaling safer and more predictable. Finally, well share lessons from overly aggressive node consolidation, launch template drift, VPC-CNI coordination, and how weve adapted our platform to support rapid, responsive scaling under crypto-scale pressure. Speakers: Frances Chong from Coinbase. Location: Building B | Level 4 | B406b-407. Categories: OPERATIONS + PERFORMANCE.",
      "metadata": {
        "title": "Rearchitecting Compute at Coinbase: Migrating To Karpenter for Fast, Reliable Scaling",
        "description": "At Coinbase, we run thousands of workloads - from high-throughput APIs to long-lived blockchain nodes. As traffic patterns scale due to cryptos volatility and expectations around reliability and cost got tighter, our prior cluster setup using cluster-autoscaler and EKS managed node groups couldnt strike the right balance. This talk covers why we moved to Karpenter (including pain points around scaling latency, bin packing, and satisfying unique topology and hardware requirements) and what it took to get there. Youll learn how we implemented a scalable and tag-driven EC2NodeClass abstraction, tuned Karpenter for burst elasticity, and built observability and guardrails to make scaling safer and more predictable. Finally, well share lessons from overly aggressive node consolidation, launch template drift, VPC-CNI coordination, and how weve adapted our platform to support rapid, responsive scaling under crypto-scale pressure.",
        "url": "http://kccncna2025.sched.com/event/aa76cf66180e56625eff21a3de19e032",
        "uid": "aa76cf66180e56625eff21a3de19e032",
        "start": "2025-11-12T11:00:00-05:00",
        "end": "2025-11-12T11:30:00-05:00",
        "categories": [
          "OPERATIONS + PERFORMANCE"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B406b-407"
        },
        "speakers": [
          {
            "name": "Frances Chong",
            "company": "Coinbase"
          }
        ]
      }
    },
    {
      "text": "Navigating platform engineering at scale requires innovation. This talk explores Spotifys 'Fleet-first' mindseta strategic shift in managing and evolving our vast software ecosystem. More than just tools, its a cultural change: treating our software as a fleet to drive rapid, reliable, and scalable improvements. Well cover how Golden Tech, Declarative Infrastructure, and Fleet Management tools support this approach. From identifying the target fleet of software, to rolling out migrations of varying complexity, well share how Spotify enables efficient change at scale. Real-world examples will show how a Fleet-first approach saves engineers time and improves overall tech health. Whether you're managing large infrastructure or evolving engineering practices, you'll gain actionable insights and a framework to adopt Fleet-first thinkingboosting both efficiency and resilience in your organization. Speakers: Andy Beane from Spotify. Location: Building B | Level 4 | B405-406a. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "Adopting a Fleet-first Mindset",
        "description": "Navigating platform engineering at scale requires innovation. This talk explores Spotifys 'Fleet-first' mindseta strategic shift in managing and evolving our vast software ecosystem. More than just tools, its a cultural change: treating our software as a fleet to drive rapid, reliable, and scalable improvements. Well cover how Golden Tech, Declarative Infrastructure, and Fleet Management tools support this approach. From identifying the target fleet of software, to rolling out migrations of varying complexity, well share how Spotify enables efficient change at scale. Real-world examples will show how a Fleet-first approach saves engineers time and improves overall tech health. Whether you're managing large infrastructure or evolving engineering practices, you'll gain actionable insights and a framework to adopt Fleet-first thinkingboosting both efficiency and resilience in your organization.",
        "url": "http://kccncna2025.sched.com/event/836be6145a66395bd683bd1958e63cdf",
        "uid": "836be6145a66395bd683bd1958e63cdf",
        "start": "2025-11-12T11:00:00-05:00",
        "end": "2025-11-12T11:30:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B405-406a"
        },
        "speakers": [
          {
            "name": "Andy Beane",
            "company": "Spotify"
          }
        ]
      }
    },
    {
      "text": "Platform engineering promises accelerated developer productivity, but complex abstractions often create barriers instead of removing them. How do you design platforms that welcome newcomers while empowering experienced users?\n\nDrawing from real-world implementations at CNCF Orgs and community insights from organizing major cloud native events, we'll demonstrate progressive platform experiences that grow with developers. Learn about abstractions from Helm, ArgoCD, Dapr, or CNOE that level up without sacrificing flexibility, implement progressive patterns, and create feedback loops ensuring platforms evolve with user needs.\n\nThrough practical examples whether GitOps or Dapr or other enablers we'll show how to build platforms serving both overwhelmed newcomers and power users demanding control. Get actionable strategies for making sophisticated platforms approachable and effective. Speakers: Luke Philips from Independant, Julia Furst Morgado from Veeam. Location: Building B | Level 3 | B312-314. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "Making Platform Engineering Accessible: From Newcomer To Power User",
        "description": "Platform engineering promises accelerated developer productivity, but complex abstractions often create barriers instead of removing them. How do you design platforms that welcome newcomers while empowering experienced users?\n\nDrawing from real-world implementations at CNCF Orgs and community insights from organizing major cloud native events, we'll demonstrate progressive platform experiences that grow with developers. Learn about abstractions from Helm, ArgoCD, Dapr, or CNOE that level up without sacrificing flexibility, implement progressive patterns, and create feedback loops ensuring platforms evolve with user needs.\n\nThrough practical examples whether GitOps or Dapr or other enablers we'll show how to build platforms serving both overwhelmed newcomers and power users demanding control. Get actionable strategies for making sophisticated platforms approachable and effective.",
        "url": "http://kccncna2025.sched.com/event/8a80a7644e746a104626ea45bcaca522",
        "uid": "8a80a7644e746a104626ea45bcaca522",
        "start": "2025-11-12T11:00:00-05:00",
        "end": "2025-11-12T11:30:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B312-314"
        },
        "speakers": [
          {
            "name": "Luke Philips",
            "company": "Independant"
          },
          {
            "name": "Julia Furst Morgado",
            "company": "Veeam"
          }
        ]
      }
    },
    {
      "text": "Kubernetes addons often sit quietly behind the scenesuntil they become your biggest security liability. Whether its an old version of a DNS provider, metrics server, or ingress controller, these components are essential to your clusters operation but rarely treated as part of a regular update cycle. In this session, well dive into the risks of neglecting addon maintenance and share practical strategies for getting ahead of potential failures or vulnerabilities. Youll learn how to assess addon health, prioritize updates, and communicate the business case for proactive maintenanceeven when everything seems to be working just fine. Walk away with tools to build a repeatable, low-friction update plan that boosts both the security and reliability of your clusters. Speakers: Stevie Caldwell from  Fairwinds, Andy Suderman from  Fairwinds. Location: Building B | Level 3 | B302-303. Categories: SECURITY.",
      "metadata": {
        "title": "Patch Me If You Can: Tackling Outdated Addons Before They Become a Risk",
        "description": "Kubernetes addons often sit quietly behind the scenesuntil they become your biggest security liability. Whether its an old version of a DNS provider, metrics server, or ingress controller, these components are essential to your clusters operation but rarely treated as part of a regular update cycle. In this session, well dive into the risks of neglecting addon maintenance and share practical strategies for getting ahead of potential failures or vulnerabilities. Youll learn how to assess addon health, prioritize updates, and communicate the business case for proactive maintenanceeven when everything seems to be working just fine. Walk away with tools to build a repeatable, low-friction update plan that boosts both the security and reliability of your clusters.",
        "url": "http://kccncna2025.sched.com/event/d7ea2570a72e83a56f1f9fa0890798c5",
        "uid": "d7ea2570a72e83a56f1f9fa0890798c5",
        "start": "2025-11-12T11:00:00-05:00",
        "end": "2025-11-12T11:30:00-05:00",
        "categories": [
          "SECURITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B302-303"
        },
        "speakers": [
          {
            "name": "Stevie Caldwell",
            "company": " Fairwinds"
          },
          {
            "name": "Andy Suderman",
            "company": " Fairwinds"
          }
        ]
      }
    },
    {
      "text": "Curious about how we build the most powerful and innovative service mesh available? Want to get started as an open source contributor in a popular CNCF graduated project, learn about the codebase underlying the mesh or simply take a peek behind the curtain to see how its done? This is your chance! Join Istio maintainers for a session diving into the codebase and learn how you can join us to help shape the future of Istio.\n\nDuring this session well cover the architecture of the two primary operating modes for Istio, how to set up your development environment, how to interact with the community and start contributing your first PR to Istio. Speakers: Ian Rudie from  Solo.io, Lin Sun from  Solo.io, Faseela Kundattil from Ericsson, Steven Jin from Microsoft. Location: Building B | Level 2 | B207. Categories:  CONTRIBFEST.",
      "metadata": {
        "title": "Contribfest: From Farm (Fork) To Table (Feature): Growing Your First (Free-range Organic) Istio PR",
        "description": "Curious about how we build the most powerful and innovative service mesh available? Want to get started as an open source contributor in a popular CNCF graduated project, learn about the codebase underlying the mesh or simply take a peek behind the curtain to see how its done? This is your chance! Join Istio maintainers for a session diving into the codebase and learn how you can join us to help shape the future of Istio.\n\nDuring this session well cover the architecture of the two primary operating modes for Istio, how to set up your development environment, how to interact with the community and start contributing your first PR to Istio.",
        "url": "http://kccncna2025.sched.com/event/aa0291d208cffb707f052016c920b511",
        "uid": "aa0291d208cffb707f052016c920b511",
        "start": "2025-11-12T11:00:00-05:00",
        "end": "2025-11-12T12:15:00-05:00",
        "categories": [
          " CONTRIBFEST"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B207"
        },
        "speakers": [
          {
            "name": "Ian Rudie",
            "company": " Solo.io"
          },
          {
            "name": "Lin Sun",
            "company": " Solo.io"
          },
          {
            "name": "Faseela Kundattil",
            "company": "Ericsson"
          },
          {
            "name": "Steven Jin",
            "company": "Microsoft"
          }
        ]
      }
    },
    {
      "text": "This hands-on session is designed to enable end-users and ecosystem partners to contribute to Kyverno, a CNCF policy as code engine that elegantly solves critical challenges across security, automation, and compliance, by understanding the internals of the project and its governance.\n\nYou will learn about Kyvernos architecture, the role of each policy type, the components, how to set up your development environment, and how to contribute to the project.\n\nThis session will be led by Kyverno maintainers and contributors and is organized so that both developers as well as non-developers can contribute across the software base, sample policies, and documentation.\n\nJoin us to shape the future of cloud native governance together! Speakers: Let's Build Together! - Jim Bugwadia from  Nirmata, Cortney Nickerson from  Nirmata. Location: Building B | Level 2 | B208. Categories:  CONTRIBFEST.",
      "metadata": {
        "title": "Contribfest: Kyverno",
        "description": "This hands-on session is designed to enable end-users and ecosystem partners to contribute to Kyverno, a CNCF policy as code engine that elegantly solves critical challenges across security, automation, and compliance, by understanding the internals of the project and its governance.\n\nYou will learn about Kyvernos architecture, the role of each policy type, the components, how to set up your development environment, and how to contribute to the project.\n\nThis session will be led by Kyverno maintainers and contributors and is organized so that both developers as well as non-developers can contribute across the software base, sample policies, and documentation.\n\nJoin us to shape the future of cloud native governance together!",
        "url": "http://kccncna2025.sched.com/event/9df3abddd3c9690028599e6514ffa330",
        "uid": "9df3abddd3c9690028599e6514ffa330",
        "start": "2025-11-12T11:00:00-05:00",
        "end": "2025-11-12T12:15:00-05:00",
        "categories": [
          " CONTRIBFEST"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B208"
        },
        "speakers": [
          {
            "name": "Let's Build Together! - Jim Bugwadia",
            "company": " Nirmata"
          },
          {
            "name": "Cortney Nickerson",
            "company": " Nirmata"
          }
        ]
      }
    },
    {
      "text": "Dive into the world of gRPC with this interactive codelab. Roll up your sleeves and build a fully functional gRPC service from the ground up, in Go, Java, or Python. You'll gain first-hand experience with:\n\n- Protocol Buffers. You'll learn how to define service contracts and data structures using this powerful interface definition language.\n\n- gRPC Code Generation: Streamline development by automatically generating Python code from your protobuf definitions.\n\n- Client/Server Communication: Implement client and server logic to establish seamless communication between distributed components.\n\n- Error Handling and Interceptors: Explore techniques for graceful error handling and implementing middleware using gRPC interceptors. Speakers: Richard Belleville from  Google, E John Feig from  Google. Location: Building B | Level 5 | Thomas Murphy Ballroom 2-3. Categories:  TUTORIALS.",
      "metadata": {
        "title": "Tutorial: Getting Started With gRPC: Hands-On Codelab",
        "description": "Dive into the world of gRPC with this interactive codelab. Roll up your sleeves and build a fully functional gRPC service from the ground up, in Go, Java, or Python. You'll gain first-hand experience with:\n\n- Protocol Buffers. You'll learn how to define service contracts and data structures using this powerful interface definition language.\n\n- gRPC Code Generation: Streamline development by automatically generating Python code from your protobuf definitions.\n\n- Client/Server Communication: Implement client and server logic to establish seamless communication between distributed components.\n\n- Error Handling and Interceptors: Explore techniques for graceful error handling and implementing middleware using gRPC interceptors.",
        "url": "http://kccncna2025.sched.com/event/f218c8a3c8c0e3a0a649d17feed9dde9",
        "uid": "f218c8a3c8c0e3a0a649d17feed9dde9",
        "start": "2025-11-12T11:00:00-05:00",
        "end": "2025-11-12T12:15:00-05:00",
        "categories": [
          " TUTORIALS"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 2-3"
        },
        "speakers": [
          {
            "name": "Richard Belleville",
            "company": " Google"
          },
          {
            "name": "E John Feig",
            "company": " Google"
          }
        ]
      }
    },
    {
      "text": "Observability should empower developers - not burden them. Yet too often, instrumenting applications for traces, metrics, and logs means code changes, redeploys, and ongoing friction.\nIn this demo-focused session, well showcase the OpenTelemetry Operator, the community project that brings no-touch instrumentation to your Kubernetes workloads. Youll see how platform engineers can:\n- Deploy the OpenTelemetry Operator and Collectors\n- Instrument applications automatically - without touching a single line of code\n- Correlate metrics, traces, and logs across services to unlock deep insights\nWell finish by visualizing the results in Dash0, showing how open standards like OpenTelemetry let you achieve full-stack observability with minimal effort - and without vendor lock-in.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.* Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: SOLUTIONS SHOWCASE.",
      "metadata": {
        "title": "Sponsored Demo: No-Touch Observability with the OpenTelemetry Operator and Dash0",
        "description": "Observability should empower developers - not burden them. Yet too often, instrumenting applications for traces, metrics, and logs means code changes, redeploys, and ongoing friction.\nIn this demo-focused session, well showcase the OpenTelemetry Operator, the community project that brings no-touch instrumentation to your Kubernetes workloads. Youll see how platform engineers can:\n- Deploy the OpenTelemetry Operator and Collectors\n- Instrument applications automatically - without touching a single line of code\n- Correlate metrics, traces, and logs across services to unlock deep insights\nWell finish by visualizing the results in Dash0, showing how open standards like OpenTelemetry let you achieve full-stack observability with minimal effort - and without vendor lock-in.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.*",
        "url": "http://kccncna2025.sched.com/event/2f8304620bbf319adf3bffc0a959e3c0",
        "uid": "2f8304620bbf319adf3bffc0a959e3c0",
        "start": "2025-11-12T11:05:00-05:00",
        "end": "2025-11-12T11:25:00-05:00",
        "categories": [
          "SOLUTIONS SHOWCASE"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "Kubernetes operations can be complex, especially when it comes to writing manifests, tuning configurations, and troubleshooting live clusters. In this demo, we'll show how the open source Amazon EKS MCP server bridges AI assistants with Kubernetes clusters to make these tasks faster and easier.\n\nYou'll see live examples of AI agents using MCP to:\n1/Generate Kubernetes manifests taking advantage of EKS Auto Mode configurations\n2/Provide context-aware guidance for cluster setup and management.\n3/Analyze logs, events, and cluster state to troubleshoot common issues.\n\nBy the end of the session, you'll understand how MCP gives AI tools the context they need to work with Kubernetes effectivelyturning complex operations into simple, guided workflows.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.* Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: SOLUTIONS SHOWCASE.",
      "metadata": {
        "title": "Sponsored Demo: Streamlining Kubernetes Operations with Model Context Protocol",
        "description": "Kubernetes operations can be complex, especially when it comes to writing manifests, tuning configurations, and troubleshooting live clusters. In this demo, we'll show how the open source Amazon EKS MCP server bridges AI assistants with Kubernetes clusters to make these tasks faster and easier.\n\nYou'll see live examples of AI agents using MCP to:\n1/Generate Kubernetes manifests taking advantage of EKS Auto Mode configurations\n2/Provide context-aware guidance for cluster setup and management.\n3/Analyze logs, events, and cluster state to troubleshoot common issues.\n\nBy the end of the session, you'll understand how MCP gives AI tools the context they need to work with Kubernetes effectivelyturning complex operations into simple, guided workflows.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.*",
        "url": "http://kccncna2025.sched.com/event/62d35e62061b34dfe254ff0ca680d46b",
        "uid": "62d35e62061b34dfe254ff0ca680d46b",
        "start": "2025-11-12T11:35:00-05:00",
        "end": "2025-11-12T11:55:00-05:00",
        "categories": [
          "SOLUTIONS SHOWCASE"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "As AI models like DeepSeek-R1 grow beyond 600B parameters, deploying them for inference becomes a major infrastructure challenge. This talk goes beyond initial setup to show how Kubernetes can support massive AI workloads reliably and efficiently in production. Well cover day 0/1 operations with latency, cost, and accuracy tradeoffs in mind: selecting full-precision vs. quantized models; sizing worker nodes for GPU, memory, and networking; managing model parallelism; traffic routing; and adaptive strategies to balance cost and performance. Well explore Kubernetes-native challenges like topology-aware scheduling, GPU-NIC binding, and orchestrating inference phases with custom controllers. To support varied prompt lengths, well discuss Prefill/Decode disaggregation in static and pooled modes. Insights come from benchmarks and production experience confirming what works at scale. Attendees leave with diagrams, checklists, and manifests to deploy confidently. Speakers: Ernest Wong from Microsoft, Jiaxin Shan from Bytedance. Location: Building B | Level 2 | B206. Categories: AI + ML.",
      "metadata": {
        "title": "AI Models Are Huge, but Your GPUs Arent: Mastering Multi-Node Distributed Inference on Kubernetes",
        "description": "As AI models like DeepSeek-R1 grow beyond 600B parameters, deploying them for inference becomes a major infrastructure challenge. This talk goes beyond initial setup to show how Kubernetes can support massive AI workloads reliably and efficiently in production. Well cover day 0/1 operations with latency, cost, and accuracy tradeoffs in mind: selecting full-precision vs. quantized models; sizing worker nodes for GPU, memory, and networking; managing model parallelism; traffic routing; and adaptive strategies to balance cost and performance. Well explore Kubernetes-native challenges like topology-aware scheduling, GPU-NIC binding, and orchestrating inference phases with custom controllers. To support varied prompt lengths, well discuss Prefill/Decode disaggregation in static and pooled modes. Insights come from benchmarks and production experience confirming what works at scale. Attendees leave with diagrams, checklists, and manifests to deploy confidently.",
        "url": "http://kccncna2025.sched.com/event/3340fdee1a14248be0afaa14b3c98213",
        "uid": "3340fdee1a14248be0afaa14b3c98213",
        "start": "2025-11-12T11:45:00-05:00",
        "end": "2025-11-12T12:15:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B206"
        },
        "speakers": [
          {
            "name": "Ernest Wong",
            "company": "Microsoft"
          },
          {
            "name": "Jiaxin Shan",
            "company": "Bytedance"
          }
        ]
      }
    },
    {
      "text": "AI/ML workloads are pushing HPC networking concepts like RDMA, MPI, and patterns for distributed collective operations into Kubernetes. This creates a new learning curve for many platform and infrastructure engineers, especially those looking to bridge their experience from more traditional networking paradigms. This session shares our practical lessons, learned from the trenches while developing networking solutions for these demanding environments. We'll demystify these advanced technologies and discuss the intricacies of integrating specialized hardware, managing out-of-band RDMA, and understanding the communication patterns vital for distributed training. Discover how Kubernetes, particularly through Dynamic Resource Allocation (DRA), is adapting to expose and manage these complex resources. Gain real-world insights, drawn from our experience building a DRA-based network driver, on making advanced AI/ML networking more accessible and manageable in your cloud-native stack. Speakers: Antonio Ojea from Google. Location: Building B | Level 4 | B401-402. Categories: AI + ML.",
      "metadata": {
        "title": "Navigating the AI/ML Networking Maze in Kubernetes: Lessons From the Trenches",
        "description": "AI/ML workloads are pushing HPC networking concepts like RDMA, MPI, and patterns for distributed collective operations into Kubernetes. This creates a new learning curve for many platform and infrastructure engineers, especially those looking to bridge their experience from more traditional networking paradigms. This session shares our practical lessons, learned from the trenches while developing networking solutions for these demanding environments. We'll demystify these advanced technologies and discuss the intricacies of integrating specialized hardware, managing out-of-band RDMA, and understanding the communication patterns vital for distributed training. Discover how Kubernetes, particularly through Dynamic Resource Allocation (DRA), is adapting to expose and manage these complex resources. Gain real-world insights, drawn from our experience building a DRA-based network driver, on making advanced AI/ML networking more accessible and manageable in your cloud-native stack.",
        "url": "http://kccncna2025.sched.com/event/31590e1aa7cfcce4b29d72ccee9ccdaa",
        "uid": "31590e1aa7cfcce4b29d72ccee9ccdaa",
        "start": "2025-11-12T11:45:00-05:00",
        "end": "2025-11-12T12:15:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B401-402"
        },
        "speakers": [
          {
            "name": "Antonio Ojea",
            "company": "Google"
          }
        ]
      }
    },
    {
      "text": "Credit Karma empowers 140M+ members toward financial progress with a personalized, data-driven Financial Assistant, offering secure insights and actionable recommendations. Building this requires a robust, scalable, and secure cloud-native architecture.\n\nThis session details how Kubernetes is foundational to Credit Karma's AI Financial Assistant by showcasing its critical role in:\n\nRetrieval Augmented Generation (RAG): K8s orchestrates RAG pipelines for accurate, context-aware LLM financial advice.\nLLM Guardrails for Safety: Discover our Kubernetes-native approach to dynamic guardrails, crucial for LLM safety and compliance in finance. K8s Sidecars enable agile deployment within our multi-infrastructure serving strategy (inc. Vertex/AWS).\n\nContent Quality Evaluation: K8s powers automated evaluation pipelines, continuously improving recommendation trustworthiness at scale. Speakers: Raj Kiran Gupta Katakam from  Credit Karma, Sukanya Moorthy from  Credit Karma. Location: Building B | Level 5 | Thomas Murphy Ballroom 1. Categories: AI + ML.",
      "metadata": {
        "title": "Unlocking Financial Progress: Credit Karma's AI Assistant Powered by Kubernetes for Personalized Ins",
        "description": "Credit Karma empowers 140M+ members toward financial progress with a personalized, data-driven Financial Assistant, offering secure insights and actionable recommendations. Building this requires a robust, scalable, and secure cloud-native architecture.\n\nThis session details how Kubernetes is foundational to Credit Karma's AI Financial Assistant by showcasing its critical role in:\n\nRetrieval Augmented Generation (RAG): K8s orchestrates RAG pipelines for accurate, context-aware LLM financial advice.\nLLM Guardrails for Safety: Discover our Kubernetes-native approach to dynamic guardrails, crucial for LLM safety and compliance in finance. K8s Sidecars enable agile deployment within our multi-infrastructure serving strategy (inc. Vertex/AWS).\n\nContent Quality Evaluation: K8s powers automated evaluation pipelines, continuously improving recommendation trustworthiness at scale.",
        "url": "http://kccncna2025.sched.com/event/7606554e1c301f2c10779ce3f662ae41",
        "uid": "7606554e1c301f2c10779ce3f662ae41",
        "start": "2025-11-12T11:45:00-05:00",
        "end": "2025-11-12T12:15:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 1"
        },
        "speakers": [
          {
            "name": "Raj Kiran Gupta Katakam",
            "company": " Credit Karma"
          },
          {
            "name": "Sukanya Moorthy",
            "company": " Credit Karma"
          }
        ]
      }
    },
    {
      "text": "In the fast-paced, ever-evolving cloud native landscape, adaptability isnt optionalits essential. Engineers with disabilities have long been experts in navigating shifting environments, not by choice, but by necessity. From working around inaccessible tooling to building inclusive, high-performing teams, theyve developed techniques for thriving in the face of friction.\n\nJoin members of the CNCF Deaf and Hard of Hearing Working Group and the Blind and Visually Impaired Initiative as they share powerful, practical lessons in resilience, creativity, and community. This panel isnt just about accessibilityits about learning to thrive in chaos and designing systems that welcome everyone. Speakers: Travis Johnson from Convo Communications, Catherine Paganini from Buoyant, Chris Khanoyan from Booz Allen Hamilton, Milad Vafaeifard from Epam, Alex Stine from Waystar. Location: Building B | Level 3 | B308-309. Categories: CLOUD NATIVE EXPERIENCE.",
      "metadata": {
        "title": "Adapt, Include, Thrive: Disability-Informed Strategies for Cloud Native Resilience",
        "description": "In the fast-paced, ever-evolving cloud native landscape, adaptability isnt optionalits essential. Engineers with disabilities have long been experts in navigating shifting environments, not by choice, but by necessity. From working around inaccessible tooling to building inclusive, high-performing teams, theyve developed techniques for thriving in the face of friction.\n\nJoin members of the CNCF Deaf and Hard of Hearing Working Group and the Blind and Visually Impaired Initiative as they share powerful, practical lessons in resilience, creativity, and community. This panel isnt just about accessibilityits about learning to thrive in chaos and designing systems that welcome everyone.",
        "url": "http://kccncna2025.sched.com/event/9e6509451c0565a3b089f2c679c16c6b",
        "uid": "9e6509451c0565a3b089f2c679c16c6b",
        "start": "2025-11-12T11:45:00-05:00",
        "end": "2025-11-12T12:15:00-05:00",
        "categories": [
          "CLOUD NATIVE EXPERIENCE"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B308-309"
        },
        "speakers": [
          {
            "name": "Travis Johnson",
            "company": "Convo Communications"
          },
          {
            "name": "Catherine Paganini",
            "company": "Buoyant"
          },
          {
            "name": "Chris Khanoyan",
            "company": "Booz Allen Hamilton"
          },
          {
            "name": "Milad Vafaeifard",
            "company": "Epam"
          },
          {
            "name": "Alex Stine",
            "company": "Waystar"
          }
        ]
      }
    },
    {
      "text": "Fluent Bit is a lightweight and blazing-fast telemetry processor widely adopted in cloud-native environments. As we celebrate 10 years of Fluent Bit, this session offers a fresh intro for new users and a look at whats next. Well cover major updates including OpenTelemetry-native support, routing enhancements, and performance improvements that let you process logs, metrics, and traces efficiently, right at the edge. Learn how Fluent Bit enables high-performance observability pipelines, scales with your infrastructure, and continues to evolve as a core building block for modern platforms. Speakers: Eduardo Silva from Chronosphere. Location: Building C | Level 3 | Georgia Ballroom 1. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Fluent Bit: Smarter Telemetry Routing, Faster Pipelines",
        "description": "Fluent Bit is a lightweight and blazing-fast telemetry processor widely adopted in cloud-native environments. As we celebrate 10 years of Fluent Bit, this session offers a fresh intro for new users and a look at whats next. Well cover major updates including OpenTelemetry-native support, routing enhancements, and performance improvements that let you process logs, metrics, and traces efficiently, right at the edge. Learn how Fluent Bit enables high-performance observability pipelines, scales with your infrastructure, and continues to evolve as a core building block for modern platforms.",
        "url": "http://kccncna2025.sched.com/event/00ed6913590107881c363358153e6b8a",
        "uid": "00ed6913590107881c363358153e6b8a",
        "start": "2025-11-12T11:45:00-05:00",
        "end": "2025-11-12T12:15:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 1"
        },
        "speakers": [
          {
            "name": "Eduardo Silva",
            "company": "Chronosphere"
          }
        ]
      }
    },
    {
      "text": "The continued embrace of Kubernetes as a platform for AI workloads (training and inference) has presented new challenges for ensuring that clusters and workloads can scale and make efficient use of hardware. Since the last Kubecon North America, SIG Autoscaling has been focused on enabling Kubernetes to autoscale to meet the needs of AI Workloads, both for Cluster Autoscaler and karpenter.\n\nJoin us to hear about the SIGs work over the past on Dynamic Resource Allocation, improved support for batch workloads, and other features.\n\nAttendees will leave the session with a better understanding of the roadmap for the SIG ensuring we can meet the needs of workloads scaling on Kubernetes into the future, and how attendees can get involved. Speakers: Jack Francis from Microsoft, Jason Deal from AWS. Location: Building C | Level 1 | C111-112. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "SIG Autoscaling Projects Update",
        "description": "The continued embrace of Kubernetes as a platform for AI workloads (training and inference) has presented new challenges for ensuring that clusters and workloads can scale and make efficient use of hardware. Since the last Kubecon North America, SIG Autoscaling has been focused on enabling Kubernetes to autoscale to meet the needs of AI Workloads, both for Cluster Autoscaler and karpenter.\n\nJoin us to hear about the SIGs work over the past on Dynamic Resource Allocation, improved support for batch workloads, and other features.\n\nAttendees will leave the session with a better understanding of the roadmap for the SIG ensuring we can meet the needs of workloads scaling on Kubernetes into the future, and how attendees can get involved.",
        "url": "http://kccncna2025.sched.com/event/75d86ee34b5a968ed643a2df73a14858",
        "uid": "75d86ee34b5a968ed643a2df73a14858",
        "start": "2025-11-12T11:45:00-05:00",
        "end": "2025-11-12T12:15:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "1",
          "room": "C111-112"
        },
        "speakers": [
          {
            "name": "Jack Francis",
            "company": "Microsoft"
          },
          {
            "name": "Jason Deal",
            "company": "AWS"
          }
        ]
      }
    },
    {
      "text": "Ingress-nginx patches have been released, & we have a working demo of InGate. What more could a Kubernetes Application Developer want? James & Marco will dive into the journey of managing two open source projectsingress-nginx and InGate. Theyll share insights on how they split the responsibilities between the two maintainers. Attendees will get an inside look at the ongoing work to implement compliance tests to support HTTPRoute, & addressing the most requested community features. Additionally, the maintainers will provide an updated timeline for archiving ingress-nginx, highlighting key milestones & steps involved in migrating to InGate. The presentation will outline how folks can get involved in the migration process, tackle current challenges, and shape the future of InGate. Whether youre maintaining existing applications, planning a migration, or interested in contributing to open source, this session offers practical guidance and a collaborative vision for the future of InGate. Speakers: James Strong from Isovalent @ Cisco, Marco Ebert from Giant Swarm. Location: Building C | Level 3 | Georgia Ballroom 3. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "To InGate and Beyond Ingress-nginx!",
        "description": "Ingress-nginx patches have been released, & we have a working demo of InGate. What more could a Kubernetes Application Developer want? James & Marco will dive into the journey of managing two open source projectsingress-nginx and InGate. Theyll share insights on how they split the responsibilities between the two maintainers. Attendees will get an inside look at the ongoing work to implement compliance tests to support HTTPRoute, & addressing the most requested community features. Additionally, the maintainers will provide an updated timeline for archiving ingress-nginx, highlighting key milestones & steps involved in migrating to InGate. The presentation will outline how folks can get involved in the migration process, tackle current challenges, and shape the future of InGate. Whether youre maintaining existing applications, planning a migration, or interested in contributing to open source, this session offers practical guidance and a collaborative vision for the future of InGate.",
        "url": "http://kccncna2025.sched.com/event/e28c4aa65a04b2579ccb3f485b6783ed",
        "uid": "e28c4aa65a04b2579ccb3f485b6783ed",
        "start": "2025-11-12T11:45:00-05:00",
        "end": "2025-11-12T12:15:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 3"
        },
        "speakers": [
          {
            "name": "James Strong",
            "company": "Isovalent @ Cisco"
          },
          {
            "name": "Marco Ebert",
            "company": "Giant Swarm"
          }
        ]
      }
    },
    {
      "text": "This talk will go through all the exciting new features we have recently added to gRPC. We will be covering topics such as OpenTelemetry, Service Mesh, K8s Gateway APIs and GAMMA. We will also cover tips and tricks for building a Microservices Application with gRPC. Speakers: Kevin Nilson from Google, Israel Shapiro from Broadcom. Location: Building C | Level 3 | Georgia Ballroom 2. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "What's New in gRPC",
        "description": "This talk will go through all the exciting new features we have recently added to gRPC. We will be covering topics such as OpenTelemetry, Service Mesh, K8s Gateway APIs and GAMMA. We will also cover tips and tricks for building a Microservices Application with gRPC.",
        "url": "http://kccncna2025.sched.com/event/cec4a04cfd3d1bfaa0f9f12b42a6db94",
        "uid": "cec4a04cfd3d1bfaa0f9f12b42a6db94",
        "start": "2025-11-12T11:45:00-05:00",
        "end": "2025-11-12T12:15:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 2"
        },
        "speakers": [
          {
            "name": "Kevin Nilson",
            "company": "Google"
          },
          {
            "name": "Israel Shapiro",
            "company": "Broadcom"
          }
        ]
      }
    },
    {
      "text": "Your infra runs on K8s, and your controllers and custom resources hum happily. Until they don't. One change later and... UH OH. The logs are a never-ending scroll of problems, dashboards flash like disco lights, and you are knee-deep in debugging hell. You check your custom resources, and they offer no guidance. You eventually fix it, add better error messages, and feel proud. And then it breaks again, with a brand new, even less helpful error. Why is this so hard? In this talk, Derik, a prolific controller-writer, and Cat, a regular listener to DevOps meltdowns, will walk you through tested strategies for making your K8s resources less mysterious and more manageable. You will learn how to: - Add meaningful, traceable errors - Make events and status your best friends - Build dashboards that humans want to use - Set up business-relevant alerts, not just CPU spikes - Automate away the slog using AI Make your controller logs and custom resource statuses a source of clarity, not chaos! Speakers: Cat Morris from  Syntasso, Derik Evangelista from  Syntasso. Location: Building B | Level 5 | Thomas Murphy Ballroom 4. Categories: OBSERVABILITY.",
      "metadata": {
        "title": "From Panic To Peace: Making K8s Controller Observability Suck Less",
        "description": "Your infra runs on K8s, and your controllers and custom resources hum happily. Until they don't. One change later and... UH OH. The logs are a never-ending scroll of problems, dashboards flash like disco lights, and you are knee-deep in debugging hell. You check your custom resources, and they offer no guidance. You eventually fix it, add better error messages, and feel proud. And then it breaks again, with a brand new, even less helpful error. Why is this so hard? In this talk, Derik, a prolific controller-writer, and Cat, a regular listener to DevOps meltdowns, will walk you through tested strategies for making your K8s resources less mysterious and more manageable. You will learn how to: - Add meaningful, traceable errors - Make events and status your best friends - Build dashboards that humans want to use - Set up business-relevant alerts, not just CPU spikes - Automate away the slog using AI Make your controller logs and custom resource statuses a source of clarity, not chaos!",
        "url": "http://kccncna2025.sched.com/event/e8aa1d607cf18b3c4eba116c909c9b01",
        "uid": "e8aa1d607cf18b3c4eba116c909c9b01",
        "start": "2025-11-12T11:45:00-05:00",
        "end": "2025-11-12T12:15:00-05:00",
        "categories": [
          "OBSERVABILITY"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 4"
        },
        "speakers": [
          {
            "name": "Cat Morris",
            "company": " Syntasso"
          },
          {
            "name": "Derik Evangelista",
            "company": " Syntasso"
          }
        ]
      }
    },
    {
      "text": "Running OpenTelemetry on Kubernetes offers immense potential for observability. This session is an introduction to OpenTelemetry for Kubernetes users, providing an analysis of core components, such as Collector receivers and their use cases, types of data collected, key metrics to monitor, and practical log collection approaches. In addition, this session explores various deployment strategies and architectural decisions. The session demonstrates using the OpenTelemetry Collector, Operator, and Helm charts, to achieve effective observability on K8s. Last but not least, it will touch on operational challenges, trade offs, and limitations of running OpenTelemetry at scale. Join us to learn why OpenTelemetry and Kubernetes is all about love! Speakers: Christos Markou from Elastic, Jacob Aronoff from Omlet. Location: Building B | Level 3 | B304-305. Categories: OBSERVABILITY.",
      "metadata": {
        "title": "OTel+K8s= : An Introduction To OpenTelemetry for Kubernetes Users",
        "description": "Running OpenTelemetry on Kubernetes offers immense potential for observability. This session is an introduction to OpenTelemetry for Kubernetes users, providing an analysis of core components, such as Collector receivers and their use cases, types of data collected, key metrics to monitor, and practical log collection approaches. In addition, this session explores various deployment strategies and architectural decisions. The session demonstrates using the OpenTelemetry Collector, Operator, and Helm charts, to achieve effective observability on K8s. Last but not least, it will touch on operational challenges, trade offs, and limitations of running OpenTelemetry at scale. Join us to learn why OpenTelemetry and Kubernetes is all about love!",
        "url": "http://kccncna2025.sched.com/event/f52049918f1ff1eeb5a59c6ad5f549b1",
        "uid": "f52049918f1ff1eeb5a59c6ad5f549b1",
        "start": "2025-11-12T11:45:00-05:00",
        "end": "2025-11-12T12:15:00-05:00",
        "categories": [
          "OBSERVABILITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B304-305"
        },
        "speakers": [
          {
            "name": "Christos Markou",
            "company": "Elastic"
          },
          {
            "name": "Jacob Aronoff",
            "company": "Omlet"
          }
        ]
      }
    },
    {
      "text": "Running stateless workloads like AI inference and video encoding demands significant compute, which can be costly and subject to shortages in a single region. Distributing workloads across regions and cloud providers helps optimize both cost and availability.\n\nThis session explores how multi-cluster scheduling and Karpenter enable dynamic provisioning across preemptible (cost-effective but region-limited) and non-preemptible node VMs. By integrating with cloud providers pricing and availability APIs, we present a unified strategy for cost-efficient scheduling and autoscaling without sacrificing availability. As we scale resources across regions and providers, we ensure traffic gets routed the right way - so your service stays responsive and efficient no matter where the pods are running.\n\nAttendees will learn how to design a resilient, multi-cloud architecture that adapts to fluctuating costs while ensuring seamless workload execution. Speakers: Wei Jiang from  CloudPilot AI, Jingkang Jiang from  CloudPilot AI, Michael McCune from Red Hat, Praseeda Sathaye from Amazon. Location: Building B | Level 4 | B406b-407. Categories: OPERATIONS + PERFORMANCE.",
      "metadata": {
        "title": "Maximizing Global Potential: Cost-Optimized, High-Availability Workloads Across Regions",
        "description": "Running stateless workloads like AI inference and video encoding demands significant compute, which can be costly and subject to shortages in a single region. Distributing workloads across regions and cloud providers helps optimize both cost and availability.\n\nThis session explores how multi-cluster scheduling and Karpenter enable dynamic provisioning across preemptible (cost-effective but region-limited) and non-preemptible node VMs. By integrating with cloud providers pricing and availability APIs, we present a unified strategy for cost-efficient scheduling and autoscaling without sacrificing availability. As we scale resources across regions and providers, we ensure traffic gets routed the right way - so your service stays responsive and efficient no matter where the pods are running.\n\nAttendees will learn how to design a resilient, multi-cloud architecture that adapts to fluctuating costs while ensuring seamless workload execution.",
        "url": "http://kccncna2025.sched.com/event/5272a410749cc289f04a66949e28053e",
        "uid": "5272a410749cc289f04a66949e28053e",
        "start": "2025-11-12T11:45:00-05:00",
        "end": "2025-11-12T12:15:00-05:00",
        "categories": [
          "OPERATIONS + PERFORMANCE"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B406b-407"
        },
        "speakers": [
          {
            "name": "Wei Jiang",
            "company": " CloudPilot AI"
          },
          {
            "name": "Jingkang Jiang",
            "company": " CloudPilot AI"
          },
          {
            "name": "Michael McCune",
            "company": "Red Hat"
          },
          {
            "name": "Praseeda Sathaye",
            "company": "Amazon"
          }
        ]
      }
    },
    {
      "text": "Plot twist: cloud compute isn't the infinitely elastic utility it once seemed! Customers increasingly rely on reservations and sophisticated capacity management to navigate this reality, especially for scarce, specialized hardware like GPUs & TPUs. This demands evolving Kubernetes beyond single clusters to become the \"operating system of the cloud for distributed systems\"what we call \"Ambient Global Compute\". As the engineering director leading OSS K8s at Google, I will share a comprehensive view on how K8s is adapting to orchestrate workloads across non-elastic, global environments. Learn about initiatives supporting this shift & how they fit together to support unified multi-cluster, often multi-cloud, deployments, including: DRA, [Multi-]Kueue, Karpenter/ ComputeClasses, MCO, ArgoCD, & more. This talk equips attendees to understand and leverage Kubernetes' evolution for modern, demanding workloads, and return to a simpler mental model despite growing complexity in infrastructure. Speakers: Jago Macleod from Google. Location: Building B | Level 4 | B405-406a. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "Ambient Global Compute: Orchestrating the Non-Elastic Cloud With Kubernetes",
        "description": "Plot twist: cloud compute isn't the infinitely elastic utility it once seemed! Customers increasingly rely on reservations and sophisticated capacity management to navigate this reality, especially for scarce, specialized hardware like GPUs & TPUs. This demands evolving Kubernetes beyond single clusters to become the \"operating system of the cloud for distributed systems\"what we call \"Ambient Global Compute\". As the engineering director leading OSS K8s at Google, I will share a comprehensive view on how K8s is adapting to orchestrate workloads across non-elastic, global environments. Learn about initiatives supporting this shift & how they fit together to support unified multi-cluster, often multi-cloud, deployments, including: DRA, [Multi-]Kueue, Karpenter/ ComputeClasses, MCO, ArgoCD, & more. This talk equips attendees to understand and leverage Kubernetes' evolution for modern, demanding workloads, and return to a simpler mental model despite growing complexity in infrastructure.",
        "url": "http://kccncna2025.sched.com/event/fc201ae46cf95730754ab2e3339aa6d9",
        "uid": "fc201ae46cf95730754ab2e3339aa6d9",
        "start": "2025-11-12T11:45:00-05:00",
        "end": "2025-11-12T12:15:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B405-406a"
        },
        "speakers": [
          {
            "name": "Jago Macleod",
            "company": "Google"
          }
        ]
      }
    },
    {
      "text": "Spotifys Declarative Infrastructure platform (a Kubernetes-based infrastructure management platform) enables Spotifys developers to manage almost a million infrastructure resources, and enables tens of Platform teams to support first- or third-party resources through the platform. The platform empowers Platform teams to manage all resources of a specific type, like Spotifys Storage team managing all Bigtable instances.\n\nYou may ask, how do those Platform teams plug into the platform to support their specific resources? Depending on their use case, they can mix and match technologies such as KCC (GCP Config Connector), kro (Kube Resource Orchestrator), K-Poperator (an internal Spotify operator framework), and Kubebuilder to meet their needs.\n\nIn this talk youll learn how these platform primitives are used by Spotifys platform teams, how these primitives support Spotifys platform principles, and lessons learned from 5 years of running the platform. Speakers: Oliver Soell from  Spotify, Fredrik Sommar from  Spotify. Location: Building B | Level 3 | B312-314. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "Managing a Million Infra Resources at Spotify: Designing the Platform To Manage Change at Scale",
        "description": "Spotifys Declarative Infrastructure platform (a Kubernetes-based infrastructure management platform) enables Spotifys developers to manage almost a million infrastructure resources, and enables tens of Platform teams to support first- or third-party resources through the platform. The platform empowers Platform teams to manage all resources of a specific type, like Spotifys Storage team managing all Bigtable instances.\n\nYou may ask, how do those Platform teams plug into the platform to support their specific resources? Depending on their use case, they can mix and match technologies such as KCC (GCP Config Connector), kro (Kube Resource Orchestrator), K-Poperator (an internal Spotify operator framework), and Kubebuilder to meet their needs.\n\nIn this talk youll learn how these platform primitives are used by Spotifys platform teams, how these primitives support Spotifys platform principles, and lessons learned from 5 years of running the platform.",
        "url": "http://kccncna2025.sched.com/event/f6a7f883f2e48812b5abed381447396f",
        "uid": "f6a7f883f2e48812b5abed381447396f",
        "start": "2025-11-12T11:45:00-05:00",
        "end": "2025-11-12T12:15:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B312-314"
        },
        "speakers": [
          {
            "name": "Oliver Soell",
            "company": " Spotify"
          },
          {
            "name": "Fredrik Sommar",
            "company": " Spotify"
          }
        ]
      }
    },
    {
      "text": "Post-Quantum Cryptography (PQC) is no longer theoretical. With Go 1.24+ enabling ML-KEM by default, Kubernetes v1.33+ inherits significant quantum resistance for key exchange. This talk dives into the practical realities. We'll briefly cover the current state of PQC standardization, such as ML-KEM (FIPS-203) and then critically examine real-world implications: how K8s \"accidentally\" already benefits from PQC key exchange, the subtle but critical downgrade risks from mismatched Go versions (e.g., Go 1.23's `X25519Kyber768Draft00` vs. 1.24's `X25519MLKEM768`), and the \"tldr.fail\" issue where large PQC key shares can break TLS handshakes due to packet size limits. We'll explore these challenges with evidence from the K8s ecosystem, offering insights for maintainers and advanced users navigating the PQC transition. Speakers: Fabian Kammel from ControlPlane. Location: Building B | Level 3 | B302-303. Categories: SECURITY.",
      "metadata": {
        "title": "Quantum-Resistant Kubernetes: Realities, Risks & (Versioning) Pitfalls",
        "description": "Post-Quantum Cryptography (PQC) is no longer theoretical. With Go 1.24+ enabling ML-KEM by default, Kubernetes v1.33+ inherits significant quantum resistance for key exchange. This talk dives into the practical realities. We'll briefly cover the current state of PQC standardization, such as ML-KEM (FIPS-203) and then critically examine real-world implications: how K8s \"accidentally\" already benefits from PQC key exchange, the subtle but critical downgrade risks from mismatched Go versions (e.g., Go 1.23's `X25519Kyber768Draft00` vs. 1.24's `X25519MLKEM768`), and the \"tldr.fail\" issue where large PQC key shares can break TLS handshakes due to packet size limits. We'll explore these challenges with evidence from the K8s ecosystem, offering insights for maintainers and advanced users navigating the PQC transition.",
        "url": "http://kccncna2025.sched.com/event/18f775687be4e97fd48a0e5eca4a63e4",
        "uid": "18f775687be4e97fd48a0e5eca4a63e4",
        "start": "2025-11-12T11:45:00-05:00",
        "end": "2025-11-12T12:15:00-05:00",
        "categories": [
          "SECURITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B302-303"
        },
        "speakers": [
          {
            "name": "Fabian Kammel",
            "company": "ControlPlane"
          }
        ]
      }
    },
    {
      "text": "Chart your course within the Kubernetes community. This dedicated meet and greet connects you directly with the SIGs and WGs that power the project. Representatives from each group will be here to discuss their charter, current initiatives, and how your skills can make an impact. Whether you're an experienced contributor looking to expand your scope or a new contributor ready to get started, this session will help you find the right team to begin or continue your journey. Location: Building B | Level 2 | B216-217. Categories: EXPERIENCES.",
      "metadata": {
        "title": "Kubernetes SIG/WG Meet + Greet, Lunch and Learn",
        "description": "Chart your course within the Kubernetes community. This dedicated meet and greet connects you directly with the SIGs and WGs that power the project. Representatives from each group will be here to discuss their charter, current initiatives, and how your skills can make an impact. Whether you're an experienced contributor looking to expand your scope or a new contributor ready to get started, this session will help you find the right team to begin or continue your journey.",
        "url": "http://kccncna2025.sched.com/event/aa316c27aa25576c46e529783dcd43b3",
        "uid": "aa316c27aa25576c46e529783dcd43b3",
        "start": "2025-11-12T12:00:00-05:00",
        "end": "2025-11-12T14:30:00-05:00",
        "categories": [
          "EXPERIENCES"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B216-217"
        }
      }
    },
    {
      "text": "Take a paws from your busy day! Join us for a visit with some friendly therapy puppies to help reduce stress and boost your mood. Location: Building B | Level 2 | Willow Garden Foyer. Categories: EXPERIENCES.",
      "metadata": {
        "title": "Pet-a-Pup",
        "description": "Take a paws from your busy day! Join us for a visit with some friendly therapy puppies to help reduce stress and boost your mood.",
        "url": "http://kccncna2025.sched.com/event/49b49877e69ddb2fcd525e50a6d241cf",
        "uid": "49b49877e69ddb2fcd525e50a6d241cf",
        "start": "2025-11-12T12:00:00-05:00",
        "end": "2025-11-12T13:00:00-05:00",
        "categories": [
          "EXPERIENCES"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "Willow Garden Foyer"
        }
      }
    },
    {
      "text": "Location: TBA. Categories: BREAKS.",
      "metadata": {
        "title": "Lunch ",
        "description": "",
        "url": "http://kccncna2025.sched.com/event/b0af2974af8974000c30c433a2aaf83c",
        "uid": "b0af2974af8974000c30c433a2aaf83c",
        "start": "2025-11-12T12:15:00-05:00",
        "end": "2025-11-12T14:15:00-05:00",
        "categories": [
          "BREAKS"
        ],
        "location": {
          "room": "TBA"
        }
      }
    },
    {
      "text": "As GenAI workloads move from prototypes to production, engineering teams hit scaling walls: exploding GPU costs, uneven latency, and bloated, black-box inference stacks. In this live demo, Red Hat will explore these three well-lit paths for scaling LLM inference on Kubernetes using the open-source llm-d framework. Each path addresses a specific challenge in real-world GenAI operations:\nIntelligent Inference Scheduling reduces latency through prefix cacheaware routing and prompt/session stickiness.\n\n\nPrefill/Decode Disaggregation improves GPU efficiency and reduces tail latency by decoupling compute stages.\n\n\nWide Expert Parallelism unlocks the ability to deploy Mixture-of-Experts (MoE) models with high throughput across multiple replicas.\n\n\nThe session will feature a live demonstration of llm-d, deployed with vLLM, Prometheus, and Grafana. Attendees will discover how to disaggregate LLM workloads into composable services and gain actionable insights for implementation on any Kubernetes platform. A key highlight will be a walkthrough of a Mixture-of-Experts (MoE) model configuration, demonstrating llm-d's efficient scheduling of models using expert parallelism across different nodes, leveraging AI accelerators.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.* Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: SOLUTIONS SHOWCASE.",
      "metadata": {
        "title": "Sponsored Demo: Three Well-Lit Paths to Scalable LLM Inference with llm-d on Kubernetes",
        "description": "As GenAI workloads move from prototypes to production, engineering teams hit scaling walls: exploding GPU costs, uneven latency, and bloated, black-box inference stacks. In this live demo, Red Hat will explore these three well-lit paths for scaling LLM inference on Kubernetes using the open-source llm-d framework. Each path addresses a specific challenge in real-world GenAI operations:\nIntelligent Inference Scheduling reduces latency through prefix cacheaware routing and prompt/session stickiness.\n\n\nPrefill/Decode Disaggregation improves GPU efficiency and reduces tail latency by decoupling compute stages.\n\n\nWide Expert Parallelism unlocks the ability to deploy Mixture-of-Experts (MoE) models with high throughput across multiple replicas.\n\n\nThe session will feature a live demonstration of llm-d, deployed with vLLM, Prometheus, and Grafana. Attendees will discover how to disaggregate LLM workloads into composable services and gain actionable insights for implementation on any Kubernetes platform. A key highlight will be a walkthrough of a Mixture-of-Experts (MoE) model configuration, demonstrating llm-d's efficient scheduling of models using expert parallelism across different nodes, leveraging AI accelerators.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.*",
        "url": "http://kccncna2025.sched.com/event/9114ab734fbf372348c2fc3f639de02c",
        "uid": "9114ab734fbf372348c2fc3f639de02c",
        "start": "2025-11-12T12:15:00-05:00",
        "end": "2025-11-12T12:35:00-05:00",
        "categories": [
          "SOLUTIONS SHOWCASE"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "Join us for casual and engaging meetups at the Network Nook during lunch breaks! These informal gatherings are open to all, whether you're a first-time attendee, a solo traveler, or simply looking to chat about shared interests. This is a great way to connect with others.&nbsp;\n\nToday's theme is: Conference Buddies\nMeet other attendees, make new connections, and find a conference buddy to explore sessions and events together! Location: Building B | Level 1 | Solutions Showcase. Categories: EXPERIENCES.",
      "metadata": {
        "title": "Network Nook Meetup: Conference Buddies",
        "description": "Join us for casual and engaging meetups at the Network Nook during lunch breaks! These informal gatherings are open to all, whether you're a first-time attendee, a solo traveler, or simply looking to chat about shared interests. This is a great way to connect with others.&nbsp;\n\nToday's theme is: Conference Buddies\nMeet other attendees, make new connections, and find a conference buddy to explore sessions and events together!",
        "url": "http://kccncna2025.sched.com/event/aa04ce30adeaeec1574c23f81a7fb339",
        "uid": "aa04ce30adeaeec1574c23f81a7fb339",
        "start": "2025-11-12T12:45:00-05:00",
        "end": "2025-11-12T13:45:00-05:00",
        "categories": [
          "EXPERIENCES"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Solutions Showcase"
        }
      }
    },
    {
      "text": "Kubernetes resource management often means choosing between wasted spend and unpredictable performance. In this session, the Global Director of Sales Engineering at ScaleOps will demonstrate how autonomous scaling delivers the right resources at the right time automatically. See how intelligent optimization improves efficiency across CPU, memory, and GPU workloads, including AI-driven environments, without manual tuning or complex configuration.\nAbout ScaleOps: The leading autonomous cloud resource management platform, trusted by enterprises like Salesforce, Wiz, DocuSign, and Coupa. ScaleOps powers thousands of workloads worldwide, ensuring performance, resilience, and cost efficiency at scale.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.* Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: SOLUTIONS SHOWCASE.",
      "metadata": {
        "title": "Sponsored Demo: Smarter Scaling for Kubernetes: Real Time Optimization for Cost and Performance",
        "description": "Kubernetes resource management often means choosing between wasted spend and unpredictable performance. In this session, the Global Director of Sales Engineering at ScaleOps will demonstrate how autonomous scaling delivers the right resources at the right time automatically. See how intelligent optimization improves efficiency across CPU, memory, and GPU workloads, including AI-driven environments, without manual tuning or complex configuration.\nAbout ScaleOps: The leading autonomous cloud resource management platform, trusted by enterprises like Salesforce, Wiz, DocuSign, and Coupa. ScaleOps powers thousands of workloads worldwide, ensuring performance, resilience, and cost efficiency at scale.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.*",
        "url": "http://kccncna2025.sched.com/event/79f9a4c9e8cc9eed914dff589bf20d39",
        "uid": "79f9a4c9e8cc9eed914dff589bf20d39",
        "start": "2025-11-12T12:45:00-05:00",
        "end": "2025-11-12T13:05:00-05:00",
        "categories": [
          "SOLUTIONS SHOWCASE"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "10-Minute Tip Talk Speakers: Hilary Carter from LF Research. Location: Level 1 | Learning Lounge. Categories: EXPERIENCES.",
      "metadata": {
        "title": "Learning Lounge: Ten Minutes, Ten Insights: What LF Research Reveals About Cloud, AI, and Open Source",
        "description": "10-Minute Tip Talk",
        "url": "http://kccncna2025.sched.com/event/c3f0d08bc25ac9c62a0af9944cf8efb9",
        "uid": "c3f0d08bc25ac9c62a0af9944cf8efb9",
        "start": "2025-11-12T13:00:00-05:00",
        "end": "2025-11-12T13:15:00-05:00",
        "categories": [
          "EXPERIENCES"
        ],
        "location": {
          "level": "1",
          "room": "Learning Lounge"
        },
        "speakers": [
          {
            "name": "Hilary Carter",
            "company": "LF Research"
          }
        ]
      }
    },
    {
      "text": "For years, scheduling GPUs in Kubernetes meant one thing: forcing a direct link between your workload and a specific node. Through a brittle web of taints, tolerations, and nodeSelectors, we've been telling our pods where to run, tightly coupling our applications to the physical infrastructure beneath them. This operational model is inefficient, hinders portability, and doesn't scale.\n\nIn this session, you'll see a live demonstration of Dynamic Resource Allocation (DRA), a new Kubernetes standard that fundamentally changes how we orchestrate specialized hardware. We'll show you how to stop targeting nodes and start requesting capabilities. Using a declarative ResourceClaim on GKE to request specific NVIDIA GPU attributes, we can let the Kubernetes scheduler intelligently match your workload with the right hardware anywhere in the cluster. This is the future: a truly portable, flexible, and automated approach to managing high-value resources.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.* Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: SOLUTIONS SHOWCASE.",
      "metadata": {
        "title": "Sponsored Demo: The DRA Paradigm Shift: Request a Capability, Not a Node",
        "description": "For years, scheduling GPUs in Kubernetes meant one thing: forcing a direct link between your workload and a specific node. Through a brittle web of taints, tolerations, and nodeSelectors, we've been telling our pods where to run, tightly coupling our applications to the physical infrastructure beneath them. This operational model is inefficient, hinders portability, and doesn't scale.\n\nIn this session, you'll see a live demonstration of Dynamic Resource Allocation (DRA), a new Kubernetes standard that fundamentally changes how we orchestrate specialized hardware. We'll show you how to stop targeting nodes and start requesting capabilities. Using a declarative ResourceClaim on GKE to request specific NVIDIA GPU attributes, we can let the Kubernetes scheduler intelligently match your workload with the right hardware anywhere in the cluster. This is the future: a truly portable, flexible, and automated approach to managing high-value resources.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.*",
        "url": "http://kccncna2025.sched.com/event/99a0e6ac4731a5f0523c7be6dfa6d701",
        "uid": "99a0e6ac4731a5f0523c7be6dfa6d701",
        "start": "2025-11-12T13:15:00-05:00",
        "end": "2025-11-12T13:35:00-05:00",
        "categories": [
          "SOLUTIONS SHOWCASE"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "Static support bundles capture logs and resource dumps, but they lack the interactivity needed for real analysis. To fully understand a Kubernetes failure, engineers must query the API as it existed during the incident. This talk introduces a technique that turns static bundles into interactive, queryable Kubernetes environments.\n\nWell start with troubleshoot.sh, which creates a diagnostic bundle of the failing cluster. Then well show troubleshoot-live, which ingests that bundle and launches a local Kubernetes API server and etcd instance, rehydrating the cluster state. The result is a high-fidelity, offline replica accessible via kubeconfig with kubectl or any compliant tool. This enables interactive debugging, post-mortem analysis, and automated triage completely offline and without production access.\n\nFinally, we highlight that by replaying real-world failures safely and consistently, teams can train AIOps pipelines, experiment with Retrieval-Augmented Generation (RAG), and develop advanced Agentic Workflows. This capability improves day-2-day troubleshooting while paving the way for next-gen intelligent Kubernetes operations.\n\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.* Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: SOLUTIONS SHOWCASE.",
      "metadata": {
        "title": "Sponsored Demo: Beyond Grep: Interactive, Offline Analysis of Kubernetes Failures",
        "description": "Static support bundles capture logs and resource dumps, but they lack the interactivity needed for real analysis. To fully understand a Kubernetes failure, engineers must query the API as it existed during the incident. This talk introduces a technique that turns static bundles into interactive, queryable Kubernetes environments.\n\nWell start with troubleshoot.sh, which creates a diagnostic bundle of the failing cluster. Then well show troubleshoot-live, which ingests that bundle and launches a local Kubernetes API server and etcd instance, rehydrating the cluster state. The result is a high-fidelity, offline replica accessible via kubeconfig with kubectl or any compliant tool. This enables interactive debugging, post-mortem analysis, and automated triage completely offline and without production access.\n\nFinally, we highlight that by replaying real-world failures safely and consistently, teams can train AIOps pipelines, experiment with Retrieval-Augmented Generation (RAG), and develop advanced Agentic Workflows. This capability improves day-2-day troubleshooting while paving the way for next-gen intelligent Kubernetes operations.\n\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.*",
        "url": "http://kccncna2025.sched.com/event/7d2a2bde5ea69d294973464ea924fde0",
        "uid": "7d2a2bde5ea69d294973464ea924fde0",
        "start": "2025-11-12T13:45:00-05:00",
        "end": "2025-11-12T14:05:00-05:00",
        "categories": [
          "SOLUTIONS SHOWCASE"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "How CNCF members directly fuel the health and growth of the cloud native community. This session goes beyond sponsorship to show how member contributions, addressing financial support to engineering resources which are vital for sustaining core projects, funding security audits, and enabling community programs. Learn about the tangible impact of membership and what an ideal contributing member looks like. You'll leave with a clear understanding of the virtuous cycle that connects membership to community vitality. Location: Building B | Level 1 | Solutions Showcase. Categories: EXPERIENCES.",
      "metadata": {
        "title": "Becoming an Impactful CNCF Member",
        "description": "How CNCF members directly fuel the health and growth of the cloud native community. This session goes beyond sponsorship to show how member contributions, addressing financial support to engineering resources which are vital for sustaining core projects, funding security audits, and enabling community programs. Learn about the tangible impact of membership and what an ideal contributing member looks like. You'll leave with a clear understanding of the virtuous cycle that connects membership to community vitality.",
        "url": "http://kccncna2025.sched.com/event/7b131a1523c6eba496b20add52ed25d8",
        "uid": "7b131a1523c6eba496b20add52ed25d8",
        "start": "2025-11-12T14:00:00-05:00",
        "end": "2025-11-12T14:30:00-05:00",
        "categories": [
          "EXPERIENCES"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Solutions Showcase"
        }
      }
    },
    {
      "text": "Live Security Challenge Speakers: Aleks Jones from LF Education. Location: Level 1 | Learning Lounge. Categories: EXPERIENCES.",
      "metadata": {
        "title": "Learning Lounge: Sensitive Keys in Codebases & Hidden in Layers Contest",
        "description": "Live Security Challenge",
        "url": "http://kccncna2025.sched.com/event/47359517dcf68710725daf7bb6b23b8a",
        "uid": "47359517dcf68710725daf7bb6b23b8a",
        "start": "2025-11-12T14:00:00-05:00",
        "end": "2025-11-12T14:15:00-05:00",
        "categories": [
          "EXPERIENCES"
        ],
        "location": {
          "level": "1",
          "room": "Learning Lounge"
        },
        "speakers": [
          {
            "name": "Aleks Jones",
            "company": "LF Education"
          }
        ]
      }
    },
    {
      "text": "Take a paws from your busy day! Join us for a visit with some friendly therapy puppies to help reduce stress and boost your mood. Location: Building B | Level 2 | Willow Garden Foyer. Categories: EXPERIENCES.",
      "metadata": {
        "title": "Pet-a-Pup",
        "description": "Take a paws from your busy day! Join us for a visit with some friendly therapy puppies to help reduce stress and boost your mood.",
        "url": "http://kccncna2025.sched.com/event/7e52d83ba88e311d2fa4daf13e96b29a",
        "uid": "7e52d83ba88e311d2fa4daf13e96b29a",
        "start": "2025-11-12T14:00:00-05:00",
        "end": "2025-11-12T15:00:00-05:00",
        "categories": [
          "EXPERIENCES"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "Willow Garden Foyer"
        }
      }
    },
    {
      "text": "Serverless ML inference is great but when GPUs are involved, cold starts can turn milliseconds into minutes. Whether scaling transformer models or using custom inference services, the startup latency caused by container initialization, GPU driver loading, and heavyweight model deserialization can kill real-time performance and cost you tons of money. In this talk, we'll break down the anatomy of GPU cold starts in modern ML serving stacks including why GPUs introduce unique cold-path delays, how CRI and device plugins contribute to it, and what really happens when a PyTorch model boot-up on a fresh pod. Well walk through production-ready strategies to reduce startup latency: - Pre-warmed GPU pod pools to bypass init time - Model snapshotting with TorchScript or ONNX to speed up deserialization - Lazy loading techniques that delay model initialization until the first request Thus helping you eliminate cold start pain and keep your services fast, efficient, and production-ready. Speakers: Nikunj Goyal from Adobe, Aditi Gupta from Disney Plus Hotstar. Location: Building B | Level 4 | B401-402. Categories: AI + ML.",
      "metadata": {
        "title": "No More GPU Cold Starts: Making Serverless ML Inference Truly Real-Time",
        "description": "Serverless ML inference is great but when GPUs are involved, cold starts can turn milliseconds into minutes. Whether scaling transformer models or using custom inference services, the startup latency caused by container initialization, GPU driver loading, and heavyweight model deserialization can kill real-time performance and cost you tons of money. In this talk, we'll break down the anatomy of GPU cold starts in modern ML serving stacks including why GPUs introduce unique cold-path delays, how CRI and device plugins contribute to it, and what really happens when a PyTorch model boot-up on a fresh pod. Well walk through production-ready strategies to reduce startup latency: - Pre-warmed GPU pod pools to bypass init time - Model snapshotting with TorchScript or ONNX to speed up deserialization - Lazy loading techniques that delay model initialization until the first request Thus helping you eliminate cold start pain and keep your services fast, efficient, and production-ready.",
        "url": "http://kccncna2025.sched.com/event/af6ab1fb57a2b55a9fd3d17ef6cef626",
        "uid": "af6ab1fb57a2b55a9fd3d17ef6cef626",
        "start": "2025-11-12T14:15:00-05:00",
        "end": "2025-11-12T14:45:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B401-402"
        },
        "speakers": [
          {
            "name": "Nikunj Goyal",
            "company": "Adobe"
          },
          {
            "name": "Aditi Gupta",
            "company": "Disney Plus Hotstar"
          }
        ]
      }
    },
    {
      "text": "Curious about what really moves the needle for GenAI performance on Kubernetes? We put Skyhook, a Kubernetes-native OS package manager, and Kaito, the CNCF Sandbox AI workload operator, through their paces. Running LLaMA, Falcon, and Phi-4 workloads on both single and dual GPU nodes, we tweaked everything from kernel flags and GRUB settings to sysctl values and GPU clock locking.\nThe real breakthrough wasnt in the numbers; it was in the process. We developed a declarative, GitOps-ready workflow that makes infrastructure benchmarking safe, repeatable, and easy to adopt.\nIn this session, well walk you through real benchmark data and Grafana dashboards, share reusable YAML examples for OS and GPU tuning, and introduce a practical A/B testing framework for GenAI. Youll leave with a clear sense of whats actually worth tuning, and what you can safely ignore, when running LLMs on Kubernetes. Speakers: Ishaan Sehgal from Omnara, Brian Lockwood from NVIDIA. Location: Building B | Level 5 | Thomas Murphy Ballroom 1. Categories: AI + ML.",
      "metadata": {
        "title": "Tuning GenAI Workloads on Kubernetes: What Actually Works (and What Doesnt)?",
        "description": "Curious about what really moves the needle for GenAI performance on Kubernetes? We put Skyhook, a Kubernetes-native OS package manager, and Kaito, the CNCF Sandbox AI workload operator, through their paces. Running LLaMA, Falcon, and Phi-4 workloads on both single and dual GPU nodes, we tweaked everything from kernel flags and GRUB settings to sysctl values and GPU clock locking.\nThe real breakthrough wasnt in the numbers; it was in the process. We developed a declarative, GitOps-ready workflow that makes infrastructure benchmarking safe, repeatable, and easy to adopt.\nIn this session, well walk you through real benchmark data and Grafana dashboards, share reusable YAML examples for OS and GPU tuning, and introduce a practical A/B testing framework for GenAI. Youll leave with a clear sense of whats actually worth tuning, and what you can safely ignore, when running LLMs on Kubernetes.",
        "url": "http://kccncna2025.sched.com/event/d1c0f8a344b7bbafad39abfad4c732ed",
        "uid": "d1c0f8a344b7bbafad39abfad4c732ed",
        "start": "2025-11-12T14:15:00-05:00",
        "end": "2025-11-12T14:45:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 1"
        },
        "speakers": [
          {
            "name": "Ishaan Sehgal",
            "company": "Omnara"
          },
          {
            "name": "Brian Lockwood",
            "company": "NVIDIA"
          }
        ]
      }
    },
    {
      "text": "But what about reliability? We heard this question 865 times when staring at 9% CPU utilization. Every time followed by a VM-era horror story or a revenue shield - \"We bring in millions in revenue; we deserve idle resources for peace of mind. This session reveals 9 battle-tested Kubernetes-native strategies that took us from 9% to 50% utilization while IMPROVING reliability. The same directors who predicted catastrophic failure now champion optimization, panic-paging our team if costs regress. Discover practical implementations and pitfalls, such as tuning workload limits, too many pods on nodes, API server pressure, reliable spot nodes, etc. You can selectively adopt and combine these strategies to build your own multi-dimensional cost optimization blueprint, precisely tailored to address the distinct challenges of your platform. Every technique uses open-source CNCF tools, because the most expensive infrastructure isnt compute - it's fear. Speakers: The Multi-Million Dollar Kubernetes Cost Optimization Question - Zain Malik from Exostellar, Nibir Bora from Clean Compute. Location: Building B | Level 3 | B308-309. Categories: CLOUD NATIVE EXPERIENCE.",
      "metadata": {
        "title": "But What About Reliability?",
        "description": "But what about reliability? We heard this question 865 times when staring at 9% CPU utilization. Every time followed by a VM-era horror story or a revenue shield - \"We bring in millions in revenue; we deserve idle resources for peace of mind. This session reveals 9 battle-tested Kubernetes-native strategies that took us from 9% to 50% utilization while IMPROVING reliability. The same directors who predicted catastrophic failure now champion optimization, panic-paging our team if costs regress. Discover practical implementations and pitfalls, such as tuning workload limits, too many pods on nodes, API server pressure, reliable spot nodes, etc. You can selectively adopt and combine these strategies to build your own multi-dimensional cost optimization blueprint, precisely tailored to address the distinct challenges of your platform. Every technique uses open-source CNCF tools, because the most expensive infrastructure isnt compute - it's fear.",
        "url": "http://kccncna2025.sched.com/event/d6efa5f17d89c450a2289d8242c871f4",
        "uid": "d6efa5f17d89c450a2289d8242c871f4",
        "start": "2025-11-12T14:15:00-05:00",
        "end": "2025-11-12T14:45:00-05:00",
        "categories": [
          "CLOUD NATIVE EXPERIENCE"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B308-309"
        },
        "speakers": [
          {
            "name": "The Multi-Million Dollar Kubernetes Cost Optimization Question - Zain Malik",
            "company": "Exostellar"
          },
          {
            "name": "Nibir Bora",
            "company": "Clean Compute"
          }
        ]
      }
    },
    {
      "text": "In the rapidly evolving world of edge computing and AI, developers often struggle to find integrated solutions that span from hardware to application-level inference. This talk presents a full-stack open source approach  built entirely in Rust and running on WebAssembly  that unifies low-cost hardware, firmware, and AI inference servers.\n\nWell walk through how a $20 hardware device can host a local voice assistant capable of voice-to-text, LLM-powered reasoning, and text-to-speech. No cloud dependencies. No black-box APIs.\n\nThe stack is fully open:\n\nFrom the microcontroller firmware,\nTo the Rust-based inference server running in WasmEdge,\nTo the open LLMs driving the assistant.\n\nThis talk will highlight:\n\nHow to deploy fully local LLM pipelines on minimal hardware.\nChallenges of working with small form-factor CPUs and limited memory.\nWhy Rust and Wasm make this architecture secure and composable.\nHow open hardware + software benefits dev communities and product builders. Speakers: Miley Fu from Second State Inc., Saiyam Pathak from LoftLabs. Location: Building B | Level 2 | B206. Categories: EMERGING + ADVANCED.",
      "metadata": {
        "title": "Open Source at the Edge: Hardware, Firmware, and AI Stacks",
        "description": "In the rapidly evolving world of edge computing and AI, developers often struggle to find integrated solutions that span from hardware to application-level inference. This talk presents a full-stack open source approach  built entirely in Rust and running on WebAssembly  that unifies low-cost hardware, firmware, and AI inference servers.\n\nWell walk through how a $20 hardware device can host a local voice assistant capable of voice-to-text, LLM-powered reasoning, and text-to-speech. No cloud dependencies. No black-box APIs.\n\nThe stack is fully open:\n\nFrom the microcontroller firmware,\nTo the Rust-based inference server running in WasmEdge,\nTo the open LLMs driving the assistant.\n\nThis talk will highlight:\n\nHow to deploy fully local LLM pipelines on minimal hardware.\nChallenges of working with small form-factor CPUs and limited memory.\nWhy Rust and Wasm make this architecture secure and composable.\nHow open hardware + software benefits dev communities and product builders.",
        "url": "http://kccncna2025.sched.com/event/b5c3f2edfa11acbf4d4bee520e7f9814",
        "uid": "b5c3f2edfa11acbf4d4bee520e7f9814",
        "start": "2025-11-12T14:15:00-05:00",
        "end": "2025-11-12T14:45:00-05:00",
        "categories": [
          "EMERGING + ADVANCED"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B206"
        },
        "speakers": [
          {
            "name": "Miley Fu",
            "company": "Second State Inc."
          },
          {
            "name": "Saiyam Pathak",
            "company": "LoftLabs"
          }
        ]
      }
    },
    {
      "text": "This session offers a comprehensive overview of recent KEDA news, highlighting new features and integrations designed to simplify Kubernetes autoscaling, as well as discussing upcoming enhancements and future roadmap items.\n\nThe talk will cover practical lessons and best practices drawn from hands-on experiences, addressing key challenges like metrics latency, overloaded infrastructure, and scaling trigger optimization. You will learn effective approaches for managing performance, minimizing scaling delays, and preventing bottlenecks. We will discuss the challenges of using (or misusing?) third-party monitoring and metrics providers for scaling decisions, exploring practical ways to overcome limitations without complex architectural changes.\n\nLearn from our direct experiences about effective strategies, performance optimization techniques, and how to build resilient, cost-optimized autoscaling solutions with KEDA. Speakers: Zbynek Roubalik from  Kedify, Jan Wozniak from  Kedify. Location: Building C | Level 3 | Georgia Ballroom 1. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Efficient Kubernetes Autoscaling: News, Challenges, and Best Practices With KEDA",
        "description": "This session offers a comprehensive overview of recent KEDA news, highlighting new features and integrations designed to simplify Kubernetes autoscaling, as well as discussing upcoming enhancements and future roadmap items.\n\nThe talk will cover practical lessons and best practices drawn from hands-on experiences, addressing key challenges like metrics latency, overloaded infrastructure, and scaling trigger optimization. You will learn effective approaches for managing performance, minimizing scaling delays, and preventing bottlenecks. We will discuss the challenges of using (or misusing?) third-party monitoring and metrics providers for scaling decisions, exploring practical ways to overcome limitations without complex architectural changes.\n\nLearn from our direct experiences about effective strategies, performance optimization techniques, and how to build resilient, cost-optimized autoscaling solutions with KEDA.",
        "url": "http://kccncna2025.sched.com/event/3995e4d43ed69d037ac702473cb825db",
        "uid": "3995e4d43ed69d037ac702473cb825db",
        "start": "2025-11-12T14:15:00-05:00",
        "end": "2025-11-12T14:45:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 1"
        },
        "speakers": [
          {
            "name": "Zbynek Roubalik",
            "company": " Kedify"
          },
          {
            "name": "Jan Wozniak",
            "company": " Kedify"
          }
        ]
      }
    },
    {
      "text": "With 12 million users of the Kubernetes documentation a year, the maintenance of our docs is key. Alongside tech docs principles, Kubernetes utilizes Hugo and Docsy to deliver the best experience for contributors and users. SIG Docs is in the process of aligning with upstream Docsy, doing the work needed to upgrade several versions and adopt the latest features. While a significant amount of groundwork has been laid for this upgrade, preparation is only half the story. Its tempting to overhaul everything at once, but it's imperative to continue delivering docs while the upgrade is in process. During this session, maintainers will cover why upgrading is worthwhile, how weve approached the refactor, and the challenges weve encountered as we push on. Learn how upgrading our docs infrastructure means ensuring were on the latest environment and dependency versions, the constant rebases a refactor requires, and the best practices SIG Docs will pass on when attempting your own upgrade. Speakers: Natali Vlatko from Cisco, Rey Lejano from Red Hat, Divya Mohan from SUSE, Sayak Mukhopadhyay from Gemini Solutions. Location: Building C | Level 3 | Georgia Ballroom 2. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Getting up To Date With Docsy: The Kubernetes Docs Upgrade in Progress",
        "description": "With 12 million users of the Kubernetes documentation a year, the maintenance of our docs is key. Alongside tech docs principles, Kubernetes utilizes Hugo and Docsy to deliver the best experience for contributors and users. SIG Docs is in the process of aligning with upstream Docsy, doing the work needed to upgrade several versions and adopt the latest features. While a significant amount of groundwork has been laid for this upgrade, preparation is only half the story. Its tempting to overhaul everything at once, but it's imperative to continue delivering docs while the upgrade is in process. During this session, maintainers will cover why upgrading is worthwhile, how weve approached the refactor, and the challenges weve encountered as we push on. Learn how upgrading our docs infrastructure means ensuring were on the latest environment and dependency versions, the constant rebases a refactor requires, and the best practices SIG Docs will pass on when attempting your own upgrade.",
        "url": "http://kccncna2025.sched.com/event/ac9f7df10cb0f180cc8bef46917063bb",
        "uid": "ac9f7df10cb0f180cc8bef46917063bb",
        "start": "2025-11-12T14:15:00-05:00",
        "end": "2025-11-12T14:45:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 2"
        },
        "speakers": [
          {
            "name": "Natali Vlatko",
            "company": "Cisco"
          },
          {
            "name": "Rey Lejano",
            "company": "Red Hat"
          },
          {
            "name": "Divya Mohan",
            "company": "SUSE"
          },
          {
            "name": "Sayak Mukhopadhyay",
            "company": "Gemini Solutions"
          }
        ]
      }
    },
    {
      "text": "Large model inference is evolving rapidly: model or expert parallelism, prefill/decode disaggregation, multi-lora and kv cache offloading push the limits of traditional serving. As infrastructure teams, we must decide  what belongs in Kubernetes core primitives vs engines vs ecosystem projects? In this session, WG-Serving chairs and industry leaders will share real-world lessons on managing these blurry boundaries. Well discuss how to evaluate new patterns, balance control vs observability, and adapt infrastructure to stay ahead in this dynamic landscape. Attendees will gain practical frameworks to decide when to extend Kubernetes vs offload to runtimes, and insights into top emerging demands from large-scale LLM workloads. Speakers: Jiaxin Shan from Bytedance, Yuan Tang from Red Hat, Sergey Kanzhelev from Google, Rita Zhang from Microsoft. Location: Building C | Level 1 | C111-112. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Navigating the Rapid Evolution of Large Model Inference: Where Does Kubernetes Fit?",
        "description": "Large model inference is evolving rapidly: model or expert parallelism, prefill/decode disaggregation, multi-lora and kv cache offloading push the limits of traditional serving. As infrastructure teams, we must decide  what belongs in Kubernetes core primitives vs engines vs ecosystem projects? In this session, WG-Serving chairs and industry leaders will share real-world lessons on managing these blurry boundaries. Well discuss how to evaluate new patterns, balance control vs observability, and adapt infrastructure to stay ahead in this dynamic landscape. Attendees will gain practical frameworks to decide when to extend Kubernetes vs offload to runtimes, and insights into top emerging demands from large-scale LLM workloads.",
        "url": "http://kccncna2025.sched.com/event/78d5d395663b8714d4d829be22a256cd",
        "uid": "78d5d395663b8714d4d829be22a256cd",
        "start": "2025-11-12T14:15:00-05:00",
        "end": "2025-11-12T14:45:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "1",
          "room": "C111-112"
        },
        "speakers": [
          {
            "name": "Jiaxin Shan",
            "company": "Bytedance"
          },
          {
            "name": "Yuan Tang",
            "company": "Red Hat"
          },
          {
            "name": "Sergey Kanzhelev",
            "company": "Google"
          },
          {
            "name": "Rita Zhang",
            "company": "Microsoft"
          }
        ]
      }
    },
    {
      "text": "Vitess powers some of the worlds largest production MySQL databases. In this session, well take you under the hood of Vitess to explore how its engineered to deliver scalability, performance, and resilience in distributed environments.\n\nWell walk through key internal components and show how they work together to manage sharded, multi-tenant, and geo-distributed workloads.\n\nThis talk is designed for contributors, operators, and advanced users who want to understand Vitess beyond the basics. Well share real-world lessons from operating Vitess at scale, recent performance improvements, and upcoming roadmap features. Whether youre looking to contribute to the project or deepen your understanding of its internals, this session will equip you with the architectural insights needed to reason about Vitess in production. Speakers: Harshit Gangal from  PlanetScale, Andres Taylor from  PlanetScale. Location: Building C | Level 3 | Georgia Ballroom 3. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Under the Hood of Vitess: Database Engineered for Scale and Resilience",
        "description": "Vitess powers some of the worlds largest production MySQL databases. In this session, well take you under the hood of Vitess to explore how its engineered to deliver scalability, performance, and resilience in distributed environments.\n\nWell walk through key internal components and show how they work together to manage sharded, multi-tenant, and geo-distributed workloads.\n\nThis talk is designed for contributors, operators, and advanced users who want to understand Vitess beyond the basics. Well share real-world lessons from operating Vitess at scale, recent performance improvements, and upcoming roadmap features. Whether youre looking to contribute to the project or deepen your understanding of its internals, this session will equip you with the architectural insights needed to reason about Vitess in production.",
        "url": "http://kccncna2025.sched.com/event/d7736be7a1d73327951a5bd43f8b3c34",
        "uid": "d7736be7a1d73327951a5bd43f8b3c34",
        "start": "2025-11-12T14:15:00-05:00",
        "end": "2025-11-12T14:45:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 3"
        },
        "speakers": [
          {
            "name": "Harshit Gangal",
            "company": " PlanetScale"
          },
          {
            "name": "Andres Taylor",
            "company": " PlanetScale"
          }
        ]
      }
    },
    {
      "text": "Observability is everywhere, but understanding where to focus can be overwhelming. As platform teams build internal developer platforms and self-service capabilities, observability must evolve from a sea of dashboards to something far more strategic: actionable insights that support performance, reliability, and developer productivity.\nThis panel brings together a lineup of observability and platform engineering leadersto share candid stories and hard-won lessons from end-user organizations like E.ON and Intuit. Together, theyll break down the many layers of observability from telemetry pipelines and OpenTelemetry adoption to aligning SLOs with business goals and embedding observability directly into developer workflows.\nWell also explore how teams are leveraging AI to reduce MTTR and turn noisy signals into clear, actionable intelligence, all while keeping costs in check. This conversation will offer guidance and help you rethink what good observability really looks like. Speakers: Danielle Cook from Independent, Whitney Lee from Datadog, Stevie Caldwell from Fairwinds, Khallai Taylor from E.ON Digital Technology GmbH, Payal Bagga from Intuit. Location: Building B | Level 3 | B312-314. Categories: OBSERVABILITY.",
      "metadata": {
        "title": "Beyond the Dashboard: Modern Observability for Platform Engineering at Scale",
        "description": "Observability is everywhere, but understanding where to focus can be overwhelming. As platform teams build internal developer platforms and self-service capabilities, observability must evolve from a sea of dashboards to something far more strategic: actionable insights that support performance, reliability, and developer productivity.\nThis panel brings together a lineup of observability and platform engineering leadersto share candid stories and hard-won lessons from end-user organizations like E.ON and Intuit. Together, theyll break down the many layers of observability from telemetry pipelines and OpenTelemetry adoption to aligning SLOs with business goals and embedding observability directly into developer workflows.\nWell also explore how teams are leveraging AI to reduce MTTR and turn noisy signals into clear, actionable intelligence, all while keeping costs in check. This conversation will offer guidance and help you rethink what good observability really looks like.",
        "url": "http://kccncna2025.sched.com/event/d967ed969ecc861c6d3811b245d16e8e",
        "uid": "d967ed969ecc861c6d3811b245d16e8e",
        "start": "2025-11-12T14:15:00-05:00",
        "end": "2025-11-12T14:45:00-05:00",
        "categories": [
          "OBSERVABILITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B312-314"
        },
        "speakers": [
          {
            "name": "Danielle Cook",
            "company": "Independent"
          },
          {
            "name": "Whitney Lee",
            "company": "Datadog"
          },
          {
            "name": "Stevie Caldwell",
            "company": "Fairwinds"
          },
          {
            "name": "Khallai Taylor",
            "company": "E.ON Digital Technology GmbH"
          },
          {
            "name": "Payal Bagga",
            "company": "Intuit"
          }
        ]
      }
    },
    {
      "text": "Prometheus and OpenTelemetry are two CNCF projects that focus on observability and truly excel at their main purposes. However, it's no secret that they started their integration journey on the wrong foot. This story is getting better over time and being done in a data-driven way! Through CNCF's LFX mentorship program, Victoria and Amy conducted UX Research to understand how Prometheus should handle OTel's Resource attributes. Using quantitative and qualitative approaches, they collected opinions from co-founders of both projects, active and old maintainers, and several end-users. By joining this talk, the audience will learn more about what is going well and what could be improved, while listening to Victoria and Amy's educated suggestions for the project maintainers. Speakers: Victoria Nduka from Independent, Amy Super from Grafana Labs. Location: Building B | Level 3 | B304-305. Categories: OBSERVABILITY.",
      "metadata": {
        "title": "UX Research Report: Prometheus and OTel's Resource Attributes.",
        "description": "Prometheus and OpenTelemetry are two CNCF projects that focus on observability and truly excel at their main purposes. However, it's no secret that they started their integration journey on the wrong foot. This story is getting better over time and being done in a data-driven way! Through CNCF's LFX mentorship program, Victoria and Amy conducted UX Research to understand how Prometheus should handle OTel's Resource attributes. Using quantitative and qualitative approaches, they collected opinions from co-founders of both projects, active and old maintainers, and several end-users. By joining this talk, the audience will learn more about what is going well and what could be improved, while listening to Victoria and Amy's educated suggestions for the project maintainers.",
        "url": "http://kccncna2025.sched.com/event/65d18cfbfa7893954a940a4e317356dc",
        "uid": "65d18cfbfa7893954a940a4e317356dc",
        "start": "2025-11-12T14:15:00-05:00",
        "end": "2025-11-12T14:45:00-05:00",
        "categories": [
          "OBSERVABILITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B304-305"
        },
        "speakers": [
          {
            "name": "Victoria Nduka",
            "company": "Independent"
          },
          {
            "name": "Amy Super",
            "company": "Grafana Labs"
          }
        ]
      }
    },
    {
      "text": "As platform engineering has experienced a surge in interest and popularity, some anti-patterns have started to emerge. If not dealt with these situations can fester and unravel the benefits of internal platforms. Recognize any of these situations? - The dumping ground: Hey, you do ops, right? Here, take over my app. - Fixing the world: We're being crushed under an inverted testing pyramid but we want the platform to fix our problems. - The kitchen sink: Hey, this new XYZ thing (probably AI) would make a great re-usable service! Scenarios like these are best dealt with by avoiding them altogether and we'll go over recognition and prevention. If you've already found yourself in the hole, we'll also talk about some things you can do to dig your way out. Speakers: David Stenglein from Missing Mass, LLC. Location: Building B | Level 4 | B405-406a. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "Anti Patterns for Platform Teams (number 3 Will Surprise You!)",
        "description": "As platform engineering has experienced a surge in interest and popularity, some anti-patterns have started to emerge. If not dealt with these situations can fester and unravel the benefits of internal platforms. Recognize any of these situations? - The dumping ground: Hey, you do ops, right? Here, take over my app. - Fixing the world: We're being crushed under an inverted testing pyramid but we want the platform to fix our problems. - The kitchen sink: Hey, this new XYZ thing (probably AI) would make a great re-usable service! Scenarios like these are best dealt with by avoiding them altogether and we'll go over recognition and prevention. If you've already found yourself in the hole, we'll also talk about some things you can do to dig your way out.",
        "url": "http://kccncna2025.sched.com/event/ca2c51dd20508101c7cfd5c77840594b",
        "uid": "ca2c51dd20508101c7cfd5c77840594b",
        "start": "2025-11-12T14:15:00-05:00",
        "end": "2025-11-12T14:45:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B405-406a"
        },
        "speakers": [
          {
            "name": "David Stenglein",
            "company": "Missing Mass, LLC"
          }
        ]
      }
    },
    {
      "text": "As organizations adopt cloud-native technologies, they often find themselves managing multiple platforms, including internal developer platforms and SaaS providers. This fragmentation creates challenges for developers and SREs, who must navigate disparate systems and tools to perform routine tasks.\n\nThis talk explores how to harmonize your platform domain by leveraging Kubernetes and Custom Resource Definitions (CRDs). CRDs allow you to extend the Kubernetes API to define and manage custom objects, representing your specific platform domain concepts.\n\nWe'll discuss the benefits of this approach, including streamlined developer workflows and increased platform adoption. We'll also address potential challenges, such as API exposure and operator sprawl, and offer strategies for overcoming them. By the end of this talk, you'll have a clear understanding of how to leverage Kubernetes and CRDs to create a cohesive and harmonious platform domain. Speakers: Sebastien Blanc from Port. Location: Building B | Level 4 | B406b-407. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "Harmonizing Your Platform Domain With Kubernetes and Custom Resource Definitions",
        "description": "As organizations adopt cloud-native technologies, they often find themselves managing multiple platforms, including internal developer platforms and SaaS providers. This fragmentation creates challenges for developers and SREs, who must navigate disparate systems and tools to perform routine tasks.\n\nThis talk explores how to harmonize your platform domain by leveraging Kubernetes and Custom Resource Definitions (CRDs). CRDs allow you to extend the Kubernetes API to define and manage custom objects, representing your specific platform domain concepts.\n\nWe'll discuss the benefits of this approach, including streamlined developer workflows and increased platform adoption. We'll also address potential challenges, such as API exposure and operator sprawl, and offer strategies for overcoming them. By the end of this talk, you'll have a clear understanding of how to leverage Kubernetes and CRDs to create a cohesive and harmonious platform domain.",
        "url": "http://kccncna2025.sched.com/event/a43afd010690e482ab613b9d1d5e5cfa",
        "uid": "a43afd010690e482ab613b9d1d5e5cfa",
        "start": "2025-11-12T14:15:00-05:00",
        "end": "2025-11-12T14:45:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B406b-407"
        },
        "speakers": [
          {
            "name": "Sebastien Blanc",
            "company": "Port"
          }
        ]
      }
    },
    {
      "text": "Netflix runs large, multi-tenant Kubernetes clusters that power the company's compute infrastructure across streaming services and batch workloads. In this talk, we share lessons from managing these fleets while building a resilient and cost-efficient capacity management system at cloud scale. We explain how a federated cellular structure to share resources across teams, how we treat latency-sensitive services and throughput-heavy batch jobs, and how we organize hardware into managed pools of nodes across a variety of users. We cover our soft capacity reservations that monitor real-time demand with shared buffers to support traffic spikes, our extended disruption budgets that use health signals to limit service impact, and our automated scaling, and predictive resizing that reduce cost. Finally, we show how unused capacity is filled with preemptible, low-priority workloads to reduce waste. Throughout all of this we will discuss what has and hasn't worked along the way. Speakers: Charles Zheng from  Netflix, Nick Parker from  Netflix. Location: Building B | Level 5 | Thomas Murphy Ballroom 4. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "Managing Netflixs Compute Infrastructure With Kubernetes and Dynamic Capacity Management",
        "description": "Netflix runs large, multi-tenant Kubernetes clusters that power the company's compute infrastructure across streaming services and batch workloads. In this talk, we share lessons from managing these fleets while building a resilient and cost-efficient capacity management system at cloud scale. We explain how a federated cellular structure to share resources across teams, how we treat latency-sensitive services and throughput-heavy batch jobs, and how we organize hardware into managed pools of nodes across a variety of users. We cover our soft capacity reservations that monitor real-time demand with shared buffers to support traffic spikes, our extended disruption budgets that use health signals to limit service impact, and our automated scaling, and predictive resizing that reduce cost. Finally, we show how unused capacity is filled with preemptible, low-priority workloads to reduce waste. Throughout all of this we will discuss what has and hasn't worked along the way.",
        "url": "http://kccncna2025.sched.com/event/6b0df02bb1a8d9fb364bd2f307bcc6cb",
        "uid": "6b0df02bb1a8d9fb364bd2f307bcc6cb",
        "start": "2025-11-12T14:15:00-05:00",
        "end": "2025-11-12T14:45:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 4"
        },
        "speakers": [
          {
            "name": "Charles Zheng",
            "company": " Netflix"
          },
          {
            "name": "Nick Parker",
            "company": " Netflix"
          }
        ]
      }
    },
    {
      "text": "What if learning Kubernetes security could be thrilling, practical - and a little chaotic? In this interactive session, we stage a live attacker-versus-defender \"chess match\" inside a Kubernetes cluster. One speaker plays the role of a determined attacker, exploiting common misconfigurations, privilege escalations, and overly permissive RBAC. The other, a vigilant defender, responds with best-practice mitigations and live troubleshooting. You'll watch a Kubernetes environment come under siege - and see how thoughtful, layered defenses can stop even persistent attackers in their tracks. Expect live demos, sharp insights, and just enough chaos to keep it real. We'll cover escalating security scenarios, from pod privilege abuse to namespace isolation, resource quotas and Admission Webhooks, showing not just what to do, but why it matters. This isn't theory-it's security by example, performed live. Speakers: Lucy Sweet from Uber, Sandeep Kanabar from Gen. Location: Building B | Level 3 | B302-303. Categories: SECURITY.",
      "metadata": {
        "title": "Red Vs. Blue: A Live Attacker-Defender Showdown in Kubernetes Security",
        "description": "What if learning Kubernetes security could be thrilling, practical - and a little chaotic? In this interactive session, we stage a live attacker-versus-defender \"chess match\" inside a Kubernetes cluster. One speaker plays the role of a determined attacker, exploiting common misconfigurations, privilege escalations, and overly permissive RBAC. The other, a vigilant defender, responds with best-practice mitigations and live troubleshooting. You'll watch a Kubernetes environment come under siege - and see how thoughtful, layered defenses can stop even persistent attackers in their tracks. Expect live demos, sharp insights, and just enough chaos to keep it real. We'll cover escalating security scenarios, from pod privilege abuse to namespace isolation, resource quotas and Admission Webhooks, showing not just what to do, but why it matters. This isn't theory-it's security by example, performed live.",
        "url": "http://kccncna2025.sched.com/event/06240bf0211e12d819661750a01cee98",
        "uid": "06240bf0211e12d819661750a01cee98",
        "start": "2025-11-12T14:15:00-05:00",
        "end": "2025-11-12T14:45:00-05:00",
        "categories": [
          "SECURITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B302-303"
        },
        "speakers": [
          {
            "name": "Lucy Sweet",
            "company": "Uber"
          },
          {
            "name": "Sandeep Kanabar",
            "company": "Gen"
          }
        ]
      }
    },
    {
      "text": "Troubleshooting Kubernetes shouldnt require hopping across dashboards, logs, and docs. With open-source tools like HolmesGPT and the Model Context Protocol (MCP) server, you can now bring an agentic experience directly into your CLI. In this demo, well show how this OSS stack can run everywhere, from lightweight kind clusters on your laptop to production-grade clusters at scale. The experience supports any LLM provider: in-cluster, local, or cloud, ensuring data never leaves your environment and costs remain predictable. We will showcase how users can ask natural-language questions (e.g., why is my pod Pending?) and get grounded reasoning, targeted diagnostics, and safe, human-in-the-loop remediation steps -- all without leaving the terminal. Whether youre experimenting locally or running mission-critical workloads, youll walk away knowing how to extend these OSS components to build your own agentic workflows in Kubernetes.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.* Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: SOLUTIONS SHOWCASE.",
      "metadata": {
        "title": "Sponsored Demo: HolmesGPT: Agentic K8s troubleshooting in your terminal",
        "description": "Troubleshooting Kubernetes shouldnt require hopping across dashboards, logs, and docs. With open-source tools like HolmesGPT and the Model Context Protocol (MCP) server, you can now bring an agentic experience directly into your CLI. In this demo, well show how this OSS stack can run everywhere, from lightweight kind clusters on your laptop to production-grade clusters at scale. The experience supports any LLM provider: in-cluster, local, or cloud, ensuring data never leaves your environment and costs remain predictable. We will showcase how users can ask natural-language questions (e.g., why is my pod Pending?) and get grounded reasoning, targeted diagnostics, and safe, human-in-the-loop remediation steps -- all without leaving the terminal. Whether youre experimenting locally or running mission-critical workloads, youll walk away knowing how to extend these OSS components to build your own agentic workflows in Kubernetes.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.*",
        "url": "http://kccncna2025.sched.com/event/ab601688aca07e6def51b7bcab84a3f6",
        "uid": "ab601688aca07e6def51b7bcab84a3f6",
        "start": "2025-11-12T14:15:00-05:00",
        "end": "2025-11-12T14:35:00-05:00",
        "categories": [
          "SOLUTIONS SHOWCASE"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "Help drive k8gb toward CNCF Incubation! In this hands-on Contribfest, well simplify core components and prepare k8gb for broader adoption. Youll work on real open issues focused on modularizing the control loop, improving testability, and refactoring strategy logic. Well also explore how to externalize zone delegation to support dynamic, provider-agnostic configurations across clustersan essential capability for real-world global failover setups. Whether you're an experienced Go developer or a newcomer eager to get involved, well guide you through setting up a multi-cluster local testbed and submitting your first PR. Your contributions will directly advance k8gbs architecture, quality, and readiness for the next phase in the CNCF ecosystem. Speakers: Yury Tsarev from Upbound, Andre Aguas from Accenture. Location: Building B | Level 2 | B208. Categories:  CONTRIBFEST.",
      "metadata": {
        "title": "Contribfest: Contribute To K8gbs Journey Toward CNCF Incubation",
        "description": "Help drive k8gb toward CNCF Incubation! In this hands-on Contribfest, well simplify core components and prepare k8gb for broader adoption. Youll work on real open issues focused on modularizing the control loop, improving testability, and refactoring strategy logic. Well also explore how to externalize zone delegation to support dynamic, provider-agnostic configurations across clustersan essential capability for real-world global failover setups. Whether you're an experienced Go developer or a newcomer eager to get involved, well guide you through setting up a multi-cluster local testbed and submitting your first PR. Your contributions will directly advance k8gbs architecture, quality, and readiness for the next phase in the CNCF ecosystem.",
        "url": "http://kccncna2025.sched.com/event/2e6c4c5ad3da7d7ad62881706315907f",
        "uid": "2e6c4c5ad3da7d7ad62881706315907f",
        "start": "2025-11-12T14:15:00-05:00",
        "end": "2025-11-12T15:30:00-05:00",
        "categories": [
          " CONTRIBFEST"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B208"
        },
        "speakers": [
          {
            "name": "Yury Tsarev",
            "company": "Upbound"
          },
          {
            "name": "Andre Aguas",
            "company": "Accenture"
          }
        ]
      }
    },
    {
      "text": "Join Helm maintainers for an interactive session contributing to core Helm and building integrations with some of Helm 4's emerging features. We'll guide contributors through creating Helm 4's newest enhancements including WebAssembly plugins, enhancements to how OCI content is manged, and implementing resource sequencing for controlled deployment order. Attendees will explore how to build Download/Postrender/CLI plugins in WebAssembly, develop capabilities related to changes to Helm's management of OCI content including repository prefixes and aliases, and use approaches for sequencing chart deployments beyond Helm's traditional mechanisms.\n\nThis session is geared toward anyone interested in Helm development including leveraging and building upon some of the latest features associated with Helm 4! Speakers: Andrew Block from Red Hat, Scott Rigby from Replicated, George Jenkins from Bloomberg. Location: Building B | Level 2 | B207. Categories:  CONTRIBFEST.",
      "metadata": {
        "title": "Contribfest: Hands-On With Helm 4: Wasm Plugins, OCI, and Resource Sequencing. Oh My!",
        "description": "Join Helm maintainers for an interactive session contributing to core Helm and building integrations with some of Helm 4's emerging features. We'll guide contributors through creating Helm 4's newest enhancements including WebAssembly plugins, enhancements to how OCI content is manged, and implementing resource sequencing for controlled deployment order. Attendees will explore how to build Download/Postrender/CLI plugins in WebAssembly, develop capabilities related to changes to Helm's management of OCI content including repository prefixes and aliases, and use approaches for sequencing chart deployments beyond Helm's traditional mechanisms.\n\nThis session is geared toward anyone interested in Helm development including leveraging and building upon some of the latest features associated with Helm 4!",
        "url": "http://kccncna2025.sched.com/event/e5d08b225667d7ff5bc484804c28181a",
        "uid": "e5d08b225667d7ff5bc484804c28181a",
        "start": "2025-11-12T14:15:00-05:00",
        "end": "2025-11-12T15:30:00-05:00",
        "categories": [
          " CONTRIBFEST"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B207"
        },
        "speakers": [
          {
            "name": "Andrew Block",
            "company": "Red Hat"
          },
          {
            "name": "Scott Rigby",
            "company": "Replicated"
          },
          {
            "name": "George Jenkins",
            "company": "Bloomberg"
          }
        ]
      }
    },
    {
      "text": "How do you test the resilience of your environment without risking an outage? Stress testing is often a one-time pre-production task, immediately forgotten due to the complexity of keeping it current. In this tutorial, well show how to automate stress testing using AI to adapt to your ever-changing Kubernetes environment. Attendees will learn to deploy a repeatable, low-effort system using Kagent and Kgateway as the human-friendly control plane, Fortio for load generation, and Istio Ambient Mesh for enhanced observability. Think of it as your eager assistant continuously probing your system until cracks appear. You'll leave with a working knowledge of how to setup and run the tools to create intelligent, production-grade stress tests anytime. Speakers: James Ilse from Solo.io. Location: Building B | Level 5 | Thomas Murphy Ballroom 2-3. Categories:  TUTORIALS.",
      "metadata": {
        "title": "Tutorial: Intelligent Failure: Using AI To Push Your Cluster To the Brink",
        "description": "How do you test the resilience of your environment without risking an outage? Stress testing is often a one-time pre-production task, immediately forgotten due to the complexity of keeping it current. In this tutorial, well show how to automate stress testing using AI to adapt to your ever-changing Kubernetes environment. Attendees will learn to deploy a repeatable, low-effort system using Kagent and Kgateway as the human-friendly control plane, Fortio for load generation, and Istio Ambient Mesh for enhanced observability. Think of it as your eager assistant continuously probing your system until cracks appear. You'll leave with a working knowledge of how to setup and run the tools to create intelligent, production-grade stress tests anytime.",
        "url": "http://kccncna2025.sched.com/event/1b2914f0eb8188c961734d0d40183f3d",
        "uid": "1b2914f0eb8188c961734d0d40183f3d",
        "start": "2025-11-12T14:15:00-05:00",
        "end": "2025-11-12T15:30:00-05:00",
        "categories": [
          " TUTORIALS"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 2-3"
        },
        "speakers": [
          {
            "name": "James Ilse",
            "company": "Solo.io"
          }
        ]
      }
    },
    {
      "text": "Do you really need a custom framework to build AI agents? Many teams invest in bespoke planning loops, tool registries, and orchestration layers. You may already have everything you need.\n\nCoding agents like Claude Code, Cursor, and Codex were designed to write software, but code itself is the universal language of infrastructure. This talk shows how we built an agent harness around Claude Code to go beyond coding tasks into SRE workflows, security operations, and infrastructure management.\n\nWell cover:\n\n* Why coding agents double as powerful sysadmins and operators\n* The architecture of our production-ready agent harness\n* Examples of applications from on-call to incident response\n* A live demo of Heroku Garden, our vibe-coding interface powered by this system\n\nLearn how to leverage existing coding agents instead of reinventing frameworks and see a production agent in action.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.* Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: SOLUTIONS SHOWCASE.",
      "metadata": {
        "title": "Sponsored Demo: Coding Agents Are The Only Agent Framework You Need",
        "description": "Do you really need a custom framework to build AI agents? Many teams invest in bespoke planning loops, tool registries, and orchestration layers. You may already have everything you need.\n\nCoding agents like Claude Code, Cursor, and Codex were designed to write software, but code itself is the universal language of infrastructure. This talk shows how we built an agent harness around Claude Code to go beyond coding tasks into SRE workflows, security operations, and infrastructure management.\n\nWell cover:\n\n* Why coding agents double as powerful sysadmins and operators\n* The architecture of our production-ready agent harness\n* Examples of applications from on-call to incident response\n* A live demo of Heroku Garden, our vibe-coding interface powered by this system\n\nLearn how to leverage existing coding agents instead of reinventing frameworks and see a production agent in action.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.*",
        "url": "http://kccncna2025.sched.com/event/b835c6b5a9fa59dbf18a5c0c6dfe6199",
        "uid": "b835c6b5a9fa59dbf18a5c0c6dfe6199",
        "start": "2025-11-12T14:45:00-05:00",
        "end": "2025-11-12T15:05:00-05:00",
        "categories": [
          "SOLUTIONS SHOWCASE"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "AI/ML pipelines generate millions of diverse, resource-hungry batch jobsGPU bursts for training or CPU and memory-intensive preprocessingthat push single-cluster schedulers beyond ETCD scalability limits and single-region failure domains.\n\nMulti-cluster batch schedulers federate Kubernetes clusters to dynamically extend capacity across on-prem and cloud environments, isolate tenants, and survive zone outages.\n\nIn a multi-cluster context, preemption must be coordinated globally to reclaim capacity where its most needed without starving distant workloads. Fair-share depends on quota enforcement so every team gets its entitled slice of compute. Gang scheduling reserves resources across clusters and only releases them when all parts of a multi-node job are ready to launch simultaneously.\n\nThis deep dive will explore how multi-cluster schedulers implement core batch scheduling features across federated Kubernetes clusters and their architectures. Speakers: Dejan Pejchev from  G-Research, Priyanka Ravi from  G-Research. Location: Building B | Level 4 | B401-402. Categories: AI + ML.",
      "metadata": {
        "title": "Multi-Cluster Wars: The Scheduler Awakens",
        "description": "AI/ML pipelines generate millions of diverse, resource-hungry batch jobsGPU bursts for training or CPU and memory-intensive preprocessingthat push single-cluster schedulers beyond ETCD scalability limits and single-region failure domains.\n\nMulti-cluster batch schedulers federate Kubernetes clusters to dynamically extend capacity across on-prem and cloud environments, isolate tenants, and survive zone outages.\n\nIn a multi-cluster context, preemption must be coordinated globally to reclaim capacity where its most needed without starving distant workloads. Fair-share depends on quota enforcement so every team gets its entitled slice of compute. Gang scheduling reserves resources across clusters and only releases them when all parts of a multi-node job are ready to launch simultaneously.\n\nThis deep dive will explore how multi-cluster schedulers implement core batch scheduling features across federated Kubernetes clusters and their architectures.",
        "url": "http://kccncna2025.sched.com/event/bbe3288995b520d14860af1adff891cc",
        "uid": "bbe3288995b520d14860af1adff891cc",
        "start": "2025-11-12T15:00:00-05:00",
        "end": "2025-11-12T15:30:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B401-402"
        },
        "speakers": [
          {
            "name": "Dejan Pejchev",
            "company": " G-Research"
          },
          {
            "name": "Priyanka Ravi",
            "company": " G-Research"
          }
        ]
      }
    },
    {
      "text": "What happens when your AI model gets hacked before it even runs? The culprit: a fragile AI/ML supply chain, vulnerable to data poisoning, model tampering, and rogue dependencies. These threats can silently wreck trust in your Kubernetes workloads. In this session, well dissect the AI/ML supply chain lifecycle, explore its evolving threat landscape, and understand practical security measures. By the end of this talk, attendees will walk away with actionable insights around SBOMs, model cards, and tools to ensure the transparency and integrity of your model within their Kubernetes environments. Speakers: Yash Pimple from Chainguard. Location: Building B | Level 5 | Thomas Murphy Ballroom 1. Categories: AI + ML.",
      "metadata": {
        "title": "The Hidden Risks in AI/ML Supply Chains: How To Secure Your Workloads",
        "description": "What happens when your AI model gets hacked before it even runs? The culprit: a fragile AI/ML supply chain, vulnerable to data poisoning, model tampering, and rogue dependencies. These threats can silently wreck trust in your Kubernetes workloads. In this session, well dissect the AI/ML supply chain lifecycle, explore its evolving threat landscape, and understand practical security measures. By the end of this talk, attendees will walk away with actionable insights around SBOMs, model cards, and tools to ensure the transparency and integrity of your model within their Kubernetes environments.",
        "url": "http://kccncna2025.sched.com/event/178cb7405a01e6bd4db89ea06a00c7a2",
        "uid": "178cb7405a01e6bd4db89ea06a00c7a2",
        "start": "2025-11-12T15:00:00-05:00",
        "end": "2025-11-12T15:30:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 1"
        },
        "speakers": [
          {
            "name": "Yash Pimple",
            "company": "Chainguard"
          }
        ]
      }
    },
    {
      "text": "Just as open source success is about more than great code, building a successful business on OSS relies on more than pricing. This talk explores how ecosystems thrive when maintainers, vendors, and users build on shared values and trust. We'll unpack why timing matters when open sourcing a project or contributing it to a foundation, how vendors can grow real businesses by adding value around open source rather than trying to control it, and why vendor success matters to the projects themselves. Drawing on Lizs experience with the Cilium project and as former Chair of the TOC, shell look at examples from the CNCF and beyond, to show how shared values can lead to collective success, and draw out the relationships between project health and vendor viability. Expect thoughtful metaphors, practical takeaways, and a reminder that open source isnt a zero-sum game, and commercial success can amplify community impact. Speakers: Liz Rice from Isovalent at Cisco. Location: Building B | Level 3 | B308-309. Categories: CLOUD NATIVE EXPERIENCE.",
      "metadata": {
        "title": "Community Capital: Making OSS and Businesses Successful Together",
        "description": "Just as open source success is about more than great code, building a successful business on OSS relies on more than pricing. This talk explores how ecosystems thrive when maintainers, vendors, and users build on shared values and trust. We'll unpack why timing matters when open sourcing a project or contributing it to a foundation, how vendors can grow real businesses by adding value around open source rather than trying to control it, and why vendor success matters to the projects themselves. Drawing on Lizs experience with the Cilium project and as former Chair of the TOC, shell look at examples from the CNCF and beyond, to show how shared values can lead to collective success, and draw out the relationships between project health and vendor viability. Expect thoughtful metaphors, practical takeaways, and a reminder that open source isnt a zero-sum game, and commercial success can amplify community impact.",
        "url": "http://kccncna2025.sched.com/event/31f66521f207e8ec7854595b8eea530d",
        "uid": "31f66521f207e8ec7854595b8eea530d",
        "start": "2025-11-12T15:00:00-05:00",
        "end": "2025-11-12T15:30:00-05:00",
        "categories": [
          "CLOUD NATIVE EXPERIENCE"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B308-309"
        },
        "speakers": [
          {
            "name": "Liz Rice",
            "company": "Isovalent at Cisco"
          }
        ]
      }
    },
    {
      "text": "This session is a panel discussion moderated by Bob Killen with members of the Public End User Technical Advisory Board. Feel free to come with questions, but we'll be doing an overview of the Public End User Technical Advisory Board's governance structure, scope, mission and processes.\n\nTo learn more about the TAB, visit&nbsp;https://github.com/cncf/tab Location: Building C | Level 3 | Georgia Ballroom 2. Categories: CLOUD NATIVE EXPERIENCE.",
      "metadata": {
        "title": "Public End User Technical Advisory Board (TAB) Town Hall",
        "description": "This session is a panel discussion moderated by Bob Killen with members of the Public End User Technical Advisory Board. Feel free to come with questions, but we'll be doing an overview of the Public End User Technical Advisory Board's governance structure, scope, mission and processes.\n\nTo learn more about the TAB, visit&nbsp;https://github.com/cncf/tab",
        "url": "http://kccncna2025.sched.com/event/6cf55619c4f8343e5de04162710342a4",
        "uid": "6cf55619c4f8343e5de04162710342a4",
        "start": "2025-11-12T15:00:00-05:00",
        "end": "2025-11-12T15:30:00-05:00",
        "categories": [
          "CLOUD NATIVE EXPERIENCE"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 2"
        }
      }
    },
    {
      "text": "This research-driven talk introduces a novel architecture paradigm that complements recent advances in timely intelligent inference routing for large language models. By integrating proxy-based classification and reranking techniques, we've developed a system that efficiently routes incoming prompts to domain-specialized LLMs based on rapid content analysis. Our approach creates a meta-layer of intelligence above traditional model serving infrastructures, enabling specialized models to handle queries they're optimized for while maintaining a unified API interface. We'll present performance research comparing this distributed approach against monolithic inference-time scaling, demonstrating how intelligent routing can achieve superior results for complex, multi-domain workloads while reducing computational overhead. The session includes a Kubernetes-based reference implementation and quantitative analysis of throughput, latency, and accuracy across diverse prompt categories. Speakers: Chen Wang from IBM Research, Huamin Chen from Red Hat. Location: Building B | Level 2 | B206. Categories: EMERGING + ADVANCED.",
      "metadata": {
        "title": "Intelligent LLM Routing: A New Paradigm for Multi-Model AI Orchestration in Kubernetes",
        "description": "This research-driven talk introduces a novel architecture paradigm that complements recent advances in timely intelligent inference routing for large language models. By integrating proxy-based classification and reranking techniques, we've developed a system that efficiently routes incoming prompts to domain-specialized LLMs based on rapid content analysis. Our approach creates a meta-layer of intelligence above traditional model serving infrastructures, enabling specialized models to handle queries they're optimized for while maintaining a unified API interface. We'll present performance research comparing this distributed approach against monolithic inference-time scaling, demonstrating how intelligent routing can achieve superior results for complex, multi-domain workloads while reducing computational overhead. The session includes a Kubernetes-based reference implementation and quantitative analysis of throughput, latency, and accuracy across diverse prompt categories.",
        "url": "http://kccncna2025.sched.com/event/293c7dd938ec12a103e557aec500a4ee",
        "uid": "293c7dd938ec12a103e557aec500a4ee",
        "start": "2025-11-12T15:00:00-05:00",
        "end": "2025-11-12T15:30:00-05:00",
        "categories": [
          "EMERGING + ADVANCED"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B206"
        },
        "speakers": [
          {
            "name": "Chen Wang",
            "company": "IBM Research"
          },
          {
            "name": "Huamin Chen",
            "company": "Red Hat"
          }
        ]
      }
    },
    {
      "text": "Immerse yourself in a 15-min \"Sound Bath\" meditative experience, where you'll be enveloped in the healing vibrations of crystal singing bowls, gongs, and chimes to release stress, restore balance, and promote deep relaxation. Simply lie down, breathe deeply, and let the resonant sounds wash over you, guiding your mind and body toward a state of peace, calm, and rejuvenation. Location: Building C | Level 1 | C108. Categories: EXPERIENCES.",
      "metadata": {
        "title": "Sound Bath",
        "description": "Immerse yourself in a 15-min \"Sound Bath\" meditative experience, where you'll be enveloped in the healing vibrations of crystal singing bowls, gongs, and chimes to release stress, restore balance, and promote deep relaxation. Simply lie down, breathe deeply, and let the resonant sounds wash over you, guiding your mind and body toward a state of peace, calm, and rejuvenation.",
        "url": "http://kccncna2025.sched.com/event/b922d65cef6e4f97ebb2b9d43926e7c9",
        "uid": "b922d65cef6e4f97ebb2b9d43926e7c9",
        "start": "2025-11-12T15:00:00-05:00",
        "end": "2025-11-12T15:15:00-05:00",
        "categories": [
          "EXPERIENCES"
        ],
        "location": {
          "building": "C",
          "level": "1",
          "room": "C108"
        }
      }
    },
    {
      "text": "In the era of rapidly evolving AI technology, efficiently running AI workloads across multiple clusters has become a critical challenge.\nKarmada, as a powerful open-source multi-cluster orchestration solution, is being increasingly adopted by users to run AI workloads.\nThis session will explore the practical strategies employed and the key capabilities that Karmada has built to support these AI workloads.\n\nSession Outline:\n- Why do we need to run AI workloads on multi-clusters\n- Whats the challenge of it\n- How Karmada address these challenges\n- Key Capabilities of Karmada for AI\n- Multicluster Scheduling\n- Resource Interpreter\n- FederatedResourceQuota\n- Multi-Cluster Queue:\n- FederatedHPA\n- Real World Practices\n- QA\n\nBy the end of this session, attendees will have a comprehensive understanding of Karmada's capabilities in running AI applications across multiple clusters and be inspired to explore new possibilities for leveraging Karmada in their own AI projects. Speakers: Hongcai Ren from Huawei, Tessa Pham from  Bloomberg, Wei-Cheng Lai from  Bloomberg. Location: Building C | Level 3 | Georgia Ballroom 1. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Karmada in Action: Scaling AI Workloads Across Multi-Cluster at Scale",
        "description": "In the era of rapidly evolving AI technology, efficiently running AI workloads across multiple clusters has become a critical challenge.\nKarmada, as a powerful open-source multi-cluster orchestration solution, is being increasingly adopted by users to run AI workloads.\nThis session will explore the practical strategies employed and the key capabilities that Karmada has built to support these AI workloads.\n\nSession Outline:\n- Why do we need to run AI workloads on multi-clusters\n- Whats the challenge of it\n- How Karmada address these challenges\n- Key Capabilities of Karmada for AI\n- Multicluster Scheduling\n- Resource Interpreter\n- FederatedResourceQuota\n- Multi-Cluster Queue:\n- FederatedHPA\n- Real World Practices\n- QA\n\nBy the end of this session, attendees will have a comprehensive understanding of Karmada's capabilities in running AI applications across multiple clusters and be inspired to explore new possibilities for leveraging Karmada in their own AI projects.",
        "url": "http://kccncna2025.sched.com/event/27feee7bc2ee21eb075fb841d92a2023",
        "uid": "27feee7bc2ee21eb075fb841d92a2023",
        "start": "2025-11-12T15:00:00-05:00",
        "end": "2025-11-12T15:30:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 1"
        },
        "speakers": [
          {
            "name": "Hongcai Ren",
            "company": "Huawei"
          },
          {
            "name": "Tessa Pham",
            "company": " Bloomberg"
          },
          {
            "name": "Wei-Cheng Lai",
            "company": " Bloomberg"
          }
        ]
      }
    },
    {
      "text": "At this maintainer track talk we will cover what is new in the Windows Special Interest Group. This talk will focus on improvements on recently added support for features such as graceful node shutdown support on Windows, recent improvements made to kube-proxy, and more! Speakers: Mark Rossetti from Microsoft, Aravindh Puthiyaparambil from Softdrive. Location: Building C | Level 3 | Georgia Ballroom 3. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Kubernetes SIG-Windows Updates",
        "description": "At this maintainer track talk we will cover what is new in the Windows Special Interest Group. This talk will focus on improvements on recently added support for features such as graceful node shutdown support on Windows, recent improvements made to kube-proxy, and more!",
        "url": "http://kccncna2025.sched.com/event/00c81cf63cff37d056f7214bb00e95f8",
        "uid": "00c81cf63cff37d056f7214bb00e95f8",
        "start": "2025-11-12T15:00:00-05:00",
        "end": "2025-11-12T15:30:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 3"
        },
        "speakers": [
          {
            "name": "Mark Rossetti",
            "company": "Microsoft"
          },
          {
            "name": "Aravindh Puthiyaparambil",
            "company": "Softdrive"
          }
        ]
      }
    },
    {
      "text": "KubeVirt is rapidly evolving. In the past year, we've introduced many new features, such as decentralized live migration with major stability improvements, VM SWAP support, seamless TCP migration with Passt, and enhancements to the VM rollout mechanism. We added initial support for Kubernetes Dynamic Resource Allocation (DRA) - and much more. Looking ahead, we're exploring support for multiple VMMs beyond QEMU/KVM, expanding into Confidential Computing across architectures, and introducing a new plugin system. As part of our journey toward CNCF graduation, were refining how we plan and deliver features through a new Enhancements process to improve roadmap clarity and community focus. Well also discuss ongoing challenges with Kubernetes native resource quota system and how rethinking it could better serve virtualized workloads. Join us to see how KubeVirt is shaping the future of virtualization in Kubernetes. Speakers: Vladik Romanovsky from Red Hat. Location: Building C | Level 1 | C111-112. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "The Future of Virtualization in Kubernetes: What's Next for KubeVirt",
        "description": "KubeVirt is rapidly evolving. In the past year, we've introduced many new features, such as decentralized live migration with major stability improvements, VM SWAP support, seamless TCP migration with Passt, and enhancements to the VM rollout mechanism. We added initial support for Kubernetes Dynamic Resource Allocation (DRA) - and much more. Looking ahead, we're exploring support for multiple VMMs beyond QEMU/KVM, expanding into Confidential Computing across architectures, and introducing a new plugin system. As part of our journey toward CNCF graduation, were refining how we plan and deliver features through a new Enhancements process to improve roadmap clarity and community focus. Well also discuss ongoing challenges with Kubernetes native resource quota system and how rethinking it could better serve virtualized workloads. Join us to see how KubeVirt is shaping the future of virtualization in Kubernetes.",
        "url": "http://kccncna2025.sched.com/event/10db6ea531c18ec0e23fbbacf7aae6c5",
        "uid": "10db6ea531c18ec0e23fbbacf7aae6c5",
        "start": "2025-11-12T15:00:00-05:00",
        "end": "2025-11-12T15:30:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "1",
          "room": "C111-112"
        },
        "speakers": [
          {
            "name": "Vladik Romanovsky",
            "company": "Red Hat"
          }
        ]
      }
    },
    {
      "text": "This talk shares how Bloomberg used distributed tracing, an OpenTelemetry standard, to address a prevalent need: timing requests from point A to point Z in a cloud native system where a whole alphabet's worth of steps occur in between. This real-time solution ingests more than 50 billion daily spans, modeled as streaming directed acyclic graphs with deep fan-outs and fan-ins. These fan-ins create scalability chokepoints but represent real-world scenarios like queuing systems for high-volume messaging, order processing or batched notifications. This session will highlight the scalability challenges and lessons from building the architecture of an Apache Kafka and Kubernetes-based observability solution that turns complex trace data into actionable insight. The resulting end-to-end latency metrics power SLOs, alerts, and root-cause analysis. If you're into building low-latency, high-throughput telemetry systems, applying trace at scale, or just geeking over graphs, this talk is for you! Speakers: Kusha Maharshi from Bloomberg. Location: Building B | Level 5 | Thomas Murphy Ballroom 4. Categories: OBSERVABILITY.",
      "metadata": {
        "title": "Building Scalable End-to-end Latency Metrics From Distributed Trace",
        "description": "This talk shares how Bloomberg used distributed tracing, an OpenTelemetry standard, to address a prevalent need: timing requests from point A to point Z in a cloud native system where a whole alphabet's worth of steps occur in between. This real-time solution ingests more than 50 billion daily spans, modeled as streaming directed acyclic graphs with deep fan-outs and fan-ins. These fan-ins create scalability chokepoints but represent real-world scenarios like queuing systems for high-volume messaging, order processing or batched notifications. This session will highlight the scalability challenges and lessons from building the architecture of an Apache Kafka and Kubernetes-based observability solution that turns complex trace data into actionable insight. The resulting end-to-end latency metrics power SLOs, alerts, and root-cause analysis. If you're into building low-latency, high-throughput telemetry systems, applying trace at scale, or just geeking over graphs, this talk is for you!",
        "url": "http://kccncna2025.sched.com/event/d5e50f7bebac37411a1b58cf39886f4a",
        "uid": "d5e50f7bebac37411a1b58cf39886f4a",
        "start": "2025-11-12T15:00:00-05:00",
        "end": "2025-11-12T15:30:00-05:00",
        "categories": [
          "OBSERVABILITY"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 4"
        },
        "speakers": [
          {
            "name": "Kusha Maharshi",
            "company": "Bloomberg"
          }
        ]
      }
    },
    {
      "text": "A Kubernetes developer opens the dashboard to check on a critical deployment, only to find the pod is stuck in \"Pending\". What happened? Wheres the bottleneck? In the journey to modernize its compute infrastructure, the Compute team at Netflix faced these same mysteries while migrating from a custom stack to open-source Kubernetes + containerd + CRI. To answer the perennial question, What happened to my Pod?, the Compute team built an end-to-end observability solution using OpenTelemetry tracing across the pod lifecycle. This talk demonstrates how connecting Netflixs custom scheduler, kubelets syncPod, and container runtime traces enabled the team to visualize hidden delays, such as global locks being the bottleneck for launching pods at scale and container registry issues affecting container launch times. The session offers a practical, story-driven exploration of transforming pod observabilityso you can finally answer your own what happened? with confidence. Speakers: Artem Tkachuk from  Netflix, JP Phillips from  Netflix. Location: Building B | Level 3 | B304-305. Categories: OBSERVABILITY.",
      "metadata": {
        "title": "Wheres My Pod? End-to-End Tracing for Kubernetes With OpenTelemetry",
        "description": "A Kubernetes developer opens the dashboard to check on a critical deployment, only to find the pod is stuck in \"Pending\". What happened? Wheres the bottleneck? In the journey to modernize its compute infrastructure, the Compute team at Netflix faced these same mysteries while migrating from a custom stack to open-source Kubernetes + containerd + CRI. To answer the perennial question, What happened to my Pod?, the Compute team built an end-to-end observability solution using OpenTelemetry tracing across the pod lifecycle. This talk demonstrates how connecting Netflixs custom scheduler, kubelets syncPod, and container runtime traces enabled the team to visualize hidden delays, such as global locks being the bottleneck for launching pods at scale and container registry issues affecting container launch times. The session offers a practical, story-driven exploration of transforming pod observabilityso you can finally answer your own what happened? with confidence.",
        "url": "http://kccncna2025.sched.com/event/6783cfc0eeea08a52c7541c7af34bce7",
        "uid": "6783cfc0eeea08a52c7541c7af34bce7",
        "start": "2025-11-12T15:00:00-05:00",
        "end": "2025-11-12T15:30:00-05:00",
        "categories": [
          "OBSERVABILITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B304-305"
        },
        "speakers": [
          {
            "name": "Artem Tkachuk",
            "company": " Netflix"
          },
          {
            "name": "JP Phillips",
            "company": " Netflix"
          }
        ]
      }
    },
    {
      "text": "Over the last 10 years, Kubernetes has changed and unified the underlying APIs to define and run our cloud native ecosystems. But Kubernetes is just the start, as the vibrant ecosystem of tools designed to add capabilities on top of your clusters is far from being unified and interoperable. This has the unintended consequence of introducing rigidity into your organizations platform, which manifests as reduced iteration speed and prolonged timeframes to adopt new technologies.\n\nIn this presentation, Marcos and Mauricio will showcase existing blueprints that combine different projects to build platforms. They will then cover three aspects (platform capabilities, platform APIs, and experiences) that can help cloud-native projects deliver consistent experiences for platform teams, mixing and matching tools to add capabilities to their platforms. This presentation not only focuses on the end-user platforms but also on how we can all contribute to driving consistency in the ecosystem. Speakers: Marcos Lilljedahl from Dagger, Mauricio \"Salaboy\" Salatino from Diagrid. Location: Building B | Level 4 | B405-406a. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "Capabilities, APIs, and Experiences: Blueprints To Build Interoperable Platforms",
        "description": "Over the last 10 years, Kubernetes has changed and unified the underlying APIs to define and run our cloud native ecosystems. But Kubernetes is just the start, as the vibrant ecosystem of tools designed to add capabilities on top of your clusters is far from being unified and interoperable. This has the unintended consequence of introducing rigidity into your organizations platform, which manifests as reduced iteration speed and prolonged timeframes to adopt new technologies.\n\nIn this presentation, Marcos and Mauricio will showcase existing blueprints that combine different projects to build platforms. They will then cover three aspects (platform capabilities, platform APIs, and experiences) that can help cloud-native projects deliver consistent experiences for platform teams, mixing and matching tools to add capabilities to their platforms. This presentation not only focuses on the end-user platforms but also on how we can all contribute to driving consistency in the ecosystem.",
        "url": "http://kccncna2025.sched.com/event/3b338e9545832aedd084091e17c8a2b7",
        "uid": "3b338e9545832aedd084091e17c8a2b7",
        "start": "2025-11-12T15:00:00-05:00",
        "end": "2025-11-12T15:30:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B405-406a"
        },
        "speakers": [
          {
            "name": "Marcos Lilljedahl",
            "company": "Dagger"
          },
          {
            "name": "Mauricio \"Salaboy\" Salatino",
            "company": "Diagrid"
          }
        ]
      }
    },
    {
      "text": "In late 2024, Chick-fil-A's Cloud Platform Engineering team set out to simplify and secure how applications communicate across our Kubernetes environments. Our digital platforms needed better visibility, consistent traffic policies, and stronger governance, without slowing down developer productivity. This talk walks through how we introduced a service mesh into our complex multi-cluster environment, the technical and organizational challenges we encountered, and the measurable impact it had. We'll share how we approached adoption incrementally, validated the architecture, and scaled up to handle production traffic  including critical workloads. We also capitalized on opportunities for cost savings, improved security posture, and faster incident response. Whether you're evaluating service meshes like Istio, planning production rollouts, or managing a mesh at scale, this session offers practical takeaways on what worked, what didn't, and what we'd do differently. Speakers: Christopher Lane from Chick-fil-A. Location: Building B | Level 3 | B312-314. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "No Chicken Left Behind: Reliability and Observability With Service Mesh at Chick-Fil-A",
        "description": "In late 2024, Chick-fil-A's Cloud Platform Engineering team set out to simplify and secure how applications communicate across our Kubernetes environments. Our digital platforms needed better visibility, consistent traffic policies, and stronger governance, without slowing down developer productivity. This talk walks through how we introduced a service mesh into our complex multi-cluster environment, the technical and organizational challenges we encountered, and the measurable impact it had. We'll share how we approached adoption incrementally, validated the architecture, and scaled up to handle production traffic  including critical workloads. We also capitalized on opportunities for cost savings, improved security posture, and faster incident response. Whether you're evaluating service meshes like Istio, planning production rollouts, or managing a mesh at scale, this session offers practical takeaways on what worked, what didn't, and what we'd do differently.",
        "url": "http://kccncna2025.sched.com/event/cf55f3e731ee79507f2ddb8679712b16",
        "uid": "cf55f3e731ee79507f2ddb8679712b16",
        "start": "2025-11-12T15:00:00-05:00",
        "end": "2025-11-12T15:30:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B312-314"
        },
        "speakers": [
          {
            "name": "Christopher Lane",
            "company": "Chick-fil-A"
          }
        ]
      }
    },
    {
      "text": "Yahoo has been an early adopter of Kubernetes, operating 37 on-premises K8s clusters that host 2,700 applications across more than 8,000 physical nodes. The daily management of these clusters & their physical nodes presents significant challenges, including the process of upgrading the K8s version, applying security updates, upgrading the OS version of nodes, and addressing node failures & safely removing faulty nodes from rotation to prevent impact on application pods. Yahoo developed the Node Manager operator, which helps the execution of maintenance tasks, performs controlled K8s version upgrades for control plane & worker nodes, ensuring no impact to currently running applications & performs continuous health checks on nodes as configured per nodegroup & auto remediates nodes in the event of any issues. This talk will discuss how Yahoo manages these operations at scale through automation, reducing manual work for engineers & improving efficiency in their infrastructure management. Speakers: How Yahoo Manages Thousands of Nodes at Scale? - Payal Patel from Yahoo. Location: Building B | Level 4 | B406b-407. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "Node Manager",
        "description": "Yahoo has been an early adopter of Kubernetes, operating 37 on-premises K8s clusters that host 2,700 applications across more than 8,000 physical nodes. The daily management of these clusters & their physical nodes presents significant challenges, including the process of upgrading the K8s version, applying security updates, upgrading the OS version of nodes, and addressing node failures & safely removing faulty nodes from rotation to prevent impact on application pods. Yahoo developed the Node Manager operator, which helps the execution of maintenance tasks, performs controlled K8s version upgrades for control plane & worker nodes, ensuring no impact to currently running applications & performs continuous health checks on nodes as configured per nodegroup & auto remediates nodes in the event of any issues. This talk will discuss how Yahoo manages these operations at scale through automation, reducing manual work for engineers & improving efficiency in their infrastructure management.",
        "url": "http://kccncna2025.sched.com/event/0625aff9eaa3de30f6d947a92d2412bc",
        "uid": "0625aff9eaa3de30f6d947a92d2412bc",
        "start": "2025-11-12T15:00:00-05:00",
        "end": "2025-11-12T15:30:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B406b-407"
        },
        "speakers": [
          {
            "name": "How Yahoo Manages Thousands of Nodes at Scale? - Payal Patel",
            "company": "Yahoo"
          }
        ]
      }
    },
    {
      "text": "Most mTLS solutions in Kubernetes are tightly coupled to service meshes or L7 proxies, introducing operational complexity, performance overhead, and limited flexibility across CNIs. In this session, we present a portable mTLS plugin built on QUIC, a modern transport protocol designed for performance and security. Our plugin offers native, transparent L4 encryption with automatic certificate management via SPIRE, and is designed to work seamlessly with any third-party CNI including Cilium, Calico, and others without sidecars or mesh dependencies. We'll deep-dive into the architecture, QUIC+eBPF redirection, SPIRE integration, and benchmarks that highlight performance gains over Envoy-based solutions. Speakers: Apurup Chevuru from  Microsoft, Michael Zappa from  Microsoft. Location: Building B | Level 3 | B302-303. Categories: SECURITY.",
      "metadata": {
        "title": "Portable MTLS for Kubernetes: A QUIC-Based Plugin Compatible With Any CNI",
        "description": "Most mTLS solutions in Kubernetes are tightly coupled to service meshes or L7 proxies, introducing operational complexity, performance overhead, and limited flexibility across CNIs. In this session, we present a portable mTLS plugin built on QUIC, a modern transport protocol designed for performance and security. Our plugin offers native, transparent L4 encryption with automatic certificate management via SPIRE, and is designed to work seamlessly with any third-party CNI including Cilium, Calico, and others without sidecars or mesh dependencies. We'll deep-dive into the architecture, QUIC+eBPF redirection, SPIRE integration, and benchmarks that highlight performance gains over Envoy-based solutions.",
        "url": "http://kccncna2025.sched.com/event/d6af369c8f409f65932ecaacd095ad11",
        "uid": "d6af369c8f409f65932ecaacd095ad11",
        "start": "2025-11-12T15:00:00-05:00",
        "end": "2025-11-12T15:30:00-05:00",
        "categories": [
          "SECURITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B302-303"
        },
        "speakers": [
          {
            "name": "Apurup Chevuru",
            "company": " Microsoft"
          },
          {
            "name": "Michael Zappa",
            "company": " Microsoft"
          }
        ]
      }
    },
    {
      "text": "Immerse yourself in a 15-min \"Sound Bath\" meditative experience, where you'll be enveloped in the healing vibrations of crystal singing bowls, gongs, and chimes to release stress, restore balance, and promote deep relaxation. Simply lie down, breathe deeply, and let the resonant sounds wash over you, guiding your mind and body toward a state of peace, calm, and rejuvenation. Location: Building C | Level 1 | C108. Categories: EXPERIENCES.",
      "metadata": {
        "title": "Sound Bath",
        "description": "Immerse yourself in a 15-min \"Sound Bath\" meditative experience, where you'll be enveloped in the healing vibrations of crystal singing bowls, gongs, and chimes to release stress, restore balance, and promote deep relaxation. Simply lie down, breathe deeply, and let the resonant sounds wash over you, guiding your mind and body toward a state of peace, calm, and rejuvenation.",
        "url": "http://kccncna2025.sched.com/event/703af6cc025f7d6291884003dc3e1320",
        "uid": "703af6cc025f7d6291884003dc3e1320",
        "start": "2025-11-12T15:20:00-05:00",
        "end": "2025-11-12T15:35:00-05:00",
        "categories": [
          "EXPERIENCES"
        ],
        "location": {
          "building": "C",
          "level": "1",
          "room": "C108"
        }
      }
    },
    {
      "text": "Location: TBA. Categories: BREAKS.",
      "metadata": {
        "title": "Coffee Break ",
        "description": "",
        "url": "http://kccncna2025.sched.com/event/c1a4649385e427a7b3672ad20982f3ff",
        "uid": "c1a4649385e427a7b3672ad20982f3ff",
        "start": "2025-11-12T15:30:00-05:00",
        "end": "2025-11-12T16:00:00-05:00",
        "categories": [
          "BREAKS"
        ],
        "location": {
          "room": "TBA"
        }
      }
    },
    {
      "text": "10-Minute Tip Talk Speakers: Cross-Skill: Aligning Teams Around Smart Learning Paths - Mary Campbell from  LF Education, Randi Armour from  LF Education. Location: Level 1 | Learning Lounge. Categories: EXPERIENCES.",
      "metadata": {
        "title": "Learning Lounge: Dont Cross Wires",
        "description": "10-Minute Tip Talk",
        "url": "http://kccncna2025.sched.com/event/db274897791c10058bb5bf4cea483017",
        "uid": "db274897791c10058bb5bf4cea483017",
        "start": "2025-11-12T15:30:00-05:00",
        "end": "2025-11-12T15:45:00-05:00",
        "categories": [
          "EXPERIENCES"
        ],
        "location": {
          "level": "1",
          "room": "Learning Lounge"
        },
        "speakers": [
          {
            "name": "Cross-Skill: Aligning Teams Around Smart Learning Paths - Mary Campbell",
            "company": " LF Education"
          },
          {
            "name": "Randi Armour",
            "company": " LF Education"
          }
        ]
      }
    },
    {
      "text": "Running etcd in production isnt always smooth sailing - slow disks, network hiccups, or unexpected leader elections can quickly bring clusters to their knees. In this demo, well walk through proven best practices for deploying and operating etcd at scale, then showcase rescue recipes for common problems like instability, database bloat, and failed upgrades. Youll leave with practical guidance to keep your clusters healthy and recover fast when things go wrong.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.* Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: SOLUTIONS SHOWCASE.",
      "metadata": {
        "title": "Sponsored Demo: Running etcd in Production: Best Practices & Rescue Recipes",
        "description": "Running etcd in production isnt always smooth sailing - slow disks, network hiccups, or unexpected leader elections can quickly bring clusters to their knees. In this demo, well walk through proven best practices for deploying and operating etcd at scale, then showcase rescue recipes for common problems like instability, database bloat, and failed upgrades. Youll leave with practical guidance to keep your clusters healthy and recover fast when things go wrong.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.*",
        "url": "http://kccncna2025.sched.com/event/be05c3e48e00b3ff063b32ef178af72f",
        "uid": "be05c3e48e00b3ff063b32ef178af72f",
        "start": "2025-11-12T15:30:00-05:00",
        "end": "2025-11-12T15:50:00-05:00",
        "categories": [
          "SOLUTIONS SHOWCASE"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "Immerse yourself in a 15-min \"Sound Bath\" meditative experience, where you'll be enveloped in the healing vibrations of crystal singing bowls, gongs, and chimes to release stress, restore balance, and promote deep relaxation. Simply lie down, breathe deeply, and let the resonant sounds wash over you, guiding your mind and body toward a state of peace, calm, and rejuvenation. Location: Building C | Level 1 | C108. Categories: EXPERIENCES.",
      "metadata": {
        "title": "Sound Bath",
        "description": "Immerse yourself in a 15-min \"Sound Bath\" meditative experience, where you'll be enveloped in the healing vibrations of crystal singing bowls, gongs, and chimes to release stress, restore balance, and promote deep relaxation. Simply lie down, breathe deeply, and let the resonant sounds wash over you, guiding your mind and body toward a state of peace, calm, and rejuvenation.",
        "url": "http://kccncna2025.sched.com/event/ed89ba5238fec824f5640e23fb5a67ca",
        "uid": "ed89ba5238fec824f5640e23fb5a67ca",
        "start": "2025-11-12T15:40:00-05:00",
        "end": "2025-11-12T15:55:00-05:00",
        "categories": [
          "EXPERIENCES"
        ],
        "location": {
          "building": "C",
          "level": "1",
          "room": "C108"
        }
      }
    },
    {
      "text": "LLM inference workloads present distinct compute-memory phase transitions. Prompt ingestion involves compute-bound attention calculations, whereas token generation becomes memory-bound due to repeated parameter loading from DRAM and HBM. Multi-agent systems integrate heterogeneous components with disparate resource demands that must operate synchronously. This session showcases how AMD GPUs and Kueue optimize compute and memory partitioning, binpacking, and colocation of tightly coupled agentic workflows alongside inference tasks with bursty resource patterns. Attendees will learn strategies to design advanced scheduling and binpacking for agent interaction workflows to achieve 50-70% higher throughput compared to traditional approaches. We'll demonstrate how high-capacity, high-bandwidth GPUs such as AMD MI355x are optimized for mixed-workload AI applications and leveraging unified memory access to minimize cross-component latency while preserving isolation. Speakers: Yuchen Fama from Independent, Jodie Su from AMD. Location: Building B | Level 4 | B401-402. Categories: AI + ML.",
      "metadata": {
        "title": "Optimizing Multi-Agent LLM Workloads With AMD GPUs and Kueue",
        "description": "LLM inference workloads present distinct compute-memory phase transitions. Prompt ingestion involves compute-bound attention calculations, whereas token generation becomes memory-bound due to repeated parameter loading from DRAM and HBM. Multi-agent systems integrate heterogeneous components with disparate resource demands that must operate synchronously. This session showcases how AMD GPUs and Kueue optimize compute and memory partitioning, binpacking, and colocation of tightly coupled agentic workflows alongside inference tasks with bursty resource patterns. Attendees will learn strategies to design advanced scheduling and binpacking for agent interaction workflows to achieve 50-70% higher throughput compared to traditional approaches. We'll demonstrate how high-capacity, high-bandwidth GPUs such as AMD MI355x are optimized for mixed-workload AI applications and leveraging unified memory access to minimize cross-component latency while preserving isolation.",
        "url": "http://kccncna2025.sched.com/event/063cf0542801f8ad5848cf0b24589031",
        "uid": "063cf0542801f8ad5848cf0b24589031",
        "start": "2025-11-12T16:00:00-05:00",
        "end": "2025-11-12T16:30:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B401-402"
        },
        "speakers": [
          {
            "name": "Yuchen Fama",
            "company": "Independent"
          },
          {
            "name": "Jodie Su",
            "company": "AMD"
          }
        ]
      }
    },
    {
      "text": "Modern observability stacks are complex, powerful, and... sometimes, overkill. As engineers, weve grown obsessed with tracing every request, logging every event, and instrumenting every line of code. But is that really making debugging easier? Or are we just drowning in data that we rarely use effectively?\n\nIn this talk, Ill challenge the dominant narrative that better observability equals better debugging. Drawing from my experiences with Dagger, Ill argue that debugging itself is a symptom of reactive thinkingchasing down problems after theyve already happened. Instead, we should shift our focus to proactive design:\n\nImmutable pipelines where container states are frozen and reproducible, reducing variabilityEphemeral, disposable environments that cleanly reset after every runAutomated rollback and self-healing mechanisms that correct errors before they escalateAI agents that adapt workflows dynamically to avoid known failure patterns Speakers: Jeremy Adams from Neo4j. Location: Building B | Level 5 | Thomas Murphy Ballroom 1. Categories: AI + ML.",
      "metadata": {
        "title": "The Future of Debugging Is No Debugging: Observability Is Dead",
        "description": "Modern observability stacks are complex, powerful, and... sometimes, overkill. As engineers, weve grown obsessed with tracing every request, logging every event, and instrumenting every line of code. But is that really making debugging easier? Or are we just drowning in data that we rarely use effectively?\n\nIn this talk, Ill challenge the dominant narrative that better observability equals better debugging. Drawing from my experiences with Dagger, Ill argue that debugging itself is a symptom of reactive thinkingchasing down problems after theyve already happened. Instead, we should shift our focus to proactive design:\n\nImmutable pipelines where container states are frozen and reproducible, reducing variabilityEphemeral, disposable environments that cleanly reset after every runAutomated rollback and self-healing mechanisms that correct errors before they escalateAI agents that adapt workflows dynamically to avoid known failure patterns",
        "url": "http://kccncna2025.sched.com/event/bd7075a4d65e8e86747894bf8623f8d5",
        "uid": "bd7075a4d65e8e86747894bf8623f8d5",
        "start": "2025-11-12T16:00:00-05:00",
        "end": "2025-11-12T16:30:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 1"
        },
        "speakers": [
          {
            "name": "Jeremy Adams",
            "company": "Neo4j"
          }
        ]
      }
    },
    {
      "text": "What if your certification study plan could solve tomorrows production issue? In this session, two CNCF Golden Kubestronauts  from Brazil and Czechia  share how their certification journeys werent just about passing exams, but rather about preparing for actual firefights in production. Well unpack real-world scenarios where skills gained while preparing for certifications like Istio, OpenTelemetry, and CKA turned into practical fixes for observability gaps, traffic chaos, and service resilience challenges. Well also share candid advice on which learning paths really translated into job impact, how to structure your upskilling around active projects, and why some certs didnt quite live up to their promise in day-to-day ops. If youre looking to grow your work impact, this session will help you connect your learning path with your production path  and turn every study sprint into a career boost. Speakers: David Pech from Wrike, Pedro Celestin from CLDF. Location: Building B | Level 3 | B308-309. Categories: CLOUD NATIVE EXPERIENCE.",
      "metadata": {
        "title": "From Kubestronaut To Production Hero: Turning Study Paths Into Real-World Wins",
        "description": "What if your certification study plan could solve tomorrows production issue? In this session, two CNCF Golden Kubestronauts  from Brazil and Czechia  share how their certification journeys werent just about passing exams, but rather about preparing for actual firefights in production. Well unpack real-world scenarios where skills gained while preparing for certifications like Istio, OpenTelemetry, and CKA turned into practical fixes for observability gaps, traffic chaos, and service resilience challenges. Well also share candid advice on which learning paths really translated into job impact, how to structure your upskilling around active projects, and why some certs didnt quite live up to their promise in day-to-day ops. If youre looking to grow your work impact, this session will help you connect your learning path with your production path  and turn every study sprint into a career boost.",
        "url": "http://kccncna2025.sched.com/event/f8f1f61a5b3069d3f590a397e77cedd6",
        "uid": "f8f1f61a5b3069d3f590a397e77cedd6",
        "start": "2025-11-12T16:00:00-05:00",
        "end": "2025-11-12T16:30:00-05:00",
        "categories": [
          "CLOUD NATIVE EXPERIENCE"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B308-309"
        },
        "speakers": [
          {
            "name": "David Pech",
            "company": "Wrike"
          },
          {
            "name": "Pedro Celestin",
            "company": "CLDF"
          }
        ]
      }
    },
    {
      "text": "Kubernetes Custom Resource Definitions (CRDs) are the de facto method for extending the Kubernetes API. While powerful and flexible, CRDs rely on etcd for storage, making them suboptimal for managing larger objects such as Software Bill of Materials (SBOMs) or other high-volume datasets since they create a high load on etcd.\nThis talk re-introduces API server aggregation as an alternative extension mechanism for those who need to become more familiar with it. By leveraging this lesser-known Kubernetes feature, projects like Kubescape have successfully managed oversized objects efficiently without burdening etcd.\nIn this session we will dive into the technical architecture, use cases, and the real-world benefits of using this technology via the use-case example of Kubescape. Speakers: Amir Malka from ARMO. Location: Building B | Level 2 | B206. Categories: EMERGING + ADVANCED.",
      "metadata": {
        "title": "Extending Kubernetes API: The Hidden Power of Aggregated Server Objects",
        "description": "Kubernetes Custom Resource Definitions (CRDs) are the de facto method for extending the Kubernetes API. While powerful and flexible, CRDs rely on etcd for storage, making them suboptimal for managing larger objects such as Software Bill of Materials (SBOMs) or other high-volume datasets since they create a high load on etcd.\nThis talk re-introduces API server aggregation as an alternative extension mechanism for those who need to become more familiar with it. By leveraging this lesser-known Kubernetes feature, projects like Kubescape have successfully managed oversized objects efficiently without burdening etcd.\nIn this session we will dive into the technical architecture, use cases, and the real-world benefits of using this technology via the use-case example of Kubescape.",
        "url": "http://kccncna2025.sched.com/event/c4244a43a20adac47d1e514e92c32048",
        "uid": "c4244a43a20adac47d1e514e92c32048",
        "start": "2025-11-12T16:00:00-05:00",
        "end": "2025-11-12T16:30:00-05:00",
        "categories": [
          "EMERGING + ADVANCED"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B206"
        },
        "speakers": [
          {
            "name": "Amir Malka",
            "company": "ARMO"
          }
        ]
      }
    },
    {
      "text": "In order to mitigate the impact of CVEs and allow continuous delivery of features, it is crucial that upgrades can be rolled out seamlessly. For stateless applications zero downtime upgrades is a solved problem, but for stateful applications, upgrades can present a significant challenge.\nAs the leading open-source identity and access management solution, Keycloak is a critical component in many organizations' infrastructure. Achieving maximum uptime is vital in order for dependent services to function.\nJoin us to discover how Keycloak has evolved to support zero-downtime rollouts of configuration changes and patch upgrades. In this talk we explain the technical and project management challenges we faced, the measures taken to overcome them and what best practices you can leverage in your projects to enable zero-downtime upgrades. Key focus areas will be the Keycloak Operator, how we ensure clustering compatibility, testing strategies and our plans for the future. Speakers: Martin Bartos Ryan Emerson from IBM. Location: Building C | Level 3 | Georgia Ballroom 3. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "A Journey To Zero-Downtime Upgrades With Keycloak",
        "description": "In order to mitigate the impact of CVEs and allow continuous delivery of features, it is crucial that upgrades can be rolled out seamlessly. For stateless applications zero downtime upgrades is a solved problem, but for stateful applications, upgrades can present a significant challenge.\nAs the leading open-source identity and access management solution, Keycloak is a critical component in many organizations' infrastructure. Achieving maximum uptime is vital in order for dependent services to function.\nJoin us to discover how Keycloak has evolved to support zero-downtime rollouts of configuration changes and patch upgrades. In this talk we explain the technical and project management challenges we faced, the measures taken to overcome them and what best practices you can leverage in your projects to enable zero-downtime upgrades. Key focus areas will be the Keycloak Operator, how we ensure clustering compatibility, testing strategies and our plans for the future.",
        "url": "http://kccncna2025.sched.com/event/50367b8ffa88a8a46496464bc870cc78",
        "uid": "50367b8ffa88a8a46496464bc870cc78",
        "start": "2025-11-12T16:00:00-05:00",
        "end": "2025-11-12T16:30:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 3"
        },
        "speakers": [
          {
            "name": "Martin Bartos",
            "title": "Ryan Emerson",
            "company": "IBM"
          }
        ]
      }
    },
    {
      "text": "In this session, KubeEdge project maintainers will provide an overview of KubeEdge's architecture, explore how KubeEdge with its industry-specific use cases. The session will kick off with a brief introduction to edge computing and its growing importance in IoT and distributed systems. The maintainers will then delve into the core components and architecture of KubeEdge, showcasing how it extends the capabilities of Kubernetes to manage edge computing workloads efficiently. Drawing on a range of industry use cases, including smart cities, industrial IoT, edge AI, robotics, and retail, the maintainers will share success stories and insights from organizations that have deployed KubeEdge in their edge environments, highlighting the tangible benefits and transformational possibilities it offers. The session will provide a detailed introduction to the certified KubeEdge conformance test. The maintainers will also share the advancements in technology and community governance in KubeEdge. Speakers: Tina Tsou from TikTok, Hongbing Zhang from DaoCloud, Huan Wei from Hangzhou Harmonycloud, Yin Ding from KubeEdge. Location: Building C | Level 3 | Georgia Ballroom 1. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "KubeEdge DeepDive: Extending Kubernetes To the Edge With Real-World Industry Use Cases",
        "description": "In this session, KubeEdge project maintainers will provide an overview of KubeEdge's architecture, explore how KubeEdge with its industry-specific use cases. The session will kick off with a brief introduction to edge computing and its growing importance in IoT and distributed systems. The maintainers will then delve into the core components and architecture of KubeEdge, showcasing how it extends the capabilities of Kubernetes to manage edge computing workloads efficiently. Drawing on a range of industry use cases, including smart cities, industrial IoT, edge AI, robotics, and retail, the maintainers will share success stories and insights from organizations that have deployed KubeEdge in their edge environments, highlighting the tangible benefits and transformational possibilities it offers. The session will provide a detailed introduction to the certified KubeEdge conformance test. The maintainers will also share the advancements in technology and community governance in KubeEdge.",
        "url": "http://kccncna2025.sched.com/event/d292237565929f2f101201e9d8e46a60",
        "uid": "d292237565929f2f101201e9d8e46a60",
        "start": "2025-11-12T16:00:00-05:00",
        "end": "2025-11-12T16:30:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 1"
        },
        "speakers": [
          {
            "name": "Tina Tsou",
            "company": "TikTok"
          },
          {
            "name": "Hongbing Zhang",
            "company": "DaoCloud"
          },
          {
            "name": "Huan Wei",
            "company": "Hangzhou Harmonycloud"
          },
          {
            "name": "Yin Ding",
            "company": "KubeEdge"
          }
        ]
      }
    },
    {
      "text": "Historically a kubernetes cluster is both a control-plane and worker nodes; management tools create and manage both. This model is simple to understand and effective, but accidentally introduces operational friction, particularly around upgrades, scalability, and cloud portability. The community has tackled many of those issues with projects such as cluster-api and karpenter, moving node management to the extensible kubernetes control plane. In this session, the kOps maintainers will explore this paradigm. We propose a clear division of responsibility where tools like kOps focus on their core strength - bootstrapping a robust, production-grade control plane - and then cede node lifecycle management to common in-cluster, kubernetes-API-driven tools like cluster-api and karpenter. We'll show how this addresses past challenges by abstracting node management behind the Kubernetes API itself, creating a powerful unified but interchangeable story for \"cluster\" management tooling. Speakers: Justin Santa Barbara from Google, Ciprian Hacman from Microsoft. Location: Building C | Level 1 | C111-112. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "The Next Decoupling: From Monolithic Cluster, To Control-Plane With Nodes",
        "description": "Historically a kubernetes cluster is both a control-plane and worker nodes; management tools create and manage both. This model is simple to understand and effective, but accidentally introduces operational friction, particularly around upgrades, scalability, and cloud portability. The community has tackled many of those issues with projects such as cluster-api and karpenter, moving node management to the extensible kubernetes control plane. In this session, the kOps maintainers will explore this paradigm. We propose a clear division of responsibility where tools like kOps focus on their core strength - bootstrapping a robust, production-grade control plane - and then cede node lifecycle management to common in-cluster, kubernetes-API-driven tools like cluster-api and karpenter. We'll show how this addresses past challenges by abstracting node management behind the Kubernetes API itself, creating a powerful unified but interchangeable story for \"cluster\" management tooling.",
        "url": "http://kccncna2025.sched.com/event/38d2b33e6672ddacd239f6c3a7fef82c",
        "uid": "38d2b33e6672ddacd239f6c3a7fef82c",
        "start": "2025-11-12T16:00:00-05:00",
        "end": "2025-11-12T16:30:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "1",
          "room": "C111-112"
        },
        "speakers": [
          {
            "name": "Justin Santa Barbara",
            "company": "Google"
          },
          {
            "name": "Ciprian Hacman",
            "company": "Microsoft"
          }
        ]
      }
    },
    {
      "text": "Imagine you have a Kubernetes cluster thats hosting some number of services, perhaps these services are written in different programming languages, perhaps there are some databases in the cluster too. Now, imagine that this cluster is intermittently experiencing errors and its not easy to tell whats going on. In this talk we will show you how you can add detailed telemetry immediately to a problematic production environment cluster, without any changes to your existing cluster configuration or applications, with the new OpenTelemetry eBPF Instrumentation project. Well show you how youll be able to get insights into whats wrong with your cluster or services, by leveraging on-demand distributed traces and connectivity graphs, even if its the first time you have heard the term OpenTelemetry. Well discuss the design principles which make this technology safe to deploy in an already problematic environment, without further compromising the stability of your cluster. Speakers: Nikola Grcevski from Grafana Labs, Tyler Yahn from Splunk. Location: Building B | Level 5 | Thomas Murphy Ballroom 4. Categories: OBSERVABILITY.",
      "metadata": {
        "title": "Debugging Your Cluster When Its on Fire",
        "description": "Imagine you have a Kubernetes cluster thats hosting some number of services, perhaps these services are written in different programming languages, perhaps there are some databases in the cluster too. Now, imagine that this cluster is intermittently experiencing errors and its not easy to tell whats going on. In this talk we will show you how you can add detailed telemetry immediately to a problematic production environment cluster, without any changes to your existing cluster configuration or applications, with the new OpenTelemetry eBPF Instrumentation project. Well show you how youll be able to get insights into whats wrong with your cluster or services, by leveraging on-demand distributed traces and connectivity graphs, even if its the first time you have heard the term OpenTelemetry. Well discuss the design principles which make this technology safe to deploy in an already problematic environment, without further compromising the stability of your cluster.",
        "url": "http://kccncna2025.sched.com/event/5b4b5161695fd9e3c40d393e5e72d2ce",
        "uid": "5b4b5161695fd9e3c40d393e5e72d2ce",
        "start": "2025-11-12T16:00:00-05:00",
        "end": "2025-11-12T16:25:00-05:00",
        "categories": [
          "OBSERVABILITY"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 4"
        },
        "speakers": [
          {
            "name": "Nikola Grcevski",
            "company": "Grafana Labs"
          },
          {
            "name": "Tyler Yahn",
            "company": "Splunk"
          }
        ]
      }
    },
    {
      "text": "Cloud-native systems demand real-time adaptabilityyet updating OpenTelemetry Collector processors often means restarts, risking data loss and breaking observability. In this talk, we introduce a powerful hot reload mechanism for dynamic reconfiguration of processors like filters, samplers, and transformerswithout ever restarting the collector. Attendees will learn how to architect hot-swappable processors that respond instantly to pipeline changes, enabling seamless updates, uninterrupted data flow, and zero downtime. Whether you're managing complex telemetry at scale or just tired of fragile restarts, this session delivers the blueprint for a more resilient, continuously observable stack. Speakers: Amir Jakoby from Sawmills, Shiran Melamed from JFrog. Location: Building B | Level 3 | B304-305. Categories: OBSERVABILITY.",
      "metadata": {
        "title": "Zero-Downtime Telemetry: Hot Reloading OpenTelemetry Collector Pipelines",
        "description": "Cloud-native systems demand real-time adaptabilityyet updating OpenTelemetry Collector processors often means restarts, risking data loss and breaking observability. In this talk, we introduce a powerful hot reload mechanism for dynamic reconfiguration of processors like filters, samplers, and transformerswithout ever restarting the collector. Attendees will learn how to architect hot-swappable processors that respond instantly to pipeline changes, enabling seamless updates, uninterrupted data flow, and zero downtime. Whether you're managing complex telemetry at scale or just tired of fragile restarts, this session delivers the blueprint for a more resilient, continuously observable stack.",
        "url": "http://kccncna2025.sched.com/event/f6cad0175154ee87ec3375fccdda310a",
        "uid": "f6cad0175154ee87ec3375fccdda310a",
        "start": "2025-11-12T16:00:00-05:00",
        "end": "2025-11-12T16:30:00-05:00",
        "categories": [
          "OBSERVABILITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B304-305"
        },
        "speakers": [
          {
            "name": "Amir Jakoby",
            "company": "Sawmills"
          },
          {
            "name": "Shiran Melamed",
            "company": "JFrog"
          }
        ]
      }
    },
    {
      "text": "At Guidewire, we needed a Kubernetes platform that reliably runs mission-critical insurance workloads while empowering teams to innovate rapidly. We developed the Component Contributor Model, combining Crossplanes resource abstraction with KubeVelas Open Application Model into a modular, extensible architecture. Application teams can now build and integrate platform components directly, eliminating centralized bottlenecks. We standardized a component lifecycle to scale across diverse cloud services. Explicit trust boundaries preserve security while granting developer autonomy. A governance layer balances speed with stability. In this session, youll discover how we configured a contributor-driven, secure platform; managed component lifecycles at scale; and applied practical governance frameworks. Youll gain actionable patterns for leveraging Crossplane and KubeVela in production, plus strategies to evolve your platform as organizational demands grow. Speakers: Anoop Gopalakrishnan from  Guidewire, Jerome Guionnet from  Guidewire. Location: Building B | Level 4 | B405-406a. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "Component Contributor Architecture: Democratizing Platform Engineering With CNCF Projects",
        "description": "At Guidewire, we needed a Kubernetes platform that reliably runs mission-critical insurance workloads while empowering teams to innovate rapidly. We developed the Component Contributor Model, combining Crossplanes resource abstraction with KubeVelas Open Application Model into a modular, extensible architecture. Application teams can now build and integrate platform components directly, eliminating centralized bottlenecks. We standardized a component lifecycle to scale across diverse cloud services. Explicit trust boundaries preserve security while granting developer autonomy. A governance layer balances speed with stability. In this session, youll discover how we configured a contributor-driven, secure platform; managed component lifecycles at scale; and applied practical governance frameworks. Youll gain actionable patterns for leveraging Crossplane and KubeVela in production, plus strategies to evolve your platform as organizational demands grow.",
        "url": "http://kccncna2025.sched.com/event/ea4cd36f94f4d3e4959915845a1b1ce2",
        "uid": "ea4cd36f94f4d3e4959915845a1b1ce2",
        "start": "2025-11-12T16:00:00-05:00",
        "end": "2025-11-12T16:30:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B405-406a"
        },
        "speakers": [
          {
            "name": "Anoop Gopalakrishnan",
            "company": " Guidewire"
          },
          {
            "name": "Jerome Guionnet",
            "company": " Guidewire"
          }
        ]
      }
    },
    {
      "text": "Imagine a GitOps operator that doesnt just blindly apply manifests but understands cost constraints, incident context, and security posture before acting.\n\nPlatform engineering today isnt just about scaling infrastructure, its about building intelligent systems that can interpret developer intent, adapt to change, and make responsible decisions autonomously.\n\nIn this session, we introduce a new architectural pattern: agentic platforms. These platforms embed situational awareness into the delivery pipeline, transforming ops from reactive to responsive. By incorporating policy, workload, and environment signals, they enable secure-by-default provisioning, context-aware automation, and smart failure recovery.\n\nWell explore how the Model Context Protocol (Kagent) supports this, offering a flexible way to inject context into every automation path. Through real-world scenarios, youll see how MCP-powered agentic flows help platforms say no when needed, manage uncertainty gracefully. Speakers: Shivay Lamba from Couchbase, Ekansh Gupta from SigNoz. Location: Building B | Level 4 | B406b-407. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "Designing Platforms With Judgment: Agentic Flows With MCP",
        "description": "Imagine a GitOps operator that doesnt just blindly apply manifests but understands cost constraints, incident context, and security posture before acting.\n\nPlatform engineering today isnt just about scaling infrastructure, its about building intelligent systems that can interpret developer intent, adapt to change, and make responsible decisions autonomously.\n\nIn this session, we introduce a new architectural pattern: agentic platforms. These platforms embed situational awareness into the delivery pipeline, transforming ops from reactive to responsive. By incorporating policy, workload, and environment signals, they enable secure-by-default provisioning, context-aware automation, and smart failure recovery.\n\nWell explore how the Model Context Protocol (Kagent) supports this, offering a flexible way to inject context into every automation path. Through real-world scenarios, youll see how MCP-powered agentic flows help platforms say no when needed, manage uncertainty gracefully.",
        "url": "http://kccncna2025.sched.com/event/01d1750a45c7f630370f78b8025bb231",
        "uid": "01d1750a45c7f630370f78b8025bb231",
        "start": "2025-11-12T16:00:00-05:00",
        "end": "2025-11-12T16:30:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B406b-407"
        },
        "speakers": [
          {
            "name": "Shivay Lamba",
            "company": "Couchbase"
          },
          {
            "name": "Ekansh Gupta",
            "company": "SigNoz"
          }
        ]
      }
    },
    {
      "text": "Transitioning a fleet to Kubernetes is challenging, even in the simplest environments. But what happens when hard business requirements demand features that Kubernetes doesnt support yet? At Uber, we faced this challenge as we migrated over 200,000 database workloads from our proprietary infrastructure to Kubernetes. In this talk, well share how we used the Node Resource Interface (NRI) as a powerful interface to extend Kubernetes with custom features critical to our business, without forking the core. NRI enabled us to meet our immediate needs while providing a clear path to deprecate it once upstream Kubernetes has the features we need. Well walk through our migration strategy, the missing features that drove our use of NRI, and how we successfully completed the transition. Finally, well outline our plans to phase out NRI, adopt a fully vanilla Kubernetes stack, and share key lessons others can take from our journey. Speakers: Johan Jensen from  Uber, Wesley Bermbach from  Uber. Location: Building B | Level 3 | B312-314. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "Not Forking Around: Leveraging NRI To Extend Kubernetes at Scale",
        "description": "Transitioning a fleet to Kubernetes is challenging, even in the simplest environments. But what happens when hard business requirements demand features that Kubernetes doesnt support yet? At Uber, we faced this challenge as we migrated over 200,000 database workloads from our proprietary infrastructure to Kubernetes. In this talk, well share how we used the Node Resource Interface (NRI) as a powerful interface to extend Kubernetes with custom features critical to our business, without forking the core. NRI enabled us to meet our immediate needs while providing a clear path to deprecate it once upstream Kubernetes has the features we need. Well walk through our migration strategy, the missing features that drove our use of NRI, and how we successfully completed the transition. Finally, well outline our plans to phase out NRI, adopt a fully vanilla Kubernetes stack, and share key lessons others can take from our journey.",
        "url": "http://kccncna2025.sched.com/event/72a156580dfff35affeb659d6dc09c4f",
        "uid": "72a156580dfff35affeb659d6dc09c4f",
        "start": "2025-11-12T16:00:00-05:00",
        "end": "2025-11-12T16:30:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B312-314"
        },
        "speakers": [
          {
            "name": "Johan Jensen",
            "company": " Uber"
          },
          {
            "name": "Wesley Bermbach",
            "company": " Uber"
          }
        ]
      }
    },
    {
      "text": "As container images shrink and teams chase the elusive 0 CVE scan, a host of other threats lurk beneath the surface of open source software. Security is more than vulnerabilities; its about trust, transparency, and maintainability. Open source can be: - Improperly governed -- at risk of hostile takeovers - Maliciously licensed -- hiding legal landmines - End-of-life -- abandoned with no path forward - Poorly documented -- where read the code is the only option - Untested -- bugs waiting to detonate at scale - Insecurely released -- exposing the supply chain These non-obvious risks often paralyze teams trying to make informed choices. But a new generation of tools is emerging to bring clarity. Well explore how CNCF projects and Linux Foundation initiatives are using OpenSSFs Security Scorecards, SLSA, Security Baseline, and the 2025 updated TAG Security guidance on supply chain security to surface and share critical metadata that empowers safer open source adoption. Speakers: Beyond 0 CVEs - John Kjell from ControlPlane. Location: Building B | Level 3 | B302-303. Categories: SECURITY.",
      "metadata": {
        "title": "Safely Sourcing OSS",
        "description": "As container images shrink and teams chase the elusive 0 CVE scan, a host of other threats lurk beneath the surface of open source software. Security is more than vulnerabilities; its about trust, transparency, and maintainability. Open source can be: - Improperly governed -- at risk of hostile takeovers - Maliciously licensed -- hiding legal landmines - End-of-life -- abandoned with no path forward - Poorly documented -- where read the code is the only option - Untested -- bugs waiting to detonate at scale - Insecurely released -- exposing the supply chain These non-obvious risks often paralyze teams trying to make informed choices. But a new generation of tools is emerging to bring clarity. Well explore how CNCF projects and Linux Foundation initiatives are using OpenSSFs Security Scorecards, SLSA, Security Baseline, and the 2025 updated TAG Security guidance on supply chain security to surface and share critical metadata that empowers safer open source adoption.",
        "url": "http://kccncna2025.sched.com/event/8884f05f3d558bb682f9ced3d81e108f",
        "uid": "8884f05f3d558bb682f9ced3d81e108f",
        "start": "2025-11-12T16:00:00-05:00",
        "end": "2025-11-12T16:30:00-05:00",
        "categories": [
          "SECURITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B302-303"
        },
        "speakers": [
          {
            "name": "Beyond 0 CVEs - John Kjell",
            "company": "ControlPlane"
          }
        ]
      }
    },
    {
      "text": "As Kubernetes workloads scale across platforms like OpenShift, EKS, GKE, and AKS, right-sizing becomes essential to balance performance and efficiency. In this session, well explore how the latest Kubecost capabilities help engineering and platform teams make smarter right-sizing decisions with enhanced usage visualizations, GPU-aware recommendations, and automated container-level controls. Well also touch on architectural upgrades that improve responsiveness and scalability. You'll walk away with real-world strategies to cut waste, plan resources more effectively, and improve performance across cloud-native environments.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.* Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: SOLUTIONS SHOWCASE.",
      "metadata": {
        "title": "Sponsored Demo: Right-Sizing Kubernetes: Gain Performance and Efficiency in OpenShift and Beyond",
        "description": "As Kubernetes workloads scale across platforms like OpenShift, EKS, GKE, and AKS, right-sizing becomes essential to balance performance and efficiency. In this session, well explore how the latest Kubecost capabilities help engineering and platform teams make smarter right-sizing decisions with enhanced usage visualizations, GPU-aware recommendations, and automated container-level controls. Well also touch on architectural upgrades that improve responsiveness and scalability. You'll walk away with real-world strategies to cut waste, plan resources more effectively, and improve performance across cloud-native environments.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.*",
        "url": "http://kccncna2025.sched.com/event/c06a74241b5e8cf72a8a512c8b910486",
        "uid": "c06a74241b5e8cf72a8a512c8b910486",
        "start": "2025-11-12T16:00:00-05:00",
        "end": "2025-11-12T16:20:00-05:00",
        "categories": [
          "SOLUTIONS SHOWCASE"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "At the heart of the AI revolution are GPUs and the platform that provides access to them is Kubernetes. Workloads historically access GPUs and other devices with the device plugin API but features are lacking. The new Dynamic Resource Allocation (DRA) feature helps maximize GPU utilization across workloads with additional features like the ability to control device sharing across Pods, use multiple GPU models per node, handle dynamic allocation of multi-instance GPU (MIG) and more. DRA is not limited to GPUs but any specialized hardware that a Pod may use including network attached resources such as edge devices like IP cameras. DRA is a new way to request for resources like GPUs and gives the ability to precisely control how resources are shared between Pods. This tutorial introduces DRA, reviews the behind-the-scenes of DRA in the Kubernetes cluster and walks through multiple ways to use DRA to request for GPU and a network attached resource. Speakers: Rey Lejano from Red Hat. Location: Building B | Level 5 | Thomas Murphy Ballroom 2-3. Categories:  TUTORIALS.",
      "metadata": {
        "title": "Tutorial: Unlock the Future of Kubernetes and Accelerators With Dynamic Resource Allocation (DRA)",
        "description": "At the heart of the AI revolution are GPUs and the platform that provides access to them is Kubernetes. Workloads historically access GPUs and other devices with the device plugin API but features are lacking. The new Dynamic Resource Allocation (DRA) feature helps maximize GPU utilization across workloads with additional features like the ability to control device sharing across Pods, use multiple GPU models per node, handle dynamic allocation of multi-instance GPU (MIG) and more. DRA is not limited to GPUs but any specialized hardware that a Pod may use including network attached resources such as edge devices like IP cameras. DRA is a new way to request for resources like GPUs and gives the ability to precisely control how resources are shared between Pods. This tutorial introduces DRA, reviews the behind-the-scenes of DRA in the Kubernetes cluster and walks through multiple ways to use DRA to request for GPU and a network attached resource.",
        "url": "http://kccncna2025.sched.com/event/a38a7c0e3809fec794119cf3c8160821",
        "uid": "a38a7c0e3809fec794119cf3c8160821",
        "start": "2025-11-12T16:00:00-05:00",
        "end": "2025-11-12T17:15:00-05:00",
        "categories": [
          " TUTORIALS"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 2-3"
        },
        "speakers": [
          {
            "name": "Rey Lejano",
            "company": "Red Hat"
          }
        ]
      }
    },
    {
      "text": "Youve just mastered Kubernetes, and now youre being asked to support AI workloads. But where do you start when building an internal developer platform that connects LLMs, agents, and knowledge bases, without locking into a proprietary service or spending weeks integrating open source tools?\n\nIn this demo-driven session, Akamai will show how to operationalize a cloud native AI stack using familiar CNCF technologies. Learn how to bridge your Kubernetes expertise into the world of AI infrastructure, automate common workflows, and deploy intelligent applications at scale without integration pain.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.* Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: SOLUTIONS SHOWCASE.",
      "metadata": {
        "title": "Sponsored Demo: From Kubernetes to AI: Building a Cloud Native Stack for AI Applications",
        "description": "Youve just mastered Kubernetes, and now youre being asked to support AI workloads. But where do you start when building an internal developer platform that connects LLMs, agents, and knowledge bases, without locking into a proprietary service or spending weeks integrating open source tools?\n\nIn this demo-driven session, Akamai will show how to operationalize a cloud native AI stack using familiar CNCF technologies. Learn how to bridge your Kubernetes expertise into the world of AI infrastructure, automate common workflows, and deploy intelligent applications at scale without integration pain.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.*",
        "url": "http://kccncna2025.sched.com/event/feae9cd6304e79587bea52a98cf6fd31",
        "uid": "feae9cd6304e79587bea52a98cf6fd31",
        "start": "2025-11-12T16:30:00-05:00",
        "end": "2025-11-12T16:50:00-05:00",
        "categories": [
          "SOLUTIONS SHOWCASE"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "Not all workloads need giant GPUs. Think about inference - smaller models could use smaller GPUs. NVIDIAs Multi-Instance GPUs (MIGs) are meant to solve this problem, but using them in Kubernetes has been a big hassle requiring static pre-provisioning of these partitions, or use of specialized CRDs and tooling.\n\nImagine if you could just ask for how much memory your model needs, and Kubernetes would dynamically provision a partition just big enough to fit it! Dynamic Resource Allocation (DRA) can make that happen!\n\nCome learn how the latest version of DRA implements simple, on-demand provisioning of MIGs based on the resource needs of your workload. Youll also learn about how that same feature enables similar use cases with other accelerator technologies like Googles TPU.\n\nDiscover how to optimize GPU utilization and see it in action with a demo! Speakers: Morten Jger Torkildsen from Google, Jan-Philip Gehrcke from NVIDIA. Location: Building B | Level 4 | B401-402. Categories: AI + ML.",
      "metadata": {
        "title": "Partitionable Devices: Putting the Dynamic Back in Dynamic Resource Allocation",
        "description": "Not all workloads need giant GPUs. Think about inference - smaller models could use smaller GPUs. NVIDIAs Multi-Instance GPUs (MIGs) are meant to solve this problem, but using them in Kubernetes has been a big hassle requiring static pre-provisioning of these partitions, or use of specialized CRDs and tooling.\n\nImagine if you could just ask for how much memory your model needs, and Kubernetes would dynamically provision a partition just big enough to fit it! Dynamic Resource Allocation (DRA) can make that happen!\n\nCome learn how the latest version of DRA implements simple, on-demand provisioning of MIGs based on the resource needs of your workload. Youll also learn about how that same feature enables similar use cases with other accelerator technologies like Googles TPU.\n\nDiscover how to optimize GPU utilization and see it in action with a demo!",
        "url": "http://kccncna2025.sched.com/event/b742642a3d9d914e51ef001b72ed596d",
        "uid": "b742642a3d9d914e51ef001b72ed596d",
        "start": "2025-11-12T16:45:00-05:00",
        "end": "2025-11-12T17:15:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B401-402"
        },
        "speakers": [
          {
            "name": "Morten Jger Torkildsen",
            "company": "Google"
          },
          {
            "name": "Jan-Philip Gehrcke",
            "company": "NVIDIA"
          }
        ]
      }
    },
    {
      "text": "As AI races into the enterprise, security, legal, and development teams are being forced to rethink governance at scale. From hallucinating copilots to uncontrolled shadow AI adoption, organizations are grappling with how to govern models, data, and outputs without stifling innovation.\n\nIn this panel, three industry leaders on the front lines of open source and enterprise AI  Brian Fox (Sonatype), Christopher \"CRob\" Robinson (OpenSSF), and Sarah Evans (Dell Technologies)  discuss the emerging best practices, cultural challenges, and open source opportunities in AI governance.\n\nThey will explore:\n-Lessons from existing software governance that do and dont translate to AI\n-The risks of duplicative AI policy efforts across teams\n-The role of open source foundations in shaping responsible AI norms\n-How to balance transparency, control, and velocity with AI adoption\n-Where regulation helps (and where it hinders) innovation Speakers: Brian Fox from Sonatype, Sarah Evans from Dell Technologies, Christopher Robinson from OpenSSF. Location: Building B | Level 5 | Thomas Murphy Ballroom 1. Categories: AI + ML.",
      "metadata": {
        "title": "Taming the AI Hydra: Real-World Lessons in Governing AI Across the Enterprise",
        "description": "As AI races into the enterprise, security, legal, and development teams are being forced to rethink governance at scale. From hallucinating copilots to uncontrolled shadow AI adoption, organizations are grappling with how to govern models, data, and outputs without stifling innovation.\n\nIn this panel, three industry leaders on the front lines of open source and enterprise AI  Brian Fox (Sonatype), Christopher \"CRob\" Robinson (OpenSSF), and Sarah Evans (Dell Technologies)  discuss the emerging best practices, cultural challenges, and open source opportunities in AI governance.\n\nThey will explore:\n-Lessons from existing software governance that do and dont translate to AI\n-The risks of duplicative AI policy efforts across teams\n-The role of open source foundations in shaping responsible AI norms\n-How to balance transparency, control, and velocity with AI adoption\n-Where regulation helps (and where it hinders) innovation",
        "url": "http://kccncna2025.sched.com/event/d155638fb9ec36b44363926237ce2bc2",
        "uid": "d155638fb9ec36b44363926237ce2bc2",
        "start": "2025-11-12T16:45:00-05:00",
        "end": "2025-11-12T17:15:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 1"
        },
        "speakers": [
          {
            "name": "Brian Fox",
            "company": "Sonatype"
          },
          {
            "name": "Sarah Evans",
            "company": "Dell Technologies"
          },
          {
            "name": "Christopher Robinson",
            "company": "OpenSSF"
          }
        ]
      }
    },
    {
      "text": "Cilium has been the standard for Kubernetes networking and security. TikTok migrated clusters to use Cilium for its advanced security features like mutual authentication, along with high performance networking and enhanced observability. The main challenge was executing this on TikTok IPv6 only datacenters, as Cilium has been battle tested with IPv4 and dual-stack, but not with IPv6 only environments.\n\nThis talk shares the journey of making Cilium work for IPv6 only Kubernetes, highlighting the limitations and techniques to overcome them. First, Cilium doesn't support tunneling over IPv6, native routing mode must be configured. Second, we encountered several bugs related to IPv6 only: NDP traffic getting dropped by Cilium Network Policy due to incorrect identification; DNS policy not allowing traffic for IPv6 DNS servers; broken cilium debug tools when IPv4 related BPF maps not found. Finally, the NodePort timeout issue was blocking us from enabling Cilium to fully replace kube-proxy. Speakers: Giri Kuncoro from  TikTok, Joseph Pallamidessi from  TikTok. Location: Building B | Level 3 | B308-309. Categories: CONNECTIVITY.",
      "metadata": {
        "title": "TikTok's IPv6 Journey To Cilium: Pitfalls and Lessons Learned",
        "description": "Cilium has been the standard for Kubernetes networking and security. TikTok migrated clusters to use Cilium for its advanced security features like mutual authentication, along with high performance networking and enhanced observability. The main challenge was executing this on TikTok IPv6 only datacenters, as Cilium has been battle tested with IPv4 and dual-stack, but not with IPv6 only environments.\n\nThis talk shares the journey of making Cilium work for IPv6 only Kubernetes, highlighting the limitations and techniques to overcome them. First, Cilium doesn't support tunneling over IPv6, native routing mode must be configured. Second, we encountered several bugs related to IPv6 only: NDP traffic getting dropped by Cilium Network Policy due to incorrect identification; DNS policy not allowing traffic for IPv6 DNS servers; broken cilium debug tools when IPv4 related BPF maps not found. Finally, the NodePort timeout issue was blocking us from enabling Cilium to fully replace kube-proxy.",
        "url": "http://kccncna2025.sched.com/event/d941dedaf997351507803d3f0c4c67e6",
        "uid": "d941dedaf997351507803d3f0c4c67e6",
        "start": "2025-11-12T16:45:00-05:00",
        "end": "2025-11-12T17:15:00-05:00",
        "categories": [
          "CONNECTIVITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B308-309"
        },
        "speakers": [
          {
            "name": "Giri Kuncoro",
            "company": " TikTok"
          },
          {
            "name": "Joseph Pallamidessi",
            "company": " TikTok"
          }
        ]
      }
    },
    {
      "text": "AI agents are reshaping healthcare operations but traditional centralized LLMs come with challenges: high latency, data privacy concerns, and steep cloud costs. In this talk, well explore how lightweight, Kubernetes-native deployments of AI agents powered by Ollama and K3s/MicroK8s enable intelligent, autonomous operations directly at the healthcare edge.\n\nWell walk through a real-world architecture where multi-agent systems orchestrate hospital workflows like patient triage, imaging coordination, and resource scheduling all without sending sensitive data offsite.\n\nYoull see how small LLMs deployed locally can drive powerful workflows, the K8s primitives used to scale and monitor agents, and how this approach achieves both operational efficiency and regulatory compliance (HIPAA, GDPR).\n\nThis talk blends cloud-native engineering, AI orchestration, and real healthcare needs and offers a blueprint for deploying resilient, scalable AI agent ecosystems anywhere edge computing is needed. Speakers: Gary Arora from  Deloitte, Samarth Shah from  Deloitte. Location: Building B | Level 2 | B206. Categories: EMERGING + ADVANCED.",
      "metadata": {
        "title": "Deploying Lightweight AI Agents at the Healthcare Edge With K8s + Ollama",
        "description": "AI agents are reshaping healthcare operations but traditional centralized LLMs come with challenges: high latency, data privacy concerns, and steep cloud costs. In this talk, well explore how lightweight, Kubernetes-native deployments of AI agents powered by Ollama and K3s/MicroK8s enable intelligent, autonomous operations directly at the healthcare edge.\n\nWell walk through a real-world architecture where multi-agent systems orchestrate hospital workflows like patient triage, imaging coordination, and resource scheduling all without sending sensitive data offsite.\n\nYoull see how small LLMs deployed locally can drive powerful workflows, the K8s primitives used to scale and monitor agents, and how this approach achieves both operational efficiency and regulatory compliance (HIPAA, GDPR).\n\nThis talk blends cloud-native engineering, AI orchestration, and real healthcare needs and offers a blueprint for deploying resilient, scalable AI agent ecosystems anywhere edge computing is needed.",
        "url": "http://kccncna2025.sched.com/event/d2a548471c64bcdd0a607256202cd32d",
        "uid": "d2a548471c64bcdd0a607256202cd32d",
        "start": "2025-11-12T16:45:00-05:00",
        "end": "2025-11-12T17:15:00-05:00",
        "categories": [
          "EMERGING + ADVANCED"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B206"
        },
        "speakers": [
          {
            "name": "Gary Arora",
            "company": " Deloitte"
          },
          {
            "name": "Samarth Shah",
            "company": " Deloitte"
          }
        ]
      }
    },
    {
      "text": "This presentation will introduce the recently rebooted CNCF TAG Infrastructure. We'll cover its operational structure and its collaborative efforts with CNCF projects in key areas such as data and storage, networking, DNS, compute, service mesh, infrastructure lifecycle, edge computing, sovereignty, and load balancing. We will also highlight our ongoing work in developing ecosystem guidance and whitepapers. Attendees will learn how to contribute to and participate in the CNCF Infrastructure community, and gain practical insights into leveraging cloud-native infrastructure in their own environments. Speakers: Dylan Page from Lambda.ai, Kashif Khan from Ericsson Software Technology. Location: Building C | Level 1 | C111-112. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Introduction To TAG Infrastructure",
        "description": "This presentation will introduce the recently rebooted CNCF TAG Infrastructure. We'll cover its operational structure and its collaborative efforts with CNCF projects in key areas such as data and storage, networking, DNS, compute, service mesh, infrastructure lifecycle, edge computing, sovereignty, and load balancing. We will also highlight our ongoing work in developing ecosystem guidance and whitepapers. Attendees will learn how to contribute to and participate in the CNCF Infrastructure community, and gain practical insights into leveraging cloud-native infrastructure in their own environments.",
        "url": "http://kccncna2025.sched.com/event/dc15770d6db1f4d5461444cb5a46bda5",
        "uid": "dc15770d6db1f4d5461444cb5a46bda5",
        "start": "2025-11-12T16:45:00-05:00",
        "end": "2025-11-12T17:15:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "1",
          "room": "C111-112"
        },
        "speakers": [
          {
            "name": "Dylan Page",
            "company": "Lambda.ai"
          },
          {
            "name": "Kashif Khan",
            "company": "Ericsson Software Technology"
          }
        ]
      }
    },
    {
      "text": "The Istio community has been hard at work making Istio even better for the hundreds of users and organizations that use it in production. Come hear about the most exciting new features from the Istio Technical Oversight Committee as well as a roadmap for what we aim to accomplish next year. Speakers: Keith Mattix from Microsoft. Location: Building C | Level 3 | Georgia Ballroom 3. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Istio Project Updates: AI Inference, Ambient Multicluster & Default Deny",
        "description": "The Istio community has been hard at work making Istio even better for the hundreds of users and organizations that use it in production. Come hear about the most exciting new features from the Istio Technical Oversight Committee as well as a roadmap for what we aim to accomplish next year.",
        "url": "http://kccncna2025.sched.com/event/0f599eefb8edc2cd7b3635cb4d5b42bc",
        "uid": "0f599eefb8edc2cd7b3635cb4d5b42bc",
        "start": "2025-11-12T16:45:00-05:00",
        "end": "2025-11-12T17:15:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 3"
        },
        "speakers": [
          {
            "name": "Keith Mattix",
            "company": "Microsoft"
          }
        ]
      }
    },
    {
      "text": "The Kubernetes Infrastructure SIG is responsible for maintaining the overall infrastructure of the Kubernetes project. In this session, we will take a deep dive into some of the projects that the SIG is currently working on, as well as existing collaborations with other platform providers and Kubernetes SIGs. We will also provide an update on the current state of the SIG and explore what's next. Speakers: Mahamed Ali from Arab Center for Research, Policy Studies. Location: Building C | Level 3 | Georgia Ballroom 1. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Kubernetes Infra SIG: Intro and Updates",
        "description": "The Kubernetes Infrastructure SIG is responsible for maintaining the overall infrastructure of the Kubernetes project. In this session, we will take a deep dive into some of the projects that the SIG is currently working on, as well as existing collaborations with other platform providers and Kubernetes SIGs. We will also provide an update on the current state of the SIG and explore what's next.",
        "url": "http://kccncna2025.sched.com/event/d05307ed08c316d5d82e0e1df94f84ba",
        "uid": "d05307ed08c316d5d82e0e1df94f84ba",
        "start": "2025-11-12T16:45:00-05:00",
        "end": "2025-11-12T17:15:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 1"
        },
        "speakers": [
          {
            "name": "Mahamed Ali",
            "company": "Arab Center for Research"
          },
          {
            "name": "Policy Studies"
          }
        ]
      }
    },
    {
      "text": "Engineers often face cognitive overload, noisy dashboards, and alert fatigue, especially when working with complex tools like OpenTelemetry. These challenges arent just technical; theyre usability failures that impact incident response and developer experience. Yet the success of observability platforms often hinges on something less visible: design. Behind every intuitive dashboard and frictionless workflow is a designer translating complexity into clarity. This session offers a behind-the-scenes look from a product designer working in observability. Drawing on real-world experience designing for Kubernetes-native platforms built on OpenTelemetry, the speaker shares how design decisions shape engineers ability to understand, trust, and act on telemetry data, especially during high-pressure incidents. Takeaways: Why design is critical to observability and DevEx, plus actionable strategies for visualizing complex telemetry. Speakers: Andrea Chomiak from Dash0. Location: Building B | Level 5 | Thomas Murphy Ballroom 4. Categories: OBSERVABILITY.",
      "metadata": {
        "title": "Designing for Observability: From Noise To Insight",
        "description": "Engineers often face cognitive overload, noisy dashboards, and alert fatigue, especially when working with complex tools like OpenTelemetry. These challenges arent just technical; theyre usability failures that impact incident response and developer experience. Yet the success of observability platforms often hinges on something less visible: design. Behind every intuitive dashboard and frictionless workflow is a designer translating complexity into clarity. This session offers a behind-the-scenes look from a product designer working in observability. Drawing on real-world experience designing for Kubernetes-native platforms built on OpenTelemetry, the speaker shares how design decisions shape engineers ability to understand, trust, and act on telemetry data, especially during high-pressure incidents. Takeaways: Why design is critical to observability and DevEx, plus actionable strategies for visualizing complex telemetry.",
        "url": "http://kccncna2025.sched.com/event/df6c0f4192854c3425a49ee555be809e",
        "uid": "df6c0f4192854c3425a49ee555be809e",
        "start": "2025-11-12T16:45:00-05:00",
        "end": "2025-11-12T17:15:00-05:00",
        "categories": [
          "OBSERVABILITY"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 4"
        },
        "speakers": [
          {
            "name": "Andrea Chomiak",
            "company": "Dash0"
          }
        ]
      }
    },
    {
      "text": "OpenTelemetry Logs are no longer the least mature signal. Theyre driving major changes across the project. This talk explores how recent developments, including the introduction of OpenTelemetry Events, richer semantic conventions, and support for complex attribute values like nested objects and arrays. These changes are not isolated. They represent a coordinated effort to unify and modernize telemetry data, improve correlation across signals, and enable richer, more structured observability experiences. This session will dive into the technical challenges, design decisions, and emerging patterns that are turning logs into a first-class citizen in the OpenTelemetry ecosystem. This session makes the case that logs are no longer legacytheyre a foundation for smarter, more unified observability. Whether you're a platform engineer, SRE, or tooling vendor, understanding this shift is key to staying ahead as OpenTelemetry evolves. Speakers: Robert Pajak from Splunk. Location: Building B | Level 3 | B304-305. Categories: OBSERVABILITY.",
      "metadata": {
        "title": "OpenTelemetry Logs Driving a Major Shift: Events, Richer Data, and Smarter Semantics",
        "description": "OpenTelemetry Logs are no longer the least mature signal. Theyre driving major changes across the project. This talk explores how recent developments, including the introduction of OpenTelemetry Events, richer semantic conventions, and support for complex attribute values like nested objects and arrays. These changes are not isolated. They represent a coordinated effort to unify and modernize telemetry data, improve correlation across signals, and enable richer, more structured observability experiences. This session will dive into the technical challenges, design decisions, and emerging patterns that are turning logs into a first-class citizen in the OpenTelemetry ecosystem. This session makes the case that logs are no longer legacytheyre a foundation for smarter, more unified observability. Whether you're a platform engineer, SRE, or tooling vendor, understanding this shift is key to staying ahead as OpenTelemetry evolves.",
        "url": "http://kccncna2025.sched.com/event/328c3de9f4aa8e14978fc40975a16ae9",
        "uid": "328c3de9f4aa8e14978fc40975a16ae9",
        "start": "2025-11-12T16:45:00-05:00",
        "end": "2025-11-12T17:15:00-05:00",
        "categories": [
          "OBSERVABILITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B304-305"
        },
        "speakers": [
          {
            "name": "Robert Pajak",
            "company": "Splunk"
          }
        ]
      }
    },
    {
      "text": "Titus, Netflix's Kubernetes-based container platform, runs hundreds of thousands of containers globally. This case study details Titus's use of ContainerD's Node Resource Interface (NRI) and OCI hooks to adapt a custom compute platform to a more conventional dataplane while operating at scale and maintaining Kubernetes compatibility. These extensions support Netflix's unique workload needs, custom business logic, sidecar management, and systemd-compatible runtime environments. The session will cover an overview of Titus and its migration to a standard Kubernetes distribution while preserving specialized runtime capabilities. It will also provide a deep dive into the NRI plugin/OCI hook implementation, detailing Titus workload lifecycle management, special network configuration, storage handling, and sidecar management. The presentation will conclude with an examination of the challenges and lessons learned from scaling these runtime extensions. Speakers: Erikson Tung from Netflix. Location: Building B | Level 4 | B405-406a. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "Container Runtime Customization at Netflix: A Case Study With NRI and OCI Hooks",
        "description": "Titus, Netflix's Kubernetes-based container platform, runs hundreds of thousands of containers globally. This case study details Titus's use of ContainerD's Node Resource Interface (NRI) and OCI hooks to adapt a custom compute platform to a more conventional dataplane while operating at scale and maintaining Kubernetes compatibility. These extensions support Netflix's unique workload needs, custom business logic, sidecar management, and systemd-compatible runtime environments. The session will cover an overview of Titus and its migration to a standard Kubernetes distribution while preserving specialized runtime capabilities. It will also provide a deep dive into the NRI plugin/OCI hook implementation, detailing Titus workload lifecycle management, special network configuration, storage handling, and sidecar management. The presentation will conclude with an examination of the challenges and lessons learned from scaling these runtime extensions.",
        "url": "http://kccncna2025.sched.com/event/acf31b98ca8bd32044992f2130e3cb10",
        "uid": "acf31b98ca8bd32044992f2130e3cb10",
        "start": "2025-11-12T16:45:00-05:00",
        "end": "2025-11-12T17:15:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B405-406a"
        },
        "speakers": [
          {
            "name": "Erikson Tung",
            "company": "Netflix"
          }
        ]
      }
    },
    {
      "text": "Building cloud-native applications which can be deployed across multiple cloud environments is challengingespecially when using cloud resources beyond Kubernetes. In this session, learn about Comcast's journey of discovering a more intuitive way to combine application and infrastructure definitions and how they are using Radius to manage resources across multiple cloud environments. As an contributor to the Radius project, Comcast is using Radius custom resource types to model application resources deployed in the cloud and on-premises. This session will explore key features and benefits of custom resource types in Radius as well as real-world use cases and best practices for implementing Radius in a multi-cloud enterprise environment. Speakers: Nick Beenham from Comcast, Jonathan Smith from Microsoft. Location: Building B | Level 4 | B406b-407. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "How Comcast Leverages Radius in Their Internal Developer Platform",
        "description": "Building cloud-native applications which can be deployed across multiple cloud environments is challengingespecially when using cloud resources beyond Kubernetes. In this session, learn about Comcast's journey of discovering a more intuitive way to combine application and infrastructure definitions and how they are using Radius to manage resources across multiple cloud environments. As an contributor to the Radius project, Comcast is using Radius custom resource types to model application resources deployed in the cloud and on-premises. This session will explore key features and benefits of custom resource types in Radius as well as real-world use cases and best practices for implementing Radius in a multi-cloud enterprise environment.",
        "url": "http://kccncna2025.sched.com/event/39db31f904ed9e1e65dc8fcac7265950",
        "uid": "39db31f904ed9e1e65dc8fcac7265950",
        "start": "2025-11-12T16:45:00-05:00",
        "end": "2025-11-12T17:15:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B406b-407"
        },
        "speakers": [
          {
            "name": "Nick Beenham",
            "company": "Comcast"
          },
          {
            "name": "Jonathan Smith",
            "company": "Microsoft"
          }
        ]
      }
    },
    {
      "text": "In 2017, our team set out to build a Kubernetes developer platform for microservices at Capital One. This talk explores our platform evolution, from a proof-of-concept serving one team to a robust platform serving the enterprise. Attendees will learn how we leveraged the operator pattern to incorporate Capital One architectural patterns into the Kubernetes API. Well also explore how building trust and partnerships is a critical, yet often overlooked, aspect of platform engineering. Expanding on the operator pattern, our platform evolved its capabilities into managing cloud resources outside the cluster with Kubernetes controllers and a managed Kubernetes offering to deploy off-the-shelf applications. Join us to hear more about the obstacles we overcame, practical lessons learned, and what we are exploring next as the platform continues its evolution. Speakers: Bradley Whitfield from  Capital One, Jacob Walden from  Capital One. Location: Building B | Level 3 | B312-314. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "On the Origin of Platforms: Evolution of a Capital One Enterprise Platform",
        "description": "In 2017, our team set out to build a Kubernetes developer platform for microservices at Capital One. This talk explores our platform evolution, from a proof-of-concept serving one team to a robust platform serving the enterprise. Attendees will learn how we leveraged the operator pattern to incorporate Capital One architectural patterns into the Kubernetes API. Well also explore how building trust and partnerships is a critical, yet often overlooked, aspect of platform engineering. Expanding on the operator pattern, our platform evolved its capabilities into managing cloud resources outside the cluster with Kubernetes controllers and a managed Kubernetes offering to deploy off-the-shelf applications. Join us to hear more about the obstacles we overcame, practical lessons learned, and what we are exploring next as the platform continues its evolution.",
        "url": "http://kccncna2025.sched.com/event/c334236c8331b59f6837345110f7eb79",
        "uid": "c334236c8331b59f6837345110f7eb79",
        "start": "2025-11-12T16:45:00-05:00",
        "end": "2025-11-12T17:15:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B312-314"
        },
        "speakers": [
          {
            "name": "Bradley Whitfield",
            "company": " Capital One"
          },
          {
            "name": "Jacob Walden",
            "company": " Capital One"
          }
        ]
      }
    },
    {
      "text": "Is your AI agent infrastructure secure? As AI agents begin to exchange model context and coordinate across systems, secure interaction is no longer optionalits essential. To bring structure to these interactions, protocols like Model Context Protocol (MCP) and Agent-to-Agent (A2A) have emerged, offering standardized ways for agents to communicate. Adopting these protocols introduces new responsibilities. Developers must implement authentication and authorization (AuthN/AuthZ) mechanisms that comply with MCP and A2A while remaining practical for real-world deployment. In this session, Yoshiyuki Tabata shares best practices for designing AuthN/AuthZ and shows how to apply key principles from the CNCF IAM whitepaper to AI agent infrastructuresuch as OAuth-based API access, P*P architecture for authorization, and workload authentication. The session includes a demo of secure AuthZ for an MCP server using Keycloak, illustrating how these practices apply in real-world agent interactions. Speakers: Yoshiyuki Tabata from Hitachi, Ltd.. Location: Building B | Level 3 | B302-303. Categories: SECURITY.",
      "metadata": {
        "title": "Securing AI Agent Infrastructure: AuthN/AuthZ Patterns for MCP and A2A",
        "description": "Is your AI agent infrastructure secure? As AI agents begin to exchange model context and coordinate across systems, secure interaction is no longer optionalits essential. To bring structure to these interactions, protocols like Model Context Protocol (MCP) and Agent-to-Agent (A2A) have emerged, offering standardized ways for agents to communicate. Adopting these protocols introduces new responsibilities. Developers must implement authentication and authorization (AuthN/AuthZ) mechanisms that comply with MCP and A2A while remaining practical for real-world deployment. In this session, Yoshiyuki Tabata shares best practices for designing AuthN/AuthZ and shows how to apply key principles from the CNCF IAM whitepaper to AI agent infrastructuresuch as OAuth-based API access, P*P architecture for authorization, and workload authentication. The session includes a demo of secure AuthZ for an MCP server using Keycloak, illustrating how these practices apply in real-world agent interactions.",
        "url": "http://kccncna2025.sched.com/event/1d709cb98825dfaa92444f66173e141e",
        "uid": "1d709cb98825dfaa92444f66173e141e",
        "start": "2025-11-12T16:45:00-05:00",
        "end": "2025-11-12T17:15:00-05:00",
        "categories": [
          "SECURITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B302-303"
        },
        "speakers": [
          {
            "name": "Yoshiyuki Tabata",
            "company": "Hitachi, Ltd."
          }
        ]
      }
    },
    {
      "text": "Kubernetes observability tools, like Fluent Bit, OpenTelemetry, and Loki, provide deep visibility, but they also handle sensitive data: user identifiers, tokens, and internal service metadata. Even with encryption at rest and in transit, telemetry data is often exposed during collection and processing.\n\nIn this lightning talk, well show how to secure observability pipelines on Kubernetes using confidential computing-enabled nodes. We demonstrate how observability components (e.g., Fluent Bit, OpenTelemetry Collector, Loki) can run inside hardware-isolated Kubernetes nodes, ensuring that telemetry data is encrypted at the source and only processed by trusted, attested workloads.\nAttendees will learn a practical, zero-intrusion design that combines Kubernetes-native observability tools with confidential compute infrastructure to deliver end-to-end encrypted, trusted observability, ideal for regulated workloads in finance, healthcare, and government. Speakers: Jitendra Singh from IBM India Pvt. Ltd.. Location: Building C | Level 3 | Georgia Ballroom 2. Categories:  LIGHTNING TALKS.",
      "metadata": {
        "title": "Lightning Talk: Confidential Observability on Kubernetes: Protecting Telemetry End-to-End",
        "description": "Kubernetes observability tools, like Fluent Bit, OpenTelemetry, and Loki, provide deep visibility, but they also handle sensitive data: user identifiers, tokens, and internal service metadata. Even with encryption at rest and in transit, telemetry data is often exposed during collection and processing.\n\nIn this lightning talk, well show how to secure observability pipelines on Kubernetes using confidential computing-enabled nodes. We demonstrate how observability components (e.g., Fluent Bit, OpenTelemetry Collector, Loki) can run inside hardware-isolated Kubernetes nodes, ensuring that telemetry data is encrypted at the source and only processed by trusted, attested workloads.\nAttendees will learn a practical, zero-intrusion design that combines Kubernetes-native observability tools with confidential compute infrastructure to deliver end-to-end encrypted, trusted observability, ideal for regulated workloads in finance, healthcare, and government.",
        "url": "http://kccncna2025.sched.com/event/2686b192b71c0152e9304bd90ea15f22",
        "uid": "2686b192b71c0152e9304bd90ea15f22",
        "start": "2025-11-12T16:45:00-05:00",
        "end": "2025-11-12T16:50:00-05:00",
        "categories": [
          " LIGHTNING TALKS"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 2"
        },
        "speakers": [
          {
            "name": "Jitendra Singh",
            "company": "IBM India Pvt. Ltd."
          }
        ]
      }
    },
    {
      "text": "As Dynamic Resource Allocation (DRA) matures in Kubernetes, the dra-example-driver (https://github.com/kubernetes-sigs/dra-example-driver) provides an end-to-end starting point for device vendors to create their own drivers, a lightweight driver implementation that can be deployed to clusters without any special hardware for users to rapidly experiment with DRA, and examples showcasing how the latest and greatest DRA features can be implemented by drivers and leveraged by users.\n\nThis talk from a project maintainer will highlight the importance of the dra-example-driver as a key component across the DRA ecosystem as DRA continues to evolve. It will also call on the community to aggregate its best practices and more examples there to reinforce the dra-example-driver as the go-to place for referencing how DRA works in practice. Speakers: Jon Huhn from Microsoft. Location: Building C | Level 3 | Georgia Ballroom 2. Categories:  LIGHTNING TALKS.",
      "metadata": {
        "title": "Lightning Talk: Getting (and Staying) up To Speed on DRA With the DRA Example Driver",
        "description": "As Dynamic Resource Allocation (DRA) matures in Kubernetes, the dra-example-driver (https://github.com/kubernetes-sigs/dra-example-driver) provides an end-to-end starting point for device vendors to create their own drivers, a lightweight driver implementation that can be deployed to clusters without any special hardware for users to rapidly experiment with DRA, and examples showcasing how the latest and greatest DRA features can be implemented by drivers and leveraged by users.\n\nThis talk from a project maintainer will highlight the importance of the dra-example-driver as a key component across the DRA ecosystem as DRA continues to evolve. It will also call on the community to aggregate its best practices and more examples there to reinforce the dra-example-driver as the go-to place for referencing how DRA works in practice.",
        "url": "http://kccncna2025.sched.com/event/93bc064d05e1d399a0d8907e4069d8bc",
        "uid": "93bc064d05e1d399a0d8907e4069d8bc",
        "start": "2025-11-12T16:52:00-05:00",
        "end": "2025-11-12T16:57:00-05:00",
        "categories": [
          " LIGHTNING TALKS"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 2"
        },
        "speakers": [
          {
            "name": "Jon Huhn",
            "company": "Microsoft"
          }
        ]
      }
    },
    {
      "text": "Leader election in kubernetes often carries a hidden cost: disruptive container restarts during lease transitions. This lightning talk will illuminate the critical caveat in current leader election mechanisms where the entire container is forcefully shutdown and restarted via an os.Exit call to facilitate a lease change. We will explore the challenges this poses, including service disruption and the inability to perform graceful cleanup. This session will outline the work that's been put in to make the entire transition process graceful and the new best practices of using the leader election client library. Speakers: Jeffrey Ying from Google. Location: Building C | Level 3 | Georgia Ballroom 2. Categories:  LIGHTNING TALKS.",
      "metadata": {
        "title": "Lightning Talk: Graceful Controller Operations: Achieving Leader Election Without Restarts",
        "description": "Leader election in kubernetes often carries a hidden cost: disruptive container restarts during lease transitions. This lightning talk will illuminate the critical caveat in current leader election mechanisms where the entire container is forcefully shutdown and restarted via an os.Exit call to facilitate a lease change. We will explore the challenges this poses, including service disruption and the inability to perform graceful cleanup. This session will outline the work that's been put in to make the entire transition process graceful and the new best practices of using the leader election client library.",
        "url": "http://kccncna2025.sched.com/event/2add13cb9a2481987527e530f36082f1",
        "uid": "2add13cb9a2481987527e530f36082f1",
        "start": "2025-11-12T16:59:00-05:00",
        "end": "2025-11-12T17:04:00-05:00",
        "categories": [
          " LIGHTNING TALKS"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 2"
        },
        "speakers": [
          {
            "name": "Jeffrey Ying",
            "company": "Google"
          }
        ]
      }
    },
    {
      "text": "Community is derived from communis, meaning shared by all. Youre part of many communitiessome by birth, others by choiceand the ones youre born into shape the communities you choose to join. Now introduce the complexity of underrepresentation and you may start to wonder if you belong there at all.\n\nOpen source is the most inclusive solution to technologys greatest problems, but did you know only 3% of the 2017 Open Source surveys respondents were women? CNCF has the power to accept contributions based on merit and inspire community members (yes, thats you!) to build confidence to take a seat at the table and contributewhether its the 1st time or 100th. If communities are shared, but individuals belong to unique groups, how can you build and support a diverse cloud native community?\n\nThis talk explores key research on underrepresentation in open source contributions, highlights the value of diverse perspectives in business, and explains why representation matters to you. Speakers: Jennifer Weir from Ford Motor Company. Location: Building C | Level 3 | Georgia Ballroom 2. Categories:  LIGHTNING TALKS.",
      "metadata": {
        "title": "Lightning Talk: Young? First-Gen? Female? New? Heres Why You Belong Here Too",
        "description": "Community is derived from communis, meaning shared by all. Youre part of many communitiessome by birth, others by choiceand the ones youre born into shape the communities you choose to join. Now introduce the complexity of underrepresentation and you may start to wonder if you belong there at all.\n\nOpen source is the most inclusive solution to technologys greatest problems, but did you know only 3% of the 2017 Open Source surveys respondents were women? CNCF has the power to accept contributions based on merit and inspire community members (yes, thats you!) to build confidence to take a seat at the table and contributewhether its the 1st time or 100th. If communities are shared, but individuals belong to unique groups, how can you build and support a diverse cloud native community?\n\nThis talk explores key research on underrepresentation in open source contributions, highlights the value of diverse perspectives in business, and explains why representation matters to you.",
        "url": "http://kccncna2025.sched.com/event/c2e34d6c05a85f9dab5c82cb325ce7c6",
        "uid": "c2e34d6c05a85f9dab5c82cb325ce7c6",
        "start": "2025-11-12T17:06:00-05:00",
        "end": "2025-11-12T17:11:00-05:00",
        "categories": [
          " LIGHTNING TALKS"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 2"
        },
        "speakers": [
          {
            "name": "Jennifer Weir",
            "company": "Ford Motor Company"
          }
        ]
      }
    },
    {
      "text": "Theres often a lot of debate in software engineering circles about the value of teaching data structures and algorithms to those just starting out. Honestly, when I was beginning my journey, I used to think of them as a complete waste of time too. This talk aims to challenge such notions by demonstrating how data structures can have real world applications in open source projects like Kubernetes.\n\nIm one of the creators and maintainers of the `depstat` project, which Kubernetes uses to evaluate dependency updates. In this talk, Ill share the design decisions we made while building this tool and how we leveraged data structures like graphs and graph traversal algorithms to implement it effectively.\n\nThis talk will provide attendees with an understanding of what the `depstat` project does and also leave them with a deeper appreciation for the application of foundational computer science concepts in the world of open source! Speakers: Arsh Sharma from MetalBear. Location: Building C | Level 3 | Georgia Ballroom 2. Categories:  LIGHTNING TALKS.",
      "metadata": {
        "title": "Lightning Talk: How We Used Data Structures When Contributing To the Kubernetes Project",
        "description": "Theres often a lot of debate in software engineering circles about the value of teaching data structures and algorithms to those just starting out. Honestly, when I was beginning my journey, I used to think of them as a complete waste of time too. This talk aims to challenge such notions by demonstrating how data structures can have real world applications in open source projects like Kubernetes.\n\nIm one of the creators and maintainers of the `depstat` project, which Kubernetes uses to evaluate dependency updates. In this talk, Ill share the design decisions we made while building this tool and how we leveraged data structures like graphs and graph traversal algorithms to implement it effectively.\n\nThis talk will provide attendees with an understanding of what the `depstat` project does and also leave them with a deeper appreciation for the application of foundational computer science concepts in the world of open source!",
        "url": "http://kccncna2025.sched.com/event/74bde56200dfd6014662e6bc5584215a",
        "uid": "74bde56200dfd6014662e6bc5584215a",
        "start": "2025-11-12T17:13:00-05:00",
        "end": "2025-11-12T17:18:00-05:00",
        "categories": [
          " LIGHTNING TALKS"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 2"
        },
        "speakers": [
          {
            "name": "Arsh Sharma",
            "company": "MetalBear"
          }
        ]
      }
    },
    {
      "text": "The past few years, you may have heard a big splash around Gateway API. There seems to be a lot of confusion on what it is, what it can do, and who it is for. Especially with ingress-nginx and ingate, Gateway API will need your help to narrow down features, get feedback, and get contributors. This speedy talk will be the what and how of Gateway API, and talk about how to get involved and what's next for the project! Speakers: Christine Kim from Isovalent at Cisco. Location: Building C | Level 3 | Georgia Ballroom 2. Categories:  LIGHTNING TALKS.",
      "metadata": {
        "title": "Lightning Talk: Know Before You Go! Speedrun Intro To Gateway API",
        "description": "The past few years, you may have heard a big splash around Gateway API. There seems to be a lot of confusion on what it is, what it can do, and who it is for. Especially with ingress-nginx and ingate, Gateway API will need your help to narrow down features, get feedback, and get contributors. This speedy talk will be the what and how of Gateway API, and talk about how to get involved and what's next for the project!",
        "url": "http://kccncna2025.sched.com/event/44fdabd7aeab1426608988adb631f002",
        "uid": "44fdabd7aeab1426608988adb631f002",
        "start": "2025-11-12T17:20:00-05:00",
        "end": "2025-11-12T17:25:00-05:00",
        "categories": [
          " LIGHTNING TALKS"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 2"
        },
        "speakers": [
          {
            "name": "Christine Kim",
            "company": "Isovalent at Cisco"
          }
        ]
      }
    },
    {
      "text": "As large language models (LLMs) move into production, raw metrics alone arent enough. This talk presents an open-source AI observability solution built on Open Data Hub (ODH) that deploys LLMs using vLLM and KServe, scrapes inference metrics using Prometheus, and feeds them into a summarization model to generate actionable insights. Well demonstrate a working UI that translates low-level metrics like latency, GPU usage, and token throughput into human-readable summariesgiving platform teams an intelligent way to monitor LLMs at scale. No dashboards to interpretjust straight answers from your models about your models. Speakers: Twinkll Sisodia from Red Hat. Location: Building C | Level 3 | Georgia Ballroom 2. Categories:  LIGHTNING TALKS.",
      "metadata": {
        "title": "Lightning Talk: Summarizing the Noise: LLM Observability With Open Data Hub, VLLM, KServe and Prometheus",
        "description": "As large language models (LLMs) move into production, raw metrics alone arent enough. This talk presents an open-source AI observability solution built on Open Data Hub (ODH) that deploys LLMs using vLLM and KServe, scrapes inference metrics using Prometheus, and feeds them into a summarization model to generate actionable insights. Well demonstrate a working UI that translates low-level metrics like latency, GPU usage, and token throughput into human-readable summariesgiving platform teams an intelligent way to monitor LLMs at scale. No dashboards to interpretjust straight answers from your models about your models.",
        "url": "http://kccncna2025.sched.com/event/77c506ed417962666fdd369f111ed215",
        "uid": "77c506ed417962666fdd369f111ed215",
        "start": "2025-11-12T17:27:00-05:00",
        "end": "2025-11-12T17:32:00-05:00",
        "categories": [
          " LIGHTNING TALKS"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 2"
        },
        "speakers": [
          {
            "name": "Twinkll Sisodia",
            "company": "Red Hat"
          }
        ]
      }
    },
    {
      "text": "Struggling with GPU shortages & sky-high inference costs? Youre not alone. Deploying production-grade LLMs on K8s in 2025 still feels like competing in the GPU Hunger Games. But what if you could 5x your clusters efficiency using battle-tested Comp. Sci. principlesnot magic? Join us to explore how the open-source project Production Stack (a first-party vLLM project) supercharges vLLM on K8s with: - Cache: Offload KV Cache using LMCache to CPU/disk/remote storage(no redundant computations!) - Smarter Routing: Match requests to GPUs with pre-computed caches (lower TTFT) - Fault Tolerance++: Migrate live requests mid-generation during failures - RAG Revolution: Blend non-prefix caches from retrieved chunks(CacheBlend=3x faster TTFT) - Benchmarks Dont Lie: See 5x throughput vs. vanilla vLLM in real-world tests Whether youre an Infra Engineer, ML Developer or SRE, this deep dive will leave you with actionable patterns to deploy faster,cheaper & more reliably. Speakers: Yuhan Liu from University of Chicago, Suraj Deshmukh from Microsoft. Location: Building B | Level 5 | Thomas Murphy Ballroom 1. Categories: AI + ML.",
      "metadata": {
        "title": "LLMs on Kubernetes: Squeeze 5x GPU Efficiency With Cache, Route, Repeat!",
        "description": "Struggling with GPU shortages & sky-high inference costs? Youre not alone. Deploying production-grade LLMs on K8s in 2025 still feels like competing in the GPU Hunger Games. But what if you could 5x your clusters efficiency using battle-tested Comp. Sci. principlesnot magic? Join us to explore how the open-source project Production Stack (a first-party vLLM project) supercharges vLLM on K8s with: - Cache: Offload KV Cache using LMCache to CPU/disk/remote storage(no redundant computations!) - Smarter Routing: Match requests to GPUs with pre-computed caches (lower TTFT) - Fault Tolerance++: Migrate live requests mid-generation during failures - RAG Revolution: Blend non-prefix caches from retrieved chunks(CacheBlend=3x faster TTFT) - Benchmarks Dont Lie: See 5x throughput vs. vanilla vLLM in real-world tests Whether youre an Infra Engineer, ML Developer or SRE, this deep dive will leave you with actionable patterns to deploy faster,cheaper & more reliably.",
        "url": "http://kccncna2025.sched.com/event/d216aaadbc58eccdd217ab15157be904",
        "uid": "d216aaadbc58eccdd217ab15157be904",
        "start": "2025-11-12T17:30:00-05:00",
        "end": "2025-11-12T18:00:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 1"
        },
        "speakers": [
          {
            "name": "Yuhan Liu",
            "company": "University of Chicago"
          },
          {
            "name": "Suraj Deshmukh",
            "company": "Microsoft"
          }
        ]
      }
    },
    {
      "text": "Machine learning jobs are particularly vulnerable to node disruptionswhether planned (like host maintenance, kernel upgrades, or security patches) or unplanned (such as GPU ECC memory errors or sudden node failures). These interruptions can derail progress and waste valuable training time. In this talk, well explore how to build disruption-tolerant ML infrastructure on Kubernetes that balances platform reliability with job continuity. Well cover techniques weve developed and battle-tested at scale, including:  Automatic Multi-stage checkpoint and restore of training jobs to allow fast and seamless recovery after interruptions.  Intelligent scheduling and smart collocation to account for node health, job characteristics, and maintenance timing.  Job-aware backpressure mechanisms that coordinate updates and reduce the likelihood of disruption during critical job phases. Attendees will leave with practical strategies for managing infrastructure disruptions leveraging Kubernetes. Speakers: Cong Gu from  LinkedIn, Ankit Goyal from  LinkedIn. Location: Building B | Level 4 | B401-402. Categories: AI + ML.",
      "metadata": {
        "title": "Prepare for Disruptions: How We Upgrade the Whole ML Training Fleet Bi-weekly",
        "description": "Machine learning jobs are particularly vulnerable to node disruptionswhether planned (like host maintenance, kernel upgrades, or security patches) or unplanned (such as GPU ECC memory errors or sudden node failures). These interruptions can derail progress and waste valuable training time. In this talk, well explore how to build disruption-tolerant ML infrastructure on Kubernetes that balances platform reliability with job continuity. Well cover techniques weve developed and battle-tested at scale, including:  Automatic Multi-stage checkpoint and restore of training jobs to allow fast and seamless recovery after interruptions.  Intelligent scheduling and smart collocation to account for node health, job characteristics, and maintenance timing.  Job-aware backpressure mechanisms that coordinate updates and reduce the likelihood of disruption during critical job phases. Attendees will leave with practical strategies for managing infrastructure disruptions leveraging Kubernetes.",
        "url": "http://kccncna2025.sched.com/event/f0846d3d9f7c8da0fb85a3f7d7f9d244",
        "uid": "f0846d3d9f7c8da0fb85a3f7d7f9d244",
        "start": "2025-11-12T17:30:00-05:00",
        "end": "2025-11-12T18:00:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B401-402"
        },
        "speakers": [
          {
            "name": "Cong Gu",
            "company": " LinkedIn"
          },
          {
            "name": "Ankit Goyal",
            "company": " LinkedIn"
          }
        ]
      }
    },
    {
      "text": "Modern cloud-native systems constantly generate data changes, and applications often need to react to them. Building change-driven solutions that respond to specific changes in distributed data is challenging. This talk introduces Drasi, a CNCF Sandbox project that simplifies the design and implementation of change-driven architectures by codifying continuous query and reaction patterns. For example, with Drasi you can declaratively write automation to detect and respond to running containers with newly identified vulnerabilities across pods and deployments in a Kubernetes cluster. Join us for a walkthrough of real-world use cases and live demos that show how Drasis approach brings structure and responsiveness to complex distributed environmentswithout writing custom code. Speakers: Aman Singh from Microsoft. Location: Building B | Level 3 | B308-309. Categories: APPLICATION DEVELOPMENT.",
      "metadata": {
        "title": "Drasi: A New Take on Change-driven Architectures",
        "description": "Modern cloud-native systems constantly generate data changes, and applications often need to react to them. Building change-driven solutions that respond to specific changes in distributed data is challenging. This talk introduces Drasi, a CNCF Sandbox project that simplifies the design and implementation of change-driven architectures by codifying continuous query and reaction patterns. For example, with Drasi you can declaratively write automation to detect and respond to running containers with newly identified vulnerabilities across pods and deployments in a Kubernetes cluster. Join us for a walkthrough of real-world use cases and live demos that show how Drasis approach brings structure and responsiveness to complex distributed environmentswithout writing custom code.",
        "url": "http://kccncna2025.sched.com/event/9fd4063696ea66fe83345030ce2e84f5",
        "uid": "9fd4063696ea66fe83345030ce2e84f5",
        "start": "2025-11-12T17:30:00-05:00",
        "end": "2025-11-12T18:00:00-05:00",
        "categories": [
          "APPLICATION DEVELOPMENT"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B308-309"
        },
        "speakers": [
          {
            "name": "Aman Singh",
            "company": "Microsoft"
          }
        ]
      }
    },
    {
      "text": "Edge computing is still a fairly new area in the cloud native tech industry and is growing fast. As computing moves to the edge, what does Kubernetes look like beyond the cloud, and why does it matter?\n\nThis session features a live demo with a Raspberry Pi, camera, and real-time AI detection. Watch as our edge device identifies raised hands, sends data to a Kubernetes cluster via KubeEdge, and visualizes results instantly.\n\nWe'll explore:\n- Edge Kubernetes challenges: connectivity, resources, security\n- KubeEdge's approach to decentralized workloads\n- Real-world applications across industries\n\nJoin us to see how AI, Kubernetes, and edge computing converge to enable powerful new possibilities. Speakers: Xavier Avrillier from  Giant Swarm, Antonia von den Driesch from  Giant Swarm. Location: Building B | Level 2 | B206. Categories: EMERGING + ADVANCED.",
      "metadata": {
        "title": "Kubernetes at the Edge  Come See It in Action!",
        "description": "Edge computing is still a fairly new area in the cloud native tech industry and is growing fast. As computing moves to the edge, what does Kubernetes look like beyond the cloud, and why does it matter?\n\nThis session features a live demo with a Raspberry Pi, camera, and real-time AI detection. Watch as our edge device identifies raised hands, sends data to a Kubernetes cluster via KubeEdge, and visualizes results instantly.\n\nWe'll explore:\n- Edge Kubernetes challenges: connectivity, resources, security\n- KubeEdge's approach to decentralized workloads\n- Real-world applications across industries\n\nJoin us to see how AI, Kubernetes, and edge computing converge to enable powerful new possibilities.",
        "url": "http://kccncna2025.sched.com/event/2d99292a77009f44de0c1eb7b614ef92",
        "uid": "2d99292a77009f44de0c1eb7b614ef92",
        "start": "2025-11-12T17:30:00-05:00",
        "end": "2025-11-12T18:00:00-05:00",
        "categories": [
          "EMERGING + ADVANCED"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B206"
        },
        "speakers": [
          {
            "name": "Xavier Avrillier",
            "company": " Giant Swarm"
          },
          {
            "name": "Antonia von den Driesch",
            "company": " Giant Swarm"
          }
        ]
      }
    },
    {
      "text": "Not only Kubernetes but a myriad of projects have evolved to be the core of the infrastructure for many companies. With this evolution, new challenges arise, including management, Day 2 operations, sustainability, and many more. If you care about the resilience and operational health of your Cloud-Native Infrastructure, join us in this session.\n\nYou will meet the recently elected leadership of the CNCF Technical Advisor Group (TAG), which is responsible for Operational Resilience.\nThe recently created OpRes TAG is responsible for Observability, Management, Business Continuity, Resource Optimization, Cost Efficiency, Energy, Performance, Troubleshooting, Reliability, and Day 2 Operations of Cloud Native infrastructure.\n\nYou will gain a bird's-eye view of the CNCF projects that fall under this TAG and explore how you can contribute to making the Cloud Native ecosystem more resilient and easier to manage, helping to shape the future of Cloud Native standards for Day 2. Speakers: TAG Operational Resilience - Rafael Brito from StormForge, Mario Fahlandt from Kubermatic, Saiyam Pathak from LoftLabs, Alolita Sharma from Apple, Nabarun Pal from Broadcom. Location: Building B | Level 5 | Thomas Murphy Ballroom 2-3. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Building Resilient Cloud Native Infrastructure in the Second Decade",
        "description": "Not only Kubernetes but a myriad of projects have evolved to be the core of the infrastructure for many companies. With this evolution, new challenges arise, including management, Day 2 operations, sustainability, and many more. If you care about the resilience and operational health of your Cloud-Native Infrastructure, join us in this session.\n\nYou will meet the recently elected leadership of the CNCF Technical Advisor Group (TAG), which is responsible for Operational Resilience.\nThe recently created OpRes TAG is responsible for Observability, Management, Business Continuity, Resource Optimization, Cost Efficiency, Energy, Performance, Troubleshooting, Reliability, and Day 2 Operations of Cloud Native infrastructure.\n\nYou will gain a bird's-eye view of the CNCF projects that fall under this TAG and explore how you can contribute to making the Cloud Native ecosystem more resilient and easier to manage, helping to shape the future of Cloud Native standards for Day 2.",
        "url": "http://kccncna2025.sched.com/event/433e1e327375b0821bef0128dd1d8963",
        "uid": "433e1e327375b0821bef0128dd1d8963",
        "start": "2025-11-12T17:30:00-05:00",
        "end": "2025-11-12T18:00:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 2-3"
        },
        "speakers": [
          {
            "name": "TAG Operational Resilience - Rafael Brito",
            "company": "StormForge"
          },
          {
            "name": "Mario Fahlandt",
            "company": "Kubermatic"
          },
          {
            "name": "Saiyam Pathak",
            "company": "LoftLabs"
          },
          {
            "name": "Alolita Sharma",
            "company": "Apple"
          },
          {
            "name": "Nabarun Pal",
            "company": "Broadcom"
          }
        ]
      }
    },
    {
      "text": "In this maintainer track we'll cover existing and upcoming features that allow developers to more easily create complex workflow based applications, as well as Agentic AI systems. We will also showcase Dapr's role as an Application Developer Platform that is filling the gap required to govern and regulate access from applications to their underlying infrastructure and providing zero-trust security, agent-to-agent discovery and event ingestion to AI agent frameworks like LangGraph, CrewAI and others Speakers: Yaron Schneider from Diagrid, Rajesh Iyer from JPMC. Location: Building C | Level 3 | Georgia Ballroom 3. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Dapr in 2026: Durable Execution and Resilient Eventing for AI Agents",
        "description": "In this maintainer track we'll cover existing and upcoming features that allow developers to more easily create complex workflow based applications, as well as Agentic AI systems. We will also showcase Dapr's role as an Application Developer Platform that is filling the gap required to govern and regulate access from applications to their underlying infrastructure and providing zero-trust security, agent-to-agent discovery and event ingestion to AI agent frameworks like LangGraph, CrewAI and others",
        "url": "http://kccncna2025.sched.com/event/98dbc4305596079881846b4b2cad6135",
        "uid": "98dbc4305596079881846b4b2cad6135",
        "start": "2025-11-12T17:30:00-05:00",
        "end": "2025-11-12T18:00:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 3"
        },
        "speakers": [
          {
            "name": "Yaron Schneider",
            "company": "Diagrid"
          },
          {
            "name": "Rajesh Iyer",
            "company": "JPMC"
          }
        ]
      }
    },
    {
      "text": "This talk is for CNCF project maintainers and community members who want to help projects improve the maturity of their security practices.\n\nTAG Security and Compliance maintains a number of sub-projects and initiatives aimed to help projects improve their security posture and reduce the likelihood and impact of vulnerabilities. Some of these services (like joint security assessments) are mandatory for projects looking to graduate through the CNCF lifecycle phases, while others are used to form recommendations for CNCF policy or are purely advisory. In this talk, Eddie and Evan will walk projects through the TAG services as well as complementary services such as LF code audits, OpenSSF Scorecard, and Best Practices Badge. You'll walk away with practical information about when projects should engage various activities and a clear understanding of the benefits that each service provides. Speakers: A Tour of TAG Security and Compliance Project Services - Evan Anderson from Custcodian, Brandt Keller from Defense Unicorns. Location: Building C | Level 3 | Georgia Ballroom 1. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "MUST/SHOULD/MAY",
        "description": "This talk is for CNCF project maintainers and community members who want to help projects improve the maturity of their security practices.\n\nTAG Security and Compliance maintains a number of sub-projects and initiatives aimed to help projects improve their security posture and reduce the likelihood and impact of vulnerabilities. Some of these services (like joint security assessments) are mandatory for projects looking to graduate through the CNCF lifecycle phases, while others are used to form recommendations for CNCF policy or are purely advisory. In this talk, Eddie and Evan will walk projects through the TAG services as well as complementary services such as LF code audits, OpenSSF Scorecard, and Best Practices Badge. You'll walk away with practical information about when projects should engage various activities and a clear understanding of the benefits that each service provides.",
        "url": "http://kccncna2025.sched.com/event/10e42c5092d57fba739fe87b0a53c68b",
        "uid": "10e42c5092d57fba739fe87b0a53c68b",
        "start": "2025-11-12T17:30:00-05:00",
        "end": "2025-11-12T18:00:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 1"
        },
        "speakers": [
          {
            "name": "A Tour of TAG Security and Compliance Project Services - Evan Anderson",
            "company": "Custcodian"
          },
          {
            "name": "Brandt Keller",
            "company": "Defense Unicorns"
          }
        ]
      }
    },
    {
      "text": "SIG-Multicluster is focused on solving common challenges related to the management of many Kubernetes clusters, and applications deployed across many clusters, or even across cloud providers.\n\nIn this session, we'll give attendees an overview of the current status of the multi-cluster problem space in Kubernetes and of the SIG. Well discuss current thinking around best practices for multi-cluster deployments and what it means to be part of a ClusterSet. Then well highlight current SIG projects, focused use cases, and ideas for whats next.\n\nMost importantly, well provide information on how you can get involved either as a contributor or as a user who wants to provide feedback about the SIG's current efforts and future direction. Bring your questions, problems, and ideas - help us expand the multi-cluster Kubernetes landscape! Speakers: Stephen Kitt from Red Hat, Pavanipriya Sajja from Independent, Jeremy Olmsted-Thompson from Google. Location: Building C | Level 1 | C111-112. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "SIG-Multicluster Intro and Deep Dive",
        "description": "SIG-Multicluster is focused on solving common challenges related to the management of many Kubernetes clusters, and applications deployed across many clusters, or even across cloud providers.\n\nIn this session, we'll give attendees an overview of the current status of the multi-cluster problem space in Kubernetes and of the SIG. Well discuss current thinking around best practices for multi-cluster deployments and what it means to be part of a ClusterSet. Then well highlight current SIG projects, focused use cases, and ideas for whats next.\n\nMost importantly, well provide information on how you can get involved either as a contributor or as a user who wants to provide feedback about the SIG's current efforts and future direction. Bring your questions, problems, and ideas - help us expand the multi-cluster Kubernetes landscape!",
        "url": "http://kccncna2025.sched.com/event/7c17a2fefb35507a1164adede8cd3934",
        "uid": "7c17a2fefb35507a1164adede8cd3934",
        "start": "2025-11-12T17:30:00-05:00",
        "end": "2025-11-12T18:00:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "1",
          "room": "C111-112"
        },
        "speakers": [
          {
            "name": "Stephen Kitt",
            "company": "Red Hat"
          },
          {
            "name": "Pavanipriya Sajja",
            "company": "Independent"
          },
          {
            "name": "Jeremy Olmsted-Thompson",
            "company": "Google"
          }
        ]
      }
    },
    {
      "text": "In this case study, well share how our team guarantees that the software we ship - packaged as a Helm chart and running in customer clusters - is performant under any situation a customer can put it in. When traditional metrics fell short, we turned to kernel-level eBPF profiling using Pixie and continuous profiling using Pyroscope. Along with OpenTelemetry tracing, we were able to drill down into our implementation's hotspots. By deploying this tooling in our own clusters, pushing our software to its limits, and correlating the telemetry gathered, we uncovered inefficient loops, then rolled out fixes before our customers hit these problems themselves. Attendees will walk away with a framework of observability tooling to enable the analysis of applications running in-cluster, and allow them to find and fix performance regressions faster than ever before! Speakers: Liam Mackie from Octopus Deploy. Location: Building B | Level 5 | Thomas Murphy Ballroom 4. Categories: OBSERVABILITY.",
      "metadata": {
        "title": "Diagnosing Application Performance With EBPF, Pyroscope, and Kubernetes",
        "description": "In this case study, well share how our team guarantees that the software we ship - packaged as a Helm chart and running in customer clusters - is performant under any situation a customer can put it in. When traditional metrics fell short, we turned to kernel-level eBPF profiling using Pixie and continuous profiling using Pyroscope. Along with OpenTelemetry tracing, we were able to drill down into our implementation's hotspots. By deploying this tooling in our own clusters, pushing our software to its limits, and correlating the telemetry gathered, we uncovered inefficient loops, then rolled out fixes before our customers hit these problems themselves. Attendees will walk away with a framework of observability tooling to enable the analysis of applications running in-cluster, and allow them to find and fix performance regressions faster than ever before!",
        "url": "http://kccncna2025.sched.com/event/19ffa39e89e6465e7d7508a9ba574609",
        "uid": "19ffa39e89e6465e7d7508a9ba574609",
        "start": "2025-11-12T17:30:00-05:00",
        "end": "2025-11-12T18:00:00-05:00",
        "categories": [
          "OBSERVABILITY"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 4"
        },
        "speakers": [
          {
            "name": "Liam Mackie",
            "company": "Octopus Deploy"
          }
        ]
      }
    },
    {
      "text": "Stories of time wasted and (lots of emotions). What time do we really measure when we instrument our applications and try to collect request duration times? What conclusions do we draw when the request duration reported by client requests dont even come close to the times reported by the server? Do we blame our network, our reverse proxies or our monitoring tools when dark matter gaps exist in our traces? This talk covers some subtle nuances in request duration measurement, which can often lead to completely misleading results. We dig deep into the OpenTelemetry instrumentation approaches in a few popular programming languages and correlate what the duration timings we see in our traces or logs mean. We'll show how using the newly donated OpenTelemetry eBPF Instrumentation for application instrumentation allows us to augment our telemetry to overcome various inaccuracies in duration measurement... and get closer to the truth. Speakers: Sam Alipio from  Grafana Labs, Mario Macias from  Grafana Labs. Location: Building B | Level 3 | B304-305. Categories: OBSERVABILITY.",
      "metadata": {
        "title": "Observing Dark Matter With OpenTelemetry",
        "description": "Stories of time wasted and (lots of emotions). What time do we really measure when we instrument our applications and try to collect request duration times? What conclusions do we draw when the request duration reported by client requests dont even come close to the times reported by the server? Do we blame our network, our reverse proxies or our monitoring tools when dark matter gaps exist in our traces? This talk covers some subtle nuances in request duration measurement, which can often lead to completely misleading results. We dig deep into the OpenTelemetry instrumentation approaches in a few popular programming languages and correlate what the duration timings we see in our traces or logs mean. We'll show how using the newly donated OpenTelemetry eBPF Instrumentation for application instrumentation allows us to augment our telemetry to overcome various inaccuracies in duration measurement... and get closer to the truth.",
        "url": "http://kccncna2025.sched.com/event/7af05c9003f8c9367fb5bfaf32f4cb67",
        "uid": "7af05c9003f8c9367fb5bfaf32f4cb67",
        "start": "2025-11-12T17:30:00-05:00",
        "end": "2025-11-12T18:00:00-05:00",
        "categories": [
          "OBSERVABILITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B304-305"
        },
        "speakers": [
          {
            "name": "Sam Alipio",
            "company": " Grafana Labs"
          },
          {
            "name": "Mario Macias",
            "company": " Grafana Labs"
          }
        ]
      }
    },
    {
      "text": "Composable platforms are redefining how internal platform teams deliver value. While the theory is compelling, the real-world results can be mixed. In this talk, well explore the patterns that actually work (and the ones that dont) when building composable platforms using Kubernetes, and tools like Backstage, Crossplane, and Kratix. Drawing from experience across regulated enterprises, scaling startups, and open source communities, well examine how teams are approaching modular service delivery, integrating self-service with governance, and balancing autonomy with consistency. You'll learn: - Which architectural and team patterns accelerate platform adoption - Why some composability efforts create more confusion than clarity with janky abstractions - How to identify early warning signs of failure, such as bloated GitOps repos and overly rigid golden paths This talk is for platform engineers, architects, and leaders who want to make composable platforms deliver real outcomes. Speakers: Daniel Bryant from Syntasso. Location: Building B | Level 4 | B405-406a. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "Composable Platforms in the Wild: Patterns That Work (and Fail)",
        "description": "Composable platforms are redefining how internal platform teams deliver value. While the theory is compelling, the real-world results can be mixed. In this talk, well explore the patterns that actually work (and the ones that dont) when building composable platforms using Kubernetes, and tools like Backstage, Crossplane, and Kratix. Drawing from experience across regulated enterprises, scaling startups, and open source communities, well examine how teams are approaching modular service delivery, integrating self-service with governance, and balancing autonomy with consistency. You'll learn: - Which architectural and team patterns accelerate platform adoption - Why some composability efforts create more confusion than clarity with janky abstractions - How to identify early warning signs of failure, such as bloated GitOps repos and overly rigid golden paths This talk is for platform engineers, architects, and leaders who want to make composable platforms deliver real outcomes.",
        "url": "http://kccncna2025.sched.com/event/021d9f8990e7325942832c3da4962034",
        "uid": "021d9f8990e7325942832c3da4962034",
        "start": "2025-11-12T17:30:00-05:00",
        "end": "2025-11-12T18:00:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B405-406a"
        },
        "speakers": [
          {
            "name": "Daniel Bryant",
            "company": "Syntasso"
          }
        ]
      }
    },
    {
      "text": "In 2020, a team of engineers at Auth0 selected Argo Workflows and ArgoCD for their new private cloud platform because of the Kubernetes compatibility, support for Kustomize, and ability to speed up the initial implementation efforts. Since then, the platform has scaled dramatically, to nearly a thousand clusters, 1M+ resources and hundreds of daily deploys. Argo has continued to prove its value, adapting seamlessly to the platforms rapid growth and evolving requirements. At KubeCon NA last year Kahou and Jeremy presented their red/black deployment strategy for zero-downtime daily updates across numerous clusters. This time they will focus on Argo, a central component of their platform's architecture. Their presentation will cover the evolution of their Argo usage and the difficulties they faced. They will share the solutions they implemented, the present status of their Argo deployments, the existing limitations, and their rationale for choosing Argo over alternative solutions. Speakers: Jeremy Albuixech from  Okta, Kahou Lei from  Okta. Location: Building B | Level 3 | B312-314. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "One Dozen To One Thousand Clusters: How Argo Kept up as We Scaled",
        "description": "In 2020, a team of engineers at Auth0 selected Argo Workflows and ArgoCD for their new private cloud platform because of the Kubernetes compatibility, support for Kustomize, and ability to speed up the initial implementation efforts. Since then, the platform has scaled dramatically, to nearly a thousand clusters, 1M+ resources and hundreds of daily deploys. Argo has continued to prove its value, adapting seamlessly to the platforms rapid growth and evolving requirements. At KubeCon NA last year Kahou and Jeremy presented their red/black deployment strategy for zero-downtime daily updates across numerous clusters. This time they will focus on Argo, a central component of their platform's architecture. Their presentation will cover the evolution of their Argo usage and the difficulties they faced. They will share the solutions they implemented, the present status of their Argo deployments, the existing limitations, and their rationale for choosing Argo over alternative solutions.",
        "url": "http://kccncna2025.sched.com/event/01e0bad28406239fda7e2ae01f6907de",
        "uid": "01e0bad28406239fda7e2ae01f6907de",
        "start": "2025-11-12T17:30:00-05:00",
        "end": "2025-11-12T18:00:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B312-314"
        },
        "speakers": [
          {
            "name": "Jeremy Albuixech",
            "company": " Okta"
          },
          {
            "name": "Kahou Lei",
            "company": " Okta"
          }
        ]
      }
    },
    {
      "text": "Self-service database platforms help teams move fastbut only if engineers can help themselves. Over the past two years, the HubSpot data infrastructure team has built and evolved a suite of LLM-powered tools to assist developers working with their large Vitess installation running on Kubernetes. In this talk, the team will share what worked (and what didn't): from interpreting slow query plans to guiding self-scaling decisions to failed attempts at RAG-based documentation search. Participants will learn about latency workarounds, integrations with chat and UI flows, prompt pitfalls, and the essential glue work that made it all usable. Speakers: Brett Warminski from  Hubspot, Gourav Khanijoe from  Hubspot. Location: Building B | Level 4 | B406b-407. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "Why Is My Query Slow? Real AI Use Cases With Vitess + Kubernetes + Prometheus",
        "description": "Self-service database platforms help teams move fastbut only if engineers can help themselves. Over the past two years, the HubSpot data infrastructure team has built and evolved a suite of LLM-powered tools to assist developers working with their large Vitess installation running on Kubernetes. In this talk, the team will share what worked (and what didn't): from interpreting slow query plans to guiding self-scaling decisions to failed attempts at RAG-based documentation search. Participants will learn about latency workarounds, integrations with chat and UI flows, prompt pitfalls, and the essential glue work that made it all usable.",
        "url": "http://kccncna2025.sched.com/event/569e805d1f26d66fe306c1d3544cdeeb",
        "uid": "569e805d1f26d66fe306c1d3544cdeeb",
        "start": "2025-11-12T17:30:00-05:00",
        "end": "2025-11-12T18:00:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B406b-407"
        },
        "speakers": [
          {
            "name": "Brett Warminski",
            "company": " Hubspot"
          },
          {
            "name": "Gourav Khanijoe",
            "company": " Hubspot"
          }
        ]
      }
    },
    {
      "text": "Kubernetes teams are drowning in dashboards, buried in YAML, and haunted by the ghost of shift left. Everyone says security is built-in, but breaches still happen, compliance still bites and engineers are still burned out. So whats actually working... and whats just performative security theater? This women-led panel cuts through the noise. Featuring OSS contributors, DevSecOps veterans, and security leads from production-grade, cloud-native environments, were here to talk honestly about what breaks, what works, and whats pure illusion. Theyre contributors and practitioners behind CNCF toolsetsand theyve seen it all: what works, what fails, and what we wish we knew earlier. Explore whats real vs. theater in Kubernetes security: how to measure impact, where CNCF tools help (or fall short), and how to stay effective under pressure. No fluff, no vendor pitches. Just battle-tested insights from engineers on the front lines of securing cloud-native infrastructure at scale. Speakers: Rotem Refael from ARMO, Constanze Roedig from Technical University of Vienna, Megan Wolf from Defense Unicorns, Stefana Muller from Salesforce, Oshrat Nir from Independent. Location: Building B | Level 3 | B302-303. Categories: SECURITY.",
      "metadata": {
        "title": "Security Theater or Real Defense? Navigating Open Source Security in a Cloud Native World",
        "description": "Kubernetes teams are drowning in dashboards, buried in YAML, and haunted by the ghost of shift left. Everyone says security is built-in, but breaches still happen, compliance still bites and engineers are still burned out. So whats actually working... and whats just performative security theater? This women-led panel cuts through the noise. Featuring OSS contributors, DevSecOps veterans, and security leads from production-grade, cloud-native environments, were here to talk honestly about what breaks, what works, and whats pure illusion. Theyre contributors and practitioners behind CNCF toolsetsand theyve seen it all: what works, what fails, and what we wish we knew earlier. Explore whats real vs. theater in Kubernetes security: how to measure impact, where CNCF tools help (or fall short), and how to stay effective under pressure. No fluff, no vendor pitches. Just battle-tested insights from engineers on the front lines of securing cloud-native infrastructure at scale.",
        "url": "http://kccncna2025.sched.com/event/cdc32938409c903665846d230588e065",
        "uid": "cdc32938409c903665846d230588e065",
        "start": "2025-11-12T17:30:00-05:00",
        "end": "2025-11-12T18:00:00-05:00",
        "categories": [
          "SECURITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B302-303"
        },
        "speakers": [
          {
            "name": "Rotem Refael",
            "company": "ARMO"
          },
          {
            "name": "Constanze Roedig",
            "company": "Technical University of Vienna"
          },
          {
            "name": "Megan Wolf",
            "company": "Defense Unicorns"
          },
          {
            "name": "Stefana Muller",
            "company": "Salesforce"
          },
          {
            "name": "Oshrat Nir",
            "company": "Independent"
          }
        ]
      }
    },
    {
      "text": "Kubernetes environments are inherently complex especially in regulated industries due to integrations with service meshes, secrets management, and policy engines. Traditional threat modeling often struggles to keep up with this dynamic ecosystem.\n\nIn this 5-minute session, Ill introduce a streamlined, Kubernetes-specific threat modeling approach that integrates naturally into dev and SRE workflows. Youll learn how to quickly identify risks across clusters, workloads, and third-party components.\n\nWell also cover how large language models (LLMs) can support this process by generating threat scenarios, mapping to MITRE ATT&CK, and helping teams continuously refine their security posture.\nYoull leave with actionable tactics to embed threat modeling into your engineering practices fast, repeatable, and built for modern cloud-native environments. Speakers: Maxime Coquerel from Royal Bank of Canada. Location: Building C | Level 3 | Georgia Ballroom 2. Categories:  LIGHTNING TALKS.",
      "metadata": {
        "title": "Lightning Talk: Threat Modeling Kubernetes: Fast, Practical, and LLM-Driven",
        "description": "Kubernetes environments are inherently complex especially in regulated industries due to integrations with service meshes, secrets management, and policy engines. Traditional threat modeling often struggles to keep up with this dynamic ecosystem.\n\nIn this 5-minute session, Ill introduce a streamlined, Kubernetes-specific threat modeling approach that integrates naturally into dev and SRE workflows. Youll learn how to quickly identify risks across clusters, workloads, and third-party components.\n\nWell also cover how large language models (LLMs) can support this process by generating threat scenarios, mapping to MITRE ATT&CK, and helping teams continuously refine their security posture.\nYoull leave with actionable tactics to embed threat modeling into your engineering practices fast, repeatable, and built for modern cloud-native environments.",
        "url": "http://kccncna2025.sched.com/event/467625f7649ca91246f0249c3de7764d",
        "uid": "467625f7649ca91246f0249c3de7764d",
        "start": "2025-11-12T17:34:00-05:00",
        "end": "2025-11-12T17:39:00-05:00",
        "categories": [
          " LIGHTNING TALKS"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 2"
        },
        "speakers": [
          {
            "name": "Maxime Coquerel",
            "company": "Royal Bank of Canada"
          }
        ]
      }
    },
    {
      "text": "Large-language-modelpowered features feel like magicuntil the magic misfires in production. Unlike the rest of our cloud-native stack, LLM apps are non-deterministic: the same prompt can yield wildly different outputs depending on model state, temperature, etc. Traditional pre-prod tests catch only a fraction of these edge cases.\n\nIn this lightning talk, Ill demo a vibe-coded LLM application that looks fine in dev but hallucinates customer-visible issues once real traffic hits.\n\nI will then inject OpenTelemetry spans and semantic attributes (prompt, temperature, model version, vector-DB latency, user feedback) and stream them into an open source observability backend. Attendees can watch in real time as traces pinpoint where uncertainty mutates into failureturning opaque AI behavior into measurable, alertable signals.\n\nAttendees will leave with a template on how to make their application more observable and reliable using OpenTelemetry Speakers: Pranay Prateek from SigNoz. Location: Building C | Level 3 | Georgia Ballroom 2. Categories:  LIGHTNING TALKS.",
      "metadata": {
        "title": "Lightning Talk: Tracing the Untraceable: OpenTelemetry for Vibe-Coded LLM Apps",
        "description": "Large-language-modelpowered features feel like magicuntil the magic misfires in production. Unlike the rest of our cloud-native stack, LLM apps are non-deterministic: the same prompt can yield wildly different outputs depending on model state, temperature, etc. Traditional pre-prod tests catch only a fraction of these edge cases.\n\nIn this lightning talk, Ill demo a vibe-coded LLM application that looks fine in dev but hallucinates customer-visible issues once real traffic hits.\n\nI will then inject OpenTelemetry spans and semantic attributes (prompt, temperature, model version, vector-DB latency, user feedback) and stream them into an open source observability backend. Attendees can watch in real time as traces pinpoint where uncertainty mutates into failureturning opaque AI behavior into measurable, alertable signals.\n\nAttendees will leave with a template on how to make their application more observable and reliable using OpenTelemetry",
        "url": "http://kccncna2025.sched.com/event/d7cae2be28801fa2b978fddb81dff393",
        "uid": "d7cae2be28801fa2b978fddb81dff393",
        "start": "2025-11-12T17:41:00-05:00",
        "end": "2025-11-12T17:46:00-05:00",
        "categories": [
          " LIGHTNING TALKS"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 2"
        },
        "speakers": [
          {
            "name": "Pranay Prateek",
            "company": "SigNoz"
          }
        ]
      }
    },
    {
      "text": "Location: Building B | Level 1 | Exhibit Hall B2. Categories: KEYNOTE SESSIONS.",
      "metadata": {
        "title": "Keynote: Welcome Back + Opening Remarks",
        "description": "",
        "url": "http://kccncna2025.sched.com/event/87962c59ecd28ba2ed01d265954dd21e",
        "uid": "87962c59ecd28ba2ed01d265954dd21e",
        "start": "2025-11-13T09:00:00-05:00",
        "end": "2025-11-13T09:05:00-05:00",
        "categories": [
          "KEYNOTE SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B2"
        }
      }
    },
    {
      "text": "Cloud native has always been about more than technology. Each wave of innovation, from early projects reshaping deployment to todays higher-level platforms, has combined technical progress with shifts in how organisations deliver value. Yet too often these movements narrow into tool-centric quick fixes.\nPlatform engineering sits at these crossroads. On one side it risks becoming another hype cycle, but on the other it offers a way out of todays fragmented, unsustainable reality.\n\nThis keynote explores how decades of platform experience paired with the Linux Foundation and CNCF are guiding this evolution through community groups, white papers, and foundational technologies. It will challenge us to see platform engineering not as another operational trend, but as a higher-level abstraction, one that highlights organisational patterns, tackles interoperability, and informs architectural choices to ensure platforms deliver lasting value. Speakers: Abby Bangser Principal Engineer from Syntasso. Location: Building B | Level 1 | Exhibit Hall B2. Categories: KEYNOTE SESSIONS.",
      "metadata": {
        "title": "Keynote: Beyond Operations: Scaling Platform Engineering in the CNCF Community",
        "description": "Cloud native has always been about more than technology. Each wave of innovation, from early projects reshaping deployment to todays higher-level platforms, has combined technical progress with shifts in how organisations deliver value. Yet too often these movements narrow into tool-centric quick fixes.\nPlatform engineering sits at these crossroads. On one side it risks becoming another hype cycle, but on the other it offers a way out of todays fragmented, unsustainable reality.\n\nThis keynote explores how decades of platform experience paired with the Linux Foundation and CNCF are guiding this evolution through community groups, white papers, and foundational technologies. It will challenge us to see platform engineering not as another operational trend, but as a higher-level abstraction, one that highlights organisational patterns, tackles interoperability, and informs architectural choices to ensure platforms deliver lasting value.",
        "url": "http://kccncna2025.sched.com/event/6845980b5776eeba3bd6d667a95ad82d",
        "uid": "6845980b5776eeba3bd6d667a95ad82d",
        "start": "2025-11-13T09:07:00-05:00",
        "end": "2025-11-13T09:23:00-05:00",
        "categories": [
          "KEYNOTE SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B2"
        },
        "speakers": [
          {
            "name": "Abby Bangser",
            "title": "Principal Engineer",
            "company": "Syntasso"
          }
        ]
      }
    },
    {
      "text": "Open source and Kubernetes are at the heart of modern AI innovation. In this keynote, Cohere and Oracle Cloud Infrastructure (OCI) will share how Cohere builds and serves cutting-edge models on top of Kubernetes leveraging open source technologies and foundational infrastructure and tooling from OCI. Attendees will get an inside look at architectural choices and lessons learned from training and serving massive AI workloads for enterprises in regulated industries worldwide, as well as how open collaboration between cloud providers and AI pioneers is shaping the future of cloud native agentic AI. Speakers: Aanand Krishnan Vice President of Products at Oracle Cloud Infrastructure from Oracle. Location: Building B | Level 1 | Exhibit Hall B2. Categories: KEYNOTE SESSIONS.",
      "metadata": {
        "title": "Sponsored Keynote: Cloud Scale Enterprise AI: How Cohere Runs on Open Source with Oracle Cloud",
        "description": "Open source and Kubernetes are at the heart of modern AI innovation. In this keynote, Cohere and Oracle Cloud Infrastructure (OCI) will share how Cohere builds and serves cutting-edge models on top of Kubernetes leveraging open source technologies and foundational infrastructure and tooling from OCI. Attendees will get an inside look at architectural choices and lessons learned from training and serving massive AI workloads for enterprises in regulated industries worldwide, as well as how open collaboration between cloud providers and AI pioneers is shaping the future of cloud native agentic AI.",
        "url": "http://kccncna2025.sched.com/event/9b8ce3a327e7e354c77587f16e99ffd9",
        "uid": "9b8ce3a327e7e354c77587f16e99ffd9",
        "start": "2025-11-13T09:25:00-05:00",
        "end": "2025-11-13T09:30:00-05:00",
        "categories": [
          "KEYNOTE SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B2"
        },
        "speakers": [
          {
            "name": "Aanand Krishnan",
            "title": "Vice President of Products at Oracle Cloud Infrastructure",
            "company": "Oracle"
          }
        ]
      }
    },
    {
      "text": "Kubernetes networking is changing significantly by moving beyond traditional technologies to meet the demands of complex and evolving needs for AI and telecommunications applications. This talk delves into the next generation of Kubernetes networking by exploring the creation of a network driver using the Dynamic Resource Allocation (DRA) framework. We aim to simplify complex concepts, highlight the benefits of this flexible and adaptable approach, and offer a practical guide to help you get started with this innovative technology.\n\nAs active Kubernetes developers in networking and part of the WG Device Management group developing DRA, we have both contributed to modeling the existing API and created DRA Networking drivers, some of which are already used in production. The presenters will provide attendees with practical, field-tested knowledge and best practices derived from their unique position in developing and deploying DRA. Speakers: Lionel Jouin Software Engineer from Red Hat, Antonio Ojea Staff Software Engineer from Google. Location: Building B | Level 1 | Exhibit Hall B2. Categories: KEYNOTE SESSIONS.",
      "metadata": {
        "title": "Keynote: The Community-Driven Evolution of the Kubernetes Network Driver",
        "description": "Kubernetes networking is changing significantly by moving beyond traditional technologies to meet the demands of complex and evolving needs for AI and telecommunications applications. This talk delves into the next generation of Kubernetes networking by exploring the creation of a network driver using the Dynamic Resource Allocation (DRA) framework. We aim to simplify complex concepts, highlight the benefits of this flexible and adaptable approach, and offer a practical guide to help you get started with this innovative technology.\n\nAs active Kubernetes developers in networking and part of the WG Device Management group developing DRA, we have both contributed to modeling the existing API and created DRA Networking drivers, some of which are already used in production. The presenters will provide attendees with practical, field-tested knowledge and best practices derived from their unique position in developing and deploying DRA.",
        "url": "http://kccncna2025.sched.com/event/0f01fde37a81b8c9250a69cec81155d7",
        "uid": "0f01fde37a81b8c9250a69cec81155d7",
        "start": "2025-11-13T09:32:00-05:00",
        "end": "2025-11-13T09:47:00-05:00",
        "categories": [
          "KEYNOTE SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B2"
        },
        "speakers": [
          {
            "name": "Lionel Jouin",
            "title": "Software Engineer",
            "company": "Red Hat"
          },
          {
            "name": "Antonio Ojea",
            "title": "Staff Software Engineer",
            "company": "Google"
          }
        ]
      }
    },
    {
      "text": "As demand for AI workloads on Kubernetes grows, multicluster inferencing has emerged as a powerful yet complex architectural pattern. While multicluster support offers benefits in terms of geographic redundancy, data sovereignty, and resource optimization, it also introduces significant challenges around orchestration, traffic routing, cost control, and operational overhead.\n\nTo address these challenges, well introduce two CNCF projectsKAITO and KubeFleetthat work together to simplify and optimize multicluster AI operations. KAITO provides a declarative framework for managing AI inference workflows with built-in support for model versioning, and performance telemetry. KubeFleet complements this by enabling seamless workload distribution across clusters, based on cost, latency, and availability. Together, these tools reduce operational complexity, improve cost efficiency, and ensure consistent performance at scale. Speakers: Jorge Palma Principal PM Lead for Azure Kubernetes Services from Microsoft. Location: Building B | Level 1 | Exhibit Hall B2. Categories: KEYNOTE SESSIONS.",
      "metadata": {
        "title": "Sponsored Keynote: Scaling Smarter: Simplifying Multicluster AI with KAITO and KubeFleet",
        "description": "As demand for AI workloads on Kubernetes grows, multicluster inferencing has emerged as a powerful yet complex architectural pattern. While multicluster support offers benefits in terms of geographic redundancy, data sovereignty, and resource optimization, it also introduces significant challenges around orchestration, traffic routing, cost control, and operational overhead.\n\nTo address these challenges, well introduce two CNCF projectsKAITO and KubeFleetthat work together to simplify and optimize multicluster AI operations. KAITO provides a declarative framework for managing AI inference workflows with built-in support for model versioning, and performance telemetry. KubeFleet complements this by enabling seamless workload distribution across clusters, based on cost, latency, and availability. Together, these tools reduce operational complexity, improve cost efficiency, and ensure consistent performance at scale.",
        "url": "http://kccncna2025.sched.com/event/ba3d1e5865a7c31d8f0e66affc747118",
        "uid": "ba3d1e5865a7c31d8f0e66affc747118",
        "start": "2025-11-13T09:49:00-05:00",
        "end": "2025-11-13T09:54:00-05:00",
        "categories": [
          "KEYNOTE SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B2"
        },
        "speakers": [
          {
            "name": "Jorge Palma",
            "title": "Principal PM Lead for Azure Kubernetes Services",
            "company": "Microsoft"
          }
        ]
      }
    },
    {
      "text": "The Cloud Native Computing Foundation (CNCF) turns 10 this year, now home to more than 200 projects across the cloud native landscape. As we look ahead, the community faces new demands around security, sustainability, complexity, and emerging workloads like AI inference and agents. As many areas of the ecosystem transition to mature foundational building blocks, we are excited to explore the next evolution of cloud native development. &nbsp;The TOC will highlight how these challenges open opportunities to shape the next generation of applications and ensure the ecosystem continues to thrive.\n\nHow are new projects addressing these new emerging workloads?How will these new projects impact security hygiene in the ecosystem?How will existing projects adapt to meet new realities?How is the CNCF evolving to support this next generation of computing?\n\nJoin us as we reflect on the first decade of cloud nativeand look ahead to how this community will power the age of AI, intelligent systems, and beyond. Speakers: Jeremy Rickard Principal Software Engineer from Microsoft, Alex Chircop Chief Architect from Akamai. Location: Building B | Level 1 | Exhibit Hall B2. Categories: KEYNOTE SESSIONS.",
      "metadata": {
        "title": "Keynote: Cloud Native Back to the Future: The Road Ahead",
        "description": "The Cloud Native Computing Foundation (CNCF) turns 10 this year, now home to more than 200 projects across the cloud native landscape. As we look ahead, the community faces new demands around security, sustainability, complexity, and emerging workloads like AI inference and agents. As many areas of the ecosystem transition to mature foundational building blocks, we are excited to explore the next evolution of cloud native development. &nbsp;The TOC will highlight how these challenges open opportunities to shape the next generation of applications and ensure the ecosystem continues to thrive.\n\nHow are new projects addressing these new emerging workloads?How will these new projects impact security hygiene in the ecosystem?How will existing projects adapt to meet new realities?How is the CNCF evolving to support this next generation of computing?\n\nJoin us as we reflect on the first decade of cloud nativeand look ahead to how this community will power the age of AI, intelligent systems, and beyond.",
        "url": "http://kccncna2025.sched.com/event/bb98d5568eee2b21634f059f193ab2ba",
        "uid": "bb98d5568eee2b21634f059f193ab2ba",
        "start": "2025-11-13T09:56:00-05:00",
        "end": "2025-11-13T10:06:00-05:00",
        "categories": [
          "KEYNOTE SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B2"
        },
        "speakers": [
          {
            "name": "Jeremy Rickard",
            "title": "Principal Software Engineer",
            "company": "Microsoft"
          },
          {
            "name": "Alex Chircop",
            "title": "Chief Architect",
            "company": "Akamai"
          }
        ]
      }
    },
    {
      "text": "Most cloud native services scale horizontally by reacting to increased incoming traffic throughput, CPU utilization or any other relevant metric. While this approach works most of the time, the reaction time might not be fast enough for high velocity events, resulting in many customer facing errors (like high latency and checkout failures), consequently, impacting customer experience.\n\nIn this session, Chunpeng and Artur will delve into how Prime Day, Diwali, Black Friday and many other high velocity events are handled to keep all services at Amazon.com available. You will learn how we use machine learning and record keeping of future events to proactively scale thousands of services running on top of AWS and then de-scale to keep running at forecasted loads for business-as-usual. Speakers: Artur Souza from  Amazon, Chunpeng Wang from  Amazon. Location: Building B | Level 1 | Exhibit Hall B2. Categories: KEYNOTE SESSIONS.",
      "metadata": {
        "title": "Keynote: Predictive Scaling and Capacity Planning With Machine Learning at Amazon.com",
        "description": "Most cloud native services scale horizontally by reacting to increased incoming traffic throughput, CPU utilization or any other relevant metric. While this approach works most of the time, the reaction time might not be fast enough for high velocity events, resulting in many customer facing errors (like high latency and checkout failures), consequently, impacting customer experience.\n\nIn this session, Chunpeng and Artur will delve into how Prime Day, Diwali, Black Friday and many other high velocity events are handled to keep all services at Amazon.com available. You will learn how we use machine learning and record keeping of future events to proactively scale thousands of services running on top of AWS and then de-scale to keep running at forecasted loads for business-as-usual.",
        "url": "http://kccncna2025.sched.com/event/8254cbb190de8183cb515a3a6075cf07",
        "uid": "8254cbb190de8183cb515a3a6075cf07",
        "start": "2025-11-13T10:08:00-05:00",
        "end": "2025-11-13T10:23:00-05:00",
        "categories": [
          "KEYNOTE SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B2"
        },
        "speakers": [
          {
            "name": "Artur Souza",
            "company": " Amazon"
          },
          {
            "name": "Chunpeng Wang",
            "company": " Amazon"
          }
        ]
      }
    },
    {
      "text": "Take a break from the buzz of the Solutions Showcase and sit back and relax at the Relaxation Station. Enjoy a soothing massage, try your hand at crocheting, or challenge someone to a game of chess. This is the perfect spot to recharge and unwind before diving back into action.\n\nSponsored by: Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: EXPERIENCES.",
      "metadata": {
        "title": "Relaxation Station",
        "description": "Take a break from the buzz of the Solutions Showcase and sit back and relax at the Relaxation Station. Enjoy a soothing massage, try your hand at crocheting, or challenge someone to a game of chess. This is the perfect spot to recharge and unwind before diving back into action.\n\nSponsored by:",
        "url": "http://kccncna2025.sched.com/event/b558f4aae390e631f5170770d14e5a20",
        "uid": "b558f4aae390e631f5170770d14e5a20",
        "start": "2025-11-13T10:15:00-05:00",
        "end": "2025-11-13T14:00:00-05:00",
        "categories": [
          "EXPERIENCES"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies. Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: SOLUTIONS SHOWCASE.",
      "metadata": {
        "title": "Solutions Showcase",
        "description": "In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.",
        "url": "http://kccncna2025.sched.com/event/55c290133fb89181453aaca2cb520ba7",
        "uid": "55c290133fb89181453aaca2cb520ba7",
        "start": "2025-11-13T10:15:00-05:00",
        "end": "2025-11-13T14:00:00-05:00",
        "categories": [
          "SOLUTIONS SHOWCASE"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "Location: Building B | Level 1 | Exhibit Hall B2. Categories: KEYNOTE SESSIONS.",
      "metadata": {
        "title": "Keynote: Closing Remarks",
        "description": "",
        "url": "http://kccncna2025.sched.com/event/e1f9765a53cddec72776bed0e1c78d68",
        "uid": "e1f9765a53cddec72776bed0e1c78d68",
        "start": "2025-11-13T10:25:00-05:00",
        "end": "2025-11-13T10:30:00-05:00",
        "categories": [
          "KEYNOTE SESSIONS"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B2"
        }
      }
    },
    {
      "text": "Location: TBA. Categories: BREAKS.",
      "metadata": {
        "title": "Coffee Break ",
        "description": "",
        "url": "http://kccncna2025.sched.com/event/adc6e722fb111ae991912e6634aa778e",
        "uid": "adc6e722fb111ae991912e6634aa778e",
        "start": "2025-11-13T10:30:00-05:00",
        "end": "2025-11-13T11:00:00-05:00",
        "categories": [
          "BREAKS"
        ],
        "location": {
          "room": "TBA"
        }
      }
    },
    {
      "text": "In this talk we will introduce how KubeHound, an opinionated, scalable, offensive-minded Kubernetes attack graph tool used by security teams across Datadog, can help you pinpoint the most critical attack within your Kubernetes cluster. Single point security findings have little traction either for an attacker or defender. So we will demonstrate how KubeHound being a queryable, graph database of attack paths makes reasoning about security problems via data-driven testing of hypotheses extremely efficient. Live demos of KubeHound will be performed during the talk.\n\nAt the end of the talk, we will leave you with an open-source tool designed to be run from a laptop to evaluate the attack paths within a single cluster from an attacker or defender point of view. Finally, we will discuss the approach and challenges of implementing a distributed, large-scale version of the tool at Datadog and how you might implement a similar solution in your own environment.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.* Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: SOLUTIONS SHOWCASE.",
      "metadata": {
        "title": "Sponsored Demo: KubeHound: Identifying attack paths in Kubernetes clusters at scale",
        "description": "In this talk we will introduce how KubeHound, an opinionated, scalable, offensive-minded Kubernetes attack graph tool used by security teams across Datadog, can help you pinpoint the most critical attack within your Kubernetes cluster. Single point security findings have little traction either for an attacker or defender. So we will demonstrate how KubeHound being a queryable, graph database of attack paths makes reasoning about security problems via data-driven testing of hypotheses extremely efficient. Live demos of KubeHound will be performed during the talk.\n\nAt the end of the talk, we will leave you with an open-source tool designed to be run from a laptop to evaluate the attack paths within a single cluster from an attacker or defender point of view. Finally, we will discuss the approach and challenges of implementing a distributed, large-scale version of the tool at Datadog and how you might implement a similar solution in your own environment.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.*",
        "url": "http://kccncna2025.sched.com/event/494bdd24490062b738bf6190a5720e55",
        "uid": "494bdd24490062b738bf6190a5720e55",
        "start": "2025-11-13T10:35:00-05:00",
        "end": "2025-11-13T10:55:00-05:00",
        "categories": [
          "SOLUTIONS SHOWCASE"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "10-Minute Tip Talk Speakers: Clyde Seepersad from LF Education. Location: Level 1 | Learning Lounge. Categories: EXPERIENCES.",
      "metadata": {
        "title": "Learning Lounge: AI May Be the Lead Singer, But You Still Need the Band",
        "description": "10-Minute Tip Talk",
        "url": "http://kccncna2025.sched.com/event/2d94ffd6d17911e5f654e0a924c8d0be",
        "uid": "2d94ffd6d17911e5f654e0a924c8d0be",
        "start": "2025-11-13T10:45:00-05:00",
        "end": "2025-11-13T11:00:00-05:00",
        "categories": [
          "EXPERIENCES"
        ],
        "location": {
          "level": "1",
          "room": "Learning Lounge"
        },
        "speakers": [
          {
            "name": "Clyde Seepersad",
            "company": "LF Education"
          }
        ]
      }
    },
    {
      "text": "Managing complex GitOps pipelines across multiple environments often requires deep Kubernetes expertise and time-consuming troubleshooting. What if your team could interact with Flux CD using natural language, getting instant root cause analysis and visualizations of your delivery pipelines? In this session, Stefan will introduce the Flux MCP Server, a new tool in the Flux CD ecosystem that connects AI assistants to Kubernetes clusters. Stefan will demonstrate how to compare deployments across clusters, debug GitOps pipelines end-to-end from Git repos to Flux resources to application logs, and even perform operations using conversational prompts. Stefan will discuss the security implications of using AI assistants in production and how the Flux MCP Server can be configured to prevent harmful operations and sensitive data exposure. The session concludes with the MCP Server roadmap and opportunities for community contribution. Speakers: Stefan Prodan from ControlPlane. Location: Building B | Level 2 | B206. Categories: AI + ML.",
      "metadata": {
        "title": "AI-Assisted GitOps With Flux MCP Server",
        "description": "Managing complex GitOps pipelines across multiple environments often requires deep Kubernetes expertise and time-consuming troubleshooting. What if your team could interact with Flux CD using natural language, getting instant root cause analysis and visualizations of your delivery pipelines? In this session, Stefan will introduce the Flux MCP Server, a new tool in the Flux CD ecosystem that connects AI assistants to Kubernetes clusters. Stefan will demonstrate how to compare deployments across clusters, debug GitOps pipelines end-to-end from Git repos to Flux resources to application logs, and even perform operations using conversational prompts. Stefan will discuss the security implications of using AI assistants in production and how the Flux MCP Server can be configured to prevent harmful operations and sensitive data exposure. The session concludes with the MCP Server roadmap and opportunities for community contribution.",
        "url": "http://kccncna2025.sched.com/event/d33e600dcdb90147be2e79663a2755f5",
        "uid": "d33e600dcdb90147be2e79663a2755f5",
        "start": "2025-11-13T11:00:00-05:00",
        "end": "2025-11-13T11:30:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B206"
        },
        "speakers": [
          {
            "name": "Stefan Prodan",
            "company": "ControlPlane"
          }
        ]
      }
    },
    {
      "text": "Modern preventative-care programs need to reach thousands of patients without drowning clinicians in manual outreach. In this session we show how an open-source, cloud-native stack (including Kubernetes, APISIX, and Prometheus), and the AutoGen multi-agent framework, automates the entire loop: (1) defining U.S. Preventive Services Task Force screening criteria, (2) filtering patient records, and (3) generating personalized emails via OSS LLMs (Llama 3 & DeepSeek-R1) served behind an OpenAI-compatible API on K8s-native AI accelerators. Well dissect the YAML and Helm chart flows that keep model endpoints, agents, and the Streamlit front end deployed. Attendees will learn how to:\n Build the model inference endpoint orchestration layers with K8s and Helm charts;\n Manage API traffic and authentication with APISIX (built on NGINX and etcd);\n Stitch agents together with async Python; and\n Oversee monitoring and observability with Prometheus and Grafana. Speakers: Benjamin Consolvo from AMD, Daron Yondem from AWS. Location: Building B | Level 3 | B308-309. Categories: AI + ML.",
      "metadata": {
        "title": "Building Cloud Native Agentic Workflows on Kubernetes for Preventative Healthcare",
        "description": "Modern preventative-care programs need to reach thousands of patients without drowning clinicians in manual outreach. In this session we show how an open-source, cloud-native stack (including Kubernetes, APISIX, and Prometheus), and the AutoGen multi-agent framework, automates the entire loop: (1) defining U.S. Preventive Services Task Force screening criteria, (2) filtering patient records, and (3) generating personalized emails via OSS LLMs (Llama 3 & DeepSeek-R1) served behind an OpenAI-compatible API on K8s-native AI accelerators. Well dissect the YAML and Helm chart flows that keep model endpoints, agents, and the Streamlit front end deployed. Attendees will learn how to:\n Build the model inference endpoint orchestration layers with K8s and Helm charts;\n Manage API traffic and authentication with APISIX (built on NGINX and etcd);\n Stitch agents together with async Python; and\n Oversee monitoring and observability with Prometheus and Grafana.",
        "url": "http://kccncna2025.sched.com/event/0984ddfab53229ed8aabd57b757fcfb6",
        "uid": "0984ddfab53229ed8aabd57b757fcfb6",
        "start": "2025-11-13T11:00:00-05:00",
        "end": "2025-11-13T11:30:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B308-309"
        },
        "speakers": [
          {
            "name": "Benjamin Consolvo",
            "company": "AMD"
          },
          {
            "name": "Daron Yondem",
            "company": "AWS"
          }
        ]
      }
    },
    {
      "text": "Running AI/ML workloads in Pods on bare-metal is common for maximizing GPU performance but lacks strong isolation and flexibility. In this talk, we share how we use KubeVirt to run high-performance AI workloads inside VMs with NVIDIA GPUs and NVLink, achieving near bare-metal speeds. This enables multi-tenancy, improved security, and resource partitioningcritical for service providers and cost-efficient for customers. Well show how VM-based worker nodes enable virtual Kubernetes clusters on shared infrastructure, supporting both full BM nodes and partitioned node use cases. We'll also dive into challenges like integrating NVIDIA Fabric Manager with the Kubebernets/KubeVirt workflow , optimizing NUMA and PCI topology, and aligning Kubernetes scheduling with VM-based GPU layouts. Finally, well share customer use cases demonstrating the need for isolated, high-performance AI environments using Kubernetes-native tooling. Speakers: Ezra Silvera from IBM, Michael Hrivnak from Red Hat. Location: Building B | Level 4 | B401-402. Categories: AI + ML.",
      "metadata": {
        "title": "High-Performance AI Workloads in KubeVirt VMs With NVIDIA GPUs: Challenges and Real-World Solutions",
        "description": "Running AI/ML workloads in Pods on bare-metal is common for maximizing GPU performance but lacks strong isolation and flexibility. In this talk, we share how we use KubeVirt to run high-performance AI workloads inside VMs with NVIDIA GPUs and NVLink, achieving near bare-metal speeds. This enables multi-tenancy, improved security, and resource partitioningcritical for service providers and cost-efficient for customers. Well show how VM-based worker nodes enable virtual Kubernetes clusters on shared infrastructure, supporting both full BM nodes and partitioned node use cases. We'll also dive into challenges like integrating NVIDIA Fabric Manager with the Kubebernets/KubeVirt workflow , optimizing NUMA and PCI topology, and aligning Kubernetes scheduling with VM-based GPU layouts. Finally, well share customer use cases demonstrating the need for isolated, high-performance AI environments using Kubernetes-native tooling.",
        "url": "http://kccncna2025.sched.com/event/88894383c0722f6b9788bf56a41ab894",
        "uid": "88894383c0722f6b9788bf56a41ab894",
        "start": "2025-11-13T11:00:00-05:00",
        "end": "2025-11-13T11:30:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B401-402"
        },
        "speakers": [
          {
            "name": "Ezra Silvera",
            "company": "IBM"
          },
          {
            "name": "Michael Hrivnak",
            "company": "Red Hat"
          }
        ]
      }
    },
    {
      "text": "The Horizonal Pod Autoscaler (HPA) in Kubernetes has limited functionality in offering container CPU or Memory as metrics to monitor pod scaling performance. However, the CNCF Graduated Project KEDA, short for Kubernetes-based Event Driven Autoscaling, offers a wide array of options. One of these includes using metrics exposed by Prometheus, another CNCF Graduated project. Another is Micrometer, an Open Source metrics facade that integrates nicely with Spring Boot, which can expose many different metrics from an application. Adding one additional dependency can help to expose those metrics in a format that is understood by Prometheus. Putting all of these together, we can expose any metric we desire from our application and use that to drive the scaling of an application in Kubernetes. Speakers: John Coyne from Capital One. Location: Building B | Level 4 | B406b-407. Categories: APPLICATION DEVELOPMENT.",
      "metadata": {
        "title": "Autoscaling Spring Boot Apps in Kubernetes With KEDA",
        "description": "The Horizonal Pod Autoscaler (HPA) in Kubernetes has limited functionality in offering container CPU or Memory as metrics to monitor pod scaling performance. However, the CNCF Graduated Project KEDA, short for Kubernetes-based Event Driven Autoscaling, offers a wide array of options. One of these includes using metrics exposed by Prometheus, another CNCF Graduated project. Another is Micrometer, an Open Source metrics facade that integrates nicely with Spring Boot, which can expose many different metrics from an application. Adding one additional dependency can help to expose those metrics in a format that is understood by Prometheus. Putting all of these together, we can expose any metric we desire from our application and use that to drive the scaling of an application in Kubernetes.",
        "url": "http://kccncna2025.sched.com/event/f11c20b15898c2660634e3ba19876337",
        "uid": "f11c20b15898c2660634e3ba19876337",
        "start": "2025-11-13T11:00:00-05:00",
        "end": "2025-11-13T11:30:00-05:00",
        "categories": [
          "APPLICATION DEVELOPMENT"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B406b-407"
        },
        "speakers": [
          {
            "name": "John Coyne",
            "company": "Capital One"
          }
        ]
      }
    },
    {
      "text": "OK, feature flags are actually pretty awesome, but if you use them wrong you could certainly be forgiven for thinking they suck. After helping many teams along their flag adoption journey, some common pitfalls become clear. In this talk we'll avoid the pain and suffering by hearing some horror stories which illustrate the most common problems that teams run into and how to avoid them.  Learn about the most common mistake - too many flags!  Marvel at 3 neat tricks to keep the number of flags in check!  Commiserate with the many organizations who roll their own feature flagging solution, then learn how CNCF's OpenFeature project can save them!  See how to track flag usage and impact using Open Telemetry! Speakers: The Problems With Feature Flagging and How To Avoid Them - Pete Hodgson from PH1. Location: Building B | Level 5 | Thomas Murphy Ballroom 2-3. Categories: APPLICATION DEVELOPMENT.",
      "metadata": {
        "title": "Feature Flags Suck!",
        "description": "OK, feature flags are actually pretty awesome, but if you use them wrong you could certainly be forgiven for thinking they suck. After helping many teams along their flag adoption journey, some common pitfalls become clear. In this talk we'll avoid the pain and suffering by hearing some horror stories which illustrate the most common problems that teams run into and how to avoid them.  Learn about the most common mistake - too many flags!  Marvel at 3 neat tricks to keep the number of flags in check!  Commiserate with the many organizations who roll their own feature flagging solution, then learn how CNCF's OpenFeature project can save them!  See how to track flag usage and impact using Open Telemetry!",
        "url": "http://kccncna2025.sched.com/event/9e7f0f9a178b26a98fcc1379b8df671b",
        "uid": "9e7f0f9a178b26a98fcc1379b8df671b",
        "start": "2025-11-13T11:00:00-05:00",
        "end": "2025-11-13T11:30:00-05:00",
        "categories": [
          "APPLICATION DEVELOPMENT"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 2-3"
        },
        "speakers": [
          {
            "name": "The Problems With Feature Flagging and How To Avoid Them - Pete Hodgson",
            "company": "PH1"
          }
        ]
      }
    },
    {
      "text": "If you're just getting started with Apache Spark on Kubernetes, this talk is for you. Especially if you're moving on from Spark on YARN where most components are tightly integrated with Spark. Spark on Kubernetes sounds great in theory, but as soon as you get started there are numerous decision to be made including how to submit your jobs (there are now 2 main operators), which shuffle service to use (again at least 2), which scheduler and queue management system to use (about 4 this time), and that doesn't even begin to touch how to optimize your storage and where to send logs. Join me on our journey through all of the above, including how we benchmarked Spark on Kubernetes with existing systems using TPC-DS and simulating real-world workloads. This talk is your field guide for getting started with Spark on Kubernetes, built from real-world experimentation and hard-earned lessons. Speakers: Damon Cortesi from Airbnb. Location: Building B | Level 4 | B405-406a. Categories: DATA PROCESSING + STORAGE.",
      "metadata": {
        "title": "Spark on Kubernetes, a Practical Guide",
        "description": "If you're just getting started with Apache Spark on Kubernetes, this talk is for you. Especially if you're moving on from Spark on YARN where most components are tightly integrated with Spark. Spark on Kubernetes sounds great in theory, but as soon as you get started there are numerous decision to be made including how to submit your jobs (there are now 2 main operators), which shuffle service to use (again at least 2), which scheduler and queue management system to use (about 4 this time), and that doesn't even begin to touch how to optimize your storage and where to send logs. Join me on our journey through all of the above, including how we benchmarked Spark on Kubernetes with existing systems using TPC-DS and simulating real-world workloads. This talk is your field guide for getting started with Spark on Kubernetes, built from real-world experimentation and hard-earned lessons.",
        "url": "http://kccncna2025.sched.com/event/ef61458a0d5482ab4c63ce3baca884f6",
        "uid": "ef61458a0d5482ab4c63ce3baca884f6",
        "start": "2025-11-13T11:00:00-05:00",
        "end": "2025-11-13T11:30:00-05:00",
        "categories": [
          "DATA PROCESSING + STORAGE"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B405-406a"
        },
        "speakers": [
          {
            "name": "Damon Cortesi",
            "company": "Airbnb"
          }
        ]
      }
    },
    {
      "text": "Strimzi is best known for its operators, but its ecosystem includes a rich set of components that make Apache Kafka on Kubernetes truly production-ready. This talk dives into the broader Strimzi landscape: the HTTP Bridge for RESTful Kafka access, the Drain Cleaner for safe node maintenance, the OAuth library for secure authentication, the Access Operator for declarative user and ACL management, and the Metrics Reporter for enhanced observability. Well also touch on other complementary tools like the Kubernetes Config Provider for dynamic configuration and the MQTT Bridge for IoT integration. Whether you're running Kafka at scale or exploring cloud-native streaming for the first time, this session will offer a practical look at how the full Strimzi ecosystem works together to simplify and strengthen your deployment. Speakers: Paolo Patierno from IBM, Michael Morris from Ericsson Software Technology. Location: Building C | Level 3 | Georgia Ballroom 3. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Beyond the Operators: The Full Strimzi Ecosystem for Kafka on Kubernetes",
        "description": "Strimzi is best known for its operators, but its ecosystem includes a rich set of components that make Apache Kafka on Kubernetes truly production-ready. This talk dives into the broader Strimzi landscape: the HTTP Bridge for RESTful Kafka access, the Drain Cleaner for safe node maintenance, the OAuth library for secure authentication, the Access Operator for declarative user and ACL management, and the Metrics Reporter for enhanced observability. Well also touch on other complementary tools like the Kubernetes Config Provider for dynamic configuration and the MQTT Bridge for IoT integration. Whether you're running Kafka at scale or exploring cloud-native streaming for the first time, this session will offer a practical look at how the full Strimzi ecosystem works together to simplify and strengthen your deployment.",
        "url": "http://kccncna2025.sched.com/event/5466c532e87f1c8ecabd27bd7fc72f83",
        "uid": "5466c532e87f1c8ecabd27bd7fc72f83",
        "start": "2025-11-13T11:00:00-05:00",
        "end": "2025-11-13T11:30:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 3"
        },
        "speakers": [
          {
            "name": "Paolo Patierno",
            "company": "IBM"
          },
          {
            "name": "Michael Morris",
            "company": "Ericsson Software Technology"
          }
        ]
      }
    },
    {
      "text": "The recently released etcd 3.6 marks a significant milestone, bringing crucial advancements that directly impact the stability, performance, and operational efficiency of Kubernetes.\nThis session will delve into the key features of etcd 3.6, and provide an upgrade checklist and highlight changes users need to make before upgrading to the 3.6 release. We will also discuss the extended support of 3.4, and roadmap for 3.7.\nWe will also bring you the latest updates of the etcd-operator. Come join us and raise your etcd questions with the on-site etcd maintainers.\n\nEven though etcd 3.6 was announce in KubeCon London, due to its importance, we want to advocate again to make sure Kubernetes are aware of the changes and well-prepared for the upgrade by providing comprehensive guidance and support. We also would like to encourage contributions to the etcd and etcd-operator projects for further enhancements. Speakers: Siyuan Zhang from  Google, Justin Santa Barbara from  Google, Wei Fu from Microsoft, Arka Saha from VMware by Broadcom, Ivan Valdes Castillo from Inmar Intelligence. Location: Building C | Level 3 | Georgia Ballroom 2. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "etcd V3.6 and Beyond + etcd-operator Updates",
        "description": "The recently released etcd 3.6 marks a significant milestone, bringing crucial advancements that directly impact the stability, performance, and operational efficiency of Kubernetes.\nThis session will delve into the key features of etcd 3.6, and provide an upgrade checklist and highlight changes users need to make before upgrading to the 3.6 release. We will also discuss the extended support of 3.4, and roadmap for 3.7.\nWe will also bring you the latest updates of the etcd-operator. Come join us and raise your etcd questions with the on-site etcd maintainers.\n\nEven though etcd 3.6 was announce in KubeCon London, due to its importance, we want to advocate again to make sure Kubernetes are aware of the changes and well-prepared for the upgrade by providing comprehensive guidance and support. We also would like to encourage contributions to the etcd and etcd-operator projects for further enhancements.",
        "url": "http://kccncna2025.sched.com/event/590a27bc59e9ef2e867c9034050c0b89",
        "uid": "590a27bc59e9ef2e867c9034050c0b89",
        "start": "2025-11-13T11:00:00-05:00",
        "end": "2025-11-13T11:30:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 2"
        },
        "speakers": [
          {
            "name": "Siyuan Zhang",
            "company": " Google"
          },
          {
            "name": "Justin Santa Barbara",
            "company": " Google"
          },
          {
            "name": "Wei Fu",
            "company": "Microsoft"
          },
          {
            "name": "Arka Saha",
            "company": "VMware by Broadcom"
          },
          {
            "name": "Ivan Valdes Castillo",
            "company": "Inmar Intelligence"
          }
        ]
      }
    },
    {
      "text": "Longhorn is a cloud-native, distributed block storage solution for Kubernetes that supports persistent volumes via CSI. It is designed for resource efficiency and flexible deployment across public cloud, private cloud, on-premises, and edge environments.\n\nLonghorn has seen widespread community adoption, with hundreds of thousands of installations worldwide, due to its high availability, resilience, and feature-rich functionality powered by its general-purpose V1 data engine. To further expand adoption, the V2 data engine is now the main focus. In the latest release, we introduced the UBLK frontend, offline replica rebuilding, and several other key capabilities. In this session, we will share upcoming plans for the V2 engine, including online replica delta chunk-based rebuilding, interruption mode for the SPDK data path to enable V2 on low-resource setups. We'll also cover roadmap and community updates, including adoption trends, contributions, and community engagement initiatives. Speakers: Shuo Wu from SUSE. Location: Building C | Level 1 | C111-112. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Longhorn: Intro, Deep Dive and Q&A",
        "description": "Longhorn is a cloud-native, distributed block storage solution for Kubernetes that supports persistent volumes via CSI. It is designed for resource efficiency and flexible deployment across public cloud, private cloud, on-premises, and edge environments.\n\nLonghorn has seen widespread community adoption, with hundreds of thousands of installations worldwide, due to its high availability, resilience, and feature-rich functionality powered by its general-purpose V1 data engine. To further expand adoption, the V2 data engine is now the main focus. In the latest release, we introduced the UBLK frontend, offline replica rebuilding, and several other key capabilities. In this session, we will share upcoming plans for the V2 engine, including online replica delta chunk-based rebuilding, interruption mode for the SPDK data path to enable V2 on low-resource setups. We'll also cover roadmap and community updates, including adoption trends, contributions, and community engagement initiatives.",
        "url": "http://kccncna2025.sched.com/event/10e9b402fd9a6f86de088febb61f882a",
        "uid": "10e9b402fd9a6f86de088febb61f882a",
        "start": "2025-11-13T11:00:00-05:00",
        "end": "2025-11-13T11:30:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "1",
          "room": "C111-112"
        },
        "speakers": [
          {
            "name": "Shuo Wu",
            "company": "SUSE"
          }
        ]
      }
    },
    {
      "text": "Over the past year, Kubernetes has expanded support for high-volume data workloads through Jobs, while the Workload APIs (StatefulSet, ReplicaSet, PDBs, etc.) have become more mature, consistent, and full-featured. SIG Apps has been hard at work, and there's even more on the horizon. In this session, the SIG Apps leads will provide an overview of the accomplishments over the past year. They will delve into specific changes that have been implemented and discuss potential directions for further improvements. A significant focus will be on the features requiring community input to reach completion. The session will conclude with an open discussion and Q&A, offering attendees insights into contributing to SIG Apps and becoming part of its ongoing evolution. Speakers: Maciej Szulik from Defense Unicorns, Janet Kuo from Google. Location: Building C | Level 3 | Georgia Ballroom 1. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Managing Data at Scale: Best Practices and Evolution of SIG-Apps",
        "description": "Over the past year, Kubernetes has expanded support for high-volume data workloads through Jobs, while the Workload APIs (StatefulSet, ReplicaSet, PDBs, etc.) have become more mature, consistent, and full-featured. SIG Apps has been hard at work, and there's even more on the horizon. In this session, the SIG Apps leads will provide an overview of the accomplishments over the past year. They will delve into specific changes that have been implemented and discuss potential directions for further improvements. A significant focus will be on the features requiring community input to reach completion. The session will conclude with an open discussion and Q&A, offering attendees insights into contributing to SIG Apps and becoming part of its ongoing evolution.",
        "url": "http://kccncna2025.sched.com/event/571cdc6b46c78a46080e95e61226b5ee",
        "uid": "571cdc6b46c78a46080e95e61226b5ee",
        "start": "2025-11-13T11:00:00-05:00",
        "end": "2025-11-13T11:30:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 1"
        },
        "speakers": [
          {
            "name": "Maciej Szulik",
            "company": "Defense Unicorns"
          },
          {
            "name": "Janet Kuo",
            "company": "Google"
          }
        ]
      }
    },
    {
      "text": "Adjusting resource requirements in Kubernetes traditionally meant disruptive Pod restarts. This session introduces the In-Place Pod Resize feature, which enables dynamic CPU and memory adjustments for running Pods. We'll explore how this feature allows on-the-fly resource changes with minimal disruption to reduce downtime for stateful applications, batch jobs, and other restart-sensitive workloads.\n\nAttendees will learn about:\n- The core concepts and mechanics of in-place pod resizing\n- Practical use cases: when, why and how to use in-place resizing\n- The current limitations and the future roadmap\n\nJoin us to discover how to leverage this powerful feature for more resilient and efficient Kubernetes deployments. Speakers: Tim Allclair from  Google, Mofi Rahman from  Google. Location: Building B | Level 5 | Thomas Murphy Ballroom 4. Categories: OPERATIONS + PERFORMANCE.",
      "metadata": {
        "title": "In-Place Pod Resize in Kubernetes: Dynamic Resource Management Without Restarts",
        "description": "Adjusting resource requirements in Kubernetes traditionally meant disruptive Pod restarts. This session introduces the In-Place Pod Resize feature, which enables dynamic CPU and memory adjustments for running Pods. We'll explore how this feature allows on-the-fly resource changes with minimal disruption to reduce downtime for stateful applications, batch jobs, and other restart-sensitive workloads.\n\nAttendees will learn about:\n- The core concepts and mechanics of in-place pod resizing\n- Practical use cases: when, why and how to use in-place resizing\n- The current limitations and the future roadmap\n\nJoin us to discover how to leverage this powerful feature for more resilient and efficient Kubernetes deployments.",
        "url": "http://kccncna2025.sched.com/event/df16aecbbe8d7eddf9fbbfb8b7702fff",
        "uid": "df16aecbbe8d7eddf9fbbfb8b7702fff",
        "start": "2025-11-13T11:00:00-05:00",
        "end": "2025-11-13T11:30:00-05:00",
        "categories": [
          "OPERATIONS + PERFORMANCE"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 4"
        },
        "speakers": [
          {
            "name": "Tim Allclair",
            "company": " Google"
          },
          {
            "name": "Mofi Rahman",
            "company": " Google"
          }
        ]
      }
    },
    {
      "text": "You've built golden paths, achieved adoption, but now face the scaling bottleneck: every new capability requires your team to build, maintain, and support it. What if instead of being the sole provider, you became the marketplace operator? This talk introduces the Internal Developer Marketplace model, which transforms platforms from centralised services into economic ecosystems where any team contributes capabilities. We'll explore how organisations can evolve from paved paths to community-driven platforms where engineering capabilities become tradeable assets. Through practical examples, we'll learn about contribution frameworks that turn domain expertise into platform capabilities, governance models that maintain quality without gatekeeping, and recognition systems that incentivise meaningful contributions. The result? Platform engineering that scales beyond your team's capacity, leverages distributed expertise, and creates sustainable growth through network effects. Speakers: Atulpriya Sharma from InfraCloud Technologies. Location: Building B | Level 3 | B312-314. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "Economics of Platforms: Building Marketplaces Beyond Golden Paths",
        "description": "You've built golden paths, achieved adoption, but now face the scaling bottleneck: every new capability requires your team to build, maintain, and support it. What if instead of being the sole provider, you became the marketplace operator? This talk introduces the Internal Developer Marketplace model, which transforms platforms from centralised services into economic ecosystems where any team contributes capabilities. We'll explore how organisations can evolve from paved paths to community-driven platforms where engineering capabilities become tradeable assets. Through practical examples, we'll learn about contribution frameworks that turn domain expertise into platform capabilities, governance models that maintain quality without gatekeeping, and recognition systems that incentivise meaningful contributions. The result? Platform engineering that scales beyond your team's capacity, leverages distributed expertise, and creates sustainable growth through network effects.",
        "url": "http://kccncna2025.sched.com/event/a76c020154f689d2e915d309d4c4d100",
        "uid": "a76c020154f689d2e915d309d4c4d100",
        "start": "2025-11-13T11:00:00-05:00",
        "end": "2025-11-13T11:30:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B312-314"
        },
        "speakers": [
          {
            "name": "Atulpriya Sharma",
            "company": "InfraCloud Technologies"
          }
        ]
      }
    },
    {
      "text": "Being a developer in 2025 means a lot more than it used to. The cognitive load and the number of development related activities other than coding that needs to be taken into consideration keeps growing every day (CI/CD, infra-as-code, cloud, finops, networking, monitoring, containers, security, etc.) Internal developer portals are meant to help with this issue but can be challenging to deploy successfully in a large organization. At Beneva, weve been running Backstage for almost three years now and our developers are grateful. In our talk, well deep dive in our journey, from the very beginning of sponsorship and financing for our portal initiative to the deployment of Backstage itself and how the mindset of our development teams as portal users evolved from one more thing they would have to care about to considering it the one thing that could help them manage and deliver their solutions more efficiently. Speakers: Mathieu Girard from  Beneva, Teddy Poingt from  Beneva. Location: Building B | Level 3 | B304-305. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "The Journey of Deploying Backstage in a Large Organization",
        "description": "Being a developer in 2025 means a lot more than it used to. The cognitive load and the number of development related activities other than coding that needs to be taken into consideration keeps growing every day (CI/CD, infra-as-code, cloud, finops, networking, monitoring, containers, security, etc.) Internal developer portals are meant to help with this issue but can be challenging to deploy successfully in a large organization. At Beneva, weve been running Backstage for almost three years now and our developers are grateful. In our talk, well deep dive in our journey, from the very beginning of sponsorship and financing for our portal initiative to the deployment of Backstage itself and how the mindset of our development teams as portal users evolved from one more thing they would have to care about to considering it the one thing that could help them manage and deliver their solutions more efficiently.",
        "url": "http://kccncna2025.sched.com/event/227e0163e1769941058b839395c4e4e7",
        "uid": "227e0163e1769941058b839395c4e4e7",
        "start": "2025-11-13T11:00:00-05:00",
        "end": "2025-11-13T11:30:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B304-305"
        },
        "speakers": [
          {
            "name": "Mathieu Girard",
            "company": " Beneva"
          },
          {
            "name": "Teddy Poingt",
            "company": " Beneva"
          }
        ]
      }
    },
    {
      "text": "Congratulations! Youve successfully built and pushed your container image to a registry, but are you ready to deploy to production? Is your SecOps team confident with your containers robustness in the face of production environments?\n\nHow do you ensure the image youve built is the one running? Are you sure it is composed of vulnerability-free software and that your supply chain hasnt been compromised along the way?\n\nDont panic! In this fun and dynamic talk, you can learn and/or improve your knowledge, about the way to secure your containers, with supply chain security.\n\nWith a mix of quiz and live demos, you will discover or dig into several supply chain concepts and frameworks, CNCF and open source projects like SBOM, SigStore, SLSA, OpenSSF, VEX, GUAC, in-toto and many more!\n\nAre you up for this new quiz challenge? Icing on the cake: Top scores will win some swags. Speakers: Aurelie Vache from OVHcloud, Sherine Khoury from Red Hat. Location: Building B | Level 3 | B302-303. Categories: SECURITY.",
      "metadata": {
        "title": "The Ultimate Container Challenge: An Interactive Trivia Game on Supply Chain Security",
        "description": "Congratulations! Youve successfully built and pushed your container image to a registry, but are you ready to deploy to production? Is your SecOps team confident with your containers robustness in the face of production environments?\n\nHow do you ensure the image youve built is the one running? Are you sure it is composed of vulnerability-free software and that your supply chain hasnt been compromised along the way?\n\nDont panic! In this fun and dynamic talk, you can learn and/or improve your knowledge, about the way to secure your containers, with supply chain security.\n\nWith a mix of quiz and live demos, you will discover or dig into several supply chain concepts and frameworks, CNCF and open source projects like SBOM, SigStore, SLSA, OpenSSF, VEX, GUAC, in-toto and many more!\n\nAre you up for this new quiz challenge? Icing on the cake: Top scores will win some swags.",
        "url": "http://kccncna2025.sched.com/event/3ce7ff94622173556f4972a889cc3380",
        "uid": "3ce7ff94622173556f4972a889cc3380",
        "start": "2025-11-13T11:00:00-05:00",
        "end": "2025-11-13T11:30:00-05:00",
        "categories": [
          "SECURITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B302-303"
        },
        "speakers": [
          {
            "name": "Aurelie Vache",
            "company": "OVHcloud"
          },
          {
            "name": "Sherine Khoury",
            "company": "Red Hat"
          }
        ]
      }
    },
    {
      "text": "Have you ever struggled writing least-privilege access control policies for Kubernetes? Are you concerned about the wide permissions of installed Helm charts? Do you manage to regularly audit who has access to sensitive resources? In this talk, Kubernetes contributors Micah and Lucas introduce you to open source tools that help you on your defense in depth journey for securing the Kubernetes API surface. They demonstrate how to right-size your RBAC rules semi-automatically, audit who can access sensitive resources, and check whether policy refactors are correct. This talk is part of a journey to improve Kubernetes access control in core. However, to make this initiative successful, user feedback is needed throughout the process. Youll learn about the planned Kubernetes Conditional Authorization feature, which will make authoring right-sized policies easier. By the end of the talk, you will know how to get involved, and future directions for improved Kubernetes access control. Speakers: Lucas Kaldstrom from Upbound, Micah Hausler from AWS. Location: Building B | Level 5 | Thomas Murphy Ballroom 1. Categories: SECURITY.",
      "metadata": {
        "title": "Tools and Strategies for Making the Most of Kubernetes Access Control",
        "description": "Have you ever struggled writing least-privilege access control policies for Kubernetes? Are you concerned about the wide permissions of installed Helm charts? Do you manage to regularly audit who has access to sensitive resources? In this talk, Kubernetes contributors Micah and Lucas introduce you to open source tools that help you on your defense in depth journey for securing the Kubernetes API surface. They demonstrate how to right-size your RBAC rules semi-automatically, audit who can access sensitive resources, and check whether policy refactors are correct. This talk is part of a journey to improve Kubernetes access control in core. However, to make this initiative successful, user feedback is needed throughout the process. Youll learn about the planned Kubernetes Conditional Authorization feature, which will make authoring right-sized policies easier. By the end of the talk, you will know how to get involved, and future directions for improved Kubernetes access control.",
        "url": "http://kccncna2025.sched.com/event/b0919524b70b4bd69f0efd746472ea23",
        "uid": "b0919524b70b4bd69f0efd746472ea23",
        "start": "2025-11-13T11:00:00-05:00",
        "end": "2025-11-13T11:30:00-05:00",
        "categories": [
          "SECURITY"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 1"
        },
        "speakers": [
          {
            "name": "Lucas Kaldstrom",
            "company": "Upbound"
          },
          {
            "name": "Micah Hausler",
            "company": "AWS"
          }
        ]
      }
    },
    {
      "text": "This session is the perfect opportunity to learn how you can take granular kernel level data (collected using eBPF!) and apply it to a wide range of troubleshooting, monitoring, and security use cases by putting your hands on the Inspektor Gadget project: A system inspection framework for observing Kubernetes and Linux hosts.\n\nWell start with a quick overview of how Inspektor Gadget works, then show you how to install and configure it in your cluster. Next, well run some live demos of Gadgets like DNS tracing and identifying the pods that use the most resources, which are common issues that come up on K8s.\n\nAfter the introduction is done, well guide you to set up the development environment, then youll have the opportunity to contribute in different ways by:\n\n- Fixing bugs\n- Developing your own creative use cases for existing gadgets\n- Implementing new features\n- Creating or extending gadgets for new use cases\n- Brainstorming ideas on features, use cases, etc. Speakers: Mauricio Vasquez Bernal from  Microsoft, Jose Blanquicet from  Microsoft. Location: Building B | Level 2 | B208. Categories:  CONTRIBFEST.",
      "metadata": {
        "title": "Contribfest: Inspektor Gadget Contribfest: Enhancing the Observability and Security of Your K8s Clusters Through an easy to use Framework",
        "description": "This session is the perfect opportunity to learn how you can take granular kernel level data (collected using eBPF!) and apply it to a wide range of troubleshooting, monitoring, and security use cases by putting your hands on the Inspektor Gadget project: A system inspection framework for observing Kubernetes and Linux hosts.\n\nWell start with a quick overview of how Inspektor Gadget works, then show you how to install and configure it in your cluster. Next, well run some live demos of Gadgets like DNS tracing and identifying the pods that use the most resources, which are common issues that come up on K8s.\n\nAfter the introduction is done, well guide you to set up the development environment, then youll have the opportunity to contribute in different ways by:\n\n- Fixing bugs\n- Developing your own creative use cases for existing gadgets\n- Implementing new features\n- Creating or extending gadgets for new use cases\n- Brainstorming ideas on features, use cases, etc.",
        "url": "http://kccncna2025.sched.com/event/296af61c938159a77f0a7330d80b87f8",
        "uid": "296af61c938159a77f0a7330d80b87f8",
        "start": "2025-11-13T11:00:00-05:00",
        "end": "2025-11-13T12:15:00-05:00",
        "categories": [
          " CONTRIBFEST"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B208"
        },
        "speakers": [
          {
            "name": "Mauricio Vasquez Bernal",
            "company": " Microsoft"
          },
          {
            "name": "Jose Blanquicet",
            "company": " Microsoft"
          }
        ]
      }
    },
    {
      "text": "Jump into the world of Backstage at our interactive ContribFest session! Whether youre just starting out or already building with Backstage, this event is designed to help you contribute confidently to this CNCF project thats transforming Internal Developer Portals.\n\nWell help you set up your development environment (think: Node.js, TypeScript, and more), walk you through the Backstage Contributing Guide, and connect you with beginner-friendly GitHub issues to get you started. Seasoned Backstage contributors can dive deeperexplore advanced topics, build plugins, or tackle more complex issues alongside maintainers and fellow developers.\n\nBring your questions, share your ideas, and collaborate in real time with the Backstage community. No matter your experience level, youll leave with practical knowledge and the satisfaction of making a real impact on Backstage! Speakers: Andre Wanlin from Patrik Oldsberg, Avantika Iyer from Spotify, Aramis Sennyey from DoorDash, Kurt King from Procore. Location: Building B | Level 2 | B207. Categories:  CONTRIBFEST.",
      "metadata": {
        "title": "Contribfest: Level up Your Open Source Journey: Hands-On Backstage Contributions!",
        "description": "Jump into the world of Backstage at our interactive ContribFest session! Whether youre just starting out or already building with Backstage, this event is designed to help you contribute confidently to this CNCF project thats transforming Internal Developer Portals.\n\nWell help you set up your development environment (think: Node.js, TypeScript, and more), walk you through the Backstage Contributing Guide, and connect you with beginner-friendly GitHub issues to get you started. Seasoned Backstage contributors can dive deeperexplore advanced topics, build plugins, or tackle more complex issues alongside maintainers and fellow developers.\n\nBring your questions, share your ideas, and collaborate in real time with the Backstage community. No matter your experience level, youll leave with practical knowledge and the satisfaction of making a real impact on Backstage!",
        "url": "http://kccncna2025.sched.com/event/e0ca6eef124f9de5628bcd56bd0bbb82",
        "uid": "e0ca6eef124f9de5628bcd56bd0bbb82",
        "start": "2025-11-13T11:00:00-05:00",
        "end": "2025-11-13T12:15:00-05:00",
        "categories": [
          " CONTRIBFEST"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B207"
        },
        "speakers": [
          {
            "name": "Andre Wanlin",
            "company": "Patrik Oldsberg"
          },
          {
            "name": "Avantika Iyer",
            "company": "Spotify"
          },
          {
            "name": "Aramis Sennyey",
            "company": "DoorDash"
          },
          {
            "name": "Kurt King",
            "company": "Procore"
          }
        ]
      }
    },
    {
      "text": "Kubernetes workloads demand diverse data services: block CSI for databases, file CSI for analytics, and native S3 for AI/ML pipelines. Today, these are delivered through siloed backends with separate lifecycles, quotas, and policies. This session shows how to unify them into a single software-defined data plane using a centralized data intelligence platform.\n\nThe platform simultaneously presents block, file, and S3 into Kubernetes via one control plane; supports multi-tenant policies and quotas; and enforces QoS with rate-limiting and priority scheduling to prevent noisy-neighbor issues. As a software-defined solution, it spans core, cloud, and hybrid models.\n\nIn the demo, we will provision multi-tenant block/file/object storage, set per-tenant quotas and QoS via APIs, and show enforcement across AI training (file), inference (block), and RAG (S3). Attendees will see how a centralized platform simplifies Kubernetes data services, ensuring predictable performance and streamlined operations.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.* Location: Building B | Level 1 | Exhibit Hall B3-B5. Categories: SOLUTIONS SHOWCASE.",
      "metadata": {
        "title": "Sponsored Demo: No Silos, One Data Plane: Fast & Secure SW-Defined Data Ops for Kubernetes",
        "description": "Kubernetes workloads demand diverse data services: block CSI for databases, file CSI for analytics, and native S3 for AI/ML pipelines. Today, these are delivered through siloed backends with separate lifecycles, quotas, and policies. This session shows how to unify them into a single software-defined data plane using a centralized data intelligence platform.\n\nThe platform simultaneously presents block, file, and S3 into Kubernetes via one control plane; supports multi-tenant policies and quotas; and enforces QoS with rate-limiting and priority scheduling to prevent noisy-neighbor issues. As a software-defined solution, it spans core, cloud, and hybrid models.\n\nIn the demo, we will provision multi-tenant block/file/object storage, set per-tenant quotas and QoS via APIs, and show enforcement across AI training (file), inference (block), and RAG (S3). Attendees will see how a centralized platform simplifies Kubernetes data services, ensuring predictable performance and streamlined operations.\n\n*In order to facilitate networking and business relationships at the event, you may choose to visit a third partys booth or access sponsored content. You are never required to visit third party booths or to access sponsored content. When visiting a booth or participating in sponsored activities, the third party will receive some of your registration data. This data includes your first name, last name, title, company, address, email, standard demographics questions (i.e. job function, industry), and details about the sponsored content or resources you interacted with. If you choose to interact with a booth or access sponsored content, you are explicitly consenting to receipt and use of such data by the third-party recipients, which will be subject to their own privacy policies.*",
        "url": "http://kccncna2025.sched.com/event/59b5104e378a9adeca6ef89ca0ecc278",
        "uid": "59b5104e378a9adeca6ef89ca0ecc278",
        "start": "2025-11-13T11:05:00-05:00",
        "end": "2025-11-13T11:25:00-05:00",
        "categories": [
          "SOLUTIONS SHOWCASE"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Exhibit Hall B3-B5"
        }
      }
    },
    {
      "text": "Kubernetes is becoming the standard container orchestration including AI/ML supporting use cases for extracting insights, parsing unstructured data, and filling-in missing multimodal data (images, text, audio, video)\n\nAI workflows used to waterfall development through one model at a time and are now trending towards data-driven, multi-path development. This means that platform engineers have to build data pipelines that support multi-model infrastructure, giving the AI app the granular ability to choose the right model for any request.\n\nHear from a panel of platform engineers on how they can build data pipelines in Kubernetes for multimodal AI that optimizes for data retrieval, advanced reasoning, and generation capabilities. Speakers: Susan Wu from  Google, Ian Chakares from  Google, Lu Qiu from LanceDB, Zhitao Li from  Uber, Lucy Sweet from  Uber. Location: Building B | Level 3 | B308-309. Categories: AI + ML.",
      "metadata": {
        "title": "Building AI/ML Pipelines on Kubernetes",
        "description": "Kubernetes is becoming the standard container orchestration including AI/ML supporting use cases for extracting insights, parsing unstructured data, and filling-in missing multimodal data (images, text, audio, video)\n\nAI workflows used to waterfall development through one model at a time and are now trending towards data-driven, multi-path development. This means that platform engineers have to build data pipelines that support multi-model infrastructure, giving the AI app the granular ability to choose the right model for any request.\n\nHear from a panel of platform engineers on how they can build data pipelines in Kubernetes for multimodal AI that optimizes for data retrieval, advanced reasoning, and generation capabilities.",
        "url": "http://kccncna2025.sched.com/event/c03c06897f7f50fa7f6e4feb61aeb224",
        "uid": "c03c06897f7f50fa7f6e4feb61aeb224",
        "start": "2025-11-13T11:45:00-05:00",
        "end": "2025-11-13T12:15:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B308-309"
        },
        "speakers": [
          {
            "name": "Susan Wu",
            "company": " Google"
          },
          {
            "name": "Ian Chakares",
            "company": " Google"
          },
          {
            "name": "Lu Qiu",
            "company": "LanceDB"
          },
          {
            "name": "Zhitao Li",
            "company": " Uber"
          },
          {
            "name": "Lucy Sweet",
            "company": " Uber"
          }
        ]
      }
    },
    {
      "text": "A long time ago (okay, not that long), stateless microservices ruled the galaxy. But a new force is rising, shaped by agents, LLMs, and highly dynamic, resource-intensive workloads. As traffic shifts from simple REST to streaming tokens, prompt orchestration and GPU-aware routing, traditional gateways are showing their limits.\n\nWell explore what it takes to build GenAI platforms capable of serving modern inference at scale without falling to the dark side of complexity. Youll learn from a real-world reference architecture using open-source tools like Envoy AI Gateway, KServe, and othersdesigned to support dynamic model-based routing, token-level rate limiting, secure upstream auth, observability, and multi-provider failover. These arent bonus featurestheyre the new minimum requirements for reliable AI inference.\n\nYoull leave with a practical blueprint for routing, serving and observing LLM traffic, and a clearer vision for how todays CNCF tools are awakening in the GenAI era. Speakers: Alexa Griffith from Bloomberg, Erica Hughberg from Tetrate. Location: Building B | Level 4 | B401-402. Categories: AI + ML.",
      "metadata": {
        "title": "Inference Awakens: Tools for the Age of GenAI",
        "description": "A long time ago (okay, not that long), stateless microservices ruled the galaxy. But a new force is rising, shaped by agents, LLMs, and highly dynamic, resource-intensive workloads. As traffic shifts from simple REST to streaming tokens, prompt orchestration and GPU-aware routing, traditional gateways are showing their limits.\n\nWell explore what it takes to build GenAI platforms capable of serving modern inference at scale without falling to the dark side of complexity. Youll learn from a real-world reference architecture using open-source tools like Envoy AI Gateway, KServe, and othersdesigned to support dynamic model-based routing, token-level rate limiting, secure upstream auth, observability, and multi-provider failover. These arent bonus featurestheyre the new minimum requirements for reliable AI inference.\n\nYoull leave with a practical blueprint for routing, serving and observing LLM traffic, and a clearer vision for how todays CNCF tools are awakening in the GenAI era.",
        "url": "http://kccncna2025.sched.com/event/d0b565454e20f93cd830386ba5b983eb",
        "uid": "d0b565454e20f93cd830386ba5b983eb",
        "start": "2025-11-13T11:45:00-05:00",
        "end": "2025-11-13T12:15:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B401-402"
        },
        "speakers": [
          {
            "name": "Alexa Griffith",
            "company": "Bloomberg"
          },
          {
            "name": "Erica Hughberg",
            "company": "Tetrate"
          }
        ]
      }
    },
    {
      "text": "Git has long been the foundation of GitOps, but what if deployment configs were treated like versioned software packages? This talk explores how the Open Container Initiative (OCI) format, originally designed for container images, is evolving to support a wide array of cloud-native artifacts, including Helm charts, WebAssembly (Wasm) modules, Lambda functions, and Kustomize configuration bundles. Well dive into how the OCI ecosystem is becoming a powerful, interoperable standard not just for deployment runtimes but for the full lifecycle of cloud-native applications. Well examine how tools like Argo CD, Flux, and Kargo are embracing OCI registries as first-class citizens and the benefits and tradeoffs of adopting this approach. Attendees will learn: how OCI extends beyond containers; how to package and distribute complex or binary artifacts; and how OCI compares to Git in a GitOps context. Speakers: Jesse Suen from Akuity. Location: Building B | Level 4 | B406b-407. Categories: APPLICATION DEVELOPMENT.",
      "metadata": {
        "title": "Bringing OCI Into the GitOps World",
        "description": "Git has long been the foundation of GitOps, but what if deployment configs were treated like versioned software packages? This talk explores how the Open Container Initiative (OCI) format, originally designed for container images, is evolving to support a wide array of cloud-native artifacts, including Helm charts, WebAssembly (Wasm) modules, Lambda functions, and Kustomize configuration bundles. Well dive into how the OCI ecosystem is becoming a powerful, interoperable standard not just for deployment runtimes but for the full lifecycle of cloud-native applications. Well examine how tools like Argo CD, Flux, and Kargo are embracing OCI registries as first-class citizens and the benefits and tradeoffs of adopting this approach. Attendees will learn: how OCI extends beyond containers; how to package and distribute complex or binary artifacts; and how OCI compares to Git in a GitOps context.",
        "url": "http://kccncna2025.sched.com/event/c46563e5e81f9ac75040d7274d5bbcd3",
        "uid": "c46563e5e81f9ac75040d7274d5bbcd3",
        "start": "2025-11-13T11:45:00-05:00",
        "end": "2025-11-13T12:15:00-05:00",
        "categories": [
          "APPLICATION DEVELOPMENT"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B406b-407"
        },
        "speakers": [
          {
            "name": "Jesse Suen",
            "company": "Akuity"
          }
        ]
      }
    },
    {
      "text": "This session is a panel discussion moderated by Chris Aniszczyk with members of the Technical Oversight Committee. Feel free to come with questions, but we'll be doing an overview of the Technical Oversight Committee's governance structure, scope, mission and processes.\n\nTo learn more about the TOC, visit&nbsp;https://github.com/cncf/toc Speakers: Moderated by Chris Aniszczyk CTO from Cloud Native Computing Foundation. Location: Building C | Level 3 | Georgia Ballroom 3. Categories: CLOUD NATIVE EXPERIENCE.",
      "metadata": {
        "title": "Public Technical Oversight Committee (TOC) Meeting",
        "description": "This session is a panel discussion moderated by Chris Aniszczyk with members of the Technical Oversight Committee. Feel free to come with questions, but we'll be doing an overview of the Technical Oversight Committee's governance structure, scope, mission and processes.\n\nTo learn more about the TOC, visit&nbsp;https://github.com/cncf/toc",
        "url": "http://kccncna2025.sched.com/event/25c8b917b333d57e70917a42a4806eea",
        "uid": "25c8b917b333d57e70917a42a4806eea",
        "start": "2025-11-13T11:45:00-05:00",
        "end": "2025-11-13T12:15:00-05:00",
        "categories": [
          "CLOUD NATIVE EXPERIENCE"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 3"
        },
        "speakers": [
          {
            "name": "Moderated by Chris Aniszczyk",
            "title": "CTO",
            "company": "Cloud Native Computing Foundation"
          }
        ]
      }
    },
    {
      "text": "A longstanding challenge within the Postgres ecosystem is the management of add-ons, such as database extensions. With hundreds of extensions available, a typical Postgres user will require at least one database extension. Yet challenges arise in immutable container environments where we want to minimize image bloat and build complexity. Thanks to the introduction of Image Volumes in Kubernetes, however, the conversation around extension management has shifted. More specifically, Image Volumes provide a powerful new way of packaging and distributing extensions using your existing cloud-native infrastructure. In this talk, you will see how Crunchy Data is using Image Volumes, together with the latest Postgres features, to enable a seamless extension management in Kubernetes. We'll walk through a real-world example using pgvector, demonstrating how extensions can be built into OCI images, distributed via an image registry, and then mounted into database Pods for installation and use. Speakers: Andrew L'Ecuyer from Crunchy Data Solutions. Location: Building B | Level 5 | Thomas Murphy Ballroom 2-3. Categories: DATA PROCESSING + STORAGE.",
      "metadata": {
        "title": "Next Generation Extension Management Using Kubernetes Image Volumes",
        "description": "A longstanding challenge within the Postgres ecosystem is the management of add-ons, such as database extensions. With hundreds of extensions available, a typical Postgres user will require at least one database extension. Yet challenges arise in immutable container environments where we want to minimize image bloat and build complexity. Thanks to the introduction of Image Volumes in Kubernetes, however, the conversation around extension management has shifted. More specifically, Image Volumes provide a powerful new way of packaging and distributing extensions using your existing cloud-native infrastructure. In this talk, you will see how Crunchy Data is using Image Volumes, together with the latest Postgres features, to enable a seamless extension management in Kubernetes. We'll walk through a real-world example using pgvector, demonstrating how extensions can be built into OCI images, distributed via an image registry, and then mounted into database Pods for installation and use.",
        "url": "http://kccncna2025.sched.com/event/6b4a60b1a9798ec3d393150d16a086c1",
        "uid": "6b4a60b1a9798ec3d393150d16a086c1",
        "start": "2025-11-13T11:45:00-05:00",
        "end": "2025-11-13T12:15:00-05:00",
        "categories": [
          "DATA PROCESSING + STORAGE"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 2-3"
        },
        "speakers": [
          {
            "name": "Andrew L'Ecuyer",
            "company": "Crunchy Data Solutions"
          }
        ]
      }
    },
    {
      "text": "Operating multiple Kubernetes clusters is becoming par for the course in any enterprise-scale Kubernetes deployment. As the complexity of your infrastructure deployments grow, so do the opportunities for inefficiencies.\n\nOnce the boundaries of a single cluster have been broken, the first place this complexity goes to is the end-user, often the least-well-informed to make decisions about optimal resource placement across a global fleet.\n\nThis talk is a deep-dive into taming the user experience of multi-cluster scheduling in order to enable platform engineering teams to reclaim the power in placing workload across fleets of clusters, and will cover:\n\n* Multi-cluster resource views (pod aggregation) and subresource proxying for a seamless multi-cluster experience.\n* Multi-cluster discovery, authentication and authorization patterns.\n* Using MultiKueue as the engine for multi-cluster quota abstractions.\n* Using the tenant as the scaling boundaries with scoped apiserver views. Speakers: Andrea Tosatto from  Apple, James Munnelly from  Apple. Location: Building B | Level 2 | B206. Categories: EMERGING + ADVANCED.",
      "metadata": {
        "title": "Building a Kubernetes-native Experience for Your Multi-cluster Fleet",
        "description": "Operating multiple Kubernetes clusters is becoming par for the course in any enterprise-scale Kubernetes deployment. As the complexity of your infrastructure deployments grow, so do the opportunities for inefficiencies.\n\nOnce the boundaries of a single cluster have been broken, the first place this complexity goes to is the end-user, often the least-well-informed to make decisions about optimal resource placement across a global fleet.\n\nThis talk is a deep-dive into taming the user experience of multi-cluster scheduling in order to enable platform engineering teams to reclaim the power in placing workload across fleets of clusters, and will cover:\n\n* Multi-cluster resource views (pod aggregation) and subresource proxying for a seamless multi-cluster experience.\n* Multi-cluster discovery, authentication and authorization patterns.\n* Using MultiKueue as the engine for multi-cluster quota abstractions.\n* Using the tenant as the scaling boundaries with scoped apiserver views.",
        "url": "http://kccncna2025.sched.com/event/95281c859f5a030c29a3008e05fe0894",
        "uid": "95281c859f5a030c29a3008e05fe0894",
        "start": "2025-11-13T11:45:00-05:00",
        "end": "2025-11-13T12:15:00-05:00",
        "categories": [
          "EMERGING + ADVANCED"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B206"
        },
        "speakers": [
          {
            "name": "Andrea Tosatto",
            "company": " Apple"
          },
          {
            "name": "James Munnelly",
            "company": " Apple"
          }
        ]
      }
    },
    {
      "text": "Kubernetes SIG Storage is responsible for ensuring that different types of file and block storage are available wherever a container is scheduled, storage capacity management (container ephemeral storage usage, volume resizing, etc.), influencing scheduling of containers based on storage (data gravity, availability, etc.), and generic operations on storage (snapshotting, etc.). SIG Storage also has a project that provides APIs for object storage support in Kubernetes. In this session, we will deep dive into some projects that SIG Storage is currently working on, provide an update on the current status, and discuss what might be coming in the future. Speakers: Xing Yang from VMware by Broadcom, Michelle Au from Google, Hemant Kumar from Red Hat. Location: Building C | Level 1 | C111-112. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Kubernetes SIG Storage: Intro & Deep Dive",
        "description": "Kubernetes SIG Storage is responsible for ensuring that different types of file and block storage are available wherever a container is scheduled, storage capacity management (container ephemeral storage usage, volume resizing, etc.), influencing scheduling of containers based on storage (data gravity, availability, etc.), and generic operations on storage (snapshotting, etc.). SIG Storage also has a project that provides APIs for object storage support in Kubernetes. In this session, we will deep dive into some projects that SIG Storage is currently working on, provide an update on the current status, and discuss what might be coming in the future.",
        "url": "http://kccncna2025.sched.com/event/17ecf33299ff393e3f82ba32cd9860de",
        "uid": "17ecf33299ff393e3f82ba32cd9860de",
        "start": "2025-11-13T11:45:00-05:00",
        "end": "2025-11-13T12:15:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "1",
          "room": "C111-112"
        },
        "speakers": [
          {
            "name": "Xing Yang",
            "company": "VMware by Broadcom"
          },
          {
            "name": "Michelle Au",
            "company": "Google"
          },
          {
            "name": "Hemant Kumar",
            "company": "Red Hat"
          }
        ]
      }
    },
    {
      "text": "Come to this session to learn about the Open Policy Agent (OPA) project. OPA is a general-purpose policy engine that solves a number of policy-related use cases for authorization, Kubernetes, service mesh, CI/CD, infrastructure permissions, and more.\n\nThis session will begin with OPA maintainers welcoming newcomers by introducing the project and covering core concepts. Current users will then receive an overview of recent changes, highlighting exciting new features and improvements across OPA and its broader ecosystem. OPA Envoy maintainer Tyler Schade will also share some details about recent changes to the OPA Envoy project, including enhancements to Envoy integration and improved support for SPIFFE identities.\n\nA short Gatekeeper update will cover VAP integration (now beta & default), a new audit violations disk export driver, Rego v1 syntax support and more.\n\nIf you are interested in policy as code and security as it relates to cloud native technology, this session is for you. OPA maintainers will also be available for questions after the session. Speakers: Philip Conrad from Apple, Tyler Schade from GEICO Tech, Rita Zhang from  Microsoft, Jaydip Gabani from  Microsoft. Location: Building C | Level 3 | Georgia Ballroom 1. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Open Policy Agent (OPA) Intro & Deep Dive",
        "description": "Come to this session to learn about the Open Policy Agent (OPA) project. OPA is a general-purpose policy engine that solves a number of policy-related use cases for authorization, Kubernetes, service mesh, CI/CD, infrastructure permissions, and more.\n\nThis session will begin with OPA maintainers welcoming newcomers by introducing the project and covering core concepts. Current users will then receive an overview of recent changes, highlighting exciting new features and improvements across OPA and its broader ecosystem. OPA Envoy maintainer Tyler Schade will also share some details about recent changes to the OPA Envoy project, including enhancements to Envoy integration and improved support for SPIFFE identities.\n\nA short Gatekeeper update will cover VAP integration (now beta & default), a new audit violations disk export driver, Rego v1 syntax support and more.\n\nIf you are interested in policy as code and security as it relates to cloud native technology, this session is for you. OPA maintainers will also be available for questions after the session.",
        "url": "http://kccncna2025.sched.com/event/1856936a9dc5200c6b4245364f6062e0",
        "uid": "1856936a9dc5200c6b4245364f6062e0",
        "start": "2025-11-13T11:45:00-05:00",
        "end": "2025-11-13T12:15:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 1"
        },
        "speakers": [
          {
            "name": "Philip Conrad",
            "company": "Apple"
          },
          {
            "name": "Tyler Schade",
            "company": "GEICO Tech"
          },
          {
            "name": "Rita Zhang",
            "company": " Microsoft"
          },
          {
            "name": "Jaydip Gabani",
            "company": " Microsoft"
          }
        ]
      }
    },
    {
      "text": "Machine learning and its particular loads, from massive training jobs to complex inference-scale pipelines, has placed unparalleled demands on Kubernetess key APIs.\n\nThis maintainer-track talk will provide an update on the SIG-API Machine Learnings current work and future directions. We will consider critical AI/ML challenges such as scaling API performance for high-throughput input, evolution of Custom Resource Definitions (CRDs) to manage complex machine learning workflows and specialized hardware (like TPUs and GPUs), and adaptation of the API pattern for efficient processing of huge data sets and distributed machine learning jobs.\n\nAttendees will be introduced to the best ways to influence the design, what future KEPs to be added, and the architectural considerations for whats next to keep Kubernetes a premier platform for AI/ML. Speakers: Joe Betz from Google, David Eads from Red Hat. Location: Building C | Level 3 | Georgia Ballroom 2. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "SIG API Machinery and AI: What Comes Next?",
        "description": "Machine learning and its particular loads, from massive training jobs to complex inference-scale pipelines, has placed unparalleled demands on Kubernetess key APIs.\n\nThis maintainer-track talk will provide an update on the SIG-API Machine Learnings current work and future directions. We will consider critical AI/ML challenges such as scaling API performance for high-throughput input, evolution of Custom Resource Definitions (CRDs) to manage complex machine learning workflows and specialized hardware (like TPUs and GPUs), and adaptation of the API pattern for efficient processing of huge data sets and distributed machine learning jobs.\n\nAttendees will be introduced to the best ways to influence the design, what future KEPs to be added, and the architectural considerations for whats next to keep Kubernetes a premier platform for AI/ML.",
        "url": "http://kccncna2025.sched.com/event/de2ea7ad4bb9f7c1e2bd108faae365d0",
        "uid": "de2ea7ad4bb9f7c1e2bd108faae365d0",
        "start": "2025-11-13T11:45:00-05:00",
        "end": "2025-11-13T12:15:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 2"
        },
        "speakers": [
          {
            "name": "Joe Betz",
            "company": "Google"
          },
          {
            "name": "David Eads",
            "company": "Red Hat"
          }
        ]
      }
    },
    {
      "text": "Anyone running Kubernetes in a large-scale production environment cares deeply about having a predictable Pod lifecycle. Having unknown actors in the system that can terminate your Pods is a scary thought  especially if you run stateful systems on Kubernetes. There are many paths in the Kubernetes core that can abruptly terminate your workloads and cause your apps to dip below their Pod Disruption Budgets, risking unavailability for your customers. Documentation doesnt go so far as to explain all these paths or how they work. In this talk, well focus on the lesser-known abrupt pod eviction modes caused by Kubernetes components  ranging from kubelet to scheduler to controller-manager  and do a deep dive into Kubernetes internals to explain exactly how these pod terminations happen and what guarantees you can expect. Well also debunk some myths like kubelet restarts are safe. At the end, youll leave with a cheatsheet to help you reason about all eviction modes in Kubernetes. Speakers: Ahmet Alp Balkan from LinkedIn. Location: Building B | Level 4 | B405-406a. Categories: OPERATIONS + PERFORMANCE.",
      "metadata": {
        "title": "Evicted! All the Ways Kubernetes Kills Your Pods (and How To Avoid Them)",
        "description": "Anyone running Kubernetes in a large-scale production environment cares deeply about having a predictable Pod lifecycle. Having unknown actors in the system that can terminate your Pods is a scary thought  especially if you run stateful systems on Kubernetes. There are many paths in the Kubernetes core that can abruptly terminate your workloads and cause your apps to dip below their Pod Disruption Budgets, risking unavailability for your customers. Documentation doesnt go so far as to explain all these paths or how they work. In this talk, well focus on the lesser-known abrupt pod eviction modes caused by Kubernetes components  ranging from kubelet to scheduler to controller-manager  and do a deep dive into Kubernetes internals to explain exactly how these pod terminations happen and what guarantees you can expect. Well also debunk some myths like kubelet restarts are safe. At the end, youll leave with a cheatsheet to help you reason about all eviction modes in Kubernetes.",
        "url": "http://kccncna2025.sched.com/event/76ce2fd0b45c6ec31d611af10af27f24",
        "uid": "76ce2fd0b45c6ec31d611af10af27f24",
        "start": "2025-11-13T11:45:00-05:00",
        "end": "2025-11-13T12:15:00-05:00",
        "categories": [
          "OPERATIONS + PERFORMANCE"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B405-406a"
        },
        "speakers": [
          {
            "name": "Ahmet Alp Balkan",
            "company": "LinkedIn"
          }
        ]
      }
    },
    {
      "text": "In the era of large AI models, deployment latency and resource utilization present significant challenges for Kubernetes operators. This session demonstrates techniques to reduce model startup times and optimize cluster resources. We'll deploy a 7B parameter LLM using Ray and vLLM for scaling and serving, implementing three key optimizations: SOCI (Seekable OCI) for lazy loading of container images, enabling containers to start without downloading the entire image first; an optimized storage layer that keeps models pre-downloaded and ready for quick access; and intelligent node provisioning using Karpenter for dynamic resource allocation. We'll compare a standard deployment against one using these optimizations, showing the differences in startup times, resource usage, and operational costs. Attendees will learn implementation steps for these techniques, which they can apply to their own Kubernetes environments to improve AI model deployment efficiency. Speakers: Lucas Duarte from  AWS, Tiago Reichert from  AWS. Location: Building B | Level 5 | Thomas Murphy Ballroom 4. Categories: OPERATIONS + PERFORMANCE.",
      "metadata": {
        "title": "From Pull To Predict: Accelerating AI Model Deployment on Kubernetes",
        "description": "In the era of large AI models, deployment latency and resource utilization present significant challenges for Kubernetes operators. This session demonstrates techniques to reduce model startup times and optimize cluster resources. We'll deploy a 7B parameter LLM using Ray and vLLM for scaling and serving, implementing three key optimizations: SOCI (Seekable OCI) for lazy loading of container images, enabling containers to start without downloading the entire image first; an optimized storage layer that keeps models pre-downloaded and ready for quick access; and intelligent node provisioning using Karpenter for dynamic resource allocation. We'll compare a standard deployment against one using these optimizations, showing the differences in startup times, resource usage, and operational costs. Attendees will learn implementation steps for these techniques, which they can apply to their own Kubernetes environments to improve AI model deployment efficiency.",
        "url": "http://kccncna2025.sched.com/event/dabefbeea7fc7f7bb189191e62729392",
        "uid": "dabefbeea7fc7f7bb189191e62729392",
        "start": "2025-11-13T11:45:00-05:00",
        "end": "2025-11-13T12:15:00-05:00",
        "categories": [
          "OPERATIONS + PERFORMANCE"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 4"
        },
        "speakers": [
          {
            "name": "Lucas Duarte",
            "company": " AWS"
          },
          {
            "name": "Tiago Reichert",
            "company": " AWS"
          }
        ]
      }
    },
    {
      "text": "At The Home Depot, we know a solid foundation is keywhether you're laying tile or deploying edge infrastructure. In this session, well walk through how we designed and built a scalable, resilient edge platform to support real-time retail operations across thousands of stores. Youll learn how we approached hardware abstraction, workload orchestration, interactions between heritage and modern systems, and observability at the edge, all while keeping developer experience and operational simplicity front and center. Well share lessons learned, tools we used (and avoided), and how were evolving the platform to support future innovation. Whether you're just framing your edge strategy or ready to hang drywall, this talk will give you practical insights to take home. Speakers: Dillon TenBrink from The Home Depot. Location: Building B | Level 3 | B312-314. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "Flip That Stack: Renovating Edge Infrastructure at the Home Depot",
        "description": "At The Home Depot, we know a solid foundation is keywhether you're laying tile or deploying edge infrastructure. In this session, well walk through how we designed and built a scalable, resilient edge platform to support real-time retail operations across thousands of stores. Youll learn how we approached hardware abstraction, workload orchestration, interactions between heritage and modern systems, and observability at the edge, all while keeping developer experience and operational simplicity front and center. Well share lessons learned, tools we used (and avoided), and how were evolving the platform to support future innovation. Whether you're just framing your edge strategy or ready to hang drywall, this talk will give you practical insights to take home.",
        "url": "http://kccncna2025.sched.com/event/7dfcdea79f42566d0ff5e9408afc2ed0",
        "uid": "7dfcdea79f42566d0ff5e9408afc2ed0",
        "start": "2025-11-13T11:45:00-05:00",
        "end": "2025-11-13T12:15:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B312-314"
        },
        "speakers": [
          {
            "name": "Dillon TenBrink",
            "company": "The Home Depot"
          }
        ]
      }
    },
    {
      "text": "Everyone is doing platform engineering  yet something still feels off. Why? Rather than celebrate what we already know, this session surfaces what we may be overlooking & the new thinking needed to move forward. Well unpack how the meaning of platform is evolving & challenge assumptions like developer experience above all, platform as a product, unclear ownership that stalls progress, and golden paths that feel more like restrictions. These are the contradictions many teams face today. In this panel, trusted platform thinkers from across the ecosystem come together to ask: Are we solving the right problems, in the right way, with the right teams or just reinforcing complexity & losing business context that platform engineering is meant to serve? Well revisit platform patterns that stood the test of time, explore shifts in open source and orchestration, and imagine what continuity and innovation should look like next. This isnt a debate  its an industry check-in. A creative reset. Speakers: Shweta Vohra from Booking.com, Ram Iyengar from Cloud Foundry Foundation, Daniel Bryant from Syntasso, Kunal Kushwaha from Civo. Location: Building B | Level 3 | B304-305. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "The Questions Not Asked: A Critical Retrospective on Platform Engineering",
        "description": "Everyone is doing platform engineering  yet something still feels off. Why? Rather than celebrate what we already know, this session surfaces what we may be overlooking & the new thinking needed to move forward. Well unpack how the meaning of platform is evolving & challenge assumptions like developer experience above all, platform as a product, unclear ownership that stalls progress, and golden paths that feel more like restrictions. These are the contradictions many teams face today. In this panel, trusted platform thinkers from across the ecosystem come together to ask: Are we solving the right problems, in the right way, with the right teams or just reinforcing complexity & losing business context that platform engineering is meant to serve? Well revisit platform patterns that stood the test of time, explore shifts in open source and orchestration, and imagine what continuity and innovation should look like next. This isnt a debate  its an industry check-in. A creative reset.",
        "url": "http://kccncna2025.sched.com/event/41fc18ddf0800ba44766ac675f777572",
        "uid": "41fc18ddf0800ba44766ac675f777572",
        "start": "2025-11-13T11:45:00-05:00",
        "end": "2025-11-13T12:15:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B304-305"
        },
        "speakers": [
          {
            "name": "Shweta Vohra",
            "company": "Booking.com"
          },
          {
            "name": "Ram Iyengar",
            "company": "Cloud Foundry Foundation"
          },
          {
            "name": "Daniel Bryant",
            "company": "Syntasso"
          },
          {
            "name": "Kunal Kushwaha",
            "company": "Civo"
          }
        ]
      }
    },
    {
      "text": "Take a paws from your busy day! Join us for a visit with some friendly therapy puppies to help reduce stress and boost your mood. Location: Building B | Level 2 | Willow Garden Foyer. Categories: EXPERIENCES.",
      "metadata": {
        "title": "Pet-a-Pup",
        "description": "Take a paws from your busy day! Join us for a visit with some friendly therapy puppies to help reduce stress and boost your mood.",
        "url": "http://kccncna2025.sched.com/event/a57796b09f87ebb800578b408419349f",
        "uid": "a57796b09f87ebb800578b408419349f",
        "start": "2025-11-13T12:00:00-05:00",
        "end": "2025-11-13T13:00:00-05:00",
        "categories": [
          "EXPERIENCES"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "Willow Garden Foyer"
        }
      }
    },
    {
      "text": "Location: TBA. Categories: BREAKS.",
      "metadata": {
        "title": "Lunch ",
        "description": "",
        "url": "http://kccncna2025.sched.com/event/da53bd5f1d030bbf4169191a8d56773a",
        "uid": "da53bd5f1d030bbf4169191a8d56773a",
        "start": "2025-11-13T12:15:00-05:00",
        "end": "2025-11-13T13:45:00-05:00",
        "categories": [
          "BREAKS"
        ],
        "location": {
          "room": "TBA"
        }
      }
    },
    {
      "text": "10-Minute Tip Talk Speakers: Aleks Jones from LF Education. Location: Level 1 | Learning Lounge. Categories: EXPERIENCES.",
      "metadata": {
        "title": "Learning Lounge: A Peek Inside the LLMOps Black Box",
        "description": "10-Minute Tip Talk",
        "url": "http://kccncna2025.sched.com/event/927c06317a507fa35be4e332dbbd5241",
        "uid": "927c06317a507fa35be4e332dbbd5241",
        "start": "2025-11-13T12:30:00-05:00",
        "end": "2025-11-13T12:45:00-05:00",
        "categories": [
          "EXPERIENCES"
        ],
        "location": {
          "level": "1",
          "room": "Learning Lounge"
        },
        "speakers": [
          {
            "name": "Aleks Jones",
            "company": "LF Education"
          }
        ]
      }
    },
    {
      "text": "Join us for casual and engaging meetups at the Network Nook during lunch breaks! These informal gatherings are open to all, whether you're a first-time attendee, a solo traveler, or simply looking to chat about shared interests. This is a great way to connect with others.&nbsp;\n\nToday's theme is: Share & Continue the Conversation\nWhat were your favorite sessions, networking events, etc., this week? Where can you contribute to the mindshare in your local community? Location: Building B | Level 1 | Solutions Showcase. Categories: EXPERIENCES.",
      "metadata": {
        "title": "Network Nook Meetup: Share & Continue the Conversation",
        "description": "Join us for casual and engaging meetups at the Network Nook during lunch breaks! These informal gatherings are open to all, whether you're a first-time attendee, a solo traveler, or simply looking to chat about shared interests. This is a great way to connect with others.&nbsp;\n\nToday's theme is: Share & Continue the Conversation\nWhat were your favorite sessions, networking events, etc., this week? Where can you contribute to the mindshare in your local community?",
        "url": "http://kccncna2025.sched.com/event/e331c9b23e8ea877b693bf113a8e9cb0",
        "uid": "e331c9b23e8ea877b693bf113a8e9cb0",
        "start": "2025-11-13T12:30:00-05:00",
        "end": "2025-11-13T13:30:00-05:00",
        "categories": [
          "EXPERIENCES"
        ],
        "location": {
          "building": "B",
          "level": "1",
          "room": "Solutions Showcase"
        }
      }
    },
    {
      "text": "Are you using the newly GA'd Dynamic Resource Allocation API for your device allocation needs, but wondering why two seemingly identical pods exhibit wildly different performance characteristics? The answer often lies in the complex world of modern hardware topologies. This talk will dive into the critical importance of device alignment  ensuring your allocated CPUs, GPUs, NICs and other devices are optimally co-located. We'll explore the nuances of multi-CPU, NUMA-aware systems, and PCIe hierarchies, demonstrating how subtle misalignments can lead to significant performance bottlenecks. We'll show how you can leverage the DRA API to achieve various forms of alignment and discuss what the community is doing to further enhance this area. Join us to learn how to optimize your high-performance workloads by truly understanding and leveraging the underlying hardware with DRA. Together, we'll make sure you're getting the most bang for your buck from your powerful machines. Speakers: Gaurav Ghildiyal from Google, Byonggon Chun from FuriosaAI. Location: Building B | Level 2 | B206. Categories: AI + ML.",
      "metadata": {
        "title": "Achieving Peak Performance Through Hardware Alignment in DRA",
        "description": "Are you using the newly GA'd Dynamic Resource Allocation API for your device allocation needs, but wondering why two seemingly identical pods exhibit wildly different performance characteristics? The answer often lies in the complex world of modern hardware topologies. This talk will dive into the critical importance of device alignment  ensuring your allocated CPUs, GPUs, NICs and other devices are optimally co-located. We'll explore the nuances of multi-CPU, NUMA-aware systems, and PCIe hierarchies, demonstrating how subtle misalignments can lead to significant performance bottlenecks. We'll show how you can leverage the DRA API to achieve various forms of alignment and discuss what the community is doing to further enhance this area. Join us to learn how to optimize your high-performance workloads by truly understanding and leveraging the underlying hardware with DRA. Together, we'll make sure you're getting the most bang for your buck from your powerful machines.",
        "url": "http://kccncna2025.sched.com/event/9dd18780bb55ddb7b54fc46a63ade2ee",
        "uid": "9dd18780bb55ddb7b54fc46a63ade2ee",
        "start": "2025-11-13T13:45:00-05:00",
        "end": "2025-11-13T14:15:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B206"
        },
        "speakers": [
          {
            "name": "Gaurav Ghildiyal",
            "company": "Google"
          },
          {
            "name": "Byonggon Chun",
            "company": "FuriosaAI"
          }
        ]
      }
    },
    {
      "text": "Join us for an enlightening presentation on effortlessly building an advanced processing form called \"processing pipeline \"for AI/ML workloads. In streaming processing, accelerators are assigned only to specific tasks in the workload. However, we can build high-performance processing infrastructure at the service level by assigning each task to a suitable accelerator and chaining them together. Native Kubernetes is a popular choice for deploying AI/ML workloads. However, more is needed to deploy a new processing form: the \"processing pipeline\" chaining accelerators. This presentation will demonstrate how effortlessly a video inference system can be built using the \"processing pipeline\", which leverages Numaflow and \"Dynamic Resource Allocation\" (DRA). It will also introduce the \"processing pipeline \"that can be integrated into MLOps through Kubeflow Pipelines. You will see a glimpse of future innovations, including high-speed communication between accelerators via the 2nd NIC. Speakers: Kazuki Yamamoto from NTT. Location: Building B | Level 3 | B308-309. Categories: AI + ML.",
      "metadata": {
        "title": "Effortlessly Build High-Performance AI/ML Processing Pipelines Within the ML Lifecycles",
        "description": "Join us for an enlightening presentation on effortlessly building an advanced processing form called \"processing pipeline \"for AI/ML workloads. In streaming processing, accelerators are assigned only to specific tasks in the workload. However, we can build high-performance processing infrastructure at the service level by assigning each task to a suitable accelerator and chaining them together. Native Kubernetes is a popular choice for deploying AI/ML workloads. However, more is needed to deploy a new processing form: the \"processing pipeline\" chaining accelerators. This presentation will demonstrate how effortlessly a video inference system can be built using the \"processing pipeline\", which leverages Numaflow and \"Dynamic Resource Allocation\" (DRA). It will also introduce the \"processing pipeline \"that can be integrated into MLOps through Kubeflow Pipelines. You will see a glimpse of future innovations, including high-speed communication between accelerators via the 2nd NIC.",
        "url": "http://kccncna2025.sched.com/event/e6cb9a183416687b58abc6b08ffcafdb",
        "uid": "e6cb9a183416687b58abc6b08ffcafdb",
        "start": "2025-11-13T13:45:00-05:00",
        "end": "2025-11-13T14:15:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B308-309"
        },
        "speakers": [
          {
            "name": "Kazuki Yamamoto",
            "company": "NTT"
          }
        ]
      }
    },
    {
      "text": "The increasing complexity of AI models drives a demand for advanced computing, leading to the evolution of workload deployment towards intricate patterns like disaggregated-PD deployment on high-performance AI clusters. Optimizing these clusters requires sophisticated orchestration, particularly regarding network topology awareness. This presentation introduces the exploration within the CNCF community, focusing on Volcano and Kueue, into network topology abstraction and scheduling. We will delve into key challenges users face in building AI infrastructure: 1. building commond topology abstraction across diverse hardware, 2. efficiently managing topology data for optimal scheduling decisions, and 3. the ecosystem support for typical workload abstractions like LWS, etc. Speakers: Kevin Wang from Huawei. Location: Building B | Level 4 | B401-402. Categories: AI + ML.",
      "metadata": {
        "title": "Intelligent Topology for AI Power: Network-Aware Scheduling Optimization With Volcano HyperNode",
        "description": "The increasing complexity of AI models drives a demand for advanced computing, leading to the evolution of workload deployment towards intricate patterns like disaggregated-PD deployment on high-performance AI clusters. Optimizing these clusters requires sophisticated orchestration, particularly regarding network topology awareness. This presentation introduces the exploration within the CNCF community, focusing on Volcano and Kueue, into network topology abstraction and scheduling. We will delve into key challenges users face in building AI infrastructure: 1. building commond topology abstraction across diverse hardware, 2. efficiently managing topology data for optimal scheduling decisions, and 3. the ecosystem support for typical workload abstractions like LWS, etc.",
        "url": "http://kccncna2025.sched.com/event/d5f8e1653c8e2e513be8536cd6a3d3d1",
        "uid": "d5f8e1653c8e2e513be8536cd6a3d3d1",
        "start": "2025-11-13T13:45:00-05:00",
        "end": "2025-11-13T14:15:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B401-402"
        },
        "speakers": [
          {
            "name": "Kevin Wang",
            "company": "Huawei"
          }
        ]
      }
    },
    {
      "text": "In this session, we will explore how Itau Unibanco, the largest bank in Brazil and Latin America, successfully implemented and maintained ephemeral runtime environments to support its 18,000 developers. This case study will delve into the challenges faced, the solutions developed, and the benefits realized from this large-scale implementation. Attendees will gain insights into the technical and organizational strategies that enabled Itau Unibanco to enhance developer productivity, reduce costs, and improve system stability.\nStandardizing technology stacks across an organization as large as Itau Unibanco is crucial for simplifying maintenance, enhancing interoperability, and reducing the learning curve for developers. This standardization also played a key role in the successful implementation of ephemeral runtime environments, as it allowed for predictable and repeatable setups that could be easily managed and scaled. Speakers: Alexandre Astolpho Thomaz from Itau Unibanco. Location: Building B | Level 4 | B406b-407. Categories: APPLICATION DEVELOPMENT.",
      "metadata": {
        "title": "Creating and Maintaining Ephemeral Runtime Environments for 18,000 Developers",
        "description": "In this session, we will explore how Itau Unibanco, the largest bank in Brazil and Latin America, successfully implemented and maintained ephemeral runtime environments to support its 18,000 developers. This case study will delve into the challenges faced, the solutions developed, and the benefits realized from this large-scale implementation. Attendees will gain insights into the technical and organizational strategies that enabled Itau Unibanco to enhance developer productivity, reduce costs, and improve system stability.\nStandardizing technology stacks across an organization as large as Itau Unibanco is crucial for simplifying maintenance, enhancing interoperability, and reducing the learning curve for developers. This standardization also played a key role in the successful implementation of ephemeral runtime environments, as it allowed for predictable and repeatable setups that could be easily managed and scaled.",
        "url": "http://kccncna2025.sched.com/event/ee8020830548410ce37e019b46ec3a3f",
        "uid": "ee8020830548410ce37e019b46ec3a3f",
        "start": "2025-11-13T13:45:00-05:00",
        "end": "2025-11-13T14:15:00-05:00",
        "categories": [
          "APPLICATION DEVELOPMENT"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B406b-407"
        },
        "speakers": [
          {
            "name": "Alexandre Astolpho Thomaz",
            "company": "Itau Unibanco"
          }
        ]
      }
    },
    {
      "text": "Object storage like Amazon S3 is known for its scalability, durability, and cost-efficiencybut can it serve as the foundation for high-performance transactional databases? In this talk, Ill share how TiKV, the storage layer of the distributed SQL database TiDB, was re-architected to use object storage as the source of truth. This shift unlocked massive scalability, faster disaster recovery and backup restores, and significantly lower storage costswithout sacrificing performance. Ill dive into the key innovations that decouple compute and storage, keeping object storage off the performance-critical path. Through smart caching, tiered storage, and optimized write paths, we achieved single-digit millisecond p99 latency and millions of TPS at cloud scale. Join us to see how this approach redefines the storage stack for cloud-native databasesand what it means for the future. Speakers: Jinpeng Zhang from PingCAP. Location: Building B | Level 5 | Thomas Murphy Ballroom 2-3. Categories: DATA PROCESSING + STORAGE.",
      "metadata": {
        "title": "Supercharge Cloud Native SQL Database With Object Storage: Scaling TiKV With S3 as the Backbone",
        "description": "Object storage like Amazon S3 is known for its scalability, durability, and cost-efficiencybut can it serve as the foundation for high-performance transactional databases? In this talk, Ill share how TiKV, the storage layer of the distributed SQL database TiDB, was re-architected to use object storage as the source of truth. This shift unlocked massive scalability, faster disaster recovery and backup restores, and significantly lower storage costswithout sacrificing performance. Ill dive into the key innovations that decouple compute and storage, keeping object storage off the performance-critical path. Through smart caching, tiered storage, and optimized write paths, we achieved single-digit millisecond p99 latency and millions of TPS at cloud scale. Join us to see how this approach redefines the storage stack for cloud-native databasesand what it means for the future.",
        "url": "http://kccncna2025.sched.com/event/acb8d808d74a845539cc8163e9706325",
        "uid": "acb8d808d74a845539cc8163e9706325",
        "start": "2025-11-13T13:45:00-05:00",
        "end": "2025-11-13T14:15:00-05:00",
        "categories": [
          "DATA PROCESSING + STORAGE"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 2-3"
        },
        "speakers": [
          {
            "name": "Jinpeng Zhang",
            "company": "PingCAP"
          }
        ]
      }
    },
    {
      "text": "10-Minute Tip Talk Speakers: James Spurin from DiveInto, Ramesh Kumar. Location: Level 1 | Learning Lounge. Categories: EXPERIENCES.",
      "metadata": {
        "title": "Learning Lounge: Starting your Kubestronaut Journey with the KCNA, CKA and CKAD",
        "description": "10-Minute Tip Talk",
        "url": "http://kccncna2025.sched.com/event/03ee1293a4cdfc724d89ebd55e60bff0",
        "uid": "03ee1293a4cdfc724d89ebd55e60bff0",
        "start": "2025-11-13T13:45:00-05:00",
        "end": "2025-11-13T14:00:00-05:00",
        "categories": [
          "EXPERIENCES"
        ],
        "location": {
          "level": "1",
          "room": "Learning Lounge"
        },
        "speakers": [
          {
            "name": "James Spurin",
            "company": "DiveInto"
          },
          {
            "name": "Ramesh Kumar"
          }
        ]
      }
    },
    {
      "text": "Following on from the previous talk at KubeCon EU, the Backstage project has continued its push for stability and maturity. The last couple of years there has been a large effort to switch to a more drop-in method of installing plugins, through the introduction of the new backend and frontend systems. This is now coming to a close with the stable release of the new frontend system, and the maintainers are excited to talk about what this means for the present and future of Backstage. You will also hear about the work towards an AI-Native Backstage, through new systems like the Actions Registry and first-class support for MCP. Theyll also share what this means for authentication in Backstage, and how that system has been evolved to allow for more use-cases. As always, there will also be highlights from the different Project Areas and time for Q&A, so heres your chance to ask any burning questions. Speakers: Ben Lambert from  Spotify, Patrik Oldsberg from  Spotify. Location: Building C | Level 3 | Georgia Ballroom 3. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Backstage Celebrations: Stable Foundations and MCP Innovations",
        "description": "Following on from the previous talk at KubeCon EU, the Backstage project has continued its push for stability and maturity. The last couple of years there has been a large effort to switch to a more drop-in method of installing plugins, through the introduction of the new backend and frontend systems. This is now coming to a close with the stable release of the new frontend system, and the maintainers are excited to talk about what this means for the present and future of Backstage. You will also hear about the work towards an AI-Native Backstage, through new systems like the Actions Registry and first-class support for MCP. Theyll also share what this means for authentication in Backstage, and how that system has been evolved to allow for more use-cases. As always, there will also be highlights from the different Project Areas and time for Q&A, so heres your chance to ask any burning questions.",
        "url": "http://kccncna2025.sched.com/event/276270f134b6b780c2875e026caeaf3a",
        "uid": "276270f134b6b780c2875e026caeaf3a",
        "start": "2025-11-13T13:45:00-05:00",
        "end": "2025-11-13T14:15:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 3"
        },
        "speakers": [
          {
            "name": "Ben Lambert",
            "company": " Spotify"
          },
          {
            "name": "Patrik Oldsberg",
            "company": " Spotify"
          }
        ]
      }
    },
    {
      "text": "Kubernetes SIG Security continues to spread security across the cloud native field. Flutter in for updates about what weve been up to, featuring VEXing bugs, the perennial third-party audit coming back up, Security Self-Assessments emerging from dormancy to bloom again, (O)wasps, budding new contributors, and collaborating across SIGs to bee better together.\n\nEverything we do as contributors has ripple effects outward. Security is everyones responsibility, and every one of us can make a difference.\n\nWhats landing, and whats taking flight? Come hear the buzz with us, and learn how you can get involved! Speakers: Ian Coldwater from Independent, Savitha Raghunathan from Red Hat, Carol Valencia from KrolCloud. Location: Building C | Level 3 | Georgia Ballroom 2. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Butterfly Effect: What Kubernetes SIG Security Has in Flight",
        "description": "Kubernetes SIG Security continues to spread security across the cloud native field. Flutter in for updates about what weve been up to, featuring VEXing bugs, the perennial third-party audit coming back up, Security Self-Assessments emerging from dormancy to bloom again, (O)wasps, budding new contributors, and collaborating across SIGs to bee better together.\n\nEverything we do as contributors has ripple effects outward. Security is everyones responsibility, and every one of us can make a difference.\n\nWhats landing, and whats taking flight? Come hear the buzz with us, and learn how you can get involved!",
        "url": "http://kccncna2025.sched.com/event/a5a9ebc5ae0faee12f2534aa088799d1",
        "uid": "a5a9ebc5ae0faee12f2534aa088799d1",
        "start": "2025-11-13T13:45:00-05:00",
        "end": "2025-11-13T14:15:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 2"
        },
        "speakers": [
          {
            "name": "Ian Coldwater",
            "company": "Independent"
          },
          {
            "name": "Savitha Raghunathan",
            "company": "Red Hat"
          },
          {
            "name": "Carol Valencia",
            "company": "KrolCloud"
          }
        ]
      }
    },
    {
      "text": "This year, after a significant refactor, the Operator Lifecycle Manager (OLM) reached its 1.0 release, and the Java Operator SDK introduced several improvements and new features across multiple minor releases.\n\nThe Operator Framework team will discuss exciting new features in OLM such as declarative approaches to installation previews and policy-based approvals, dynamic workload configuration, and new content types. The team will also cover enhancements in the Java Operator SDK addressing common but complex challenges in building Kubernetes operators, including the expectation pattern.\n\nPlease join the team to talk shop about all things operators! Speakers: Jordan Keister from Rashmi Gottipati, Joe Lanford from Red Hat, Attila Meszaros from Apple. Location: Building C | Level 3 | Georgia Ballroom 1. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Package Management for Your Cluster, Reimagined",
        "description": "This year, after a significant refactor, the Operator Lifecycle Manager (OLM) reached its 1.0 release, and the Java Operator SDK introduced several improvements and new features across multiple minor releases.\n\nThe Operator Framework team will discuss exciting new features in OLM such as declarative approaches to installation previews and policy-based approvals, dynamic workload configuration, and new content types. The team will also cover enhancements in the Java Operator SDK addressing common but complex challenges in building Kubernetes operators, including the expectation pattern.\n\nPlease join the team to talk shop about all things operators!",
        "url": "http://kccncna2025.sched.com/event/02e65ec9a3e7b285f929defd0789bde6",
        "uid": "02e65ec9a3e7b285f929defd0789bde6",
        "start": "2025-11-13T13:45:00-05:00",
        "end": "2025-11-13T14:15:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 1"
        },
        "speakers": [
          {
            "name": "Jordan Keister",
            "company": "Rashmi Gottipati"
          },
          {
            "name": "Joe Lanford",
            "company": "Red Hat"
          },
          {
            "name": "Attila Meszaros",
            "company": "Apple"
          }
        ]
      }
    },
    {
      "text": "As the 2nd oldest project in the CNCF, you have probably heard about Prometheus before. Nevertheless, the project maintainers will give you an introduction from the very beginning, followed by a deep dive into the exciting new features that have been released recently or are in the pipeline. You will learn about many opportunities to use Prometheus, and maybe we can even tempt you to contribute to the project yourself. Speakers: Owen Williams from Grafana Labs. Location: Building C | Level 1 | C111-112. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Prometheus Intro, Deep Dive, and Open Q+A",
        "description": "As the 2nd oldest project in the CNCF, you have probably heard about Prometheus before. Nevertheless, the project maintainers will give you an introduction from the very beginning, followed by a deep dive into the exciting new features that have been released recently or are in the pipeline. You will learn about many opportunities to use Prometheus, and maybe we can even tempt you to contribute to the project yourself.",
        "url": "http://kccncna2025.sched.com/event/43e5b1910df73ac8b0fc793ab5039bfe",
        "uid": "43e5b1910df73ac8b0fc793ab5039bfe",
        "start": "2025-11-13T13:45:00-05:00",
        "end": "2025-11-13T14:15:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "1",
          "room": "C111-112"
        },
        "speakers": [
          {
            "name": "Owen Williams",
            "company": "Grafana Labs"
          }
        ]
      }
    },
    {
      "text": "At Meta, we run over 150 eBPF programs on our machines which provide a range of custom functionality from network observability, load balancing, network stack specialization and security features. We update these eBPF programs at least once a week to cater to changes in our microservice stack which introduces opportunities for outages. While we maintain a custom and flexible in house CI/CD pipeline for ensuring high velocity of our microservices, we observed that we were unable to use the same pipeline for our eBPF programs because of nuances of the eBPF ecosystem and the fact our eBPF programs run in the kernel. Over the last five years, we have tailored our CI/CD pipeline to effectively support eBPF programs and their nuances. In this talk, we describe challenges faced in tailoring our CI/CD pipeline, highlight lessons learned from several production outages, and discuss on-going work to further enhance our eBPF-centric CI/CD pipeline. Speakers: Theophilus Benson from  Meta, Prankur Gupta from  Meta. Location: Building B | Level 4 | B405-406a. Categories: OPERATIONS + PERFORMANCE.",
      "metadata": {
        "title": "Fast and the Furious: CICD Pipeline for eBPF Programs at Meta Scale",
        "description": "At Meta, we run over 150 eBPF programs on our machines which provide a range of custom functionality from network observability, load balancing, network stack specialization and security features. We update these eBPF programs at least once a week to cater to changes in our microservice stack which introduces opportunities for outages. While we maintain a custom and flexible in house CI/CD pipeline for ensuring high velocity of our microservices, we observed that we were unable to use the same pipeline for our eBPF programs because of nuances of the eBPF ecosystem and the fact our eBPF programs run in the kernel. Over the last five years, we have tailored our CI/CD pipeline to effectively support eBPF programs and their nuances. In this talk, we describe challenges faced in tailoring our CI/CD pipeline, highlight lessons learned from several production outages, and discuss on-going work to further enhance our eBPF-centric CI/CD pipeline.",
        "url": "http://kccncna2025.sched.com/event/f3057844ee4e0c95de7f1419a4f88821",
        "uid": "f3057844ee4e0c95de7f1419a4f88821",
        "start": "2025-11-13T13:45:00-05:00",
        "end": "2025-11-13T14:15:00-05:00",
        "categories": [
          "OPERATIONS + PERFORMANCE"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B405-406a"
        },
        "speakers": [
          {
            "name": "Theophilus Benson",
            "company": " Meta"
          },
          {
            "name": "Prankur Gupta",
            "company": " Meta"
          }
        ]
      }
    },
    {
      "text": "ClickOps vs GitOps? Why not both? Initiating every change with an update to Git means finding the right lines of files to change, committing the fix, and updating production. But when your application is broken, speed matters. Do you have time to work out how to modify a 3000-line Helm chart and figure out which other teams, workloads, and clusters this will impact? Or you can break glass and edit live production state; but now you have created drift from desired state! We want to end your frustration - with a new approach. We will demonstrate an evolution of GitOps where you can query and operate on configuration in bulk, use Kubernetes dashboards to fix runtime errors quickly, and synchronize bidirectionally with your clusters. Our solution is to separate all config data from the code used to update it. We store config as fully rendered plain YAML resources (Write Every Time) and show how to update this live without using DRY templates, variables, inline conditionals or loops. Speakers: Brian Grant from  ConfigHub Inc., Alexis Richardson from  ConfigHub Inc.. Location: Building B | Level 5 | Thomas Murphy Ballroom 1. Categories: OPERATIONS + PERFORMANCE.",
      "metadata": {
        "title": "GitOps Without Variables",
        "description": "ClickOps vs GitOps? Why not both? Initiating every change with an update to Git means finding the right lines of files to change, committing the fix, and updating production. But when your application is broken, speed matters. Do you have time to work out how to modify a 3000-line Helm chart and figure out which other teams, workloads, and clusters this will impact? Or you can break glass and edit live production state; but now you have created drift from desired state! We want to end your frustration - with a new approach. We will demonstrate an evolution of GitOps where you can query and operate on configuration in bulk, use Kubernetes dashboards to fix runtime errors quickly, and synchronize bidirectionally with your clusters. Our solution is to separate all config data from the code used to update it. We store config as fully rendered plain YAML resources (Write Every Time) and show how to update this live without using DRY templates, variables, inline conditionals or loops.",
        "url": "http://kccncna2025.sched.com/event/5499bac598d22c33167ea95e354e173e",
        "uid": "5499bac598d22c33167ea95e354e173e",
        "start": "2025-11-13T13:45:00-05:00",
        "end": "2025-11-13T14:15:00-05:00",
        "categories": [
          "OPERATIONS + PERFORMANCE"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 1"
        },
        "speakers": [
          {
            "name": "Brian Grant",
            "company": " ConfigHub Inc."
          },
          {
            "name": "Alexis Richardson",
            "company": " ConfigHub Inc."
          }
        ]
      }
    },
    {
      "text": "What if your next Helm deployment silently deletes a LoadBalancer, a Gateway, or an entire namespace? Weve lived that nightmaremultiple times. In this talk, well share how we turned painful Sev1 outages into a resilient, guardrail-first deployment strategy. By integrating Helm Diff and Argo CD Diff, we built a system that scans every deployment for destructive changeslike the removal of LoadBalancers, KGateways, Services, PVCs, or Namespacesand blocks them unless explicitly approved. This second-layer approval acts as a safety circuit for your release pipelines. No guesswork. No blind deploys. Just real-time visibility into whats about to breakbefore it actually does. Whether youre managing a single cluster or an entire fleet, this talk will show you how to stop fearing Helm and start trusting it again. Because resilience isnt about avoiding failureits about learning, adapting, and building guardrails that protect everyone. Speakers: Payal Godhani from Oracle. Location: Building B | Level 5 | Thomas Murphy Ballroom 4. Categories: OPERATIONS + PERFORMANCE.",
      "metadata": {
        "title": "Mission Abort: Intercepting Dangerous Deletes Before Helm Hits Apply",
        "description": "What if your next Helm deployment silently deletes a LoadBalancer, a Gateway, or an entire namespace? Weve lived that nightmaremultiple times. In this talk, well share how we turned painful Sev1 outages into a resilient, guardrail-first deployment strategy. By integrating Helm Diff and Argo CD Diff, we built a system that scans every deployment for destructive changeslike the removal of LoadBalancers, KGateways, Services, PVCs, or Namespacesand blocks them unless explicitly approved. This second-layer approval acts as a safety circuit for your release pipelines. No guesswork. No blind deploys. Just real-time visibility into whats about to breakbefore it actually does. Whether youre managing a single cluster or an entire fleet, this talk will show you how to stop fearing Helm and start trusting it again. Because resilience isnt about avoiding failureits about learning, adapting, and building guardrails that protect everyone.",
        "url": "http://kccncna2025.sched.com/event/90f37d56f6885980b7676bc601c718b0",
        "uid": "90f37d56f6885980b7676bc601c718b0",
        "start": "2025-11-13T13:45:00-05:00",
        "end": "2025-11-13T14:15:00-05:00",
        "categories": [
          "OPERATIONS + PERFORMANCE"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 4"
        },
        "speakers": [
          {
            "name": "Payal Godhani",
            "company": "Oracle"
          }
        ]
      }
    },
    {
      "text": "As Kubernetes adoption grows, so does the need to manage manifests in a scalable and maintainable way. We used to rely mainly on Helm and Kustomize for templating, but today the ecosystem is evolving rapidly - new manifest-generation tools appear regularly, each with its own syntax, execution model, and design philosophy. This talk explores the fragmented landscape of manifest rendering tools and how well they align - or clash - with GitOps principles. Well examine the core differences between tools that render manifests outside the cluster (e.g., Helm, Kustomize) and those that rely on in-cluster controllers and CRDs (e.g., Crossplane, KubeVela, Kro). These two paradigms differ not only technically, but also in how they integrate with popular GitOps platforms like Argo CD and Flux. Through practical comparisons, attendees will gain a clear understanding of the core paradigms behind these tools - their strengths, limitations, and how well they align with GitOps workflows. Speakers: Dag Bjerre Andersen from Egmont. Location: Building B | Level 3 | B312-314. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "GitOps and the Manifest Dilemma: Helm, Kustomize, Crossplane, Kro, and Beyond",
        "description": "As Kubernetes adoption grows, so does the need to manage manifests in a scalable and maintainable way. We used to rely mainly on Helm and Kustomize for templating, but today the ecosystem is evolving rapidly - new manifest-generation tools appear regularly, each with its own syntax, execution model, and design philosophy. This talk explores the fragmented landscape of manifest rendering tools and how well they align - or clash - with GitOps principles. Well examine the core differences between tools that render manifests outside the cluster (e.g., Helm, Kustomize) and those that rely on in-cluster controllers and CRDs (e.g., Crossplane, KubeVela, Kro). These two paradigms differ not only technically, but also in how they integrate with popular GitOps platforms like Argo CD and Flux. Through practical comparisons, attendees will gain a clear understanding of the core paradigms behind these tools - their strengths, limitations, and how well they align with GitOps workflows.",
        "url": "http://kccncna2025.sched.com/event/581b85a63aa2995bb2e9463b38804b2b",
        "uid": "581b85a63aa2995bb2e9463b38804b2b",
        "start": "2025-11-13T13:45:00-05:00",
        "end": "2025-11-13T14:15:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B312-314"
        },
        "speakers": [
          {
            "name": "Dag Bjerre Andersen",
            "company": "Egmont"
          }
        ]
      }
    },
    {
      "text": "In the dynamic landscape of application development and efficiently managing Kubernetes clusters while ensuring security, isolation, and ease of use is a persistent challenge. Electronic Arts developed a Kubernetes framework that transforms standard clusters into secure, fully segregated multi-tenant platforms. Our custom operator and CRDs enable seamless tenant onboarding with complete isolation across network, RBAC, and resources. This approach allows teams to manage fewer clusters while reducing overall costs. Our solution simplifies complex deployments by handling ingress, certificates, secrets, GitOps, and daily operations through specialized CRDs. Development teams can leverage Kubernetes capabilities without managing its underlying complexity. This presentation reveals our problem-solving strategies and technical implementation details - essential knowledge for anyone tackling Kubernetes multi-tenancy challenges or seeking to simplify Kubernetes adoption for end users. Speakers: Michael Dundek from  Electronic Arts, Ruben Vasconcelos from  Electronic Arts. Location: Building B | Level 3 | B304-305. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "Transforming Kubernetes Clusters Into a Multi-Tenant Powerhouse at Electronic Arts",
        "description": "In the dynamic landscape of application development and efficiently managing Kubernetes clusters while ensuring security, isolation, and ease of use is a persistent challenge. Electronic Arts developed a Kubernetes framework that transforms standard clusters into secure, fully segregated multi-tenant platforms. Our custom operator and CRDs enable seamless tenant onboarding with complete isolation across network, RBAC, and resources. This approach allows teams to manage fewer clusters while reducing overall costs. Our solution simplifies complex deployments by handling ingress, certificates, secrets, GitOps, and daily operations through specialized CRDs. Development teams can leverage Kubernetes capabilities without managing its underlying complexity. This presentation reveals our problem-solving strategies and technical implementation details - essential knowledge for anyone tackling Kubernetes multi-tenancy challenges or seeking to simplify Kubernetes adoption for end users.",
        "url": "http://kccncna2025.sched.com/event/be8713a11c326c814a6821a897f37470",
        "uid": "be8713a11c326c814a6821a897f37470",
        "start": "2025-11-13T13:45:00-05:00",
        "end": "2025-11-13T14:15:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B304-305"
        },
        "speakers": [
          {
            "name": "Michael Dundek",
            "company": " Electronic Arts"
          },
          {
            "name": "Ruben Vasconcelos",
            "company": " Electronic Arts"
          }
        ]
      }
    },
    {
      "text": "Uber operates one of the worlds largest and most complex microservice architectures, composed of thousands of services built in diverse languages and maintained by independent teams. Ensuring consistent, secure service-to-service communication, without requiring code changes, posed a massive challenge.\n\nIn this talk, well share how we built and scaled a platform-level authentication and authorization solution based on Envoy, SPIRE, and the SPIFFE standard. Over a 3-year journey, we rolled out a Zero Trust architecture securing every service interaction with mTLS, authenticating workloads using SPIFFE identities, and enforcing fine-grained policies through a unified control plane.\n\nAttendees will learn about the architectural decisions, operational hurdles, and user-experience tradeoffs we faced along the way. Whether youre starting your Zero Trust journey or looking to scale Envoy/SPIRE across a large org, this talk will offer practical insights from real-world deployment at scale. Speakers: Yangmin Zhu from  Uber, Matt Mathew from  Uber. Location: Building B | Level 3 | B302-303. Categories: SECURITY.",
      "metadata": {
        "title": "Authenticating and Authorizing Every Connection at Uber",
        "description": "Uber operates one of the worlds largest and most complex microservice architectures, composed of thousands of services built in diverse languages and maintained by independent teams. Ensuring consistent, secure service-to-service communication, without requiring code changes, posed a massive challenge.\n\nIn this talk, well share how we built and scaled a platform-level authentication and authorization solution based on Envoy, SPIRE, and the SPIFFE standard. Over a 3-year journey, we rolled out a Zero Trust architecture securing every service interaction with mTLS, authenticating workloads using SPIFFE identities, and enforcing fine-grained policies through a unified control plane.\n\nAttendees will learn about the architectural decisions, operational hurdles, and user-experience tradeoffs we faced along the way. Whether youre starting your Zero Trust journey or looking to scale Envoy/SPIRE across a large org, this talk will offer practical insights from real-world deployment at scale.",
        "url": "http://kccncna2025.sched.com/event/42e9e881d8c30eaa25d2c5149949ae61",
        "uid": "42e9e881d8c30eaa25d2c5149949ae61",
        "start": "2025-11-13T13:45:00-05:00",
        "end": "2025-11-13T14:15:00-05:00",
        "categories": [
          "SECURITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B302-303"
        },
        "speakers": [
          {
            "name": "Yangmin Zhu",
            "company": " Uber"
          },
          {
            "name": "Matt Mathew",
            "company": " Uber"
          }
        ]
      }
    },
    {
      "text": "This Contribfest is focused on creating a few generators for popular SaaS projects. With this contribfest, you'll be able to see how easy it is to contribute any secrets generation mechanism you need to leverage internally, thus making your infrastructure much safer by allowing dynamic credentials rotation out of the box! Speakers: Gustavo Carvalho from External Secrets Inc.. Location: Building B | Level 2 | B208. Categories:  CONTRIBFEST.",
      "metadata": {
        "title": "Contribfest: Create Your Own Generators for External Secrets!",
        "description": "This Contribfest is focused on creating a few generators for popular SaaS projects. With this contribfest, you'll be able to see how easy it is to contribute any secrets generation mechanism you need to leverage internally, thus making your infrastructure much safer by allowing dynamic credentials rotation out of the box!",
        "url": "http://kccncna2025.sched.com/event/71861c2dfbe6ba8611b0e9e88a8ee528",
        "uid": "71861c2dfbe6ba8611b0e9e88a8ee528",
        "start": "2025-11-13T13:45:00-05:00",
        "end": "2025-11-13T15:00:00-05:00",
        "categories": [
          " CONTRIBFEST"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B208"
        },
        "speakers": [
          {
            "name": "Gustavo Carvalho",
            "company": "External Secrets Inc."
          }
        ]
      }
    },
    {
      "text": "Join us for an in-depth session on Meshery a leading cloud native management plane with Meshery maintainers and community. This is your chance to get hands-on with the tools shaping the future of collaborative cloud native management. We will walk through the Contributing Guide to help you familiarize yourself with the project and the contribution process with opportunities to work on core functionality in the Server (Golang) or UI (React) or extend Meshery by building your own plugin.\n\nContribute to the documentation by incorporating your own examples of cloud native architectures using Meshery Designer. You will gain experience with cloud native technologies, including essentially every CNCF project and open source development practices. This session will be led by Meshery maintainers and contributors. No Prior Experience Needed: We welcome contributions from all levels of experience. Join us at Meshery Contribfest and be part of the future of collaborative cloud native management. Speakers: Yash Sharma from DigitalOcean, Lee Calcote from Layer5. Location: Building B | Level 2 | B207. Categories:  CONTRIBFEST.",
      "metadata": {
        "title": "Contribfest: Meshery Contribfest: Dive Deep Into Extending Cloud Native Management",
        "description": "Join us for an in-depth session on Meshery a leading cloud native management plane with Meshery maintainers and community. This is your chance to get hands-on with the tools shaping the future of collaborative cloud native management. We will walk through the Contributing Guide to help you familiarize yourself with the project and the contribution process with opportunities to work on core functionality in the Server (Golang) or UI (React) or extend Meshery by building your own plugin.\n\nContribute to the documentation by incorporating your own examples of cloud native architectures using Meshery Designer. You will gain experience with cloud native technologies, including essentially every CNCF project and open source development practices. This session will be led by Meshery maintainers and contributors. No Prior Experience Needed: We welcome contributions from all levels of experience. Join us at Meshery Contribfest and be part of the future of collaborative cloud native management.",
        "url": "http://kccncna2025.sched.com/event/fb80145b04593f42c3523537960d0731",
        "uid": "fb80145b04593f42c3523537960d0731",
        "start": "2025-11-13T13:45:00-05:00",
        "end": "2025-11-13T15:00:00-05:00",
        "categories": [
          " CONTRIBFEST"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B207"
        },
        "speakers": [
          {
            "name": "Yash Sharma",
            "company": "DigitalOcean"
          },
          {
            "name": "Lee Calcote",
            "company": "Layer5"
          }
        ]
      }
    },
    {
      "text": "Take a paws from your busy day! Join us for a visit with some friendly therapy puppies to help reduce stress and boost your mood. Location: Building B | Level 2 | Willow Garden Foyer. Categories: EXPERIENCES.",
      "metadata": {
        "title": "Pet-a-Pup",
        "description": "Take a paws from your busy day! Join us for a visit with some friendly therapy puppies to help reduce stress and boost your mood.",
        "url": "http://kccncna2025.sched.com/event/85c6d41dcffd37c73fa602de9151cb3b",
        "uid": "85c6d41dcffd37c73fa602de9151cb3b",
        "start": "2025-11-13T14:00:00-05:00",
        "end": "2025-11-13T15:00:00-05:00",
        "categories": [
          "EXPERIENCES"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "Willow Garden Foyer"
        }
      }
    },
    {
      "text": "Your AI inference workloads need more GPUs than any single cluster can provide. Sound familiar? When demand exceeds local capacity and your resources are spread across multiple clusters, intelligent routing becomes critical. This talk introduces Multi-Cluster Inference Gateway, a new part of the open-source Inference Gateway project that tackles distributed AI infrastructure head-on. We'll show you how it leverages existing Gateway API and multi-cluster patterns to dynamically shift traffic where GPUs are available. Solving your GPU scarcity problem starts here. We'll share practical deployment strategies, show you how to optimize costs by intelligently utilizing GPUs, and ensure your AI workloads remain highly available across clusters. Get ready for real-world examples that illustrate how to scale AI serving beyond the confines of a single cluster, empowering you to maximize utilization and minimize latency for your distributed AI workloads. Speakers: Rob Scott from Google, Daneyon Hansen from Solo.io. Location: Building B | Level 2 | B206. Categories: AI + ML.",
      "metadata": {
        "title": "AI Inference Without Boundaries: Dynamic Routing With Multi-Cluster Inference Gateway",
        "description": "Your AI inference workloads need more GPUs than any single cluster can provide. Sound familiar? When demand exceeds local capacity and your resources are spread across multiple clusters, intelligent routing becomes critical. This talk introduces Multi-Cluster Inference Gateway, a new part of the open-source Inference Gateway project that tackles distributed AI infrastructure head-on. We'll show you how it leverages existing Gateway API and multi-cluster patterns to dynamically shift traffic where GPUs are available. Solving your GPU scarcity problem starts here. We'll share practical deployment strategies, show you how to optimize costs by intelligently utilizing GPUs, and ensure your AI workloads remain highly available across clusters. Get ready for real-world examples that illustrate how to scale AI serving beyond the confines of a single cluster, empowering you to maximize utilization and minimize latency for your distributed AI workloads.",
        "url": "http://kccncna2025.sched.com/event/b78757a1fbbea776b5f541f95fc5b8a7",
        "uid": "b78757a1fbbea776b5f541f95fc5b8a7",
        "start": "2025-11-13T14:30:00-05:00",
        "end": "2025-11-13T15:00:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B206"
        },
        "speakers": [
          {
            "name": "Rob Scott",
            "company": "Google"
          },
          {
            "name": "Daneyon Hansen",
            "company": "Solo.io"
          }
        ]
      }
    },
    {
      "text": "Today, Kubernetes users rely on extensions to provide key scheduling functionality needed by AI workloads, including workload-aware scheduling and preemption, and topology-aware scheduling. These extensions can keep clusters full of expensive accelerators highly utilized, share them fairly between teams, and support parallel training and inference on complex hardware topologies. However, they are complex to write and maintain, and are not designed to interoperate. In this session we offer a comparison of \"second-level schedulers\", including Kueue, Volcano, Ray, and Slurm, and of how they interact with the Kubernetes core scheduler (kube-scheduler). We'll cover the current and future work to extend kube-scheduler with resource reservations, workload-awareness, and integration with infrastructure autoscaling. These changes create a clear separation of responsibilities between the core and second-level schedulers. Speakers: Eric Tune from  Google, Wojciech Tyczynski from  Google. Location: Building B | Level 3 | B308-309. Categories: AI + ML.",
      "metadata": {
        "title": "Evolving Kubernetes Scheduling",
        "description": "Today, Kubernetes users rely on extensions to provide key scheduling functionality needed by AI workloads, including workload-aware scheduling and preemption, and topology-aware scheduling. These extensions can keep clusters full of expensive accelerators highly utilized, share them fairly between teams, and support parallel training and inference on complex hardware topologies. However, they are complex to write and maintain, and are not designed to interoperate. In this session we offer a comparison of \"second-level schedulers\", including Kueue, Volcano, Ray, and Slurm, and of how they interact with the Kubernetes core scheduler (kube-scheduler). We'll cover the current and future work to extend kube-scheduler with resource reservations, workload-awareness, and integration with infrastructure autoscaling. These changes create a clear separation of responsibilities between the core and second-level schedulers.",
        "url": "http://kccncna2025.sched.com/event/37d41e1c006723d5eaa218873cde7f7a",
        "uid": "37d41e1c006723d5eaa218873cde7f7a",
        "start": "2025-11-13T14:30:00-05:00",
        "end": "2025-11-13T15:00:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B308-309"
        },
        "speakers": [
          {
            "name": "Eric Tune",
            "company": " Google"
          },
          {
            "name": "Wojciech Tyczynski",
            "company": " Google"
          }
        ]
      }
    },
    {
      "text": "Large language model serving has grown beyond one GPU per pod. Kubernetes clusters now mix GPUs, TPUs and custom AI ASICs, yet the community still needs a unified recipe to harness them. llm-d is a Kubernetes-native distributed-inference stack built around vLLM. It adds a workload-aware scheduler, disaggregated prefill and decode, a tiered KV cache and visibility into interconnect bandwidth, from NIXL fabrics to GPU peer-to-peer links. This talk shows how llm-d feeds that topology data to Kubernetes so each request lands on the accelerator and network path that meets its latency target at the lowest cost. Attendees learn how llm-d reasons about accelerator classes and interconnects, and receive a clear scorecard for selecting the best hardware mix for chat, long-context or batch generation. They leave with a practical blueprint for llm-d understanding, ready to combine high performance with tight budgets. Speakers: Erwan Gallen from Red Hat. Location: Building B | Level 4 | B401-402. Categories: AI + ML.",
      "metadata": {
        "title": "Llm-d: Multi-Accelerator LLM Inference on Kubernetes",
        "description": "Large language model serving has grown beyond one GPU per pod. Kubernetes clusters now mix GPUs, TPUs and custom AI ASICs, yet the community still needs a unified recipe to harness them. llm-d is a Kubernetes-native distributed-inference stack built around vLLM. It adds a workload-aware scheduler, disaggregated prefill and decode, a tiered KV cache and visibility into interconnect bandwidth, from NIXL fabrics to GPU peer-to-peer links. This talk shows how llm-d feeds that topology data to Kubernetes so each request lands on the accelerator and network path that meets its latency target at the lowest cost. Attendees learn how llm-d reasons about accelerator classes and interconnects, and receive a clear scorecard for selecting the best hardware mix for chat, long-context or batch generation. They leave with a practical blueprint for llm-d understanding, ready to combine high performance with tight budgets.",
        "url": "http://kccncna2025.sched.com/event/9d05d0117f7e30f440a8c0ba4274ce8a",
        "uid": "9d05d0117f7e30f440a8c0ba4274ce8a",
        "start": "2025-11-13T14:30:00-05:00",
        "end": "2025-11-13T15:00:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B401-402"
        },
        "speakers": [
          {
            "name": "Erwan Gallen",
            "company": "Red Hat"
          }
        ]
      }
    },
    {
      "text": "Modern centralized authorization systems like OpenFGA dont just centralize policythey also amalgamate authorization data such as users, roles, and relationships. This shift brings great flexibility and visibility, but introduces a key challenge: keeping that data in sync with distributed application state. As having a single shared database is an anti-pattern, this talk will explore options to handle this challenge reliably at scale. Using Daprs building block APIsincluding pub/sub and state managementattendees will learn how to coordinate consistent dual writes between apps and OpenFGA. Attendees will walk away with an architecture that emits domain events from services and uses Dapr to process them asynchronously, ensuring consistency without tight coupling or fragile orchestration. Jose and Alice will demonstrate a real-world example where centralized authorization is integrated cleanly into an open source, microservices system. Speakers: Jose Padilla from Auth0, Alice Gibbons from Diagrid. Location: Building B | Level 4 | B406b-407. Categories: APPLICATION DEVELOPMENT.",
      "metadata": {
        "title": "Design Patterns for Consistent Centralized Authorization",
        "description": "Modern centralized authorization systems like OpenFGA dont just centralize policythey also amalgamate authorization data such as users, roles, and relationships. This shift brings great flexibility and visibility, but introduces a key challenge: keeping that data in sync with distributed application state. As having a single shared database is an anti-pattern, this talk will explore options to handle this challenge reliably at scale. Using Daprs building block APIsincluding pub/sub and state managementattendees will learn how to coordinate consistent dual writes between apps and OpenFGA. Attendees will walk away with an architecture that emits domain events from services and uses Dapr to process them asynchronously, ensuring consistency without tight coupling or fragile orchestration. Jose and Alice will demonstrate a real-world example where centralized authorization is integrated cleanly into an open source, microservices system.",
        "url": "http://kccncna2025.sched.com/event/a7e42e5d1e1b9fc19f63ee8388138e82",
        "uid": "a7e42e5d1e1b9fc19f63ee8388138e82",
        "start": "2025-11-13T14:30:00-05:00",
        "end": "2025-11-13T15:00:00-05:00",
        "categories": [
          "APPLICATION DEVELOPMENT"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B406b-407"
        },
        "speakers": [
          {
            "name": "Jose Padilla",
            "company": "Auth0"
          },
          {
            "name": "Alice Gibbons",
            "company": "Diagrid"
          }
        ]
      }
    },
    {
      "text": "Stateful workloads like databases, caching systems, and message brokers are the backbone of many modern applications, yet they pose distinct challenges within Kubernetes. Unlike their stateless counterparts, these workloads demand persistent storage, stable network identities, and precise resource allocations. The default Kubernetes scheduler, while robust, often struggles to meet these specialized needs, potentially resulting in performance degradation, resource inefficiencies, or operational instability. In this session, well take a deep dive into the art of scheduling stateful workloads, breaking it down into three essential components - why, what and how of the most popular Kubernetes schedulers out there. By the end of this talk, attendees will walk away with a clear understanding of how to adapt Kubernetes scheduling to the unique demands of big data workloads. Speakers: The Why from What and How of K8s Schedulers - Rahul Sharma, Wilfred Spiegelenburg from Cloudera. Location: Building B | Level 5 | Thomas Murphy Ballroom 2-3. Categories: DATA PROCESSING + STORAGE.",
      "metadata": {
        "title": "Optimized Scheduling for Big Data Workloads",
        "description": "Stateful workloads like databases, caching systems, and message brokers are the backbone of many modern applications, yet they pose distinct challenges within Kubernetes. Unlike their stateless counterparts, these workloads demand persistent storage, stable network identities, and precise resource allocations. The default Kubernetes scheduler, while robust, often struggles to meet these specialized needs, potentially resulting in performance degradation, resource inefficiencies, or operational instability. In this session, well take a deep dive into the art of scheduling stateful workloads, breaking it down into three essential components - why, what and how of the most popular Kubernetes schedulers out there. By the end of this talk, attendees will walk away with a clear understanding of how to adapt Kubernetes scheduling to the unique demands of big data workloads.",
        "url": "http://kccncna2025.sched.com/event/49960a0f21a5705a319289603e3ea7fc",
        "uid": "49960a0f21a5705a319289603e3ea7fc",
        "start": "2025-11-13T14:30:00-05:00",
        "end": "2025-11-13T15:00:00-05:00",
        "categories": [
          "DATA PROCESSING + STORAGE"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 2-3"
        },
        "speakers": [
          {
            "name": "The Why",
            "company": "What and How of K8s Schedulers - Rahul Sharma"
          },
          {
            "name": "Wilfred Spiegelenburg",
            "company": "Cloudera"
          }
        ]
      }
    },
    {
      "text": "GenAI is redefining what a cloud-native ML platform must deliver. Kubeflow answers with a modular stack, from pipeline orchestration and data processing to distributed training, tuning, and inference. In this update, we will map that frontier for the entire ML workload lifecycle.\n\nIt unveils reproducible blueprints for fine-tuning and serving large language models on diverse GPU fleets driven by Kubeflow families and components that balance utilization with isolation.\n\nWe explain how declarative components, artifact versioning, and lineage tracking keep experiments portable between on-prem and cloud. Additionally, it outlines the twelve-month roadmap: security hardening, comprehensive ML user experience, and multi-cluster awareness.\n\nThe session ends with an open Q&A and contribution on-ramps for good-first issues, mentorship, and governance so that attendees depart with step-by-step recipes, architecture guides, and a concrete way to shape Kubeflows next chapter. Speakers: Yuki Iwai from CyberAgent, Inc., Valentina Rodriguez Sosa from Red Hat, Johnu George from Nutanix, Akshay Chitneni from Apple, Josh Bottum from Indemnify AI. Location: Building C | Level 1 | C111-112. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Kubeflow Ecosystem: Navigating the Cloud Native AI/ML and LLMOps Frontier",
        "description": "GenAI is redefining what a cloud-native ML platform must deliver. Kubeflow answers with a modular stack, from pipeline orchestration and data processing to distributed training, tuning, and inference. In this update, we will map that frontier for the entire ML workload lifecycle.\n\nIt unveils reproducible blueprints for fine-tuning and serving large language models on diverse GPU fleets driven by Kubeflow families and components that balance utilization with isolation.\n\nWe explain how declarative components, artifact versioning, and lineage tracking keep experiments portable between on-prem and cloud. Additionally, it outlines the twelve-month roadmap: security hardening, comprehensive ML user experience, and multi-cluster awareness.\n\nThe session ends with an open Q&A and contribution on-ramps for good-first issues, mentorship, and governance so that attendees depart with step-by-step recipes, architecture guides, and a concrete way to shape Kubeflows next chapter.",
        "url": "http://kccncna2025.sched.com/event/19a79d0b8290d754d39c5969edead368",
        "uid": "19a79d0b8290d754d39c5969edead368",
        "start": "2025-11-13T14:30:00-05:00",
        "end": "2025-11-13T15:00:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "1",
          "room": "C111-112"
        },
        "speakers": [
          {
            "name": "Yuki Iwai",
            "company": "CyberAgent, Inc."
          },
          {
            "name": "Valentina Rodriguez Sosa",
            "company": "Red Hat"
          },
          {
            "name": "Johnu George",
            "company": "Nutanix"
          },
          {
            "name": "Akshay Chitneni",
            "company": "Apple"
          },
          {
            "name": "Josh Bottum",
            "company": "Indemnify AI"
          }
        ]
      }
    },
    {
      "text": "This talk highlights the major advancements in Harbor from version 2.12 to 2.13. In v2.12, Harbor introduced enhanced robot accounts for better CI/CD automation, added proxy cache speed limits for efficient network usage, improved LDAP onboarding for smoother authentication, and expanded integration with ACR & ACR EE registries for flexible image replication. In v2.13, Harbor continues this momentum with significant security and observability improvements: an extended audit log offers detailed user action tracking, OIDC enhancements add better session handling and PKCE support, and Redis TLS ensures secure communicationthough a known TLS config issue with external Redis was noted. New CloudNativeAI integration now supports AI model storage and lifecycle management. Dragonfly preheating was optimized for large AI artifacts. Join us to get the information first hand were are we going with 2.14 and onwards! Speakers: Where Are We Heading? - Orlin Vasilev from SUSE. Location: Building C | Level 3 | Georgia Ballroom 1. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Project Harbor Maintainers Update",
        "description": "This talk highlights the major advancements in Harbor from version 2.12 to 2.13. In v2.12, Harbor introduced enhanced robot accounts for better CI/CD automation, added proxy cache speed limits for efficient network usage, improved LDAP onboarding for smoother authentication, and expanded integration with ACR & ACR EE registries for flexible image replication. In v2.13, Harbor continues this momentum with significant security and observability improvements: an extended audit log offers detailed user action tracking, OIDC enhancements add better session handling and PKCE support, and Redis TLS ensures secure communicationthough a known TLS config issue with external Redis was noted. New CloudNativeAI integration now supports AI model storage and lifecycle management. Dragonfly preheating was optimized for large AI artifacts. Join us to get the information first hand were are we going with 2.14 and onwards!",
        "url": "http://kccncna2025.sched.com/event/b860673d144f60a25832699c8e68764a",
        "uid": "b860673d144f60a25832699c8e68764a",
        "start": "2025-11-13T14:30:00-05:00",
        "end": "2025-11-13T15:00:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 1"
        },
        "speakers": [
          {
            "name": "Where Are We Heading? - Orlin Vasilev",
            "company": "SUSE"
          }
        ]
      }
    },
    {
      "text": "Argo Rollouts is a Kubernetes controller for Progressive Delivery (blue/green and canary deployments). The controller already supports a plugin system for traffic providers (Istio, Traefik, Gateway API, etc.) and for metric providers (Prometheus, Datadog, etc.). In the latest release, the Argo team completed the trilogy by implementing support for Canary Step plugins. This extends Argo Rollouts capabilities and enriches the progressive delivery experience to accommodate a multitude of scenarios. With Canary step plugins, you can now fully control what happens DURING the canary process and implement any custom functionality that you want within the canary steps. Did you always want to do canary gating? Deployment sync between different controllers? Custom notifications while the canary is running? Now you can! In this talk we will see the architecture of the new plugin mechanism and explain how you can extend canary deployments with your own custom workflows. Speakers: Kostis Kapelonis from Octopus Deploy, Alexandre Gaudreault from Intuit. Location: Building C | Level 3 | Georgia Ballroom 2. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Supercharge Your Canary Deployments With Argo Rollouts Step Plugins",
        "description": "Argo Rollouts is a Kubernetes controller for Progressive Delivery (blue/green and canary deployments). The controller already supports a plugin system for traffic providers (Istio, Traefik, Gateway API, etc.) and for metric providers (Prometheus, Datadog, etc.). In the latest release, the Argo team completed the trilogy by implementing support for Canary Step plugins. This extends Argo Rollouts capabilities and enriches the progressive delivery experience to accommodate a multitude of scenarios. With Canary step plugins, you can now fully control what happens DURING the canary process and implement any custom functionality that you want within the canary steps. Did you always want to do canary gating? Deployment sync between different controllers? Custom notifications while the canary is running? Now you can! In this talk we will see the architecture of the new plugin mechanism and explain how you can extend canary deployments with your own custom workflows.",
        "url": "http://kccncna2025.sched.com/event/f7b2f07ed8febcee995f832ec76a8252",
        "uid": "f7b2f07ed8febcee995f832ec76a8252",
        "start": "2025-11-13T14:30:00-05:00",
        "end": "2025-11-13T15:00:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 2"
        },
        "speakers": [
          {
            "name": "Kostis Kapelonis",
            "company": "Octopus Deploy"
          },
          {
            "name": "Alexandre Gaudreault",
            "company": "Intuit"
          }
        ]
      }
    },
    {
      "text": "Have you ever wondered how kubectl and kustomize enhancements are designed and built? Curious why your favorite feature request wasn't accepted? Join the folks from Kubernetes SIG CLI to find out!\n\nIn this session, the SIG CLI maintainers will provide an introduction to the plethora of tooling they are working on and an overview of how to get started contributing. They will share the work done over the past year and the roadmap for what is next. Join us to help shape your favorite tools! Speakers: Marly Salazar from Independent, Arda Guclu from Red Hat, Maciej Szulik from  Defense Unicorns, Eddie Zaneski from  Defense Unicorns. Location: Building C | Level 3 | Georgia Ballroom 3. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "What's New With Kubectl and Kustomize ... and How You Can Help!",
        "description": "Have you ever wondered how kubectl and kustomize enhancements are designed and built? Curious why your favorite feature request wasn't accepted? Join the folks from Kubernetes SIG CLI to find out!\n\nIn this session, the SIG CLI maintainers will provide an introduction to the plethora of tooling they are working on and an overview of how to get started contributing. They will share the work done over the past year and the roadmap for what is next. Join us to help shape your favorite tools!",
        "url": "http://kccncna2025.sched.com/event/58162b0f8c7eba01f40656a041bfc825",
        "uid": "58162b0f8c7eba01f40656a041bfc825",
        "start": "2025-11-13T14:30:00-05:00",
        "end": "2025-11-13T15:00:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 3"
        },
        "speakers": [
          {
            "name": "Marly Salazar",
            "company": "Independent"
          },
          {
            "name": "Arda Guclu",
            "company": "Red Hat"
          },
          {
            "name": "Maciej Szulik",
            "company": " Defense Unicorns"
          },
          {
            "name": "Eddie Zaneski",
            "company": " Defense Unicorns"
          }
        ]
      }
    },
    {
      "text": "Zynga, a global leader in interactive entertainment and a wholly-owned subsidiary of Take-Two Interactive Software, Inc, launches new mobile games with our platform engineering team multiple times a year on Kubernetes. Join the central infrastructure teams behind the company that made mobile hits like Words with Friends, FarmVille, Zynga Poker, and many more. Learn from both Amazon and Zynga how together they support game teams and central teams to scale applications for game launches before, during, and after to make sure they are ready for everything. Speakers: What Zynga Monitors When Game Teams Perform World Wide Launches from  Inc., How We Prepare - Molly Sheets from  Inc., Krunal Soni from  Inc., Steve Phillips from Amazon, Justin Schwartz from Zynga. Location: Building B | Level 4 | B405-406a. Categories: OPERATIONS + PERFORMANCE.",
      "metadata": {
        "title": "Final Boss Fights",
        "description": "Zynga, a global leader in interactive entertainment and a wholly-owned subsidiary of Take-Two Interactive Software, Inc, launches new mobile games with our platform engineering team multiple times a year on Kubernetes. Join the central infrastructure teams behind the company that made mobile hits like Words with Friends, FarmVille, Zynga Poker, and many more. Learn from both Amazon and Zynga how together they support game teams and central teams to scale applications for game launches before, during, and after to make sure they are ready for everything.",
        "url": "http://kccncna2025.sched.com/event/2307618b0c9d0ec99b67176fedd9c127",
        "uid": "2307618b0c9d0ec99b67176fedd9c127",
        "start": "2025-11-13T14:30:00-05:00",
        "end": "2025-11-13T15:00:00-05:00",
        "categories": [
          "OPERATIONS + PERFORMANCE"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B405-406a"
        },
        "speakers": [
          {
            "name": "What Zynga Monitors When Game Teams Perform World Wide Launches",
            "company": " Inc."
          },
          {
            "name": "How We Prepare - Molly Sheets",
            "company": " Inc."
          },
          {
            "name": "Krunal Soni",
            "company": " Inc."
          },
          {
            "name": "Steve Phillips",
            "company": "Amazon"
          },
          {
            "name": "Justin Schwartz",
            "company": "Zynga"
          }
        ]
      }
    },
    {
      "text": "A client came to us with a problem were seeing more and more, their large language model (LLM) was deployed, but inference was painfully slow, GPU usage was unpredictable, and costs were spiraling out of control. Kubernetes alone wasnt enough, they needed a production-ready, efficient, and scalable stack. In this talk, well walk through how we diagnosed and solved the issue using open-source CNCF tools, turning a chaotic deployment into a well-oiled inference machine. Youll learn how to: 1. Use KServe and Kubeflow to serve LLMs reliably. 2. Benchmark and auto-scale workloads using Volcano and KEDA while optimizing resource usage and latency. 3. Track model performance and drift with Prometheus, Grafana, and OpenTelemetry. Well share benchmarks, architectures, and lessons from the field, all based on open-source tooling you can try today. Whether youre running LLMs at scale or just exploring GenAI, this talk is packed with real-world solutions to help you do more with less. Speakers: Aditya Soni from Forrester Research, Hrittik Roy from Loft Labs. Location: Building B | Level 5 | Thomas Murphy Ballroom 4. Categories: OPERATIONS + PERFORMANCE.",
      "metadata": {
        "title": "Help! My LLM Is a Resource Hog: How We Tamed Inference With Kubernetes and Open Source Muscle",
        "description": "A client came to us with a problem were seeing more and more, their large language model (LLM) was deployed, but inference was painfully slow, GPU usage was unpredictable, and costs were spiraling out of control. Kubernetes alone wasnt enough, they needed a production-ready, efficient, and scalable stack. In this talk, well walk through how we diagnosed and solved the issue using open-source CNCF tools, turning a chaotic deployment into a well-oiled inference machine. Youll learn how to: 1. Use KServe and Kubeflow to serve LLMs reliably. 2. Benchmark and auto-scale workloads using Volcano and KEDA while optimizing resource usage and latency. 3. Track model performance and drift with Prometheus, Grafana, and OpenTelemetry. Well share benchmarks, architectures, and lessons from the field, all based on open-source tooling you can try today. Whether youre running LLMs at scale or just exploring GenAI, this talk is packed with real-world solutions to help you do more with less.",
        "url": "http://kccncna2025.sched.com/event/652b71d5847cb226d4b38709c5e3e9e9",
        "uid": "652b71d5847cb226d4b38709c5e3e9e9",
        "start": "2025-11-13T14:30:00-05:00",
        "end": "2025-11-13T15:00:00-05:00",
        "categories": [
          "OPERATIONS + PERFORMANCE"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 4"
        },
        "speakers": [
          {
            "name": "Aditya Soni",
            "company": "Forrester Research"
          },
          {
            "name": "Hrittik Roy",
            "company": "Loft Labs"
          }
        ]
      }
    },
    {
      "text": "Creating a successful platform plugin or product is a strategic and technical journey requiring clear vision, deliberate engineering, and a focus on user needs. In this talk, Kate and I will share our experience at Spotify, from engineering and product perspectives, as we developed a Backstage plugin that evolved from a simple internal tool to support diverse user groups. Well explore Spotifys journey, balancing challenges and opportunities at scale, and share key lessons for addressing diverse user needs. Attendees will gain a practical framework to align product strategy with engineering execution and externalize internal tools effectively. Using a real-world example, well provide actionable insights on crafting a strong product vision, managing technical trade-offs, and prioritizing for impact. Whether building a plugin, platform, or product, this talk equips participants with tools to drive adoption, stakeholder satisfaction, and alignment between strategy and engineering. Speakers: Sri Chandrasekaran from  Spotify, Kate Klymkovska from  Spotify. Location: Building B | Level 3 | B312-314. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "Harmonizing Strategy and Engineering: Lessons Learnt in Building a Platform Plugin for Diverse Users",
        "description": "Creating a successful platform plugin or product is a strategic and technical journey requiring clear vision, deliberate engineering, and a focus on user needs. In this talk, Kate and I will share our experience at Spotify, from engineering and product perspectives, as we developed a Backstage plugin that evolved from a simple internal tool to support diverse user groups. Well explore Spotifys journey, balancing challenges and opportunities at scale, and share key lessons for addressing diverse user needs. Attendees will gain a practical framework to align product strategy with engineering execution and externalize internal tools effectively. Using a real-world example, well provide actionable insights on crafting a strong product vision, managing technical trade-offs, and prioritizing for impact. Whether building a plugin, platform, or product, this talk equips participants with tools to drive adoption, stakeholder satisfaction, and alignment between strategy and engineering.",
        "url": "http://kccncna2025.sched.com/event/3d1da2443405eac57ba6353a88c1402e",
        "uid": "3d1da2443405eac57ba6353a88c1402e",
        "start": "2025-11-13T14:30:00-05:00",
        "end": "2025-11-13T15:00:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B312-314"
        },
        "speakers": [
          {
            "name": "Sri Chandrasekaran",
            "company": " Spotify"
          },
          {
            "name": "Kate Klymkovska",
            "company": " Spotify"
          }
        ]
      }
    },
    {
      "text": "Embark on an epic journey paralleling Ulysses' Odyssey with the challenges faced in modern platform engineering. Like Ulysses navigating mythical trials, platform teams encounter cultural resistance, integration complexities, resource constraints, and technical debt. This session creatively aligns these common blockers to Ulysses legendary adventure, providing practical strategies to overcome each obstacle. Join us to discover how clear vision, resilience, and strategic navigation empower teams to successfully adopt platform engineering and drive exceptional developer experiences. Speakers: William Rizzo from Mirantis. Location: Building B | Level 3 | B304-305. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "Ulysses Odyssey Through Platform Engineering",
        "description": "Embark on an epic journey paralleling Ulysses' Odyssey with the challenges faced in modern platform engineering. Like Ulysses navigating mythical trials, platform teams encounter cultural resistance, integration complexities, resource constraints, and technical debt. This session creatively aligns these common blockers to Ulysses legendary adventure, providing practical strategies to overcome each obstacle. Join us to discover how clear vision, resilience, and strategic navigation empower teams to successfully adopt platform engineering and drive exceptional developer experiences.",
        "url": "http://kccncna2025.sched.com/event/58fd157b2bbc3c6cc10896f953c095a9",
        "uid": "58fd157b2bbc3c6cc10896f953c095a9",
        "start": "2025-11-13T14:30:00-05:00",
        "end": "2025-11-13T15:00:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B304-305"
        },
        "speakers": [
          {
            "name": "William Rizzo",
            "company": "Mirantis"
          }
        ]
      }
    },
    {
      "text": "At Pinterest, our data processing platform runs nearly 90K jobs on 20K nodes ingesting about 200PB of data daily, powering ML models, user insights, data lakes, and more. This massive scale, while pushing the limits of cloud computing, requires secure, least-privileged data management that also has to meet evolving regulations. To address these needs, we introduced Finer Grained Access Control (FGAC) into Moka, our new Kubernetes-based processing platform. FGAC integrates Kubernetes and AWS features (namespaces, sidecars, service accounts, RBAC, STS, EKS, IRSA) to authenticate with internal services (servicemesh, mTLS, IAM proxy) for a secure multi-tenant environment supporting Spark, Ray, and Flink. In this talk, we detail our design for Moka FGAC and current migration status. We also share the trade-offs and design decisions that led to better data isolation, scale, improved resource utilization and an overall simpler approach compared to our previous Hadoop/Kerberos based solution. Speakers: Soam Acharya from  Pinterest, William Tom from  Pinterest. Location: Building B | Level 3 | B302-303. Categories: SECURITY.",
      "metadata": {
        "title": "Securing Data Applications at Pinterest With Finer Grained Access Control on Kubernetes",
        "description": "At Pinterest, our data processing platform runs nearly 90K jobs on 20K nodes ingesting about 200PB of data daily, powering ML models, user insights, data lakes, and more. This massive scale, while pushing the limits of cloud computing, requires secure, least-privileged data management that also has to meet evolving regulations. To address these needs, we introduced Finer Grained Access Control (FGAC) into Moka, our new Kubernetes-based processing platform. FGAC integrates Kubernetes and AWS features (namespaces, sidecars, service accounts, RBAC, STS, EKS, IRSA) to authenticate with internal services (servicemesh, mTLS, IAM proxy) for a secure multi-tenant environment supporting Spark, Ray, and Flink. In this talk, we detail our design for Moka FGAC and current migration status. We also share the trade-offs and design decisions that led to better data isolation, scale, improved resource utilization and an overall simpler approach compared to our previous Hadoop/Kerberos based solution.",
        "url": "http://kccncna2025.sched.com/event/9248015d029bded98a02cef0e7f63f6f",
        "uid": "9248015d029bded98a02cef0e7f63f6f",
        "start": "2025-11-13T14:30:00-05:00",
        "end": "2025-11-13T15:00:00-05:00",
        "categories": [
          "SECURITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B302-303"
        },
        "speakers": [
          {
            "name": "Soam Acharya",
            "company": " Pinterest"
          },
          {
            "name": "William Tom",
            "company": " Pinterest"
          }
        ]
      }
    },
    {
      "text": "Most breach post-mortems start with Which CVE? However, ours usually end with There wasnt one. We analyzed 10 B Kubernetes audit events and scanned over 3000 clusters to map compromise paths that rely solely on insecure defaults shipped by default in widely trusted Helm charts. The pattern is painfully consistent: world-reachable Service/Ingress, authentication set to off by default, and a pod that have permissions to go wild. Well chain those three defaults against Apache Pinot, Selenium Grid and Meshery all without a single vulnerability. To flip the script, well walk through hardening the same workloads using existing community tools like OPA Gatekeeper, Kyverno, Pod Security Admission, and GitHub Actions to enforce guardrails before someone in your organization is going to deploy an \"official\" Helm chart. Speakers: Michael Katchinskiy from  Microsoft, Yossi Weizman from  Microsoft. Location: Building B | Level 5 | Thomas Murphy Ballroom 1. Categories: SECURITY.",
      "metadata": {
        "title": "You Deployed What?! Data-Driven Lessons on Unsafe Helm Chart Defaults",
        "description": "Most breach post-mortems start with Which CVE? However, ours usually end with There wasnt one. We analyzed 10 B Kubernetes audit events and scanned over 3000 clusters to map compromise paths that rely solely on insecure defaults shipped by default in widely trusted Helm charts. The pattern is painfully consistent: world-reachable Service/Ingress, authentication set to off by default, and a pod that have permissions to go wild. Well chain those three defaults against Apache Pinot, Selenium Grid and Meshery all without a single vulnerability. To flip the script, well walk through hardening the same workloads using existing community tools like OPA Gatekeeper, Kyverno, Pod Security Admission, and GitHub Actions to enforce guardrails before someone in your organization is going to deploy an \"official\" Helm chart.",
        "url": "http://kccncna2025.sched.com/event/631d858dc3de962ad5a246e5dbf56233",
        "uid": "631d858dc3de962ad5a246e5dbf56233",
        "start": "2025-11-13T14:30:00-05:00",
        "end": "2025-11-13T15:00:00-05:00",
        "categories": [
          "SECURITY"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 1"
        },
        "speakers": [
          {
            "name": "Michael Katchinskiy",
            "company": " Microsoft"
          },
          {
            "name": "Yossi Weizman",
            "company": " Microsoft"
          }
        ]
      }
    },
    {
      "text": "AI workloads require increasing scale for both compute and data, as well as significant heterogeneity across workloads, models, data types, and hardware accelerators. As a consequence, the software stack for running compute-intensive AI workloads is fragmented and rapidly evolving. Companies that productionize AI end up building large AI platform teams to manage these workloads. However, within the fragmented landscape, common patterns are beginning to emerge. This talk describes a popular software stack combining Kubernetes, Ray, PyTorch, and vLLM. It describes the role of each of these frameworks, how they operate together, and illustrates this combination with case studies from Pinterest, Uber, and Roblox as well as from todays most popular post-training frameworks. Speakers: Robert Nishihara from Anyscale. Location: Building B | Level 2 | B206. Categories: AI + ML.",
      "metadata": {
        "title": "An Open Source AI Compute Stack: Kubernetes + Ray + PyTorch + VLLM",
        "description": "AI workloads require increasing scale for both compute and data, as well as significant heterogeneity across workloads, models, data types, and hardware accelerators. As a consequence, the software stack for running compute-intensive AI workloads is fragmented and rapidly evolving. Companies that productionize AI end up building large AI platform teams to manage these workloads. However, within the fragmented landscape, common patterns are beginning to emerge. This talk describes a popular software stack combining Kubernetes, Ray, PyTorch, and vLLM. It describes the role of each of these frameworks, how they operate together, and illustrates this combination with case studies from Pinterest, Uber, and Roblox as well as from todays most popular post-training frameworks.",
        "url": "http://kccncna2025.sched.com/event/fb65f16ff2f8e5ec8a8744ce55157992",
        "uid": "fb65f16ff2f8e5ec8a8744ce55157992",
        "start": "2025-11-13T15:15:00-05:00",
        "end": "2025-11-13T15:45:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "2",
          "room": "B206"
        },
        "speakers": [
          {
            "name": "Robert Nishihara",
            "company": "Anyscale"
          }
        ]
      }
    },
    {
      "text": "Agentic AI is evolving from hype to hands-on realityno longer just copilots, but autonomous actors in Kubernetes clusters. But how effective are these AI agents in real-world ops?\n\nThis panel brings together builders and operators who've deployed LLM-powered agents at scale in production to share what worked, what broke, and what surprised them. Expect a candid, high-signal conversation on the true strengths and sharp limitations of AI agents for Kubernetes.\n\nSREs, platform engineers/operatorscome with questions, leave with a clearer sense of where AI can reduce toil, when it still needs babysitting(human-in-the-loop), and how to experiment and deploy safely.\n\nWell cover:\n\n- High-efficacy use cases: RCA, triage, incident summarization\n- Common failure patterns: hallucinations, context loss, unpredictability, alert attention\n- Evaluation strategies in dynamic prod environments\n- Design trends: agent chaining, feedback loops, safety guardrails Speakers: Pavneet Ahluwalia from Microsoft, Idit Levine from Solo.io, Arik ALon from Robusta.dev, Valeria Ortiz from Akamai. Location: Building B | Level 3 | B308-309. Categories: AI + ML.",
      "metadata": {
        "title": "Beyond ChatOps: Agentic AI in KubernetesWhat Works, What Breaks, and Whats Next",
        "description": "Agentic AI is evolving from hype to hands-on realityno longer just copilots, but autonomous actors in Kubernetes clusters. But how effective are these AI agents in real-world ops?\n\nThis panel brings together builders and operators who've deployed LLM-powered agents at scale in production to share what worked, what broke, and what surprised them. Expect a candid, high-signal conversation on the true strengths and sharp limitations of AI agents for Kubernetes.\n\nSREs, platform engineers/operatorscome with questions, leave with a clearer sense of where AI can reduce toil, when it still needs babysitting(human-in-the-loop), and how to experiment and deploy safely.\n\nWell cover:\n\n- High-efficacy use cases: RCA, triage, incident summarization\n- Common failure patterns: hallucinations, context loss, unpredictability, alert attention\n- Evaluation strategies in dynamic prod environments\n- Design trends: agent chaining, feedback loops, safety guardrails",
        "url": "http://kccncna2025.sched.com/event/eba12734da4080c4c51c31c19ac7cbc7",
        "uid": "eba12734da4080c4c51c31c19ac7cbc7",
        "start": "2025-11-13T15:15:00-05:00",
        "end": "2025-11-13T15:45:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B308-309"
        },
        "speakers": [
          {
            "name": "Pavneet Ahluwalia",
            "company": "Microsoft"
          },
          {
            "name": "Idit Levine",
            "company": "Solo.io"
          },
          {
            "name": "Arik ALon",
            "company": "Robusta.dev"
          },
          {
            "name": "Valeria Ortiz",
            "company": "Akamai"
          }
        ]
      }
    },
    {
      "text": "As AI agents evolve from toy experiments to production-grade workflows, engineering teams face new orchestration challenges. LLM-based agents don't just need GPUsthey need state, retries, memory & coordination across tools, APIs, & data systems. Enter Argo: the battle-tested workflow engine that's quietly becoming the backbone of serious agentic infrastructure. In this talk, we'll explore how Argo Workflows power the runtime execution of complex agent pipelineschaining tasks, managing dependencies & scaling based on dynamic resource needswhile Argo CD provides GitOps-style control over the K8s infra and configurations those agents rely on. Together, they enable full lifecycle management: declarative deployment, dynamic execution, and safe rollbacks. We'll also share how layering agents on top of Argo unlocks new capabilitiesfrom safely iterating on prompt-driven pipelines, to automatically rolling back failed steps, to integrating observability and human-in-the-loop checkpoints. Speakers: Benji Kalman from Root.io, Shiran Melamed from JFrog. Location: Building B | Level 4 | B401-402. Categories: AI + ML.",
      "metadata": {
        "title": "GitOps for AI Agents: Building Reliable AI Pipelines With Argo",
        "description": "As AI agents evolve from toy experiments to production-grade workflows, engineering teams face new orchestration challenges. LLM-based agents don't just need GPUsthey need state, retries, memory & coordination across tools, APIs, & data systems. Enter Argo: the battle-tested workflow engine that's quietly becoming the backbone of serious agentic infrastructure. In this talk, we'll explore how Argo Workflows power the runtime execution of complex agent pipelineschaining tasks, managing dependencies & scaling based on dynamic resource needswhile Argo CD provides GitOps-style control over the K8s infra and configurations those agents rely on. Together, they enable full lifecycle management: declarative deployment, dynamic execution, and safe rollbacks. We'll also share how layering agents on top of Argo unlocks new capabilitiesfrom safely iterating on prompt-driven pipelines, to automatically rolling back failed steps, to integrating observability and human-in-the-loop checkpoints.",
        "url": "http://kccncna2025.sched.com/event/8a9e6660f41a6e83bec61640f45f7320",
        "uid": "8a9e6660f41a6e83bec61640f45f7320",
        "start": "2025-11-13T15:15:00-05:00",
        "end": "2025-11-13T15:45:00-05:00",
        "categories": [
          "AI + ML"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B401-402"
        },
        "speakers": [
          {
            "name": "Benji Kalman",
            "company": "Root.io"
          },
          {
            "name": "Shiran Melamed",
            "company": "JFrog"
          }
        ]
      }
    },
    {
      "text": "Feature flags decouple deployment from release, enabling safe rollouts and continuous delivery. But at scale, they introduce challenges: drift between environments, inconsistent definitions, and runtime bugs from undefined or mistyped flags. At one of the largest health systems in the US, daily releases using feature flags boosted delivery speed but exposed risks due to poor flag hygiene. To address this, we created Feature Flag Driven Development (FFDD); a workflow that embeds flag management into the SDLC. This talk introduces FFDD, a practice that treats feature flags as first-class citizens. Built on the CNCF OpenFeature spec and tools like the OpenFeature CLI, FFDD eliminates manual coordination, reduces errors, and enables GitOps-driven promotion. Well demo the full FFDD flow: defining flags, generating type-safe code, validating in CI, syncing flags, and promoting safely across environments using GitHub Actions. Speakers: Kris Coleman from TestifySec, Michael Beemer from Dynatrace. Location: Building B | Level 4 | B406b-407. Categories: APPLICATION DEVELOPMENT.",
      "metadata": {
        "title": "Feature Flag Driven Development: Seamlessly Integrate Feature Flags Into Your SDLC",
        "description": "Feature flags decouple deployment from release, enabling safe rollouts and continuous delivery. But at scale, they introduce challenges: drift between environments, inconsistent definitions, and runtime bugs from undefined or mistyped flags. At one of the largest health systems in the US, daily releases using feature flags boosted delivery speed but exposed risks due to poor flag hygiene. To address this, we created Feature Flag Driven Development (FFDD); a workflow that embeds flag management into the SDLC. This talk introduces FFDD, a practice that treats feature flags as first-class citizens. Built on the CNCF OpenFeature spec and tools like the OpenFeature CLI, FFDD eliminates manual coordination, reduces errors, and enables GitOps-driven promotion. Well demo the full FFDD flow: defining flags, generating type-safe code, validating in CI, syncing flags, and promoting safely across environments using GitHub Actions.",
        "url": "http://kccncna2025.sched.com/event/48642572823f0c8a7a70408faed7f0dd",
        "uid": "48642572823f0c8a7a70408faed7f0dd",
        "start": "2025-11-13T15:15:00-05:00",
        "end": "2025-11-13T15:45:00-05:00",
        "categories": [
          "APPLICATION DEVELOPMENT"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B406b-407"
        },
        "speakers": [
          {
            "name": "Kris Coleman",
            "company": "TestifySec"
          },
          {
            "name": "Michael Beemer",
            "company": "Dynatrace"
          }
        ]
      }
    },
    {
      "text": "Most people dont think of Postgres in the context of quorum or distributed systems theory but vanilla open source Postgres has supported quorum commits across multiple replicas for almost 10 years now. Technologies like cassandra and dynamo popularized quorum consistency in the hot path of distributed writes and reads, but the theory also applies to cluster reconfigurations in a single-writer database like Postgres. Stateful operators at level V of the capabilities framework require very careful end-to-end coordination between control plane and data plane algorithms to avoid data loss when providing auto-healing under circumstances like network partitions or compounded failures. This session will explore how quorum consistency can be applied in the CloudNativePG operator, offering lessons and insights to fellow maintainers of other Kubernetes operators for stateful workloads. Speakers: Jeremy Schneider from GEICO Tech, Leonardo Cecchi from EDB. Location: Building B | Level 5 | Thomas Murphy Ballroom 2-3. Categories: DATA PROCESSING + STORAGE.",
      "metadata": {
        "title": "Quorum-Based Consistency for Cluster Changes With CloudNativePG Operator",
        "description": "Most people dont think of Postgres in the context of quorum or distributed systems theory but vanilla open source Postgres has supported quorum commits across multiple replicas for almost 10 years now. Technologies like cassandra and dynamo popularized quorum consistency in the hot path of distributed writes and reads, but the theory also applies to cluster reconfigurations in a single-writer database like Postgres. Stateful operators at level V of the capabilities framework require very careful end-to-end coordination between control plane and data plane algorithms to avoid data loss when providing auto-healing under circumstances like network partitions or compounded failures. This session will explore how quorum consistency can be applied in the CloudNativePG operator, offering lessons and insights to fellow maintainers of other Kubernetes operators for stateful workloads.",
        "url": "http://kccncna2025.sched.com/event/db48a98ee2456366aafbad8d2057eb73",
        "uid": "db48a98ee2456366aafbad8d2057eb73",
        "start": "2025-11-13T15:15:00-05:00",
        "end": "2025-11-13T15:45:00-05:00",
        "categories": [
          "DATA PROCESSING + STORAGE"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 2-3"
        },
        "speakers": [
          {
            "name": "Jeremy Schneider",
            "company": "GEICO Tech"
          },
          {
            "name": "Leonardo Cecchi",
            "company": "EDB"
          }
        ]
      }
    },
    {
      "text": "Dragonfly provides efficient, stable, and secure file distribution and image acceleration using P2P technology within cloud-native architectures. This talk will briefly introduce Dragonfly and highlight the features of its latest version. Key updates include enhanced security and new functionalities tailored for more efficient and robust model distribution. We will also demonstrate how Dragonfly preheats and distributes AI models (packaged as OCI Artifacts) to read-only volumes in Kubernetes, enabling faster deployments. Speakers: Intro Updates from Model Distribution With Cloud Native Infra - Wenbo Qi, Chenyu Zhang from Ant Group. Location: Building C | Level 3 | Georgia Ballroom 2. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Dragonfly v2.3.0",
        "description": "Dragonfly provides efficient, stable, and secure file distribution and image acceleration using P2P technology within cloud-native architectures. This talk will briefly introduce Dragonfly and highlight the features of its latest version. Key updates include enhanced security and new functionalities tailored for more efficient and robust model distribution. We will also demonstrate how Dragonfly preheats and distributes AI models (packaged as OCI Artifacts) to read-only volumes in Kubernetes, enabling faster deployments.",
        "url": "http://kccncna2025.sched.com/event/d30ca8864fb0706b7c980f20b61e820e",
        "uid": "d30ca8864fb0706b7c980f20b61e820e",
        "start": "2025-11-13T15:15:00-05:00",
        "end": "2025-11-13T15:45:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 2"
        },
        "speakers": [
          {
            "name": "Intro",
            "title": "Updates",
            "company": "Model Distribution With Cloud Native Infra - Wenbo Qi"
          },
          {
            "name": "Chenyu Zhang",
            "company": "Ant Group"
          }
        ]
      }
    },
    {
      "text": "The CNCF Cloud Native Maturity Model has long been a guiding framework for organizations navigating cloud native adoption. But the ecosystem moves fast, and so must the model.\n\nIn this interactive session, members of the CNCF Cartografos Working Group will unveil the latest evolution of the model, designed to meet the demands of todays fast-changing landscape, including AI, security, platform engineering and developer experience.\n\nWell share whats changed, explore how to apply the model, and open the floor for your input. Whether youre leading transformation, building cloud native applications and platforms, or guiding your team through complexity, this session will help you benchmark where you are, align across stakeholders, and influence where the model goes next.\n\nBring your challenges, your wins, and your voice. This is more than a presentationit is your chance to help shape the communitys vision of what the cloud native maturity journey looks like. Speakers: Danielle Cook from Independent, Simon Forster from Stackegy, Robert Glenn from Glennium. Location: Building C | Level 1 | C111-112. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Mapping the Next Phase: Updating the Cloud Native Maturity Model for 2025, The AI Era and Beyond",
        "description": "The CNCF Cloud Native Maturity Model has long been a guiding framework for organizations navigating cloud native adoption. But the ecosystem moves fast, and so must the model.\n\nIn this interactive session, members of the CNCF Cartografos Working Group will unveil the latest evolution of the model, designed to meet the demands of todays fast-changing landscape, including AI, security, platform engineering and developer experience.\n\nWell share whats changed, explore how to apply the model, and open the floor for your input. Whether youre leading transformation, building cloud native applications and platforms, or guiding your team through complexity, this session will help you benchmark where you are, align across stakeholders, and influence where the model goes next.\n\nBring your challenges, your wins, and your voice. This is more than a presentationit is your chance to help shape the communitys vision of what the cloud native maturity journey looks like.",
        "url": "http://kccncna2025.sched.com/event/825d7a54a9a36045f98211da34d564cf",
        "uid": "825d7a54a9a36045f98211da34d564cf",
        "start": "2025-11-13T15:15:00-05:00",
        "end": "2025-11-13T15:45:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "1",
          "room": "C111-112"
        },
        "speakers": [
          {
            "name": "Danielle Cook",
            "company": "Independent"
          },
          {
            "name": "Simon Forster",
            "company": "Stackegy"
          },
          {
            "name": "Robert Glenn",
            "company": "Glennium"
          }
        ]
      }
    },
    {
      "text": "CoreDNS continues to evolve as the DNS backbone of Kubernetes, with recent updates focused on performance, extensibility, and operational hardening. This session explores a new plugin that improves multi-core scalability, enabling higher throughput and lower latency in large-scale clusters. Well share tuning strategies, production insights, and how CoreDNS is adapting to modern DNS workloads. Well also touch on best practices for securing DNS in Kubernetesincluding common attack patterns like spoofing and cache abuseand how CoreDNS features can help mitigate them. Finally, well review recent plugin ecosystem changes and preview whats ahead on the project roadmap. Whether you operate clusters or contribute upstream, this session offers practical guidance on running CoreDNS securely and efficiently at scale. Speakers: Yong Tang from DataDirect Networks, John Belamaric from Google. Location: Building C | Level 3 | Georgia Ballroom 1. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "Scaling and Securing CoreDNS: Performance and Resilience",
        "description": "CoreDNS continues to evolve as the DNS backbone of Kubernetes, with recent updates focused on performance, extensibility, and operational hardening. This session explores a new plugin that improves multi-core scalability, enabling higher throughput and lower latency in large-scale clusters. Well share tuning strategies, production insights, and how CoreDNS is adapting to modern DNS workloads. Well also touch on best practices for securing DNS in Kubernetesincluding common attack patterns like spoofing and cache abuseand how CoreDNS features can help mitigate them. Finally, well review recent plugin ecosystem changes and preview whats ahead on the project roadmap. Whether you operate clusters or contribute upstream, this session offers practical guidance on running CoreDNS securely and efficiently at scale.",
        "url": "http://kccncna2025.sched.com/event/3f9fc30b05a57476821a1b161cfea51c",
        "uid": "3f9fc30b05a57476821a1b161cfea51c",
        "start": "2025-11-13T15:15:00-05:00",
        "end": "2025-11-13T15:45:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 1"
        },
        "speakers": [
          {
            "name": "Yong Tang",
            "company": "DataDirect Networks"
          },
          {
            "name": "John Belamaric",
            "company": "Google"
          }
        ]
      }
    },
    {
      "text": "When SIG Cloud Provider began, a major focus was the migration of cloud provider code out of the main Kubernetes code repository. The successful out-of-tree migration increased flexibility but also added challenges for testing and verification. Well cover where efficiencies and coordination between providers are making the ecosystem more robust. CSI, CNI, and other domain-specific API solutions often lack broader reuse across the ecosystem, so providers themselves are collaborating to build the authoritative low-level KRM layer, clearing the way with robust cloud resource management abstractions so as to allow builders to create solutions at higher layers.\n\nThe SIG maintainers will discuss how doing more collaboration and creating cross-provider building blocks in the Kubernetes community will lead to a better platform for everyone. Expect to walk away from this talk with a clear vision for where SIG Cloud Provider has evolved, and how you can contribute to creating the SIGs future! Speakers: Bridget Kromhout from Microsoft, Michael McCune from  Red Hat, Joel Speed from  Red Hat, Walter Fender from Google, Jesse Butler from AWS. Location: Building C | Level 3 | Georgia Ballroom 3. Categories: MAINTAINER TRACK.",
      "metadata": {
        "title": "SIG Cloud Provider Deep Dive: Expanding Our Mission",
        "description": "When SIG Cloud Provider began, a major focus was the migration of cloud provider code out of the main Kubernetes code repository. The successful out-of-tree migration increased flexibility but also added challenges for testing and verification. Well cover where efficiencies and coordination between providers are making the ecosystem more robust. CSI, CNI, and other domain-specific API solutions often lack broader reuse across the ecosystem, so providers themselves are collaborating to build the authoritative low-level KRM layer, clearing the way with robust cloud resource management abstractions so as to allow builders to create solutions at higher layers.\n\nThe SIG maintainers will discuss how doing more collaboration and creating cross-provider building blocks in the Kubernetes community will lead to a better platform for everyone. Expect to walk away from this talk with a clear vision for where SIG Cloud Provider has evolved, and how you can contribute to creating the SIGs future!",
        "url": "http://kccncna2025.sched.com/event/1d715061e8fc1cf83fe5aa4b22ed8920",
        "uid": "1d715061e8fc1cf83fe5aa4b22ed8920",
        "start": "2025-11-13T15:15:00-05:00",
        "end": "2025-11-13T15:45:00-05:00",
        "categories": [
          "MAINTAINER TRACK"
        ],
        "location": {
          "building": "C",
          "level": "3",
          "room": "Georgia Ballroom 3"
        },
        "speakers": [
          {
            "name": "Bridget Kromhout",
            "company": "Microsoft"
          },
          {
            "name": "Michael McCune",
            "company": " Red Hat"
          },
          {
            "name": "Joel Speed",
            "company": " Red Hat"
          },
          {
            "name": "Walter Fender",
            "company": "Google"
          },
          {
            "name": "Jesse Butler",
            "company": "AWS"
          }
        ]
      }
    },
    {
      "text": "Effectively managing memory pressure is key to stable Kubernetes workloads and preventing OOM errors. This talk shows how using disk-space as temporary memory (swap) on Kubernetes nodes enhances application stability and makes your nodes more resilient to memory spikes. The Kubernetes NodeSwap feature, set for GA in 1.34, promises better resource management and node stability. NodeSwap offers stability for long-running applications from abrupt termination due to sudden memory spikes. However, swap is not without trade-offs, as it can decrease predictability and degrade performance for some workloads. We'll share our stress-test learnings on potential problems and performance tuning with kernel parameters to optimize swap on Kubernetes nodes. Attendees will learn practical swap utilization limits, recommended configurations and their effects on node stability. We will also discuss ongoing work of a critical pod-level API for fine-grained swap control and workload compatibility. Speakers: Ajay Sundar Karuppasamy from Google LLC, Itamar Holder from Red Hat. Location: Building B | Level 4 | B405-406a. Categories: OPERATIONS + PERFORMANCE.",
      "metadata": {
        "title": "Deep Dive: Handling Kubernetes Memory Pressure & Achieving Workload Stability With NodeSwap",
        "description": "Effectively managing memory pressure is key to stable Kubernetes workloads and preventing OOM errors. This talk shows how using disk-space as temporary memory (swap) on Kubernetes nodes enhances application stability and makes your nodes more resilient to memory spikes. The Kubernetes NodeSwap feature, set for GA in 1.34, promises better resource management and node stability. NodeSwap offers stability for long-running applications from abrupt termination due to sudden memory spikes. However, swap is not without trade-offs, as it can decrease predictability and degrade performance for some workloads. We'll share our stress-test learnings on potential problems and performance tuning with kernel parameters to optimize swap on Kubernetes nodes. Attendees will learn practical swap utilization limits, recommended configurations and their effects on node stability. We will also discuss ongoing work of a critical pod-level API for fine-grained swap control and workload compatibility.",
        "url": "http://kccncna2025.sched.com/event/dd1483bb74f02af3c69fc761310a5a6f",
        "uid": "dd1483bb74f02af3c69fc761310a5a6f",
        "start": "2025-11-13T15:15:00-05:00",
        "end": "2025-11-13T15:45:00-05:00",
        "categories": [
          "OPERATIONS + PERFORMANCE"
        ],
        "location": {
          "building": "B",
          "level": "4",
          "room": "B405-406a"
        },
        "speakers": [
          {
            "name": "Ajay Sundar Karuppasamy",
            "company": "Google LLC"
          },
          {
            "name": "Itamar Holder",
            "company": "Red Hat"
          }
        ]
      }
    },
    {
      "text": "For years, multi-cluster systems created an ad hoc and proprietary list of clusters, which led to fragmentation in the market. Ever dreamt of having a Cluster Inventory that you could use with every controller, on every platform? This talk introduces the newly standardized credential support for the ClusterProfile CRD, resolving a key blocker for the multi-cluster controller community. Learn how Sig-multicluster's year-long effort has culminated in a universal Cluster Inventory, usable with any controller on any platform. We will also go over some of the Fleet managers that support ClusterProfile, and how a multi-cluster application can leverage the ClusterProfile API to interact with multiple clusters at the same time. Additionally, we will discuss best practices and future extensions for ClusterProfile. This session empowers you to learn a unified approach to multi-cluster management, eliminating ad hoc solutions and fostering interoperability. Speakers: Corentin Debains from Google, Ryan Zhang from Microsoft. Location: Building B | Level 5 | Thomas Murphy Ballroom 4. Categories: OPERATIONS + PERFORMANCE.",
      "metadata": {
        "title": "Finally, a Cluster Inventory I Can USE!",
        "description": "For years, multi-cluster systems created an ad hoc and proprietary list of clusters, which led to fragmentation in the market. Ever dreamt of having a Cluster Inventory that you could use with every controller, on every platform? This talk introduces the newly standardized credential support for the ClusterProfile CRD, resolving a key blocker for the multi-cluster controller community. Learn how Sig-multicluster's year-long effort has culminated in a universal Cluster Inventory, usable with any controller on any platform. We will also go over some of the Fleet managers that support ClusterProfile, and how a multi-cluster application can leverage the ClusterProfile API to interact with multiple clusters at the same time. Additionally, we will discuss best practices and future extensions for ClusterProfile. This session empowers you to learn a unified approach to multi-cluster management, eliminating ad hoc solutions and fostering interoperability.",
        "url": "http://kccncna2025.sched.com/event/f2663aefb0ef06519b1af83f50524f7e",
        "uid": "f2663aefb0ef06519b1af83f50524f7e",
        "start": "2025-11-13T15:15:00-05:00",
        "end": "2025-11-13T15:45:00-05:00",
        "categories": [
          "OPERATIONS + PERFORMANCE"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 4"
        },
        "speakers": [
          {
            "name": "Corentin Debains",
            "company": "Google"
          },
          {
            "name": "Ryan Zhang",
            "company": "Microsoft"
          }
        ]
      }
    },
    {
      "text": "There is a sea of tools one can use for the critical phase of Deployment during your SDLC. To keep our environment secure and reliable, ING chose to work with Kubernetes and Azure DevOps. In this talk, we will share the success story of how 1400 in-house developed APIs reached 100k+ Production deployments in half a year, using one single pipeline. In order to stay in control, we use Open Policy Agent. To ensure the reliability and the resilience of the APIs, we use tools like: QuotaAutoscaler (ING open source CRD) and HorizontalPodAustoscaler, native rollback mechanisms with Helm, automatic certificates using CertManager and Prometheus monitoring. The pipeline deploys code in Azure Kubernetes Service and on-prem Kubernetes clusters. This solution was built as a platform, designed to be agnostic to the target system, reducing the cognitive load on the teams and allowing them to focus on the application development. We call this The Kingsroad. Speakers: Andrada Raducanu from ING Hubs Romania. Location: Building B | Level 3 | B312-314. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "From Code To Cluster: Orchestrating 100,000+ Kubernetes Deployments With 1 Pipeline",
        "description": "There is a sea of tools one can use for the critical phase of Deployment during your SDLC. To keep our environment secure and reliable, ING chose to work with Kubernetes and Azure DevOps. In this talk, we will share the success story of how 1400 in-house developed APIs reached 100k+ Production deployments in half a year, using one single pipeline. In order to stay in control, we use Open Policy Agent. To ensure the reliability and the resilience of the APIs, we use tools like: QuotaAutoscaler (ING open source CRD) and HorizontalPodAustoscaler, native rollback mechanisms with Helm, automatic certificates using CertManager and Prometheus monitoring. The pipeline deploys code in Azure Kubernetes Service and on-prem Kubernetes clusters. This solution was built as a platform, designed to be agnostic to the target system, reducing the cognitive load on the teams and allowing them to focus on the application development. We call this The Kingsroad.",
        "url": "http://kccncna2025.sched.com/event/bae57d514c0e23bf6f529b702feade51",
        "uid": "bae57d514c0e23bf6f529b702feade51",
        "start": "2025-11-13T15:15:00-05:00",
        "end": "2025-11-13T15:45:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B312-314"
        },
        "speakers": [
          {
            "name": "Andrada Raducanu",
            "company": "ING Hubs Romania"
          }
        ]
      }
    },
    {
      "text": "Argo CD is a foundational tool in GitOps workflows, enabling declarative continuous delivery in Kubernetes environments. However, it relies heavily on Redis for caching and state management, making Redis a critical component that can become a bottleneck as workloads scale. Enter Dragonfly, a drop-in Redis replacement purpose-built for modern cloud hardware. Dragonfly delivers up to 25x better performance at 80% lower cost, making it a compelling alternative for performance-intensive Kubernetes-native applications. In this session, well share how we seamlessly replaced Redis in Argo CD with Dragonfly, using the Dragonfly Operator without modifying Argo CDs internals. Youll learn how to deploy Dragonfly with Kubernetes-native tooling, manage it at scale, and configure it for high availability, security, and resilience. This talk is ideal for platform engineers, SREs, DevOps teams, and Kubernetes users seeking improved performance, lower costs, or easier Redis operations. Speakers: Soumya Ghosh Dastidar from  Akuity Inc., Justin Marquis from  Akuity Inc.. Location: Building B | Level 3 | B304-305. Categories: PLATFORM ENGINEERING.",
      "metadata": {
        "title": "Turbocharging Argo CD: Replacing Redis With Dragonfly for Better Performance and Lower Bills",
        "description": "Argo CD is a foundational tool in GitOps workflows, enabling declarative continuous delivery in Kubernetes environments. However, it relies heavily on Redis for caching and state management, making Redis a critical component that can become a bottleneck as workloads scale. Enter Dragonfly, a drop-in Redis replacement purpose-built for modern cloud hardware. Dragonfly delivers up to 25x better performance at 80% lower cost, making it a compelling alternative for performance-intensive Kubernetes-native applications. In this session, well share how we seamlessly replaced Redis in Argo CD with Dragonfly, using the Dragonfly Operator without modifying Argo CDs internals. Youll learn how to deploy Dragonfly with Kubernetes-native tooling, manage it at scale, and configure it for high availability, security, and resilience. This talk is ideal for platform engineers, SREs, DevOps teams, and Kubernetes users seeking improved performance, lower costs, or easier Redis operations.",
        "url": "http://kccncna2025.sched.com/event/5ddcaf89736788123ed779040949f42b",
        "uid": "5ddcaf89736788123ed779040949f42b",
        "start": "2025-11-13T15:15:00-05:00",
        "end": "2025-11-13T15:45:00-05:00",
        "categories": [
          "PLATFORM ENGINEERING"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B304-305"
        },
        "speakers": [
          {
            "name": "Soumya Ghosh Dastidar",
            "company": " Akuity Inc."
          },
          {
            "name": "Justin Marquis",
            "company": " Akuity Inc."
          }
        ]
      }
    },
    {
      "text": "As AI becomes integral to enterprise applications, securing AI/ML systems is paramount. While MITRE ATLAS provides a robust framework for understanding adversarial threats to AI, enterprises often struggle to adopt it in cloud-native\nenvironments. This session demonstrates practical strategies for using open-source tools to operationalize AI security and align with the MITRE ATLAS framework.\nWe'll explore real-world use cases illustrating how tools like Kubeflow, Clair, Falco, StackRox, and Kubescape can be combined to detect and mitigate threats such as data poisoning, model extraction, and evasion attacks throughout the AI\nlifecyclefrom training to inference.\nAttendees will gain insights into:\nUnderstanding the MITRE ATLAS framework and its significance for AI/ML security, Mapping open-source tools to the ATLAS matrix for actionable, layered defenses, Integrating security controls into MLOps pipelines using Kubernetes-native tooling. Speakers: Doron Caspin from  Red Hat, Valentina Rodriguez Sosa from  Red Hat. Location: Building B | Level 3 | B302-303. Categories: SECURITY.",
      "metadata": {
        "title": "Aligning Enterprise AI Security With MITRE ATLAS Using Open Source Technologies",
        "description": "As AI becomes integral to enterprise applications, securing AI/ML systems is paramount. While MITRE ATLAS provides a robust framework for understanding adversarial threats to AI, enterprises often struggle to adopt it in cloud-native\nenvironments. This session demonstrates practical strategies for using open-source tools to operationalize AI security and align with the MITRE ATLAS framework.\nWe'll explore real-world use cases illustrating how tools like Kubeflow, Clair, Falco, StackRox, and Kubescape can be combined to detect and mitigate threats such as data poisoning, model extraction, and evasion attacks throughout the AI\nlifecyclefrom training to inference.\nAttendees will gain insights into:\nUnderstanding the MITRE ATLAS framework and its significance for AI/ML security, Mapping open-source tools to the ATLAS matrix for actionable, layered defenses, Integrating security controls into MLOps pipelines using Kubernetes-native tooling.",
        "url": "http://kccncna2025.sched.com/event/f70f64f39d7571cc868c480fa9b8f216",
        "uid": "f70f64f39d7571cc868c480fa9b8f216",
        "start": "2025-11-13T15:15:00-05:00",
        "end": "2025-11-13T15:45:00-05:00",
        "categories": [
          "SECURITY"
        ],
        "location": {
          "building": "B",
          "level": "3",
          "room": "B302-303"
        },
        "speakers": [
          {
            "name": "Doron Caspin",
            "company": " Red Hat"
          },
          {
            "name": "Valentina Rodriguez Sosa",
            "company": " Red Hat"
          }
        ]
      }
    },
    {
      "text": "Securing a k8s cluster isnt just a taskits a team sport. From writing secure code to locking down containers, networks, and runtime environments, security spans every layer of the cloud-native stack. But lets face it: it can be overwhelming.\nSo, what if learning about k8s security was as thrilling as a game show?\nJoin us for an interactive, high-energy session inspired by Who Wants to Be a Millionaire?where the audience becomes the contestant, and the grand prize is... a fully secured cluster!\n\nIn Who Wants to Secure Your Cluster?, well explore:\n Best practices across the k8s security lifecycle\n Hands-on comparisons of popular open source CNCF security tools\n Actionable recommendations from real-world experience\n\nThis session blends education, entertainment, and expertise. Whether you're a developer, DevOps engineer, or security lead, youll walk away with practical insights, and maybe even bragging rights as the one who secured it all.\nAre you ready to play? Speakers: Henrik Rexed from  Dynatrace, Simon Reisinger from  Dynatrace. Location: Building B | Level 5 | Thomas Murphy Ballroom 1. Categories: SECURITY.",
      "metadata": {
        "title": "Who Wants To Secure Clusters ?",
        "description": "Securing a k8s cluster isnt just a taskits a team sport. From writing secure code to locking down containers, networks, and runtime environments, security spans every layer of the cloud-native stack. But lets face it: it can be overwhelming.\nSo, what if learning about k8s security was as thrilling as a game show?\nJoin us for an interactive, high-energy session inspired by Who Wants to Be a Millionaire?where the audience becomes the contestant, and the grand prize is... a fully secured cluster!\n\nIn Who Wants to Secure Your Cluster?, well explore:\n Best practices across the k8s security lifecycle\n Hands-on comparisons of popular open source CNCF security tools\n Actionable recommendations from real-world experience\n\nThis session blends education, entertainment, and expertise. Whether you're a developer, DevOps engineer, or security lead, youll walk away with practical insights, and maybe even bragging rights as the one who secured it all.\nAre you ready to play?",
        "url": "http://kccncna2025.sched.com/event/afeb498d16f8b1574c665cca46a85834",
        "uid": "afeb498d16f8b1574c665cca46a85834",
        "start": "2025-11-13T15:15:00-05:00",
        "end": "2025-11-13T15:45:00-05:00",
        "categories": [
          "SECURITY"
        ],
        "location": {
          "building": "B",
          "level": "5",
          "room": "Thomas Murphy Ballroom 1"
        },
        "speakers": [
          {
            "name": "Henrik Rexed",
            "company": " Dynatrace"
          },
          {
            "name": "Simon Reisinger",
            "company": " Dynatrace"
          }
        ]
      }
    }
  ]
}